The following modules were not unloaded:
  (Use "module --force purge" to unload all):

  1) CCconfig        6)  ucx/1.14.1         11) flexiblas/3.3.1
  2) gentoo/2023     7)  libfabric/1.18.0   12) aocl-blas/5.1
  3) gcccore/.12.3   8)  pmix/4.2.4         13) aocl-lapack/5.1
  4) gcc/12.3        9)  ucc/1.2.0          14) StdEnv/2023
  5) hwloc/2.9.1     10) openmpi/4.1.5
Working in SLURM_TMPDIR: /localscratch/toulabin.15760724.0
Cloning repository...
Repository cloned.
Creating virtual environment...
Activated virtualenv.
Installing dependencies...
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/gentoo2023/x86-64-v4, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/gentoo2023/x86-64-v3, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/gentoo2023/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Requirement already satisfied: numpy>=1.20.0 in /cvmfs/soft.computecanada.ca/easybuild/software/2023/x86-64-v4/Compiler/gcccore/scipy-stack/2025a/lib/python3.11/site-packages (from -r requirements.txt (line 3)) (2.2.2+computecanada)
Collecting jax>=0.4.0 (from -r requirements.txt (line 4))
  Obtaining dependency information for jax>=0.4.0 from https://files.pythonhosted.org/packages/f9/e7/19b8cfc8963b2e10a01a4db7bb27ec5fa39ecd024bc62f8e2d1de5625a9d/jax-0.8.1-py3-none-any.whl.metadata
  Using cached jax-0.8.1-py3-none-any.whl.metadata (13 kB)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/gentoo2023/x86-64-v3/jaxlib-0.7.2+computecanada-cp311-cp311-linux_x86_64.whl (from -r requirements.txt (line 5))
Collecting gymnasium>=0.29.0 (from -r requirements.txt (line 8))
  Obtaining dependency information for gymnasium>=0.29.0 from https://files.pythonhosted.org/packages/c7/53/39cd8c2f85e213fce1f32367c4bdbd3402d3bcde7d0826a1172a0f2c5cc0/gymnasium-1.2.2-py3-none-any.whl.metadata
  Using cached gymnasium-1.2.2-py3-none-any.whl.metadata (10 kB)
Requirement already satisfied: pandas>=1.3.0 in /cvmfs/soft.computecanada.ca/easybuild/software/2023/x86-64-v4/Compiler/gcccore/scipy-stack/2025a/lib/python3.11/site-packages (from -r requirements.txt (line 11)) (2.2.3+computecanada)
Requirement already satisfied: scipy>=1.7.0 in /cvmfs/soft.computecanada.ca/easybuild/software/2023/x86-64-v4/Compiler/gcccore/scipy-stack/2025a/lib/python3.11/site-packages (from -r requirements.txt (line 14)) (1.15.1+computecanada)
Requirement already satisfied: matplotlib>=3.4.0 in /cvmfs/soft.computecanada.ca/easybuild/software/2023/x86-64-v4/Compiler/gcccore/scipy-stack/2025a/lib/python3.11/site-packages (from -r requirements.txt (line 17)) (3.10.0+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tqdm-4.67.1+computecanada-py3-none-any.whl (from -r requirements.txt (line 20))
INFO: pip is looking at multiple versions of jax to determine which version is compatible with other requirements. This could take a while.
Collecting jax>=0.4.0 (from -r requirements.txt (line 4))
  Obtaining dependency information for jax>=0.4.0 from https://files.pythonhosted.org/packages/b3/77/4e6c9a54247810eff8ac8a1af7dc1be0779b52df0d82f3fc8586061914f3/jax-0.8.0-py3-none-any.whl.metadata
  Using cached jax-0.8.0-py3-none-any.whl.metadata (13 kB)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/jax-0.7.2+computecanada-py3-none-any.whl (from -r requirements.txt (line 4))
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/gentoo2023/generic/ml_dtypes-0.5.1+computecanada-cp311-cp311-linux_x86_64.whl (from jax>=0.4.0->-r requirements.txt (line 4))
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/opt_einsum-3.4.0+computecanada-py3-none-any.whl (from jax>=0.4.0->-r requirements.txt (line 4))
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/cloudpickle-3.1.2+computecanada-py3-none-any.whl (from gymnasium>=0.29.0->-r requirements.txt (line 8))
Requirement already satisfied: typing-extensions>=4.3.0 in /cvmfs/soft.computecanada.ca/easybuild/software/2023/x86-64-v4/Compiler/gcccore/ipykernel/2025a/lib/python3.11/site-packages (from gymnasium>=0.29.0->-r requirements.txt (line 8)) (4.12.2+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/Farama_Notifications-0.0.4+computecanada-py3-none-any.whl (from gymnasium>=0.29.0->-r requirements.txt (line 8))
Requirement already satisfied: python-dateutil>=2.8.2 in /cvmfs/soft.computecanada.ca/easybuild/software/2023/x86-64-v4/Compiler/gcccore/scipy-stack/2025a/lib/python3.11/site-packages (from pandas>=1.3.0->-r requirements.txt (line 11)) (2.9.0.post0+computecanada)
Requirement already satisfied: pytz>=2020.1 in /cvmfs/soft.computecanada.ca/easybuild/software/2023/x86-64-v4/Compiler/gcccore/scipy-stack/2025a/lib/python3.11/site-packages (from pandas>=1.3.0->-r requirements.txt (line 11)) (2025.1+computecanada)
Requirement already satisfied: tzdata>=2022.7 in /cvmfs/soft.computecanada.ca/easybuild/software/2023/x86-64-v4/Compiler/gcccore/scipy-stack/2025a/lib/python3.11/site-packages (from pandas>=1.3.0->-r requirements.txt (line 11)) (2025.1+computecanada)
Requirement already satisfied: contourpy>=1.0.1 in /cvmfs/soft.computecanada.ca/easybuild/software/2023/x86-64-v4/Compiler/gcccore/scipy-stack/2025a/lib/python3.11/site-packages (from matplotlib>=3.4.0->-r requirements.txt (line 17)) (1.3.1+computecanada)
Requirement already satisfied: cycler>=0.10 in /cvmfs/soft.computecanada.ca/easybuild/software/2023/x86-64-v4/Compiler/gcccore/scipy-stack/2025a/lib/python3.11/site-packages (from matplotlib>=3.4.0->-r requirements.txt (line 17)) (0.12.1+computecanada)
Requirement already satisfied: fonttools>=4.22.0 in /cvmfs/soft.computecanada.ca/easybuild/software/2023/x86-64-v4/Compiler/gcccore/scipy-stack/2025a/lib/python3.11/site-packages (from matplotlib>=3.4.0->-r requirements.txt (line 17)) (4.55.8+computecanada)
Requirement already satisfied: kiwisolver>=1.3.1 in /cvmfs/soft.computecanada.ca/easybuild/software/2023/x86-64-v4/Compiler/gcccore/scipy-stack/2025a/lib/python3.11/site-packages (from matplotlib>=3.4.0->-r requirements.txt (line 17)) (1.4.8+computecanada)
Requirement already satisfied: packaging>=20.0 in /cvmfs/soft.computecanada.ca/easybuild/software/2023/x86-64-v4/Compiler/gcccore/scipy-stack/2025a/lib/python3.11/site-packages (from matplotlib>=3.4.0->-r requirements.txt (line 17)) (24.2+computecanada)
Requirement already satisfied: pillow>=8 in /cvmfs/soft.computecanada.ca/easybuild/software/2023/x86-64-v4/Compiler/gcccore/scipy-stack/2025a/lib/python3.11/site-packages (from matplotlib>=3.4.0->-r requirements.txt (line 17)) (11.1.0+computecanada)
Requirement already satisfied: pyparsing>=2.3.1 in /cvmfs/soft.computecanada.ca/easybuild/software/2023/x86-64-v4/Compiler/gcccore/scipy-stack/2025a/lib/python3.11/site-packages (from matplotlib>=3.4.0->-r requirements.txt (line 17)) (3.2.1+computecanada)
Requirement already satisfied: six>=1.5 in /cvmfs/soft.computecanada.ca/easybuild/software/2023/x86-64-v4/Compiler/gcccore/scipy-stack/2025a/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas>=1.3.0->-r requirements.txt (line 11)) (1.17.0+computecanada)
Using cached gymnasium-1.2.2-py3-none-any.whl (952 kB)
Installing collected packages: farama-notifications, tqdm, opt_einsum, ml_dtypes, cloudpickle, jaxlib, gymnasium, jax
Successfully installed cloudpickle-3.1.2+computecanada farama-notifications-0.0.4+computecanada gymnasium-1.2.2 jax-0.7.2+computecanada jaxlib-0.7.2+computecanada ml_dtypes-0.5.1+computecanada opt_einsum-3.4.0+computecanada tqdm-4.67.1+computecanada
Dependencies installed.
---- Starting seed index 2 ----
================================================================================
TWO ACTIVE INFERENCE AGENTS - INDIVIDUALLY COLLECTIVE PARADIGM
================================================================================

Experiment Parameters:
  Number of seeds: 1
  Episodes per seed: 100
  Episodes per config: 20
  Max steps per episode: 30
  Logging to: /localscratch/toulabin.15760724.0/project/Fn_ActiveInference/logs/two_aif_agents_individually_collective_seeds1_ep100_20251216_034908.csv

================================================================================
SEED 0 (1/1)
================================================================================

================================================================================
SEED 0 - CONFIG 1
Red at (1, 0), Blue at (1, 2)
Episodes 1-20
================================================================================

================================================================================
EPISODE 1
================================================================================
Environment: Red at (1, 0), Blue at (1, 2)

Initial state:
1 r .
. . .
. b 2


--- Step 1 ---
Agent 1 joint action: 6 → (DOWN, UP)
Agent 2 joint action: 6 → (DOWN, UP)
Executed: Agent 1: DOWN, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 0:1.00, 8:0.00, 7:0.00
    agent2_pos: 8:1.00, 0:0.00, 7:0.00
    red_button_pos: 7:0.14, 3:0.14, 6:0.14
    blue_button_pos: 7:0.14, 3:0.14, 6:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 0:1.00, 8:0.00, 7:0.00
    agent2_pos: 8:1.00, 0:0.00, 7:0.00
    red_button_pos: 7:0.14, 3:0.14, 6:0.14
    blue_button_pos: 7:0.14, 3:0.14, 6:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 244:0.02; 676:0.02; 316:0.02; 748:0.02; 677:0.01
  Agent2 top policies: 244:0.02; 676:0.02; 316:0.02; 748:0.02; 677:0.01
. r .
1 . 2
. b .

Reward: +0.00, Result: neutral

--- Step 2 ---
Agent 1 joint action: 8 → (DOWN, LEFT)
Agent 2 joint action: 8 → (DOWN, LEFT)
Executed: Agent 1: DOWN, Agent 2: LEFT
  Agent1 beliefs:
    agent1_pos: 3:1.00, 8:0.00, 5:0.00
    agent2_pos: 5:1.00, 8:0.00, 3:0.00
    red_button_pos: 7:0.20, 1:0.20, 6:0.20
    blue_button_pos: 7:0.20, 1:0.20, 6:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 3:1.00, 8:0.00, 5:0.00
    agent2_pos: 5:1.00, 8:0.00, 3:0.00
    red_button_pos: 7:0.20, 1:0.20, 6:0.20
    blue_button_pos: 7:0.20, 1:0.20, 6:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 316:0.05; 676:0.05; 244:0.05; 313:0.02; 243:0.02
  Agent2 top policies: 316:0.05; 676:0.05; 244:0.05; 313:0.02; 243:0.02
. r .
. 2 .
1 b .

Reward: +0.00, Result: neutral

--- Step 3 ---
Agent 1 joint action: 18 → (RIGHT, UP)
Agent 2 joint action: 18 → (RIGHT, UP)
Executed: Agent 1: RIGHT, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 6:1.00, 8:0.00, 5:0.00
    agent2_pos: 4:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:0.33, 1:0.33, 2:0.33
    blue_button_pos: 7:0.33, 1:0.33, 2:0.33
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 6:1.00, 8:0.00, 5:0.00
    agent2_pos: 4:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:0.33, 1:0.33, 2:0.33
    blue_button_pos: 7:0.33, 1:0.33, 2:0.33
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 676:0.28; 675:0.06; 677:0.06; 682:0.06; 658:0.06
  Agent2 top policies: 676:0.28; 675:0.06; 677:0.06; 682:0.06; 658:0.06
. 2 .
. . .
. 1 .

Reward: +0.00, Result: neutral

--- Step 4 ---
Agent 1 joint action: 10 → (DOWN, PRESS)
Agent 2 joint action: 10 → (DOWN, PRESS)
Executed: Agent 1: DOWN, Agent 2: PRESS
  Agent1 beliefs:
    agent1_pos: 7:1.00, 8:0.00, 6:0.00
    agent2_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 2:0.00, 7:0.00
    blue_button_pos: 7:1.00, 1:0.00, 2:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 7:1.00, 8:0.00, 6:0.00
    agent2_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 2:0.00, 7:0.00
    blue_button_pos: 7:1.00, 1:0.00, 2:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 386:0.08; 1253:0.08; 1250:0.08; 1251:0.08; 1252:0.08
  Agent2 top policies: 386:0.08; 1253:0.08; 1250:0.08; 1251:0.08; 1252:0.08
. 2 .
. . .
. 1 .

Reward: +0.00, Result: neutral
Button pressed: red by Agent 2

--- Step 5 ---
Agent 1 joint action: 24 → (PRESS, UP)
Agent 2 joint action: 24 → (PRESS, UP)
Executed: Agent 1: PRESS, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 7:1.00, 8:0.00, 6:0.00
    agent2_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 2:0.00, 7:0.00
    blue_button_pos: 7:1.00, 1:0.00, 2:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 7:1.00, 8:0.00, 6:0.00
    agent2_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 2:0.00, 7:0.00
    blue_button_pos: 7:1.00, 1:0.00, 2:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 1051:0.00; 1052:0.00; 1053:0.00; 1054:0.00; 1055:0.00
  Agent2 top policies: 1051:0.00; 1052:0.00; 1053:0.00; 1054:0.00; 1055:0.00
. 2 .
. . .
. 1 .

Reward: +1.00, Result: win
Button pressed: blue by Agent 1

Result: ✅ WIN - win (steps: 5, reward: +1.00)

================================================================================
EPISODE 2
================================================================================
Environment: Red at (1, 0), Blue at (1, 2)

Initial state:
1 r .
. . .
. b 2


--- Step 1 ---
Agent 1 joint action: 6 → (DOWN, UP)
Agent 2 joint action: 6 → (DOWN, UP)
Executed: Agent 1: DOWN, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 0:1.00, 8:0.00, 7:0.00
    agent2_pos: 8:1.00, 0:0.00, 7:0.00
    red_button_pos: 7:0.14, 3:0.14, 6:0.14
    blue_button_pos: 7:0.14, 3:0.14, 6:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 0:1.00, 8:0.00, 7:0.00
    agent2_pos: 8:1.00, 0:0.00, 7:0.00
    red_button_pos: 7:0.14, 3:0.14, 6:0.14
    blue_button_pos: 7:0.14, 3:0.14, 6:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 244:0.02; 676:0.02; 316:0.02; 748:0.02; 677:0.01
  Agent2 top policies: 244:0.02; 676:0.02; 316:0.02; 748:0.02; 677:0.01
. r .
1 . 2
. b .

Reward: +0.00, Result: neutral

--- Step 2 ---
Agent 1 joint action: 8 → (DOWN, LEFT)
Agent 2 joint action: 8 → (DOWN, LEFT)
Executed: Agent 1: DOWN, Agent 2: LEFT
  Agent1 beliefs:
    agent1_pos: 3:1.00, 8:0.00, 5:0.00
    agent2_pos: 5:1.00, 8:0.00, 3:0.00
    red_button_pos: 7:0.20, 1:0.20, 6:0.20
    blue_button_pos: 7:0.20, 1:0.20, 6:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 3:1.00, 8:0.00, 5:0.00
    agent2_pos: 5:1.00, 8:0.00, 3:0.00
    red_button_pos: 7:0.20, 1:0.20, 6:0.20
    blue_button_pos: 7:0.20, 1:0.20, 6:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 316:0.05; 676:0.05; 244:0.05; 313:0.02; 243:0.02
  Agent2 top policies: 316:0.05; 676:0.05; 244:0.05; 313:0.02; 243:0.02
. r .
. 2 .
1 b .

Reward: +0.00, Result: neutral

--- Step 3 ---
Agent 1 joint action: 18 → (RIGHT, UP)
Agent 2 joint action: 18 → (RIGHT, UP)
Executed: Agent 1: RIGHT, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 6:1.00, 8:0.00, 5:0.00
    agent2_pos: 4:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:0.33, 1:0.33, 2:0.33
    blue_button_pos: 7:0.33, 1:0.33, 2:0.33
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 6:1.00, 8:0.00, 5:0.00
    agent2_pos: 4:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:0.33, 1:0.33, 2:0.33
    blue_button_pos: 7:0.33, 1:0.33, 2:0.33
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 676:0.28; 675:0.06; 677:0.06; 682:0.06; 658:0.06
  Agent2 top policies: 676:0.28; 675:0.06; 677:0.06; 682:0.06; 658:0.06
. 2 .
. . .
. 1 .

Reward: +0.00, Result: neutral

--- Step 4 ---
Agent 1 joint action: 10 → (DOWN, PRESS)
Agent 2 joint action: 10 → (DOWN, PRESS)
Executed: Agent 1: DOWN, Agent 2: PRESS
  Agent1 beliefs:
    agent1_pos: 7:1.00, 8:0.00, 6:0.00
    agent2_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 2:0.00, 7:0.00
    blue_button_pos: 7:1.00, 1:0.00, 2:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 7:1.00, 8:0.00, 6:0.00
    agent2_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 2:0.00, 7:0.00
    blue_button_pos: 7:1.00, 1:0.00, 2:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 386:0.08; 1253:0.08; 1250:0.08; 1251:0.08; 1252:0.08
  Agent2 top policies: 386:0.08; 1253:0.08; 1250:0.08; 1251:0.08; 1252:0.08
. 2 .
. . .
. 1 .

Reward: +0.00, Result: neutral
Button pressed: red by Agent 2

--- Step 5 ---
Agent 1 joint action: 24 → (PRESS, UP)
Agent 2 joint action: 24 → (PRESS, UP)
Executed: Agent 1: PRESS, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 7:1.00, 8:0.00, 6:0.00
    agent2_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 2:0.00, 7:0.00
    blue_button_pos: 7:1.00, 1:0.00, 2:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 7:1.00, 8:0.00, 6:0.00
    agent2_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 2:0.00, 7:0.00
    blue_button_pos: 7:1.00, 1:0.00, 2:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 1051:0.00; 1052:0.00; 1053:0.00; 1054:0.00; 1055:0.00
  Agent2 top policies: 1051:0.00; 1052:0.00; 1053:0.00; 1054:0.00; 1055:0.00
. 2 .
. . .
. 1 .

Reward: +1.00, Result: win
Button pressed: blue by Agent 1

Result: ✅ WIN - win (steps: 5, reward: +1.00)

================================================================================
EPISODE 3
================================================================================
Environment: Red at (1, 0), Blue at (1, 2)

Initial state:
1 r .
. . .
. b 2


--- Step 1 ---
Agent 1 joint action: 6 → (DOWN, UP)
Agent 2 joint action: 6 → (DOWN, UP)
Executed: Agent 1: DOWN, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 0:1.00, 8:0.00, 7:0.00
    agent2_pos: 8:1.00, 0:0.00, 7:0.00
    red_button_pos: 7:0.14, 3:0.14, 6:0.14
    blue_button_pos: 7:0.14, 3:0.14, 6:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 0:1.00, 8:0.00, 7:0.00
    agent2_pos: 8:1.00, 0:0.00, 7:0.00
    red_button_pos: 7:0.14, 3:0.14, 6:0.14
    blue_button_pos: 7:0.14, 3:0.14, 6:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 244:0.02; 676:0.02; 316:0.02; 748:0.02; 677:0.01
  Agent2 top policies: 244:0.02; 676:0.02; 316:0.02; 748:0.02; 677:0.01
. r .
1 . 2
. b .

Reward: +0.00, Result: neutral

--- Step 2 ---
Agent 1 joint action: 8 → (DOWN, LEFT)
Agent 2 joint action: 8 → (DOWN, LEFT)
Executed: Agent 1: DOWN, Agent 2: LEFT
  Agent1 beliefs:
    agent1_pos: 3:1.00, 8:0.00, 5:0.00
    agent2_pos: 5:1.00, 8:0.00, 3:0.00
    red_button_pos: 7:0.20, 1:0.20, 6:0.20
    blue_button_pos: 7:0.20, 1:0.20, 6:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 3:1.00, 8:0.00, 5:0.00
    agent2_pos: 5:1.00, 8:0.00, 3:0.00
    red_button_pos: 7:0.20, 1:0.20, 6:0.20
    blue_button_pos: 7:0.20, 1:0.20, 6:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 316:0.05; 676:0.05; 244:0.05; 313:0.02; 243:0.02
  Agent2 top policies: 316:0.05; 676:0.05; 244:0.05; 313:0.02; 243:0.02
. r .
. 2 .
1 b .

Reward: +0.00, Result: neutral

--- Step 3 ---
Agent 1 joint action: 18 → (RIGHT, UP)
Agent 2 joint action: 18 → (RIGHT, UP)
Executed: Agent 1: RIGHT, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 6:1.00, 8:0.00, 5:0.00
    agent2_pos: 4:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:0.33, 1:0.33, 2:0.33
    blue_button_pos: 7:0.33, 1:0.33, 2:0.33
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 6:1.00, 8:0.00, 5:0.00
    agent2_pos: 4:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:0.33, 1:0.33, 2:0.33
    blue_button_pos: 7:0.33, 1:0.33, 2:0.33
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 676:0.28; 675:0.06; 677:0.06; 682:0.06; 658:0.06
  Agent2 top policies: 676:0.28; 675:0.06; 677:0.06; 682:0.06; 658:0.06
. 2 .
. . .
. 1 .

Reward: +0.00, Result: neutral

--- Step 4 ---
Agent 1 joint action: 10 → (DOWN, PRESS)
Agent 2 joint action: 10 → (DOWN, PRESS)
Executed: Agent 1: DOWN, Agent 2: PRESS
  Agent1 beliefs:
    agent1_pos: 7:1.00, 8:0.00, 6:0.00
    agent2_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 2:0.00, 7:0.00
    blue_button_pos: 7:1.00, 1:0.00, 2:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 7:1.00, 8:0.00, 6:0.00
    agent2_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 2:0.00, 7:0.00
    blue_button_pos: 7:1.00, 1:0.00, 2:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 386:0.08; 1253:0.08; 1250:0.08; 1251:0.08; 1252:0.08
  Agent2 top policies: 386:0.08; 1253:0.08; 1250:0.08; 1251:0.08; 1252:0.08
. 2 .
. . .
. 1 .

Reward: +0.00, Result: neutral
Button pressed: red by Agent 2

--- Step 5 ---
Agent 1 joint action: 24 → (PRESS, UP)
Agent 2 joint action: 24 → (PRESS, UP)
Executed: Agent 1: PRESS, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 7:1.00, 8:0.00, 6:0.00
    agent2_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 2:0.00, 7:0.00
    blue_button_pos: 7:1.00, 1:0.00, 2:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 7:1.00, 8:0.00, 6:0.00
    agent2_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 2:0.00, 7:0.00
    blue_button_pos: 7:1.00, 1:0.00, 2:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 1051:0.00; 1052:0.00; 1053:0.00; 1054:0.00; 1055:0.00
  Agent2 top policies: 1051:0.00; 1052:0.00; 1053:0.00; 1054:0.00; 1055:0.00
. 2 .
. . .
. 1 .

Reward: +1.00, Result: win
Button pressed: blue by Agent 1

Result: ✅ WIN - win (steps: 5, reward: +1.00)

================================================================================
EPISODE 4
================================================================================
Environment: Red at (1, 0), Blue at (1, 2)

Initial state:
1 r .
. . .
. b 2


--- Step 1 ---
Agent 1 joint action: 6 → (DOWN, UP)
Agent 2 joint action: 6 → (DOWN, UP)
Executed: Agent 1: DOWN, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 0:1.00, 8:0.00, 7:0.00
    agent2_pos: 8:1.00, 0:0.00, 7:0.00
    red_button_pos: 7:0.14, 3:0.14, 6:0.14
    blue_button_pos: 7:0.14, 3:0.14, 6:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 0:1.00, 8:0.00, 7:0.00
    agent2_pos: 8:1.00, 0:0.00, 7:0.00
    red_button_pos: 7:0.14, 3:0.14, 6:0.14
    blue_button_pos: 7:0.14, 3:0.14, 6:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 244:0.02; 676:0.02; 316:0.02; 748:0.02; 677:0.01
  Agent2 top policies: 244:0.02; 676:0.02; 316:0.02; 748:0.02; 677:0.01
. r .
1 . 2
. b .

Reward: +0.00, Result: neutral

--- Step 2 ---
Agent 1 joint action: 8 → (DOWN, LEFT)
Agent 2 joint action: 8 → (DOWN, LEFT)
Executed: Agent 1: DOWN, Agent 2: LEFT
  Agent1 beliefs:
    agent1_pos: 3:1.00, 8:0.00, 5:0.00
    agent2_pos: 5:1.00, 8:0.00, 3:0.00
    red_button_pos: 7:0.20, 1:0.20, 6:0.20
    blue_button_pos: 7:0.20, 1:0.20, 6:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 3:1.00, 8:0.00, 5:0.00
    agent2_pos: 5:1.00, 8:0.00, 3:0.00
    red_button_pos: 7:0.20, 1:0.20, 6:0.20
    blue_button_pos: 7:0.20, 1:0.20, 6:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 316:0.05; 676:0.05; 244:0.05; 313:0.02; 243:0.02
  Agent2 top policies: 316:0.05; 676:0.05; 244:0.05; 313:0.02; 243:0.02
. r .
. 2 .
1 b .

Reward: +0.00, Result: neutral

--- Step 3 ---
Agent 1 joint action: 18 → (RIGHT, UP)
Agent 2 joint action: 18 → (RIGHT, UP)
Executed: Agent 1: RIGHT, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 6:1.00, 8:0.00, 5:0.00
    agent2_pos: 4:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:0.33, 1:0.33, 2:0.33
    blue_button_pos: 7:0.33, 1:0.33, 2:0.33
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 6:1.00, 8:0.00, 5:0.00
    agent2_pos: 4:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:0.33, 1:0.33, 2:0.33
    blue_button_pos: 7:0.33, 1:0.33, 2:0.33
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 676:0.28; 675:0.06; 677:0.06; 682:0.06; 658:0.06
  Agent2 top policies: 676:0.28; 675:0.06; 677:0.06; 682:0.06; 658:0.06
. 2 .
. . .
. 1 .

Reward: +0.00, Result: neutral

--- Step 4 ---
Agent 1 joint action: 10 → (DOWN, PRESS)
Agent 2 joint action: 10 → (DOWN, PRESS)
Executed: Agent 1: DOWN, Agent 2: PRESS
  Agent1 beliefs:
    agent1_pos: 7:1.00, 8:0.00, 6:0.00
    agent2_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 2:0.00, 7:0.00
    blue_button_pos: 7:1.00, 1:0.00, 2:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 7:1.00, 8:0.00, 6:0.00
    agent2_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 2:0.00, 7:0.00
    blue_button_pos: 7:1.00, 1:0.00, 2:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 386:0.08; 1253:0.08; 1250:0.08; 1251:0.08; 1252:0.08
  Agent2 top policies: 386:0.08; 1253:0.08; 1250:0.08; 1251:0.08; 1252:0.08
. 2 .
. . .
. 1 .

Reward: +0.00, Result: neutral
Button pressed: red by Agent 2

--- Step 5 ---
Agent 1 joint action: 24 → (PRESS, UP)
Agent 2 joint action: 24 → (PRESS, UP)
Executed: Agent 1: PRESS, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 7:1.00, 8:0.00, 6:0.00
    agent2_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 2:0.00, 7:0.00
    blue_button_pos: 7:1.00, 1:0.00, 2:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 7:1.00, 8:0.00, 6:0.00
    agent2_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 2:0.00, 7:0.00
    blue_button_pos: 7:1.00, 1:0.00, 2:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 1051:0.00; 1052:0.00; 1053:0.00; 1054:0.00; 1055:0.00
  Agent2 top policies: 1051:0.00; 1052:0.00; 1053:0.00; 1054:0.00; 1055:0.00
. 2 .
. . .
. 1 .

Reward: +1.00, Result: win
Button pressed: blue by Agent 1

Result: ✅ WIN - win (steps: 5, reward: +1.00)

================================================================================
EPISODE 5
================================================================================
Environment: Red at (1, 0), Blue at (1, 2)

Initial state:
1 r .
. . .
. b 2


--- Step 1 ---
Agent 1 joint action: 6 → (DOWN, UP)
Agent 2 joint action: 6 → (DOWN, UP)
Executed: Agent 1: DOWN, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 0:1.00, 8:0.00, 7:0.00
    agent2_pos: 8:1.00, 0:0.00, 7:0.00
    red_button_pos: 7:0.14, 3:0.14, 6:0.14
    blue_button_pos: 7:0.14, 3:0.14, 6:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 0:1.00, 8:0.00, 7:0.00
    agent2_pos: 8:1.00, 0:0.00, 7:0.00
    red_button_pos: 7:0.14, 3:0.14, 6:0.14
    blue_button_pos: 7:0.14, 3:0.14, 6:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 244:0.02; 676:0.02; 316:0.02; 748:0.02; 677:0.01
  Agent2 top policies: 244:0.02; 676:0.02; 316:0.02; 748:0.02; 677:0.01
. r .
1 . 2
. b .

Reward: +0.00, Result: neutral

--- Step 2 ---
Agent 1 joint action: 8 → (DOWN, LEFT)
Agent 2 joint action: 8 → (DOWN, LEFT)
Executed: Agent 1: DOWN, Agent 2: LEFT
  Agent1 beliefs:
    agent1_pos: 3:1.00, 8:0.00, 5:0.00
    agent2_pos: 5:1.00, 8:0.00, 3:0.00
    red_button_pos: 7:0.20, 1:0.20, 6:0.20
    blue_button_pos: 7:0.20, 1:0.20, 6:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 3:1.00, 8:0.00, 5:0.00
    agent2_pos: 5:1.00, 8:0.00, 3:0.00
    red_button_pos: 7:0.20, 1:0.20, 6:0.20
    blue_button_pos: 7:0.20, 1:0.20, 6:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 316:0.05; 676:0.05; 244:0.05; 313:0.02; 243:0.02
  Agent2 top policies: 316:0.05; 676:0.05; 244:0.05; 313:0.02; 243:0.02
. r .
. 2 .
1 b .

Reward: +0.00, Result: neutral

--- Step 3 ---
Agent 1 joint action: 18 → (RIGHT, UP)
Agent 2 joint action: 18 → (RIGHT, UP)
Executed: Agent 1: RIGHT, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 6:1.00, 8:0.00, 5:0.00
    agent2_pos: 4:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:0.33, 1:0.33, 2:0.33
    blue_button_pos: 7:0.33, 1:0.33, 2:0.33
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 6:1.00, 8:0.00, 5:0.00
    agent2_pos: 4:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:0.33, 1:0.33, 2:0.33
    blue_button_pos: 7:0.33, 1:0.33, 2:0.33
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 676:0.28; 675:0.06; 677:0.06; 682:0.06; 658:0.06
  Agent2 top policies: 676:0.28; 675:0.06; 677:0.06; 682:0.06; 658:0.06
. 2 .
. . .
. 1 .

Reward: +0.00, Result: neutral

--- Step 4 ---
Agent 1 joint action: 10 → (DOWN, PRESS)
Agent 2 joint action: 10 → (DOWN, PRESS)
Executed: Agent 1: DOWN, Agent 2: PRESS
  Agent1 beliefs:
    agent1_pos: 7:1.00, 8:0.00, 6:0.00
    agent2_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 2:0.00, 7:0.00
    blue_button_pos: 7:1.00, 1:0.00, 2:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 7:1.00, 8:0.00, 6:0.00
    agent2_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 2:0.00, 7:0.00
    blue_button_pos: 7:1.00, 1:0.00, 2:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 386:0.08; 1253:0.08; 1250:0.08; 1251:0.08; 1252:0.08
  Agent2 top policies: 386:0.08; 1253:0.08; 1250:0.08; 1251:0.08; 1252:0.08
. 2 .
. . .
. 1 .

Reward: +0.00, Result: neutral
Button pressed: red by Agent 2

--- Step 5 ---
Agent 1 joint action: 24 → (PRESS, UP)
Agent 2 joint action: 24 → (PRESS, UP)
Executed: Agent 1: PRESS, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 7:1.00, 8:0.00, 6:0.00
    agent2_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 2:0.00, 7:0.00
    blue_button_pos: 7:1.00, 1:0.00, 2:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 7:1.00, 8:0.00, 6:0.00
    agent2_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 2:0.00, 7:0.00
    blue_button_pos: 7:1.00, 1:0.00, 2:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 1051:0.00; 1052:0.00; 1053:0.00; 1054:0.00; 1055:0.00
  Agent2 top policies: 1051:0.00; 1052:0.00; 1053:0.00; 1054:0.00; 1055:0.00
. 2 .
. . .
. 1 .

Reward: +1.00, Result: win
Button pressed: blue by Agent 1

Result: ✅ WIN - win (steps: 5, reward: +1.00)

================================================================================
EPISODE 6
================================================================================
Environment: Red at (1, 0), Blue at (1, 2)

Initial state:
1 r .
. . .
. b 2


--- Step 1 ---
Agent 1 joint action: 6 → (DOWN, UP)
Agent 2 joint action: 6 → (DOWN, UP)
Executed: Agent 1: DOWN, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 0:1.00, 8:0.00, 7:0.00
    agent2_pos: 8:1.00, 0:0.00, 7:0.00
    red_button_pos: 7:0.14, 3:0.14, 6:0.14
    blue_button_pos: 7:0.14, 3:0.14, 6:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 0:1.00, 8:0.00, 7:0.00
    agent2_pos: 8:1.00, 0:0.00, 7:0.00
    red_button_pos: 7:0.14, 3:0.14, 6:0.14
    blue_button_pos: 7:0.14, 3:0.14, 6:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 244:0.02; 676:0.02; 316:0.02; 748:0.02; 677:0.01
  Agent2 top policies: 244:0.02; 676:0.02; 316:0.02; 748:0.02; 677:0.01
. r .
1 . 2
. b .

Reward: +0.00, Result: neutral

--- Step 2 ---
Agent 1 joint action: 8 → (DOWN, LEFT)
Agent 2 joint action: 8 → (DOWN, LEFT)
Executed: Agent 1: DOWN, Agent 2: LEFT
  Agent1 beliefs:
    agent1_pos: 3:1.00, 8:0.00, 5:0.00
    agent2_pos: 5:1.00, 8:0.00, 3:0.00
    red_button_pos: 7:0.20, 1:0.20, 6:0.20
    blue_button_pos: 7:0.20, 1:0.20, 6:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 3:1.00, 8:0.00, 5:0.00
    agent2_pos: 5:1.00, 8:0.00, 3:0.00
    red_button_pos: 7:0.20, 1:0.20, 6:0.20
    blue_button_pos: 7:0.20, 1:0.20, 6:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 316:0.05; 676:0.05; 244:0.05; 313:0.02; 243:0.02
  Agent2 top policies: 316:0.05; 676:0.05; 244:0.05; 313:0.02; 243:0.02
. r .
. 2 .
1 b .

Reward: +0.00, Result: neutral

--- Step 3 ---
Agent 1 joint action: 18 → (RIGHT, UP)
Agent 2 joint action: 18 → (RIGHT, UP)
Executed: Agent 1: RIGHT, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 6:1.00, 8:0.00, 5:0.00
    agent2_pos: 4:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:0.33, 1:0.33, 2:0.33
    blue_button_pos: 7:0.33, 1:0.33, 2:0.33
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 6:1.00, 8:0.00, 5:0.00
    agent2_pos: 4:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:0.33, 1:0.33, 2:0.33
    blue_button_pos: 7:0.33, 1:0.33, 2:0.33
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 676:0.28; 675:0.06; 677:0.06; 682:0.06; 658:0.06
  Agent2 top policies: 676:0.28; 675:0.06; 677:0.06; 682:0.06; 658:0.06
. 2 .
. . .
. 1 .

Reward: +0.00, Result: neutral

--- Step 4 ---
Agent 1 joint action: 10 → (DOWN, PRESS)
Agent 2 joint action: 10 → (DOWN, PRESS)
Executed: Agent 1: DOWN, Agent 2: PRESS
  Agent1 beliefs:
    agent1_pos: 7:1.00, 8:0.00, 6:0.00
    agent2_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 2:0.00, 7:0.00
    blue_button_pos: 7:1.00, 1:0.00, 2:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 7:1.00, 8:0.00, 6:0.00
    agent2_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 2:0.00, 7:0.00
    blue_button_pos: 7:1.00, 1:0.00, 2:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 386:0.08; 1253:0.08; 1250:0.08; 1251:0.08; 1252:0.08
  Agent2 top policies: 386:0.08; 1253:0.08; 1250:0.08; 1251:0.08; 1252:0.08
. 2 .
. . .
. 1 .

Reward: +0.00, Result: neutral
Button pressed: red by Agent 2

--- Step 5 ---
Agent 1 joint action: 24 → (PRESS, UP)
Agent 2 joint action: 24 → (PRESS, UP)
Executed: Agent 1: PRESS, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 7:1.00, 8:0.00, 6:0.00
    agent2_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 2:0.00, 7:0.00
    blue_button_pos: 7:1.00, 1:0.00, 2:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 7:1.00, 8:0.00, 6:0.00
    agent2_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 2:0.00, 7:0.00
    blue_button_pos: 7:1.00, 1:0.00, 2:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 1051:0.00; 1052:0.00; 1053:0.00; 1054:0.00; 1055:0.00
  Agent2 top policies: 1051:0.00; 1052:0.00; 1053:0.00; 1054:0.00; 1055:0.00
. 2 .
. . .
. 1 .

Reward: +1.00, Result: win
Button pressed: blue by Agent 1

Result: ✅ WIN - win (steps: 5, reward: +1.00)

================================================================================
EPISODE 7
================================================================================
Environment: Red at (1, 0), Blue at (1, 2)

Initial state:
1 r .
. . .
. b 2


--- Step 1 ---
Agent 1 joint action: 6 → (DOWN, UP)
Agent 2 joint action: 6 → (DOWN, UP)
Executed: Agent 1: DOWN, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 0:1.00, 8:0.00, 7:0.00
    agent2_pos: 8:1.00, 0:0.00, 7:0.00
    red_button_pos: 7:0.14, 3:0.14, 6:0.14
    blue_button_pos: 7:0.14, 3:0.14, 6:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 0:1.00, 8:0.00, 7:0.00
    agent2_pos: 8:1.00, 0:0.00, 7:0.00
    red_button_pos: 7:0.14, 3:0.14, 6:0.14
    blue_button_pos: 7:0.14, 3:0.14, 6:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 244:0.02; 676:0.02; 316:0.02; 748:0.02; 677:0.01
  Agent2 top policies: 244:0.02; 676:0.02; 316:0.02; 748:0.02; 677:0.01
. r .
1 . 2
. b .

Reward: +0.00, Result: neutral

--- Step 2 ---
Agent 1 joint action: 8 → (DOWN, LEFT)
Agent 2 joint action: 8 → (DOWN, LEFT)
Executed: Agent 1: DOWN, Agent 2: LEFT
  Agent1 beliefs:
    agent1_pos: 3:1.00, 8:0.00, 5:0.00
    agent2_pos: 5:1.00, 8:0.00, 3:0.00
    red_button_pos: 7:0.20, 1:0.20, 6:0.20
    blue_button_pos: 7:0.20, 1:0.20, 6:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 3:1.00, 8:0.00, 5:0.00
    agent2_pos: 5:1.00, 8:0.00, 3:0.00
    red_button_pos: 7:0.20, 1:0.20, 6:0.20
    blue_button_pos: 7:0.20, 1:0.20, 6:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 316:0.05; 676:0.05; 244:0.05; 313:0.02; 243:0.02
  Agent2 top policies: 316:0.05; 676:0.05; 244:0.05; 313:0.02; 243:0.02
. r .
. 2 .
1 b .

Reward: +0.00, Result: neutral

--- Step 3 ---
Agent 1 joint action: 18 → (RIGHT, UP)
Agent 2 joint action: 18 → (RIGHT, UP)
Executed: Agent 1: RIGHT, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 6:1.00, 8:0.00, 5:0.00
    agent2_pos: 4:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:0.33, 1:0.33, 2:0.33
    blue_button_pos: 7:0.33, 1:0.33, 2:0.33
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 6:1.00, 8:0.00, 5:0.00
    agent2_pos: 4:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:0.33, 1:0.33, 2:0.33
    blue_button_pos: 7:0.33, 1:0.33, 2:0.33
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 676:0.28; 675:0.06; 677:0.06; 682:0.06; 658:0.06
  Agent2 top policies: 676:0.28; 675:0.06; 677:0.06; 682:0.06; 658:0.06
. 2 .
. . .
. 1 .

Reward: +0.00, Result: neutral

--- Step 4 ---
Agent 1 joint action: 10 → (DOWN, PRESS)
Agent 2 joint action: 10 → (DOWN, PRESS)
Executed: Agent 1: DOWN, Agent 2: PRESS
  Agent1 beliefs:
    agent1_pos: 7:1.00, 8:0.00, 6:0.00
    agent2_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 2:0.00, 7:0.00
    blue_button_pos: 7:1.00, 1:0.00, 2:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 7:1.00, 8:0.00, 6:0.00
    agent2_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 2:0.00, 7:0.00
    blue_button_pos: 7:1.00, 1:0.00, 2:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 386:0.08; 1253:0.08; 1250:0.08; 1251:0.08; 1252:0.08
  Agent2 top policies: 386:0.08; 1253:0.08; 1250:0.08; 1251:0.08; 1252:0.08
. 2 .
. . .
. 1 .

Reward: +0.00, Result: neutral
Button pressed: red by Agent 2

--- Step 5 ---
Agent 1 joint action: 24 → (PRESS, UP)
Agent 2 joint action: 24 → (PRESS, UP)
Executed: Agent 1: PRESS, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 7:1.00, 8:0.00, 6:0.00
    agent2_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 2:0.00, 7:0.00
    blue_button_pos: 7:1.00, 1:0.00, 2:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 7:1.00, 8:0.00, 6:0.00
    agent2_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 2:0.00, 7:0.00
    blue_button_pos: 7:1.00, 1:0.00, 2:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 1051:0.00; 1052:0.00; 1053:0.00; 1054:0.00; 1055:0.00
  Agent2 top policies: 1051:0.00; 1052:0.00; 1053:0.00; 1054:0.00; 1055:0.00
. 2 .
. . .
. 1 .

Reward: +1.00, Result: win
Button pressed: blue by Agent 1

Result: ✅ WIN - win (steps: 5, reward: +1.00)

================================================================================
EPISODE 8
================================================================================
Environment: Red at (1, 0), Blue at (1, 2)

Initial state:
1 r .
. . .
. b 2


--- Step 1 ---
Agent 1 joint action: 6 → (DOWN, UP)
Agent 2 joint action: 6 → (DOWN, UP)
Executed: Agent 1: DOWN, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 0:1.00, 8:0.00, 7:0.00
    agent2_pos: 8:1.00, 0:0.00, 7:0.00
    red_button_pos: 7:0.14, 3:0.14, 6:0.14
    blue_button_pos: 7:0.14, 3:0.14, 6:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 0:1.00, 8:0.00, 7:0.00
    agent2_pos: 8:1.00, 0:0.00, 7:0.00
    red_button_pos: 7:0.14, 3:0.14, 6:0.14
    blue_button_pos: 7:0.14, 3:0.14, 6:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 244:0.02; 676:0.02; 316:0.02; 748:0.02; 677:0.01
  Agent2 top policies: 244:0.02; 676:0.02; 316:0.02; 748:0.02; 677:0.01
. r .
1 . 2
. b .

Reward: +0.00, Result: neutral

--- Step 2 ---
Agent 1 joint action: 8 → (DOWN, LEFT)
Agent 2 joint action: 8 → (DOWN, LEFT)
Executed: Agent 1: DOWN, Agent 2: LEFT
  Agent1 beliefs:
    agent1_pos: 3:1.00, 8:0.00, 5:0.00
    agent2_pos: 5:1.00, 8:0.00, 3:0.00
    red_button_pos: 7:0.20, 1:0.20, 6:0.20
    blue_button_pos: 7:0.20, 1:0.20, 6:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 3:1.00, 8:0.00, 5:0.00
    agent2_pos: 5:1.00, 8:0.00, 3:0.00
    red_button_pos: 7:0.20, 1:0.20, 6:0.20
    blue_button_pos: 7:0.20, 1:0.20, 6:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 316:0.05; 676:0.05; 244:0.05; 313:0.02; 243:0.02
  Agent2 top policies: 316:0.05; 676:0.05; 244:0.05; 313:0.02; 243:0.02
. r .
. 2 .
1 b .

Reward: +0.00, Result: neutral

--- Step 3 ---
Agent 1 joint action: 18 → (RIGHT, UP)
Agent 2 joint action: 18 → (RIGHT, UP)
Executed: Agent 1: RIGHT, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 6:1.00, 8:0.00, 5:0.00
    agent2_pos: 4:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:0.33, 1:0.33, 2:0.33
    blue_button_pos: 7:0.33, 1:0.33, 2:0.33
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 6:1.00, 8:0.00, 5:0.00
    agent2_pos: 4:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:0.33, 1:0.33, 2:0.33
    blue_button_pos: 7:0.33, 1:0.33, 2:0.33
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 676:0.28; 675:0.06; 677:0.06; 682:0.06; 658:0.06
  Agent2 top policies: 676:0.28; 675:0.06; 677:0.06; 682:0.06; 658:0.06
. 2 .
. . .
. 1 .

Reward: +0.00, Result: neutral

--- Step 4 ---
Agent 1 joint action: 10 → (DOWN, PRESS)
Agent 2 joint action: 10 → (DOWN, PRESS)
Executed: Agent 1: DOWN, Agent 2: PRESS
  Agent1 beliefs:
    agent1_pos: 7:1.00, 8:0.00, 6:0.00
    agent2_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 2:0.00, 7:0.00
    blue_button_pos: 7:1.00, 1:0.00, 2:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 7:1.00, 8:0.00, 6:0.00
    agent2_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 2:0.00, 7:0.00
    blue_button_pos: 7:1.00, 1:0.00, 2:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 386:0.08; 1253:0.08; 1250:0.08; 1251:0.08; 1252:0.08
  Agent2 top policies: 386:0.08; 1253:0.08; 1250:0.08; 1251:0.08; 1252:0.08
. 2 .
. . .
. 1 .

Reward: +0.00, Result: neutral
Button pressed: red by Agent 2

--- Step 5 ---
Agent 1 joint action: 24 → (PRESS, UP)
Agent 2 joint action: 24 → (PRESS, UP)
Executed: Agent 1: PRESS, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 7:1.00, 8:0.00, 6:0.00
    agent2_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 2:0.00, 7:0.00
    blue_button_pos: 7:1.00, 1:0.00, 2:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 7:1.00, 8:0.00, 6:0.00
    agent2_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 2:0.00, 7:0.00
    blue_button_pos: 7:1.00, 1:0.00, 2:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 1051:0.00; 1052:0.00; 1053:0.00; 1054:0.00; 1055:0.00
  Agent2 top policies: 1051:0.00; 1052:0.00; 1053:0.00; 1054:0.00; 1055:0.00
. 2 .
. . .
. 1 .

Reward: +1.00, Result: win
Button pressed: blue by Agent 1

Result: ✅ WIN - win (steps: 5, reward: +1.00)

================================================================================
EPISODE 9
================================================================================
Environment: Red at (1, 0), Blue at (1, 2)

Initial state:
1 r .
. . .
. b 2


--- Step 1 ---
Agent 1 joint action: 6 → (DOWN, UP)
Agent 2 joint action: 6 → (DOWN, UP)
Executed: Agent 1: DOWN, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 0:1.00, 8:0.00, 7:0.00
    agent2_pos: 8:1.00, 0:0.00, 7:0.00
    red_button_pos: 7:0.14, 3:0.14, 6:0.14
    blue_button_pos: 7:0.14, 3:0.14, 6:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 0:1.00, 8:0.00, 7:0.00
    agent2_pos: 8:1.00, 0:0.00, 7:0.00
    red_button_pos: 7:0.14, 3:0.14, 6:0.14
    blue_button_pos: 7:0.14, 3:0.14, 6:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 244:0.02; 676:0.02; 316:0.02; 748:0.02; 677:0.01
  Agent2 top policies: 244:0.02; 676:0.02; 316:0.02; 748:0.02; 677:0.01
. r .
1 . 2
. b .

Reward: +0.00, Result: neutral

--- Step 2 ---
Agent 1 joint action: 8 → (DOWN, LEFT)
Agent 2 joint action: 8 → (DOWN, LEFT)
Executed: Agent 1: DOWN, Agent 2: LEFT
  Agent1 beliefs:
    agent1_pos: 3:1.00, 8:0.00, 5:0.00
    agent2_pos: 5:1.00, 8:0.00, 3:0.00
    red_button_pos: 7:0.20, 1:0.20, 6:0.20
    blue_button_pos: 7:0.20, 1:0.20, 6:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 3:1.00, 8:0.00, 5:0.00
    agent2_pos: 5:1.00, 8:0.00, 3:0.00
    red_button_pos: 7:0.20, 1:0.20, 6:0.20
    blue_button_pos: 7:0.20, 1:0.20, 6:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 316:0.05; 676:0.05; 244:0.05; 313:0.02; 243:0.02
  Agent2 top policies: 316:0.05; 676:0.05; 244:0.05; 313:0.02; 243:0.02
. r .
. 2 .
1 b .

Reward: +0.00, Result: neutral

--- Step 3 ---
Agent 1 joint action: 18 → (RIGHT, UP)
Agent 2 joint action: 18 → (RIGHT, UP)
Executed: Agent 1: RIGHT, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 6:1.00, 8:0.00, 5:0.00
    agent2_pos: 4:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:0.33, 1:0.33, 2:0.33
    blue_button_pos: 7:0.33, 1:0.33, 2:0.33
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 6:1.00, 8:0.00, 5:0.00
    agent2_pos: 4:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:0.33, 1:0.33, 2:0.33
    blue_button_pos: 7:0.33, 1:0.33, 2:0.33
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 676:0.28; 675:0.06; 677:0.06; 682:0.06; 658:0.06
  Agent2 top policies: 676:0.28; 675:0.06; 677:0.06; 682:0.06; 658:0.06
. 2 .
. . .
. 1 .

Reward: +0.00, Result: neutral

--- Step 4 ---
Agent 1 joint action: 10 → (DOWN, PRESS)
Agent 2 joint action: 10 → (DOWN, PRESS)
Executed: Agent 1: DOWN, Agent 2: PRESS
  Agent1 beliefs:
    agent1_pos: 7:1.00, 8:0.00, 6:0.00
    agent2_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 2:0.00, 7:0.00
    blue_button_pos: 7:1.00, 1:0.00, 2:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 7:1.00, 8:0.00, 6:0.00
    agent2_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 2:0.00, 7:0.00
    blue_button_pos: 7:1.00, 1:0.00, 2:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 386:0.08; 1253:0.08; 1250:0.08; 1251:0.08; 1252:0.08
  Agent2 top policies: 386:0.08; 1253:0.08; 1250:0.08; 1251:0.08; 1252:0.08
. 2 .
. . .
. 1 .

Reward: +0.00, Result: neutral
Button pressed: red by Agent 2

--- Step 5 ---
Agent 1 joint action: 24 → (PRESS, UP)
Agent 2 joint action: 24 → (PRESS, UP)
Executed: Agent 1: PRESS, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 7:1.00, 8:0.00, 6:0.00
    agent2_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 2:0.00, 7:0.00
    blue_button_pos: 7:1.00, 1:0.00, 2:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 7:1.00, 8:0.00, 6:0.00
    agent2_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 2:0.00, 7:0.00
    blue_button_pos: 7:1.00, 1:0.00, 2:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 1051:0.00; 1052:0.00; 1053:0.00; 1054:0.00; 1055:0.00
  Agent2 top policies: 1051:0.00; 1052:0.00; 1053:0.00; 1054:0.00; 1055:0.00
. 2 .
. . .
. 1 .

Reward: +1.00, Result: win
Button pressed: blue by Agent 1

Result: ✅ WIN - win (steps: 5, reward: +1.00)

================================================================================
EPISODE 10
================================================================================
Environment: Red at (1, 0), Blue at (1, 2)

Initial state:
1 r .
. . .
. b 2


--- Step 1 ---
Agent 1 joint action: 6 → (DOWN, UP)
Agent 2 joint action: 6 → (DOWN, UP)
Executed: Agent 1: DOWN, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 0:1.00, 8:0.00, 7:0.00
    agent2_pos: 8:1.00, 0:0.00, 7:0.00
    red_button_pos: 7:0.14, 3:0.14, 6:0.14
    blue_button_pos: 7:0.14, 3:0.14, 6:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 0:1.00, 8:0.00, 7:0.00
    agent2_pos: 8:1.00, 0:0.00, 7:0.00
    red_button_pos: 7:0.14, 3:0.14, 6:0.14
    blue_button_pos: 7:0.14, 3:0.14, 6:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 244:0.02; 676:0.02; 316:0.02; 748:0.02; 677:0.01
  Agent2 top policies: 244:0.02; 676:0.02; 316:0.02; 748:0.02; 677:0.01
. r .
1 . 2
. b .

Reward: +0.00, Result: neutral

--- Step 2 ---
Agent 1 joint action: 8 → (DOWN, LEFT)
Agent 2 joint action: 8 → (DOWN, LEFT)
Executed: Agent 1: DOWN, Agent 2: LEFT
  Agent1 beliefs:
    agent1_pos: 3:1.00, 8:0.00, 5:0.00
    agent2_pos: 5:1.00, 8:0.00, 3:0.00
    red_button_pos: 7:0.20, 1:0.20, 6:0.20
    blue_button_pos: 7:0.20, 1:0.20, 6:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 3:1.00, 8:0.00, 5:0.00
    agent2_pos: 5:1.00, 8:0.00, 3:0.00
    red_button_pos: 7:0.20, 1:0.20, 6:0.20
    blue_button_pos: 7:0.20, 1:0.20, 6:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 316:0.05; 676:0.05; 244:0.05; 313:0.02; 243:0.02
  Agent2 top policies: 316:0.05; 676:0.05; 244:0.05; 313:0.02; 243:0.02
. r .
. 2 .
1 b .

Reward: +0.00, Result: neutral

--- Step 3 ---
Agent 1 joint action: 18 → (RIGHT, UP)
Agent 2 joint action: 18 → (RIGHT, UP)
Executed: Agent 1: RIGHT, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 6:1.00, 8:0.00, 5:0.00
    agent2_pos: 4:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:0.33, 1:0.33, 2:0.33
    blue_button_pos: 7:0.33, 1:0.33, 2:0.33
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 6:1.00, 8:0.00, 5:0.00
    agent2_pos: 4:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:0.33, 1:0.33, 2:0.33
    blue_button_pos: 7:0.33, 1:0.33, 2:0.33
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 676:0.28; 675:0.06; 677:0.06; 682:0.06; 658:0.06
  Agent2 top policies: 676:0.28; 675:0.06; 677:0.06; 682:0.06; 658:0.06
. 2 .
. . .
. 1 .

Reward: +0.00, Result: neutral

--- Step 4 ---
Agent 1 joint action: 10 → (DOWN, PRESS)
Agent 2 joint action: 10 → (DOWN, PRESS)
Executed: Agent 1: DOWN, Agent 2: PRESS
  Agent1 beliefs:
    agent1_pos: 7:1.00, 8:0.00, 6:0.00
    agent2_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 2:0.00, 7:0.00
    blue_button_pos: 7:1.00, 1:0.00, 2:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 7:1.00, 8:0.00, 6:0.00
    agent2_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 2:0.00, 7:0.00
    blue_button_pos: 7:1.00, 1:0.00, 2:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 386:0.08; 1253:0.08; 1250:0.08; 1251:0.08; 1252:0.08
  Agent2 top policies: 386:0.08; 1253:0.08; 1250:0.08; 1251:0.08; 1252:0.08
. 2 .
. . .
. 1 .

Reward: +0.00, Result: neutral
Button pressed: red by Agent 2

--- Step 5 ---
Agent 1 joint action: 24 → (PRESS, UP)
Agent 2 joint action: 24 → (PRESS, UP)
Executed: Agent 1: PRESS, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 7:1.00, 8:0.00, 6:0.00
    agent2_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 2:0.00, 7:0.00
    blue_button_pos: 7:1.00, 1:0.00, 2:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 7:1.00, 8:0.00, 6:0.00
    agent2_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 2:0.00, 7:0.00
    blue_button_pos: 7:1.00, 1:0.00, 2:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 1051:0.00; 1052:0.00; 1053:0.00; 1054:0.00; 1055:0.00
  Agent2 top policies: 1051:0.00; 1052:0.00; 1053:0.00; 1054:0.00; 1055:0.00
. 2 .
. . .
. 1 .

Reward: +1.00, Result: win
Button pressed: blue by Agent 1

Result: ✅ WIN - win (steps: 5, reward: +1.00)

================================================================================
EPISODE 11
================================================================================
Environment: Red at (1, 0), Blue at (1, 2)

Initial state:
1 r .
. . .
. b 2


--- Step 1 ---
Agent 1 joint action: 6 → (DOWN, UP)
Agent 2 joint action: 6 → (DOWN, UP)
Executed: Agent 1: DOWN, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 0:1.00, 8:0.00, 7:0.00
    agent2_pos: 8:1.00, 0:0.00, 7:0.00
    red_button_pos: 7:0.14, 3:0.14, 6:0.14
    blue_button_pos: 7:0.14, 3:0.14, 6:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 0:1.00, 8:0.00, 7:0.00
    agent2_pos: 8:1.00, 0:0.00, 7:0.00
    red_button_pos: 7:0.14, 3:0.14, 6:0.14
    blue_button_pos: 7:0.14, 3:0.14, 6:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 244:0.02; 676:0.02; 316:0.02; 748:0.02; 677:0.01
  Agent2 top policies: 244:0.02; 676:0.02; 316:0.02; 748:0.02; 677:0.01
. r .
1 . 2
. b .

Reward: +0.00, Result: neutral

--- Step 2 ---
Agent 1 joint action: 8 → (DOWN, LEFT)
Agent 2 joint action: 8 → (DOWN, LEFT)
Executed: Agent 1: DOWN, Agent 2: LEFT
  Agent1 beliefs:
    agent1_pos: 3:1.00, 8:0.00, 5:0.00
    agent2_pos: 5:1.00, 8:0.00, 3:0.00
    red_button_pos: 7:0.20, 1:0.20, 6:0.20
    blue_button_pos: 7:0.20, 1:0.20, 6:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 3:1.00, 8:0.00, 5:0.00
    agent2_pos: 5:1.00, 8:0.00, 3:0.00
    red_button_pos: 7:0.20, 1:0.20, 6:0.20
    blue_button_pos: 7:0.20, 1:0.20, 6:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 316:0.05; 676:0.05; 244:0.05; 313:0.02; 243:0.02
  Agent2 top policies: 316:0.05; 676:0.05; 244:0.05; 313:0.02; 243:0.02
. r .
. 2 .
1 b .

Reward: +0.00, Result: neutral

--- Step 3 ---
Agent 1 joint action: 18 → (RIGHT, UP)
Agent 2 joint action: 18 → (RIGHT, UP)
Executed: Agent 1: RIGHT, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 6:1.00, 8:0.00, 5:0.00
    agent2_pos: 4:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:0.33, 1:0.33, 2:0.33
    blue_button_pos: 7:0.33, 1:0.33, 2:0.33
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 6:1.00, 8:0.00, 5:0.00
    agent2_pos: 4:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:0.33, 1:0.33, 2:0.33
    blue_button_pos: 7:0.33, 1:0.33, 2:0.33
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 676:0.28; 675:0.06; 677:0.06; 682:0.06; 658:0.06
  Agent2 top policies: 676:0.28; 675:0.06; 677:0.06; 682:0.06; 658:0.06
. 2 .
. . .
. 1 .

Reward: +0.00, Result: neutral

--- Step 4 ---
Agent 1 joint action: 10 → (DOWN, PRESS)
Agent 2 joint action: 10 → (DOWN, PRESS)
Executed: Agent 1: DOWN, Agent 2: PRESS
  Agent1 beliefs:
    agent1_pos: 7:1.00, 8:0.00, 6:0.00
    agent2_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 2:0.00, 7:0.00
    blue_button_pos: 7:1.00, 1:0.00, 2:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 7:1.00, 8:0.00, 6:0.00
    agent2_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 2:0.00, 7:0.00
    blue_button_pos: 7:1.00, 1:0.00, 2:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 386:0.08; 1253:0.08; 1250:0.08; 1251:0.08; 1252:0.08
  Agent2 top policies: 386:0.08; 1253:0.08; 1250:0.08; 1251:0.08; 1252:0.08
. 2 .
. . .
. 1 .

Reward: +0.00, Result: neutral
Button pressed: red by Agent 2

--- Step 5 ---
Agent 1 joint action: 24 → (PRESS, UP)
Agent 2 joint action: 24 → (PRESS, UP)
Executed: Agent 1: PRESS, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 7:1.00, 8:0.00, 6:0.00
    agent2_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 2:0.00, 7:0.00
    blue_button_pos: 7:1.00, 1:0.00, 2:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 7:1.00, 8:0.00, 6:0.00
    agent2_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 2:0.00, 7:0.00
    blue_button_pos: 7:1.00, 1:0.00, 2:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 1051:0.00; 1052:0.00; 1053:0.00; 1054:0.00; 1055:0.00
  Agent2 top policies: 1051:0.00; 1052:0.00; 1053:0.00; 1054:0.00; 1055:0.00
. 2 .
. . .
. 1 .

Reward: +1.00, Result: win
Button pressed: blue by Agent 1

Result: ✅ WIN - win (steps: 5, reward: +1.00)

================================================================================
EPISODE 12
================================================================================
Environment: Red at (1, 0), Blue at (1, 2)

Initial state:
1 r .
. . .
. b 2


--- Step 1 ---
Agent 1 joint action: 6 → (DOWN, UP)
Agent 2 joint action: 6 → (DOWN, UP)
Executed: Agent 1: DOWN, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 0:1.00, 8:0.00, 7:0.00
    agent2_pos: 8:1.00, 0:0.00, 7:0.00
    red_button_pos: 7:0.14, 3:0.14, 6:0.14
    blue_button_pos: 7:0.14, 3:0.14, 6:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 0:1.00, 8:0.00, 7:0.00
    agent2_pos: 8:1.00, 0:0.00, 7:0.00
    red_button_pos: 7:0.14, 3:0.14, 6:0.14
    blue_button_pos: 7:0.14, 3:0.14, 6:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 244:0.02; 676:0.02; 316:0.02; 748:0.02; 677:0.01
  Agent2 top policies: 244:0.02; 676:0.02; 316:0.02; 748:0.02; 677:0.01
. r .
1 . 2
. b .

Reward: +0.00, Result: neutral

--- Step 2 ---
Agent 1 joint action: 8 → (DOWN, LEFT)
Agent 2 joint action: 8 → (DOWN, LEFT)
Executed: Agent 1: DOWN, Agent 2: LEFT
  Agent1 beliefs:
    agent1_pos: 3:1.00, 8:0.00, 5:0.00
    agent2_pos: 5:1.00, 8:0.00, 3:0.00
    red_button_pos: 7:0.20, 1:0.20, 6:0.20
    blue_button_pos: 7:0.20, 1:0.20, 6:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 3:1.00, 8:0.00, 5:0.00
    agent2_pos: 5:1.00, 8:0.00, 3:0.00
    red_button_pos: 7:0.20, 1:0.20, 6:0.20
    blue_button_pos: 7:0.20, 1:0.20, 6:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 316:0.05; 676:0.05; 244:0.05; 313:0.02; 243:0.02
  Agent2 top policies: 316:0.05; 676:0.05; 244:0.05; 313:0.02; 243:0.02
. r .
. 2 .
1 b .

Reward: +0.00, Result: neutral

--- Step 3 ---
Agent 1 joint action: 18 → (RIGHT, UP)
Agent 2 joint action: 18 → (RIGHT, UP)
Executed: Agent 1: RIGHT, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 6:1.00, 8:0.00, 5:0.00
    agent2_pos: 4:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:0.33, 1:0.33, 2:0.33
    blue_button_pos: 7:0.33, 1:0.33, 2:0.33
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 6:1.00, 8:0.00, 5:0.00
    agent2_pos: 4:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:0.33, 1:0.33, 2:0.33
    blue_button_pos: 7:0.33, 1:0.33, 2:0.33
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 676:0.28; 675:0.06; 677:0.06; 682:0.06; 658:0.06
  Agent2 top policies: 676:0.28; 675:0.06; 677:0.06; 682:0.06; 658:0.06
. 2 .
. . .
. 1 .

Reward: +0.00, Result: neutral

--- Step 4 ---
Agent 1 joint action: 10 → (DOWN, PRESS)
Agent 2 joint action: 10 → (DOWN, PRESS)
Executed: Agent 1: DOWN, Agent 2: PRESS
  Agent1 beliefs:
    agent1_pos: 7:1.00, 8:0.00, 6:0.00
    agent2_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 2:0.00, 7:0.00
    blue_button_pos: 7:1.00, 1:0.00, 2:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 7:1.00, 8:0.00, 6:0.00
    agent2_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 2:0.00, 7:0.00
    blue_button_pos: 7:1.00, 1:0.00, 2:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 386:0.08; 1253:0.08; 1250:0.08; 1251:0.08; 1252:0.08
  Agent2 top policies: 386:0.08; 1253:0.08; 1250:0.08; 1251:0.08; 1252:0.08
. 2 .
. . .
. 1 .

Reward: +0.00, Result: neutral
Button pressed: red by Agent 2

--- Step 5 ---
Agent 1 joint action: 24 → (PRESS, UP)
Agent 2 joint action: 24 → (PRESS, UP)
Executed: Agent 1: PRESS, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 7:1.00, 8:0.00, 6:0.00
    agent2_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 2:0.00, 7:0.00
    blue_button_pos: 7:1.00, 1:0.00, 2:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 7:1.00, 8:0.00, 6:0.00
    agent2_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 2:0.00, 7:0.00
    blue_button_pos: 7:1.00, 1:0.00, 2:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 1051:0.00; 1052:0.00; 1053:0.00; 1054:0.00; 1055:0.00
  Agent2 top policies: 1051:0.00; 1052:0.00; 1053:0.00; 1054:0.00; 1055:0.00
. 2 .
. . .
. 1 .

Reward: +1.00, Result: win
Button pressed: blue by Agent 1

Result: ✅ WIN - win (steps: 5, reward: +1.00)

================================================================================
EPISODE 13
================================================================================
Environment: Red at (1, 0), Blue at (1, 2)

Initial state:
1 r .
. . .
. b 2


--- Step 1 ---
Agent 1 joint action: 6 → (DOWN, UP)
Agent 2 joint action: 6 → (DOWN, UP)
Executed: Agent 1: DOWN, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 0:1.00, 8:0.00, 7:0.00
    agent2_pos: 8:1.00, 0:0.00, 7:0.00
    red_button_pos: 7:0.14, 3:0.14, 6:0.14
    blue_button_pos: 7:0.14, 3:0.14, 6:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 0:1.00, 8:0.00, 7:0.00
    agent2_pos: 8:1.00, 0:0.00, 7:0.00
    red_button_pos: 7:0.14, 3:0.14, 6:0.14
    blue_button_pos: 7:0.14, 3:0.14, 6:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 244:0.02; 676:0.02; 316:0.02; 748:0.02; 677:0.01
  Agent2 top policies: 244:0.02; 676:0.02; 316:0.02; 748:0.02; 677:0.01
. r .
1 . 2
. b .

Reward: +0.00, Result: neutral

--- Step 2 ---
Agent 1 joint action: 8 → (DOWN, LEFT)
Agent 2 joint action: 8 → (DOWN, LEFT)
Executed: Agent 1: DOWN, Agent 2: LEFT
  Agent1 beliefs:
    agent1_pos: 3:1.00, 8:0.00, 5:0.00
    agent2_pos: 5:1.00, 8:0.00, 3:0.00
    red_button_pos: 7:0.20, 1:0.20, 6:0.20
    blue_button_pos: 7:0.20, 1:0.20, 6:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 3:1.00, 8:0.00, 5:0.00
    agent2_pos: 5:1.00, 8:0.00, 3:0.00
    red_button_pos: 7:0.20, 1:0.20, 6:0.20
    blue_button_pos: 7:0.20, 1:0.20, 6:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 316:0.05; 676:0.05; 244:0.05; 313:0.02; 243:0.02
  Agent2 top policies: 316:0.05; 676:0.05; 244:0.05; 313:0.02; 243:0.02
. r .
. 2 .
1 b .

Reward: +0.00, Result: neutral

--- Step 3 ---
Agent 1 joint action: 18 → (RIGHT, UP)
Agent 2 joint action: 18 → (RIGHT, UP)
Executed: Agent 1: RIGHT, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 6:1.00, 8:0.00, 5:0.00
    agent2_pos: 4:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:0.33, 1:0.33, 2:0.33
    blue_button_pos: 7:0.33, 1:0.33, 2:0.33
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 6:1.00, 8:0.00, 5:0.00
    agent2_pos: 4:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:0.33, 1:0.33, 2:0.33
    blue_button_pos: 7:0.33, 1:0.33, 2:0.33
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 676:0.28; 675:0.06; 677:0.06; 682:0.06; 658:0.06
  Agent2 top policies: 676:0.28; 675:0.06; 677:0.06; 682:0.06; 658:0.06
. 2 .
. . .
. 1 .

Reward: +0.00, Result: neutral

--- Step 4 ---
Agent 1 joint action: 10 → (DOWN, PRESS)
Agent 2 joint action: 10 → (DOWN, PRESS)
Executed: Agent 1: DOWN, Agent 2: PRESS
  Agent1 beliefs:
    agent1_pos: 7:1.00, 8:0.00, 6:0.00
    agent2_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 2:0.00, 7:0.00
    blue_button_pos: 7:1.00, 1:0.00, 2:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 7:1.00, 8:0.00, 6:0.00
    agent2_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 2:0.00, 7:0.00
    blue_button_pos: 7:1.00, 1:0.00, 2:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 386:0.08; 1253:0.08; 1250:0.08; 1251:0.08; 1252:0.08
  Agent2 top policies: 386:0.08; 1253:0.08; 1250:0.08; 1251:0.08; 1252:0.08
. 2 .
. . .
. 1 .

Reward: +0.00, Result: neutral
Button pressed: red by Agent 2

--- Step 5 ---
Agent 1 joint action: 24 → (PRESS, UP)
Agent 2 joint action: 24 → (PRESS, UP)
Executed: Agent 1: PRESS, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 7:1.00, 8:0.00, 6:0.00
    agent2_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 2:0.00, 7:0.00
    blue_button_pos: 7:1.00, 1:0.00, 2:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 7:1.00, 8:0.00, 6:0.00
    agent2_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 2:0.00, 7:0.00
    blue_button_pos: 7:1.00, 1:0.00, 2:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 1051:0.00; 1052:0.00; 1053:0.00; 1054:0.00; 1055:0.00
  Agent2 top policies: 1051:0.00; 1052:0.00; 1053:0.00; 1054:0.00; 1055:0.00
. 2 .
. . .
. 1 .

Reward: +1.00, Result: win
Button pressed: blue by Agent 1

Result: ✅ WIN - win (steps: 5, reward: +1.00)

================================================================================
EPISODE 14
================================================================================
Environment: Red at (1, 0), Blue at (1, 2)

Initial state:
1 r .
. . .
. b 2


--- Step 1 ---
Agent 1 joint action: 6 → (DOWN, UP)
Agent 2 joint action: 6 → (DOWN, UP)
Executed: Agent 1: DOWN, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 0:1.00, 8:0.00, 7:0.00
    agent2_pos: 8:1.00, 0:0.00, 7:0.00
    red_button_pos: 7:0.14, 3:0.14, 6:0.14
    blue_button_pos: 7:0.14, 3:0.14, 6:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 0:1.00, 8:0.00, 7:0.00
    agent2_pos: 8:1.00, 0:0.00, 7:0.00
    red_button_pos: 7:0.14, 3:0.14, 6:0.14
    blue_button_pos: 7:0.14, 3:0.14, 6:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 244:0.02; 676:0.02; 316:0.02; 748:0.02; 677:0.01
  Agent2 top policies: 244:0.02; 676:0.02; 316:0.02; 748:0.02; 677:0.01
. r .
1 . 2
. b .

Reward: +0.00, Result: neutral

--- Step 2 ---
Agent 1 joint action: 8 → (DOWN, LEFT)
Agent 2 joint action: 8 → (DOWN, LEFT)
Executed: Agent 1: DOWN, Agent 2: LEFT
  Agent1 beliefs:
    agent1_pos: 3:1.00, 8:0.00, 5:0.00
    agent2_pos: 5:1.00, 8:0.00, 3:0.00
    red_button_pos: 7:0.20, 1:0.20, 6:0.20
    blue_button_pos: 7:0.20, 1:0.20, 6:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 3:1.00, 8:0.00, 5:0.00
    agent2_pos: 5:1.00, 8:0.00, 3:0.00
    red_button_pos: 7:0.20, 1:0.20, 6:0.20
    blue_button_pos: 7:0.20, 1:0.20, 6:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 316:0.05; 676:0.05; 244:0.05; 313:0.02; 243:0.02
  Agent2 top policies: 316:0.05; 676:0.05; 244:0.05; 313:0.02; 243:0.02
. r .
. 2 .
1 b .

Reward: +0.00, Result: neutral

--- Step 3 ---
Agent 1 joint action: 18 → (RIGHT, UP)
Agent 2 joint action: 18 → (RIGHT, UP)
Executed: Agent 1: RIGHT, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 6:1.00, 8:0.00, 5:0.00
    agent2_pos: 4:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:0.33, 1:0.33, 2:0.33
    blue_button_pos: 7:0.33, 1:0.33, 2:0.33
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 6:1.00, 8:0.00, 5:0.00
    agent2_pos: 4:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:0.33, 1:0.33, 2:0.33
    blue_button_pos: 7:0.33, 1:0.33, 2:0.33
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 676:0.28; 675:0.06; 677:0.06; 682:0.06; 658:0.06
  Agent2 top policies: 676:0.28; 675:0.06; 677:0.06; 682:0.06; 658:0.06
. 2 .
. . .
. 1 .

Reward: +0.00, Result: neutral

--- Step 4 ---
Agent 1 joint action: 10 → (DOWN, PRESS)
Agent 2 joint action: 10 → (DOWN, PRESS)
Executed: Agent 1: DOWN, Agent 2: PRESS
  Agent1 beliefs:
    agent1_pos: 7:1.00, 8:0.00, 6:0.00
    agent2_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 2:0.00, 7:0.00
    blue_button_pos: 7:1.00, 1:0.00, 2:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 7:1.00, 8:0.00, 6:0.00
    agent2_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 2:0.00, 7:0.00
    blue_button_pos: 7:1.00, 1:0.00, 2:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 386:0.08; 1253:0.08; 1250:0.08; 1251:0.08; 1252:0.08
  Agent2 top policies: 386:0.08; 1253:0.08; 1250:0.08; 1251:0.08; 1252:0.08
. 2 .
. . .
. 1 .

Reward: +0.00, Result: neutral
Button pressed: red by Agent 2

--- Step 5 ---
Agent 1 joint action: 24 → (PRESS, UP)
Agent 2 joint action: 24 → (PRESS, UP)
Executed: Agent 1: PRESS, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 7:1.00, 8:0.00, 6:0.00
    agent2_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 2:0.00, 7:0.00
    blue_button_pos: 7:1.00, 1:0.00, 2:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 7:1.00, 8:0.00, 6:0.00
    agent2_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 2:0.00, 7:0.00
    blue_button_pos: 7:1.00, 1:0.00, 2:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 1051:0.00; 1052:0.00; 1053:0.00; 1054:0.00; 1055:0.00
  Agent2 top policies: 1051:0.00; 1052:0.00; 1053:0.00; 1054:0.00; 1055:0.00
. 2 .
. . .
. 1 .

Reward: +1.00, Result: win
Button pressed: blue by Agent 1

Result: ✅ WIN - win (steps: 5, reward: +1.00)

================================================================================
EPISODE 15
================================================================================
Environment: Red at (1, 0), Blue at (1, 2)

Initial state:
1 r .
. . .
. b 2


--- Step 1 ---
Agent 1 joint action: 6 → (DOWN, UP)
Agent 2 joint action: 6 → (DOWN, UP)
Executed: Agent 1: DOWN, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 0:1.00, 8:0.00, 7:0.00
    agent2_pos: 8:1.00, 0:0.00, 7:0.00
    red_button_pos: 7:0.14, 3:0.14, 6:0.14
    blue_button_pos: 7:0.14, 3:0.14, 6:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 0:1.00, 8:0.00, 7:0.00
    agent2_pos: 8:1.00, 0:0.00, 7:0.00
    red_button_pos: 7:0.14, 3:0.14, 6:0.14
    blue_button_pos: 7:0.14, 3:0.14, 6:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 244:0.02; 676:0.02; 316:0.02; 748:0.02; 677:0.01
  Agent2 top policies: 244:0.02; 676:0.02; 316:0.02; 748:0.02; 677:0.01
. r .
1 . 2
. b .

Reward: +0.00, Result: neutral

--- Step 2 ---
Agent 1 joint action: 8 → (DOWN, LEFT)
Agent 2 joint action: 8 → (DOWN, LEFT)
Executed: Agent 1: DOWN, Agent 2: LEFT
  Agent1 beliefs:
    agent1_pos: 3:1.00, 8:0.00, 5:0.00
    agent2_pos: 5:1.00, 8:0.00, 3:0.00
    red_button_pos: 7:0.20, 1:0.20, 6:0.20
    blue_button_pos: 7:0.20, 1:0.20, 6:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 3:1.00, 8:0.00, 5:0.00
    agent2_pos: 5:1.00, 8:0.00, 3:0.00
    red_button_pos: 7:0.20, 1:0.20, 6:0.20
    blue_button_pos: 7:0.20, 1:0.20, 6:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 316:0.05; 676:0.05; 244:0.05; 313:0.02; 243:0.02
  Agent2 top policies: 316:0.05; 676:0.05; 244:0.05; 313:0.02; 243:0.02
. r .
. 2 .
1 b .

Reward: +0.00, Result: neutral

--- Step 3 ---
Agent 1 joint action: 18 → (RIGHT, UP)
Agent 2 joint action: 18 → (RIGHT, UP)
Executed: Agent 1: RIGHT, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 6:1.00, 8:0.00, 5:0.00
    agent2_pos: 4:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:0.33, 1:0.33, 2:0.33
    blue_button_pos: 7:0.33, 1:0.33, 2:0.33
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 6:1.00, 8:0.00, 5:0.00
    agent2_pos: 4:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:0.33, 1:0.33, 2:0.33
    blue_button_pos: 7:0.33, 1:0.33, 2:0.33
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 676:0.28; 675:0.06; 677:0.06; 682:0.06; 658:0.06
  Agent2 top policies: 676:0.28; 675:0.06; 677:0.06; 682:0.06; 658:0.06
. 2 .
. . .
. 1 .

Reward: +0.00, Result: neutral

--- Step 4 ---
Agent 1 joint action: 10 → (DOWN, PRESS)
Agent 2 joint action: 10 → (DOWN, PRESS)
Executed: Agent 1: DOWN, Agent 2: PRESS
  Agent1 beliefs:
    agent1_pos: 7:1.00, 8:0.00, 6:0.00
    agent2_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 2:0.00, 7:0.00
    blue_button_pos: 7:1.00, 1:0.00, 2:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 7:1.00, 8:0.00, 6:0.00
    agent2_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 2:0.00, 7:0.00
    blue_button_pos: 7:1.00, 1:0.00, 2:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 386:0.08; 1253:0.08; 1250:0.08; 1251:0.08; 1252:0.08
  Agent2 top policies: 386:0.08; 1253:0.08; 1250:0.08; 1251:0.08; 1252:0.08
. 2 .
. . .
. 1 .

Reward: +0.00, Result: neutral
Button pressed: red by Agent 2

--- Step 5 ---
Agent 1 joint action: 24 → (PRESS, UP)
Agent 2 joint action: 24 → (PRESS, UP)
Executed: Agent 1: PRESS, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 7:1.00, 8:0.00, 6:0.00
    agent2_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 2:0.00, 7:0.00
    blue_button_pos: 7:1.00, 1:0.00, 2:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 7:1.00, 8:0.00, 6:0.00
    agent2_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 2:0.00, 7:0.00
    blue_button_pos: 7:1.00, 1:0.00, 2:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 1051:0.00; 1052:0.00; 1053:0.00; 1054:0.00; 1055:0.00
  Agent2 top policies: 1051:0.00; 1052:0.00; 1053:0.00; 1054:0.00; 1055:0.00
. 2 .
. . .
. 1 .

Reward: +1.00, Result: win
Button pressed: blue by Agent 1

Result: ✅ WIN - win (steps: 5, reward: +1.00)

================================================================================
EPISODE 16
================================================================================
Environment: Red at (1, 0), Blue at (1, 2)

Initial state:
1 r .
. . .
. b 2


--- Step 1 ---
Agent 1 joint action: 6 → (DOWN, UP)
Agent 2 joint action: 6 → (DOWN, UP)
Executed: Agent 1: DOWN, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 0:1.00, 8:0.00, 7:0.00
    agent2_pos: 8:1.00, 0:0.00, 7:0.00
    red_button_pos: 7:0.14, 3:0.14, 6:0.14
    blue_button_pos: 7:0.14, 3:0.14, 6:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 0:1.00, 8:0.00, 7:0.00
    agent2_pos: 8:1.00, 0:0.00, 7:0.00
    red_button_pos: 7:0.14, 3:0.14, 6:0.14
    blue_button_pos: 7:0.14, 3:0.14, 6:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 244:0.02; 676:0.02; 316:0.02; 748:0.02; 677:0.01
  Agent2 top policies: 244:0.02; 676:0.02; 316:0.02; 748:0.02; 677:0.01
. r .
1 . 2
. b .

Reward: +0.00, Result: neutral

--- Step 2 ---
Agent 1 joint action: 8 → (DOWN, LEFT)
Agent 2 joint action: 8 → (DOWN, LEFT)
Executed: Agent 1: DOWN, Agent 2: LEFT
  Agent1 beliefs:
    agent1_pos: 3:1.00, 8:0.00, 5:0.00
    agent2_pos: 5:1.00, 8:0.00, 3:0.00
    red_button_pos: 7:0.20, 1:0.20, 6:0.20
    blue_button_pos: 7:0.20, 1:0.20, 6:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 3:1.00, 8:0.00, 5:0.00
    agent2_pos: 5:1.00, 8:0.00, 3:0.00
    red_button_pos: 7:0.20, 1:0.20, 6:0.20
    blue_button_pos: 7:0.20, 1:0.20, 6:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 316:0.05; 676:0.05; 244:0.05; 313:0.02; 243:0.02
  Agent2 top policies: 316:0.05; 676:0.05; 244:0.05; 313:0.02; 243:0.02
. r .
. 2 .
1 b .

Reward: +0.00, Result: neutral

--- Step 3 ---
Agent 1 joint action: 18 → (RIGHT, UP)
Agent 2 joint action: 18 → (RIGHT, UP)
Executed: Agent 1: RIGHT, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 6:1.00, 8:0.00, 5:0.00
    agent2_pos: 4:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:0.33, 1:0.33, 2:0.33
    blue_button_pos: 7:0.33, 1:0.33, 2:0.33
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 6:1.00, 8:0.00, 5:0.00
    agent2_pos: 4:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:0.33, 1:0.33, 2:0.33
    blue_button_pos: 7:0.33, 1:0.33, 2:0.33
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 676:0.28; 675:0.06; 677:0.06; 682:0.06; 658:0.06
  Agent2 top policies: 676:0.28; 675:0.06; 677:0.06; 682:0.06; 658:0.06
. 2 .
. . .
. 1 .

Reward: +0.00, Result: neutral

--- Step 4 ---
Agent 1 joint action: 10 → (DOWN, PRESS)
Agent 2 joint action: 10 → (DOWN, PRESS)
Executed: Agent 1: DOWN, Agent 2: PRESS
  Agent1 beliefs:
    agent1_pos: 7:1.00, 8:0.00, 6:0.00
    agent2_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 2:0.00, 7:0.00
    blue_button_pos: 7:1.00, 1:0.00, 2:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 7:1.00, 8:0.00, 6:0.00
    agent2_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 2:0.00, 7:0.00
    blue_button_pos: 7:1.00, 1:0.00, 2:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 386:0.08; 1253:0.08; 1250:0.08; 1251:0.08; 1252:0.08
  Agent2 top policies: 386:0.08; 1253:0.08; 1250:0.08; 1251:0.08; 1252:0.08
. 2 .
. . .
. 1 .

Reward: +0.00, Result: neutral
Button pressed: red by Agent 2

--- Step 5 ---
Agent 1 joint action: 24 → (PRESS, UP)
Agent 2 joint action: 24 → (PRESS, UP)
Executed: Agent 1: PRESS, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 7:1.00, 8:0.00, 6:0.00
    agent2_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 2:0.00, 7:0.00
    blue_button_pos: 7:1.00, 1:0.00, 2:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 7:1.00, 8:0.00, 6:0.00
    agent2_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 2:0.00, 7:0.00
    blue_button_pos: 7:1.00, 1:0.00, 2:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 1051:0.00; 1052:0.00; 1053:0.00; 1054:0.00; 1055:0.00
  Agent2 top policies: 1051:0.00; 1052:0.00; 1053:0.00; 1054:0.00; 1055:0.00
. 2 .
. . .
. 1 .

Reward: +1.00, Result: win
Button pressed: blue by Agent 1

Result: ✅ WIN - win (steps: 5, reward: +1.00)

================================================================================
EPISODE 17
================================================================================
Environment: Red at (1, 0), Blue at (1, 2)

Initial state:
1 r .
. . .
. b 2


--- Step 1 ---
Agent 1 joint action: 6 → (DOWN, UP)
Agent 2 joint action: 6 → (DOWN, UP)
Executed: Agent 1: DOWN, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 0:1.00, 8:0.00, 7:0.00
    agent2_pos: 8:1.00, 0:0.00, 7:0.00
    red_button_pos: 7:0.14, 3:0.14, 6:0.14
    blue_button_pos: 7:0.14, 3:0.14, 6:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 0:1.00, 8:0.00, 7:0.00
    agent2_pos: 8:1.00, 0:0.00, 7:0.00
    red_button_pos: 7:0.14, 3:0.14, 6:0.14
    blue_button_pos: 7:0.14, 3:0.14, 6:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 244:0.02; 676:0.02; 316:0.02; 748:0.02; 677:0.01
  Agent2 top policies: 244:0.02; 676:0.02; 316:0.02; 748:0.02; 677:0.01
. r .
1 . 2
. b .

Reward: +0.00, Result: neutral

--- Step 2 ---
Agent 1 joint action: 8 → (DOWN, LEFT)
Agent 2 joint action: 8 → (DOWN, LEFT)
Executed: Agent 1: DOWN, Agent 2: LEFT
  Agent1 beliefs:
    agent1_pos: 3:1.00, 8:0.00, 5:0.00
    agent2_pos: 5:1.00, 8:0.00, 3:0.00
    red_button_pos: 7:0.20, 1:0.20, 6:0.20
    blue_button_pos: 7:0.20, 1:0.20, 6:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 3:1.00, 8:0.00, 5:0.00
    agent2_pos: 5:1.00, 8:0.00, 3:0.00
    red_button_pos: 7:0.20, 1:0.20, 6:0.20
    blue_button_pos: 7:0.20, 1:0.20, 6:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 316:0.05; 676:0.05; 244:0.05; 313:0.02; 243:0.02
  Agent2 top policies: 316:0.05; 676:0.05; 244:0.05; 313:0.02; 243:0.02
. r .
. 2 .
1 b .

Reward: +0.00, Result: neutral

--- Step 3 ---
Agent 1 joint action: 18 → (RIGHT, UP)
Agent 2 joint action: 18 → (RIGHT, UP)
Executed: Agent 1: RIGHT, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 6:1.00, 8:0.00, 5:0.00
    agent2_pos: 4:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:0.33, 1:0.33, 2:0.33
    blue_button_pos: 7:0.33, 1:0.33, 2:0.33
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 6:1.00, 8:0.00, 5:0.00
    agent2_pos: 4:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:0.33, 1:0.33, 2:0.33
    blue_button_pos: 7:0.33, 1:0.33, 2:0.33
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 676:0.28; 675:0.06; 677:0.06; 682:0.06; 658:0.06
  Agent2 top policies: 676:0.28; 675:0.06; 677:0.06; 682:0.06; 658:0.06
. 2 .
. . .
. 1 .

Reward: +0.00, Result: neutral

--- Step 4 ---
Agent 1 joint action: 10 → (DOWN, PRESS)
Agent 2 joint action: 10 → (DOWN, PRESS)
Executed: Agent 1: DOWN, Agent 2: PRESS
  Agent1 beliefs:
    agent1_pos: 7:1.00, 8:0.00, 6:0.00
    agent2_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 2:0.00, 7:0.00
    blue_button_pos: 7:1.00, 1:0.00, 2:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 7:1.00, 8:0.00, 6:0.00
    agent2_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 2:0.00, 7:0.00
    blue_button_pos: 7:1.00, 1:0.00, 2:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 386:0.08; 1253:0.08; 1250:0.08; 1251:0.08; 1252:0.08
  Agent2 top policies: 386:0.08; 1253:0.08; 1250:0.08; 1251:0.08; 1252:0.08
. 2 .
. . .
. 1 .

Reward: +0.00, Result: neutral
Button pressed: red by Agent 2

--- Step 5 ---
Agent 1 joint action: 24 → (PRESS, UP)
Agent 2 joint action: 24 → (PRESS, UP)
Executed: Agent 1: PRESS, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 7:1.00, 8:0.00, 6:0.00
    agent2_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 2:0.00, 7:0.00
    blue_button_pos: 7:1.00, 1:0.00, 2:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 7:1.00, 8:0.00, 6:0.00
    agent2_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 2:0.00, 7:0.00
    blue_button_pos: 7:1.00, 1:0.00, 2:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 1051:0.00; 1052:0.00; 1053:0.00; 1054:0.00; 1055:0.00
  Agent2 top policies: 1051:0.00; 1052:0.00; 1053:0.00; 1054:0.00; 1055:0.00
. 2 .
. . .
. 1 .

Reward: +1.00, Result: win
Button pressed: blue by Agent 1

Result: ✅ WIN - win (steps: 5, reward: +1.00)

================================================================================
EPISODE 18
================================================================================
Environment: Red at (1, 0), Blue at (1, 2)

Initial state:
1 r .
. . .
. b 2


--- Step 1 ---
Agent 1 joint action: 6 → (DOWN, UP)
Agent 2 joint action: 6 → (DOWN, UP)
Executed: Agent 1: DOWN, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 0:1.00, 8:0.00, 7:0.00
    agent2_pos: 8:1.00, 0:0.00, 7:0.00
    red_button_pos: 7:0.14, 3:0.14, 6:0.14
    blue_button_pos: 7:0.14, 3:0.14, 6:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 0:1.00, 8:0.00, 7:0.00
    agent2_pos: 8:1.00, 0:0.00, 7:0.00
    red_button_pos: 7:0.14, 3:0.14, 6:0.14
    blue_button_pos: 7:0.14, 3:0.14, 6:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 244:0.02; 676:0.02; 316:0.02; 748:0.02; 677:0.01
  Agent2 top policies: 244:0.02; 676:0.02; 316:0.02; 748:0.02; 677:0.01
. r .
1 . 2
. b .

Reward: +0.00, Result: neutral

--- Step 2 ---
Agent 1 joint action: 8 → (DOWN, LEFT)
Agent 2 joint action: 8 → (DOWN, LEFT)
Executed: Agent 1: DOWN, Agent 2: LEFT
  Agent1 beliefs:
    agent1_pos: 3:1.00, 8:0.00, 5:0.00
    agent2_pos: 5:1.00, 8:0.00, 3:0.00
    red_button_pos: 7:0.20, 1:0.20, 6:0.20
    blue_button_pos: 7:0.20, 1:0.20, 6:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 3:1.00, 8:0.00, 5:0.00
    agent2_pos: 5:1.00, 8:0.00, 3:0.00
    red_button_pos: 7:0.20, 1:0.20, 6:0.20
    blue_button_pos: 7:0.20, 1:0.20, 6:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 316:0.05; 676:0.05; 244:0.05; 313:0.02; 243:0.02
  Agent2 top policies: 316:0.05; 676:0.05; 244:0.05; 313:0.02; 243:0.02
. r .
. 2 .
1 b .

Reward: +0.00, Result: neutral

--- Step 3 ---
Agent 1 joint action: 18 → (RIGHT, UP)
Agent 2 joint action: 18 → (RIGHT, UP)
Executed: Agent 1: RIGHT, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 6:1.00, 8:0.00, 5:0.00
    agent2_pos: 4:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:0.33, 1:0.33, 2:0.33
    blue_button_pos: 7:0.33, 1:0.33, 2:0.33
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 6:1.00, 8:0.00, 5:0.00
    agent2_pos: 4:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:0.33, 1:0.33, 2:0.33
    blue_button_pos: 7:0.33, 1:0.33, 2:0.33
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 676:0.28; 675:0.06; 677:0.06; 682:0.06; 658:0.06
  Agent2 top policies: 676:0.28; 675:0.06; 677:0.06; 682:0.06; 658:0.06
. 2 .
. . .
. 1 .

Reward: +0.00, Result: neutral

--- Step 4 ---
Agent 1 joint action: 10 → (DOWN, PRESS)
Agent 2 joint action: 10 → (DOWN, PRESS)
Executed: Agent 1: DOWN, Agent 2: PRESS
  Agent1 beliefs:
    agent1_pos: 7:1.00, 8:0.00, 6:0.00
    agent2_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 2:0.00, 7:0.00
    blue_button_pos: 7:1.00, 1:0.00, 2:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 7:1.00, 8:0.00, 6:0.00
    agent2_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 2:0.00, 7:0.00
    blue_button_pos: 7:1.00, 1:0.00, 2:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 386:0.08; 1253:0.08; 1250:0.08; 1251:0.08; 1252:0.08
  Agent2 top policies: 386:0.08; 1253:0.08; 1250:0.08; 1251:0.08; 1252:0.08
. 2 .
. . .
. 1 .

Reward: +0.00, Result: neutral
Button pressed: red by Agent 2

--- Step 5 ---
Agent 1 joint action: 24 → (PRESS, UP)
Agent 2 joint action: 24 → (PRESS, UP)
Executed: Agent 1: PRESS, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 7:1.00, 8:0.00, 6:0.00
    agent2_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 2:0.00, 7:0.00
    blue_button_pos: 7:1.00, 1:0.00, 2:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 7:1.00, 8:0.00, 6:0.00
    agent2_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 2:0.00, 7:0.00
    blue_button_pos: 7:1.00, 1:0.00, 2:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 1051:0.00; 1052:0.00; 1053:0.00; 1054:0.00; 1055:0.00
  Agent2 top policies: 1051:0.00; 1052:0.00; 1053:0.00; 1054:0.00; 1055:0.00
. 2 .
. . .
. 1 .

Reward: +1.00, Result: win
Button pressed: blue by Agent 1

Result: ✅ WIN - win (steps: 5, reward: +1.00)

================================================================================
EPISODE 19
================================================================================
Environment: Red at (1, 0), Blue at (1, 2)

Initial state:
1 r .
. . .
. b 2


--- Step 1 ---
Agent 1 joint action: 6 → (DOWN, UP)
Agent 2 joint action: 6 → (DOWN, UP)
Executed: Agent 1: DOWN, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 0:1.00, 8:0.00, 7:0.00
    agent2_pos: 8:1.00, 0:0.00, 7:0.00
    red_button_pos: 7:0.14, 3:0.14, 6:0.14
    blue_button_pos: 7:0.14, 3:0.14, 6:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 0:1.00, 8:0.00, 7:0.00
    agent2_pos: 8:1.00, 0:0.00, 7:0.00
    red_button_pos: 7:0.14, 3:0.14, 6:0.14
    blue_button_pos: 7:0.14, 3:0.14, 6:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 244:0.02; 676:0.02; 316:0.02; 748:0.02; 677:0.01
  Agent2 top policies: 244:0.02; 676:0.02; 316:0.02; 748:0.02; 677:0.01
. r .
1 . 2
. b .

Reward: +0.00, Result: neutral

--- Step 2 ---
Agent 1 joint action: 8 → (DOWN, LEFT)
Agent 2 joint action: 8 → (DOWN, LEFT)
Executed: Agent 1: DOWN, Agent 2: LEFT
  Agent1 beliefs:
    agent1_pos: 3:1.00, 8:0.00, 5:0.00
    agent2_pos: 5:1.00, 8:0.00, 3:0.00
    red_button_pos: 7:0.20, 1:0.20, 6:0.20
    blue_button_pos: 7:0.20, 1:0.20, 6:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 3:1.00, 8:0.00, 5:0.00
    agent2_pos: 5:1.00, 8:0.00, 3:0.00
    red_button_pos: 7:0.20, 1:0.20, 6:0.20
    blue_button_pos: 7:0.20, 1:0.20, 6:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 316:0.05; 676:0.05; 244:0.05; 313:0.02; 243:0.02
  Agent2 top policies: 316:0.05; 676:0.05; 244:0.05; 313:0.02; 243:0.02
. r .
. 2 .
1 b .

Reward: +0.00, Result: neutral

--- Step 3 ---
Agent 1 joint action: 18 → (RIGHT, UP)
Agent 2 joint action: 18 → (RIGHT, UP)
Executed: Agent 1: RIGHT, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 6:1.00, 8:0.00, 5:0.00
    agent2_pos: 4:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:0.33, 1:0.33, 2:0.33
    blue_button_pos: 7:0.33, 1:0.33, 2:0.33
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 6:1.00, 8:0.00, 5:0.00
    agent2_pos: 4:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:0.33, 1:0.33, 2:0.33
    blue_button_pos: 7:0.33, 1:0.33, 2:0.33
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 676:0.28; 675:0.06; 677:0.06; 682:0.06; 658:0.06
  Agent2 top policies: 676:0.28; 675:0.06; 677:0.06; 682:0.06; 658:0.06
. 2 .
. . .
. 1 .

Reward: +0.00, Result: neutral

--- Step 4 ---
Agent 1 joint action: 10 → (DOWN, PRESS)
Agent 2 joint action: 10 → (DOWN, PRESS)
Executed: Agent 1: DOWN, Agent 2: PRESS
  Agent1 beliefs:
    agent1_pos: 7:1.00, 8:0.00, 6:0.00
    agent2_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 2:0.00, 7:0.00
    blue_button_pos: 7:1.00, 1:0.00, 2:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 7:1.00, 8:0.00, 6:0.00
    agent2_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 2:0.00, 7:0.00
    blue_button_pos: 7:1.00, 1:0.00, 2:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 386:0.08; 1253:0.08; 1250:0.08; 1251:0.08; 1252:0.08
  Agent2 top policies: 386:0.08; 1253:0.08; 1250:0.08; 1251:0.08; 1252:0.08
. 2 .
. . .
. 1 .

Reward: +0.00, Result: neutral
Button pressed: red by Agent 2

--- Step 5 ---
Agent 1 joint action: 24 → (PRESS, UP)
Agent 2 joint action: 24 → (PRESS, UP)
Executed: Agent 1: PRESS, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 7:1.00, 8:0.00, 6:0.00
    agent2_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 2:0.00, 7:0.00
    blue_button_pos: 7:1.00, 1:0.00, 2:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 7:1.00, 8:0.00, 6:0.00
    agent2_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 2:0.00, 7:0.00
    blue_button_pos: 7:1.00, 1:0.00, 2:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 1051:0.00; 1052:0.00; 1053:0.00; 1054:0.00; 1055:0.00
  Agent2 top policies: 1051:0.00; 1052:0.00; 1053:0.00; 1054:0.00; 1055:0.00
. 2 .
. . .
. 1 .

Reward: +1.00, Result: win
Button pressed: blue by Agent 1

Result: ✅ WIN - win (steps: 5, reward: +1.00)

================================================================================
EPISODE 20
================================================================================
Environment: Red at (1, 0), Blue at (1, 2)

Initial state:
1 r .
. . .
. b 2


--- Step 1 ---
Agent 1 joint action: 6 → (DOWN, UP)
Agent 2 joint action: 6 → (DOWN, UP)
Executed: Agent 1: DOWN, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 0:1.00, 8:0.00, 7:0.00
    agent2_pos: 8:1.00, 0:0.00, 7:0.00
    red_button_pos: 7:0.14, 3:0.14, 6:0.14
    blue_button_pos: 7:0.14, 3:0.14, 6:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 0:1.00, 8:0.00, 7:0.00
    agent2_pos: 8:1.00, 0:0.00, 7:0.00
    red_button_pos: 7:0.14, 3:0.14, 6:0.14
    blue_button_pos: 7:0.14, 3:0.14, 6:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 244:0.02; 676:0.02; 316:0.02; 748:0.02; 677:0.01
  Agent2 top policies: 244:0.02; 676:0.02; 316:0.02; 748:0.02; 677:0.01
. r .
1 . 2
. b .

Reward: +0.00, Result: neutral

--- Step 2 ---
Agent 1 joint action: 8 → (DOWN, LEFT)
Agent 2 joint action: 8 → (DOWN, LEFT)
Executed: Agent 1: DOWN, Agent 2: LEFT
  Agent1 beliefs:
    agent1_pos: 3:1.00, 8:0.00, 5:0.00
    agent2_pos: 5:1.00, 8:0.00, 3:0.00
    red_button_pos: 7:0.20, 1:0.20, 6:0.20
    blue_button_pos: 7:0.20, 1:0.20, 6:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 3:1.00, 8:0.00, 5:0.00
    agent2_pos: 5:1.00, 8:0.00, 3:0.00
    red_button_pos: 7:0.20, 1:0.20, 6:0.20
    blue_button_pos: 7:0.20, 1:0.20, 6:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 316:0.05; 676:0.05; 244:0.05; 313:0.02; 243:0.02
  Agent2 top policies: 316:0.05; 676:0.05; 244:0.05; 313:0.02; 243:0.02
. r .
. 2 .
1 b .

Reward: +0.00, Result: neutral

--- Step 3 ---
Agent 1 joint action: 18 → (RIGHT, UP)
Agent 2 joint action: 18 → (RIGHT, UP)
Executed: Agent 1: RIGHT, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 6:1.00, 8:0.00, 5:0.00
    agent2_pos: 4:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:0.33, 1:0.33, 2:0.33
    blue_button_pos: 7:0.33, 1:0.33, 2:0.33
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 6:1.00, 8:0.00, 5:0.00
    agent2_pos: 4:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:0.33, 1:0.33, 2:0.33
    blue_button_pos: 7:0.33, 1:0.33, 2:0.33
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 676:0.28; 675:0.06; 677:0.06; 682:0.06; 658:0.06
  Agent2 top policies: 676:0.28; 675:0.06; 677:0.06; 682:0.06; 658:0.06
. 2 .
. . .
. 1 .

Reward: +0.00, Result: neutral

--- Step 4 ---
Agent 1 joint action: 10 → (DOWN, PRESS)
Agent 2 joint action: 10 → (DOWN, PRESS)
Executed: Agent 1: DOWN, Agent 2: PRESS
  Agent1 beliefs:
    agent1_pos: 7:1.00, 8:0.00, 6:0.00
    agent2_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 2:0.00, 7:0.00
    blue_button_pos: 7:1.00, 1:0.00, 2:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 7:1.00, 8:0.00, 6:0.00
    agent2_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 2:0.00, 7:0.00
    blue_button_pos: 7:1.00, 1:0.00, 2:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 386:0.08; 1253:0.08; 1250:0.08; 1251:0.08; 1252:0.08
  Agent2 top policies: 386:0.08; 1253:0.08; 1250:0.08; 1251:0.08; 1252:0.08
. 2 .
. . .
. 1 .

Reward: +0.00, Result: neutral
Button pressed: red by Agent 2

--- Step 5 ---
Agent 1 joint action: 24 → (PRESS, UP)
Agent 2 joint action: 24 → (PRESS, UP)
Executed: Agent 1: PRESS, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 7:1.00, 8:0.00, 6:0.00
    agent2_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 2:0.00, 7:0.00
    blue_button_pos: 7:1.00, 1:0.00, 2:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 7:1.00, 8:0.00, 6:0.00
    agent2_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 2:0.00, 7:0.00
    blue_button_pos: 7:1.00, 1:0.00, 2:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 1051:0.00; 1052:0.00; 1053:0.00; 1054:0.00; 1055:0.00
  Agent2 top policies: 1051:0.00; 1052:0.00; 1053:0.00; 1054:0.00; 1055:0.00
. 2 .
. . .
. 1 .

Reward: +1.00, Result: win
Button pressed: blue by Agent 1

Result: ✅ WIN - win (steps: 5, reward: +1.00)

================================================================================
SEED 0 - CONFIG 2
Red at (2, 0), Blue at (1, 0)
Episodes 21-40
================================================================================

================================================================================
EPISODE 21
================================================================================
Environment: Red at (2, 0), Blue at (1, 0)

Initial state:
1 b r
. . .
. . 2


--- Step 1 ---
Agent 1 joint action: 6 → (DOWN, UP)
Agent 2 joint action: 6 → (DOWN, UP)
Executed: Agent 1: DOWN, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 0:1.00, 8:0.00, 7:0.00
    agent2_pos: 8:1.00, 0:0.00, 7:0.00
    red_button_pos: 7:0.14, 3:0.14, 6:0.14
    blue_button_pos: 7:0.14, 3:0.14, 6:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 0:1.00, 8:0.00, 7:0.00
    agent2_pos: 8:1.00, 0:0.00, 7:0.00
    red_button_pos: 7:0.14, 3:0.14, 6:0.14
    blue_button_pos: 7:0.14, 3:0.14, 6:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 244:0.02; 676:0.02; 316:0.02; 748:0.02; 677:0.01
  Agent2 top policies: 244:0.02; 676:0.02; 316:0.02; 748:0.02; 677:0.01
. b r
1 . 2
. . .

Reward: +0.00, Result: neutral

--- Step 2 ---
Agent 1 joint action: 8 → (DOWN, LEFT)
Agent 2 joint action: 8 → (DOWN, LEFT)
Executed: Agent 1: DOWN, Agent 2: LEFT
  Agent1 beliefs:
    agent1_pos: 3:1.00, 8:0.00, 5:0.00
    agent2_pos: 5:1.00, 8:0.00, 3:0.00
    red_button_pos: 7:0.20, 1:0.20, 6:0.20
    blue_button_pos: 7:0.20, 1:0.20, 6:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 3:1.00, 8:0.00, 5:0.00
    agent2_pos: 5:1.00, 8:0.00, 3:0.00
    red_button_pos: 7:0.20, 1:0.20, 6:0.20
    blue_button_pos: 7:0.20, 1:0.20, 6:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 316:0.05; 676:0.05; 244:0.05; 313:0.02; 243:0.02
  Agent2 top policies: 316:0.05; 676:0.05; 244:0.05; 313:0.02; 243:0.02
. b r
. 2 .
1 . .

Reward: +0.00, Result: neutral

--- Step 3 ---
Agent 1 joint action: 18 → (RIGHT, UP)
Agent 2 joint action: 18 → (RIGHT, UP)
Executed: Agent 1: RIGHT, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 6:1.00, 8:0.00, 5:0.00
    agent2_pos: 4:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:0.33, 1:0.33, 2:0.33
    blue_button_pos: 7:0.33, 1:0.33, 2:0.33
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 6:1.00, 8:0.00, 5:0.00
    agent2_pos: 4:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:0.33, 1:0.33, 2:0.33
    blue_button_pos: 7:0.33, 1:0.33, 2:0.33
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 676:0.28; 675:0.06; 677:0.06; 682:0.06; 658:0.06
  Agent2 top policies: 676:0.28; 675:0.06; 677:0.06; 682:0.06; 658:0.06
. 2 r
. . .
. 1 .

Reward: +0.00, Result: neutral

--- Step 4 ---
Agent 1 joint action: 3 → (UP, RIGHT)
Agent 2 joint action: 3 → (UP, RIGHT)
Executed: Agent 1: UP, Agent 2: RIGHT
  Agent1 beliefs:
    agent1_pos: 7:1.00, 8:0.00, 6:0.00
    agent2_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 2:1.00, 8:0.00, 0:0.00
    blue_button_pos: 1:1.00, 2:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 7:1.00, 8:0.00, 6:0.00
    agent2_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 2:1.00, 8:0.00, 0:0.00
    blue_button_pos: 1:1.00, 2:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 112:0.00; 352:0.00; 772:0.00; 118:0.00; 778:0.00
  Agent2 top policies: 112:0.00; 352:0.00; 772:0.00; 118:0.00; 778:0.00
. b 2
. 1 .
. . .

Reward: +0.00, Result: neutral

--- Step 5 ---
Agent 1 joint action: 4 → (UP, PRESS)
Agent 2 joint action: 4 → (UP, PRESS)
Executed: Agent 1: UP, Agent 2: PRESS
  Agent1 beliefs:
    agent1_pos: 4:1.00, 8:0.00, 7:0.00
    agent2_pos: 2:1.00, 8:0.00, 7:0.00
    red_button_pos: 2:1.00, 8:0.00, 0:0.00
    blue_button_pos: 1:1.00, 7:0.00, 8:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 4:1.00, 8:0.00, 7:0.00
    agent2_pos: 2:1.00, 8:0.00, 7:0.00
    red_button_pos: 2:1.00, 8:0.00, 0:0.00
    blue_button_pos: 1:1.00, 7:0.00, 8:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 171:0.16; 172:0.16; 168:0.16; 169:0.16; 173:0.16
  Agent2 top policies: 171:0.16; 172:0.16; 168:0.16; 169:0.16; 173:0.16
. 1 2
. . .
. . .

Reward: +0.00, Result: neutral
Button pressed: red by Agent 2

--- Step 6 ---
Agent 1 joint action: 24 → (PRESS, UP)
Agent 2 joint action: 24 → (PRESS, UP)
Executed: Agent 1: PRESS, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 1:1.00, 8:0.00, 7:0.00
    agent2_pos: 2:1.00, 8:0.00, 7:0.00
    red_button_pos: 2:1.00, 8:0.00, 7:0.00
    blue_button_pos: 1:1.00, 7:0.00, 8:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 1:1.00, 8:0.00, 7:0.00
    agent2_pos: 2:1.00, 8:0.00, 7:0.00
    red_button_pos: 2:1.00, 8:0.00, 7:0.00
    blue_button_pos: 1:1.00, 7:0.00, 8:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 982:0.00; 983:0.00; 984:0.00; 985:0.00; 986:0.00
  Agent2 top policies: 982:0.00; 983:0.00; 984:0.00; 985:0.00; 986:0.00
. 1 2
. . .
. . .

Reward: +1.00, Result: win
Button pressed: blue by Agent 1

Result: ✅ WIN - win (steps: 6, reward: +1.00)

================================================================================
EPISODE 22
================================================================================
Environment: Red at (2, 0), Blue at (1, 0)

Initial state:
1 b r
. . .
. . 2


--- Step 1 ---
Agent 1 joint action: 6 → (DOWN, UP)
Agent 2 joint action: 6 → (DOWN, UP)
Executed: Agent 1: DOWN, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 0:1.00, 8:0.00, 7:0.00
    agent2_pos: 8:1.00, 0:0.00, 7:0.00
    red_button_pos: 7:0.14, 3:0.14, 6:0.14
    blue_button_pos: 7:0.14, 3:0.14, 6:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 0:1.00, 8:0.00, 7:0.00
    agent2_pos: 8:1.00, 0:0.00, 7:0.00
    red_button_pos: 7:0.14, 3:0.14, 6:0.14
    blue_button_pos: 7:0.14, 3:0.14, 6:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 244:0.02; 676:0.02; 316:0.02; 748:0.02; 677:0.01
  Agent2 top policies: 244:0.02; 676:0.02; 316:0.02; 748:0.02; 677:0.01
. b r
1 . 2
. . .

Reward: +0.00, Result: neutral

--- Step 2 ---
Agent 1 joint action: 8 → (DOWN, LEFT)
Agent 2 joint action: 8 → (DOWN, LEFT)
Executed: Agent 1: DOWN, Agent 2: LEFT
  Agent1 beliefs:
    agent1_pos: 3:1.00, 8:0.00, 5:0.00
    agent2_pos: 5:1.00, 8:0.00, 3:0.00
    red_button_pos: 7:0.20, 1:0.20, 6:0.20
    blue_button_pos: 7:0.20, 1:0.20, 6:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 3:1.00, 8:0.00, 5:0.00
    agent2_pos: 5:1.00, 8:0.00, 3:0.00
    red_button_pos: 7:0.20, 1:0.20, 6:0.20
    blue_button_pos: 7:0.20, 1:0.20, 6:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 316:0.05; 676:0.05; 244:0.05; 313:0.02; 243:0.02
  Agent2 top policies: 316:0.05; 676:0.05; 244:0.05; 313:0.02; 243:0.02
. b r
. 2 .
1 . .

Reward: +0.00, Result: neutral

--- Step 3 ---
Agent 1 joint action: 18 → (RIGHT, UP)
Agent 2 joint action: 18 → (RIGHT, UP)
Executed: Agent 1: RIGHT, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 6:1.00, 8:0.00, 5:0.00
    agent2_pos: 4:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:0.33, 1:0.33, 2:0.33
    blue_button_pos: 7:0.33, 1:0.33, 2:0.33
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 6:1.00, 8:0.00, 5:0.00
    agent2_pos: 4:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:0.33, 1:0.33, 2:0.33
    blue_button_pos: 7:0.33, 1:0.33, 2:0.33
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 676:0.28; 675:0.06; 677:0.06; 682:0.06; 658:0.06
  Agent2 top policies: 676:0.28; 675:0.06; 677:0.06; 682:0.06; 658:0.06
. 2 r
. . .
. 1 .

Reward: +0.00, Result: neutral

--- Step 4 ---
Agent 1 joint action: 3 → (UP, RIGHT)
Agent 2 joint action: 3 → (UP, RIGHT)
Executed: Agent 1: UP, Agent 2: RIGHT
  Agent1 beliefs:
    agent1_pos: 7:1.00, 8:0.00, 6:0.00
    agent2_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 2:1.00, 8:0.00, 0:0.00
    blue_button_pos: 1:1.00, 2:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 7:1.00, 8:0.00, 6:0.00
    agent2_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 2:1.00, 8:0.00, 0:0.00
    blue_button_pos: 1:1.00, 2:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 112:0.00; 352:0.00; 772:0.00; 118:0.00; 778:0.00
  Agent2 top policies: 112:0.00; 352:0.00; 772:0.00; 118:0.00; 778:0.00
. b 2
. 1 .
. . .

Reward: +0.00, Result: neutral

--- Step 5 ---
Agent 1 joint action: 4 → (UP, PRESS)
Agent 2 joint action: 4 → (UP, PRESS)
Executed: Agent 1: UP, Agent 2: PRESS
  Agent1 beliefs:
    agent1_pos: 4:1.00, 8:0.00, 7:0.00
    agent2_pos: 2:1.00, 8:0.00, 7:0.00
    red_button_pos: 2:1.00, 8:0.00, 0:0.00
    blue_button_pos: 1:1.00, 7:0.00, 8:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 4:1.00, 8:0.00, 7:0.00
    agent2_pos: 2:1.00, 8:0.00, 7:0.00
    red_button_pos: 2:1.00, 8:0.00, 0:0.00
    blue_button_pos: 1:1.00, 7:0.00, 8:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 171:0.16; 172:0.16; 168:0.16; 169:0.16; 173:0.16
  Agent2 top policies: 171:0.16; 172:0.16; 168:0.16; 169:0.16; 173:0.16
. 1 2
. . .
. . .

Reward: +0.00, Result: neutral
Button pressed: red by Agent 2

--- Step 6 ---
Agent 1 joint action: 24 → (PRESS, UP)
Agent 2 joint action: 24 → (PRESS, UP)
Executed: Agent 1: PRESS, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 1:1.00, 8:0.00, 7:0.00
    agent2_pos: 2:1.00, 8:0.00, 7:0.00
    red_button_pos: 2:1.00, 8:0.00, 7:0.00
    blue_button_pos: 1:1.00, 7:0.00, 8:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 1:1.00, 8:0.00, 7:0.00
    agent2_pos: 2:1.00, 8:0.00, 7:0.00
    red_button_pos: 2:1.00, 8:0.00, 7:0.00
    blue_button_pos: 1:1.00, 7:0.00, 8:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 982:0.00; 983:0.00; 984:0.00; 985:0.00; 986:0.00
  Agent2 top policies: 982:0.00; 983:0.00; 984:0.00; 985:0.00; 986:0.00
. 1 2
. . .
. . .

Reward: +1.00, Result: win
Button pressed: blue by Agent 1

Result: ✅ WIN - win (steps: 6, reward: +1.00)

================================================================================
EPISODE 23
================================================================================
Environment: Red at (2, 0), Blue at (1, 0)

Initial state:
1 b r
. . .
. . 2


--- Step 1 ---
Agent 1 joint action: 6 → (DOWN, UP)
Agent 2 joint action: 6 → (DOWN, UP)
Executed: Agent 1: DOWN, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 0:1.00, 8:0.00, 7:0.00
    agent2_pos: 8:1.00, 0:0.00, 7:0.00
    red_button_pos: 7:0.14, 3:0.14, 6:0.14
    blue_button_pos: 7:0.14, 3:0.14, 6:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 0:1.00, 8:0.00, 7:0.00
    agent2_pos: 8:1.00, 0:0.00, 7:0.00
    red_button_pos: 7:0.14, 3:0.14, 6:0.14
    blue_button_pos: 7:0.14, 3:0.14, 6:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 244:0.02; 676:0.02; 316:0.02; 748:0.02; 677:0.01
  Agent2 top policies: 244:0.02; 676:0.02; 316:0.02; 748:0.02; 677:0.01
. b r
1 . 2
. . .

Reward: +0.00, Result: neutral

--- Step 2 ---
Agent 1 joint action: 8 → (DOWN, LEFT)
Agent 2 joint action: 8 → (DOWN, LEFT)
Executed: Agent 1: DOWN, Agent 2: LEFT
  Agent1 beliefs:
    agent1_pos: 3:1.00, 8:0.00, 5:0.00
    agent2_pos: 5:1.00, 8:0.00, 3:0.00
    red_button_pos: 7:0.20, 1:0.20, 6:0.20
    blue_button_pos: 7:0.20, 1:0.20, 6:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 3:1.00, 8:0.00, 5:0.00
    agent2_pos: 5:1.00, 8:0.00, 3:0.00
    red_button_pos: 7:0.20, 1:0.20, 6:0.20
    blue_button_pos: 7:0.20, 1:0.20, 6:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 316:0.05; 676:0.05; 244:0.05; 313:0.02; 243:0.02
  Agent2 top policies: 316:0.05; 676:0.05; 244:0.05; 313:0.02; 243:0.02
. b r
. 2 .
1 . .

Reward: +0.00, Result: neutral

--- Step 3 ---
Agent 1 joint action: 18 → (RIGHT, UP)
Agent 2 joint action: 18 → (RIGHT, UP)
Executed: Agent 1: RIGHT, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 6:1.00, 8:0.00, 5:0.00
    agent2_pos: 4:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:0.33, 1:0.33, 2:0.33
    blue_button_pos: 7:0.33, 1:0.33, 2:0.33
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 6:1.00, 8:0.00, 5:0.00
    agent2_pos: 4:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:0.33, 1:0.33, 2:0.33
    blue_button_pos: 7:0.33, 1:0.33, 2:0.33
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 676:0.28; 675:0.06; 677:0.06; 682:0.06; 658:0.06
  Agent2 top policies: 676:0.28; 675:0.06; 677:0.06; 682:0.06; 658:0.06
. 2 r
. . .
. 1 .

Reward: +0.00, Result: neutral

--- Step 4 ---
Agent 1 joint action: 3 → (UP, RIGHT)
Agent 2 joint action: 3 → (UP, RIGHT)
Executed: Agent 1: UP, Agent 2: RIGHT
  Agent1 beliefs:
    agent1_pos: 7:1.00, 8:0.00, 6:0.00
    agent2_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 2:1.00, 8:0.00, 0:0.00
    blue_button_pos: 1:1.00, 2:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 7:1.00, 8:0.00, 6:0.00
    agent2_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 2:1.00, 8:0.00, 0:0.00
    blue_button_pos: 1:1.00, 2:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 112:0.00; 352:0.00; 772:0.00; 118:0.00; 778:0.00
  Agent2 top policies: 112:0.00; 352:0.00; 772:0.00; 118:0.00; 778:0.00
. b 2
. 1 .
. . .

Reward: +0.00, Result: neutral

--- Step 5 ---
Agent 1 joint action: 4 → (UP, PRESS)
Agent 2 joint action: 4 → (UP, PRESS)
Executed: Agent 1: UP, Agent 2: PRESS
  Agent1 beliefs:
    agent1_pos: 4:1.00, 8:0.00, 7:0.00
    agent2_pos: 2:1.00, 8:0.00, 7:0.00
    red_button_pos: 2:1.00, 8:0.00, 0:0.00
    blue_button_pos: 1:1.00, 7:0.00, 8:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 4:1.00, 8:0.00, 7:0.00
    agent2_pos: 2:1.00, 8:0.00, 7:0.00
    red_button_pos: 2:1.00, 8:0.00, 0:0.00
    blue_button_pos: 1:1.00, 7:0.00, 8:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 171:0.16; 172:0.16; 168:0.16; 169:0.16; 173:0.16
  Agent2 top policies: 171:0.16; 172:0.16; 168:0.16; 169:0.16; 173:0.16
. 1 2
. . .
. . .

Reward: +0.00, Result: neutral
Button pressed: red by Agent 2

--- Step 6 ---
Agent 1 joint action: 24 → (PRESS, UP)
Agent 2 joint action: 24 → (PRESS, UP)
Executed: Agent 1: PRESS, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 1:1.00, 8:0.00, 7:0.00
    agent2_pos: 2:1.00, 8:0.00, 7:0.00
    red_button_pos: 2:1.00, 8:0.00, 7:0.00
    blue_button_pos: 1:1.00, 7:0.00, 8:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 1:1.00, 8:0.00, 7:0.00
    agent2_pos: 2:1.00, 8:0.00, 7:0.00
    red_button_pos: 2:1.00, 8:0.00, 7:0.00
    blue_button_pos: 1:1.00, 7:0.00, 8:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 982:0.00; 983:0.00; 984:0.00; 985:0.00; 986:0.00
  Agent2 top policies: 982:0.00; 983:0.00; 984:0.00; 985:0.00; 986:0.00
. 1 2
. . .
. . .

Reward: +1.00, Result: win
Button pressed: blue by Agent 1

Result: ✅ WIN - win (steps: 6, reward: +1.00)

================================================================================
EPISODE 24
================================================================================
Environment: Red at (2, 0), Blue at (1, 0)

Initial state:
1 b r
. . .
. . 2


--- Step 1 ---
Agent 1 joint action: 6 → (DOWN, UP)
Agent 2 joint action: 6 → (DOWN, UP)
Executed: Agent 1: DOWN, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 0:1.00, 8:0.00, 7:0.00
    agent2_pos: 8:1.00, 0:0.00, 7:0.00
    red_button_pos: 7:0.14, 3:0.14, 6:0.14
    blue_button_pos: 7:0.14, 3:0.14, 6:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 0:1.00, 8:0.00, 7:0.00
    agent2_pos: 8:1.00, 0:0.00, 7:0.00
    red_button_pos: 7:0.14, 3:0.14, 6:0.14
    blue_button_pos: 7:0.14, 3:0.14, 6:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 244:0.02; 676:0.02; 316:0.02; 748:0.02; 677:0.01
  Agent2 top policies: 244:0.02; 676:0.02; 316:0.02; 748:0.02; 677:0.01
. b r
1 . 2
. . .

Reward: +0.00, Result: neutral

--- Step 2 ---
Agent 1 joint action: 8 → (DOWN, LEFT)
Agent 2 joint action: 8 → (DOWN, LEFT)
Executed: Agent 1: DOWN, Agent 2: LEFT
  Agent1 beliefs:
    agent1_pos: 3:1.00, 8:0.00, 5:0.00
    agent2_pos: 5:1.00, 8:0.00, 3:0.00
    red_button_pos: 7:0.20, 1:0.20, 6:0.20
    blue_button_pos: 7:0.20, 1:0.20, 6:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 3:1.00, 8:0.00, 5:0.00
    agent2_pos: 5:1.00, 8:0.00, 3:0.00
    red_button_pos: 7:0.20, 1:0.20, 6:0.20
    blue_button_pos: 7:0.20, 1:0.20, 6:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 316:0.05; 676:0.05; 244:0.05; 313:0.02; 243:0.02
  Agent2 top policies: 316:0.05; 676:0.05; 244:0.05; 313:0.02; 243:0.02
. b r
. 2 .
1 . .

Reward: +0.00, Result: neutral

--- Step 3 ---
Agent 1 joint action: 18 → (RIGHT, UP)
Agent 2 joint action: 18 → (RIGHT, UP)
Executed: Agent 1: RIGHT, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 6:1.00, 8:0.00, 5:0.00
    agent2_pos: 4:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:0.33, 1:0.33, 2:0.33
    blue_button_pos: 7:0.33, 1:0.33, 2:0.33
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 6:1.00, 8:0.00, 5:0.00
    agent2_pos: 4:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:0.33, 1:0.33, 2:0.33
    blue_button_pos: 7:0.33, 1:0.33, 2:0.33
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 676:0.28; 675:0.06; 677:0.06; 682:0.06; 658:0.06
  Agent2 top policies: 676:0.28; 675:0.06; 677:0.06; 682:0.06; 658:0.06
. 2 r
. . .
. 1 .

Reward: +0.00, Result: neutral

--- Step 4 ---
Agent 1 joint action: 3 → (UP, RIGHT)
Agent 2 joint action: 3 → (UP, RIGHT)
Executed: Agent 1: UP, Agent 2: RIGHT
  Agent1 beliefs:
    agent1_pos: 7:1.00, 8:0.00, 6:0.00
    agent2_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 2:1.00, 8:0.00, 0:0.00
    blue_button_pos: 1:1.00, 2:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 7:1.00, 8:0.00, 6:0.00
    agent2_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 2:1.00, 8:0.00, 0:0.00
    blue_button_pos: 1:1.00, 2:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 112:0.00; 352:0.00; 772:0.00; 118:0.00; 778:0.00
  Agent2 top policies: 112:0.00; 352:0.00; 772:0.00; 118:0.00; 778:0.00
. b 2
. 1 .
. . .

Reward: +0.00, Result: neutral

--- Step 5 ---
Agent 1 joint action: 4 → (UP, PRESS)
Agent 2 joint action: 4 → (UP, PRESS)
Executed: Agent 1: UP, Agent 2: PRESS
  Agent1 beliefs:
    agent1_pos: 4:1.00, 8:0.00, 7:0.00
    agent2_pos: 2:1.00, 8:0.00, 7:0.00
    red_button_pos: 2:1.00, 8:0.00, 0:0.00
    blue_button_pos: 1:1.00, 7:0.00, 8:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 4:1.00, 8:0.00, 7:0.00
    agent2_pos: 2:1.00, 8:0.00, 7:0.00
    red_button_pos: 2:1.00, 8:0.00, 0:0.00
    blue_button_pos: 1:1.00, 7:0.00, 8:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 171:0.16; 172:0.16; 168:0.16; 169:0.16; 173:0.16
  Agent2 top policies: 171:0.16; 172:0.16; 168:0.16; 169:0.16; 173:0.16
. 1 2
. . .
. . .

Reward: +0.00, Result: neutral
Button pressed: red by Agent 2

--- Step 6 ---
Agent 1 joint action: 24 → (PRESS, UP)
Agent 2 joint action: 24 → (PRESS, UP)
Executed: Agent 1: PRESS, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 1:1.00, 8:0.00, 7:0.00
    agent2_pos: 2:1.00, 8:0.00, 7:0.00
    red_button_pos: 2:1.00, 8:0.00, 7:0.00
    blue_button_pos: 1:1.00, 7:0.00, 8:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 1:1.00, 8:0.00, 7:0.00
    agent2_pos: 2:1.00, 8:0.00, 7:0.00
    red_button_pos: 2:1.00, 8:0.00, 7:0.00
    blue_button_pos: 1:1.00, 7:0.00, 8:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 982:0.00; 983:0.00; 984:0.00; 985:0.00; 986:0.00
  Agent2 top policies: 982:0.00; 983:0.00; 984:0.00; 985:0.00; 986:0.00
. 1 2
. . .
. . .

Reward: +1.00, Result: win
Button pressed: blue by Agent 1

Result: ✅ WIN - win (steps: 6, reward: +1.00)

================================================================================
EPISODE 25
================================================================================
Environment: Red at (2, 0), Blue at (1, 0)

Initial state:
1 b r
. . .
. . 2


--- Step 1 ---
Agent 1 joint action: 6 → (DOWN, UP)
Agent 2 joint action: 6 → (DOWN, UP)
Executed: Agent 1: DOWN, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 0:1.00, 8:0.00, 7:0.00
    agent2_pos: 8:1.00, 0:0.00, 7:0.00
    red_button_pos: 7:0.14, 3:0.14, 6:0.14
    blue_button_pos: 7:0.14, 3:0.14, 6:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 0:1.00, 8:0.00, 7:0.00
    agent2_pos: 8:1.00, 0:0.00, 7:0.00
    red_button_pos: 7:0.14, 3:0.14, 6:0.14
    blue_button_pos: 7:0.14, 3:0.14, 6:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 244:0.02; 676:0.02; 316:0.02; 748:0.02; 677:0.01
  Agent2 top policies: 244:0.02; 676:0.02; 316:0.02; 748:0.02; 677:0.01
. b r
1 . 2
. . .

Reward: +0.00, Result: neutral

--- Step 2 ---
Agent 1 joint action: 8 → (DOWN, LEFT)
Agent 2 joint action: 8 → (DOWN, LEFT)
Executed: Agent 1: DOWN, Agent 2: LEFT
  Agent1 beliefs:
    agent1_pos: 3:1.00, 8:0.00, 5:0.00
    agent2_pos: 5:1.00, 8:0.00, 3:0.00
    red_button_pos: 7:0.20, 1:0.20, 6:0.20
    blue_button_pos: 7:0.20, 1:0.20, 6:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 3:1.00, 8:0.00, 5:0.00
    agent2_pos: 5:1.00, 8:0.00, 3:0.00
    red_button_pos: 7:0.20, 1:0.20, 6:0.20
    blue_button_pos: 7:0.20, 1:0.20, 6:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 316:0.05; 676:0.05; 244:0.05; 313:0.02; 243:0.02
  Agent2 top policies: 316:0.05; 676:0.05; 244:0.05; 313:0.02; 243:0.02
. b r
. 2 .
1 . .

Reward: +0.00, Result: neutral

--- Step 3 ---
Agent 1 joint action: 18 → (RIGHT, UP)
Agent 2 joint action: 18 → (RIGHT, UP)
Executed: Agent 1: RIGHT, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 6:1.00, 8:0.00, 5:0.00
    agent2_pos: 4:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:0.33, 1:0.33, 2:0.33
    blue_button_pos: 7:0.33, 1:0.33, 2:0.33
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 6:1.00, 8:0.00, 5:0.00
    agent2_pos: 4:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:0.33, 1:0.33, 2:0.33
    blue_button_pos: 7:0.33, 1:0.33, 2:0.33
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 676:0.28; 675:0.06; 677:0.06; 682:0.06; 658:0.06
  Agent2 top policies: 676:0.28; 675:0.06; 677:0.06; 682:0.06; 658:0.06
. 2 r
. . .
. 1 .

Reward: +0.00, Result: neutral

--- Step 4 ---
Agent 1 joint action: 3 → (UP, RIGHT)
Agent 2 joint action: 3 → (UP, RIGHT)
Executed: Agent 1: UP, Agent 2: RIGHT
  Agent1 beliefs:
    agent1_pos: 7:1.00, 8:0.00, 6:0.00
    agent2_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 2:1.00, 8:0.00, 0:0.00
    blue_button_pos: 1:1.00, 2:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 7:1.00, 8:0.00, 6:0.00
    agent2_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 2:1.00, 8:0.00, 0:0.00
    blue_button_pos: 1:1.00, 2:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 112:0.00; 352:0.00; 772:0.00; 118:0.00; 778:0.00
  Agent2 top policies: 112:0.00; 352:0.00; 772:0.00; 118:0.00; 778:0.00
. b 2
. 1 .
. . .

Reward: +0.00, Result: neutral

--- Step 5 ---
Agent 1 joint action: 4 → (UP, PRESS)
Agent 2 joint action: 4 → (UP, PRESS)
Executed: Agent 1: UP, Agent 2: PRESS
  Agent1 beliefs:
    agent1_pos: 4:1.00, 8:0.00, 7:0.00
    agent2_pos: 2:1.00, 8:0.00, 7:0.00
    red_button_pos: 2:1.00, 8:0.00, 0:0.00
    blue_button_pos: 1:1.00, 7:0.00, 8:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 4:1.00, 8:0.00, 7:0.00
    agent2_pos: 2:1.00, 8:0.00, 7:0.00
    red_button_pos: 2:1.00, 8:0.00, 0:0.00
    blue_button_pos: 1:1.00, 7:0.00, 8:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 171:0.16; 172:0.16; 168:0.16; 169:0.16; 173:0.16
  Agent2 top policies: 171:0.16; 172:0.16; 168:0.16; 169:0.16; 173:0.16
. 1 2
. . .
. . .

Reward: +0.00, Result: neutral
Button pressed: red by Agent 2

--- Step 6 ---
Agent 1 joint action: 24 → (PRESS, UP)
Agent 2 joint action: 24 → (PRESS, UP)
Executed: Agent 1: PRESS, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 1:1.00, 8:0.00, 7:0.00
    agent2_pos: 2:1.00, 8:0.00, 7:0.00
    red_button_pos: 2:1.00, 8:0.00, 7:0.00
    blue_button_pos: 1:1.00, 7:0.00, 8:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 1:1.00, 8:0.00, 7:0.00
    agent2_pos: 2:1.00, 8:0.00, 7:0.00
    red_button_pos: 2:1.00, 8:0.00, 7:0.00
    blue_button_pos: 1:1.00, 7:0.00, 8:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 982:0.00; 983:0.00; 984:0.00; 985:0.00; 986:0.00
  Agent2 top policies: 982:0.00; 983:0.00; 984:0.00; 985:0.00; 986:0.00
. 1 2
. . .
. . .

Reward: +1.00, Result: win
Button pressed: blue by Agent 1

Result: ✅ WIN - win (steps: 6, reward: +1.00)

================================================================================
EPISODE 26
================================================================================
Environment: Red at (2, 0), Blue at (1, 0)

Initial state:
1 b r
. . .
. . 2


--- Step 1 ---
Agent 1 joint action: 6 → (DOWN, UP)
Agent 2 joint action: 6 → (DOWN, UP)
Executed: Agent 1: DOWN, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 0:1.00, 8:0.00, 7:0.00
    agent2_pos: 8:1.00, 0:0.00, 7:0.00
    red_button_pos: 7:0.14, 3:0.14, 6:0.14
    blue_button_pos: 7:0.14, 3:0.14, 6:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 0:1.00, 8:0.00, 7:0.00
    agent2_pos: 8:1.00, 0:0.00, 7:0.00
    red_button_pos: 7:0.14, 3:0.14, 6:0.14
    blue_button_pos: 7:0.14, 3:0.14, 6:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 244:0.02; 676:0.02; 316:0.02; 748:0.02; 677:0.01
  Agent2 top policies: 244:0.02; 676:0.02; 316:0.02; 748:0.02; 677:0.01
. b r
1 . 2
. . .

Reward: +0.00, Result: neutral

--- Step 2 ---
Agent 1 joint action: 8 → (DOWN, LEFT)
Agent 2 joint action: 8 → (DOWN, LEFT)
Executed: Agent 1: DOWN, Agent 2: LEFT
  Agent1 beliefs:
    agent1_pos: 3:1.00, 8:0.00, 5:0.00
    agent2_pos: 5:1.00, 8:0.00, 3:0.00
    red_button_pos: 7:0.20, 1:0.20, 6:0.20
    blue_button_pos: 7:0.20, 1:0.20, 6:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 3:1.00, 8:0.00, 5:0.00
    agent2_pos: 5:1.00, 8:0.00, 3:0.00
    red_button_pos: 7:0.20, 1:0.20, 6:0.20
    blue_button_pos: 7:0.20, 1:0.20, 6:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 316:0.05; 676:0.05; 244:0.05; 313:0.02; 243:0.02
  Agent2 top policies: 316:0.05; 676:0.05; 244:0.05; 313:0.02; 243:0.02
. b r
. 2 .
1 . .

Reward: +0.00, Result: neutral

--- Step 3 ---
Agent 1 joint action: 18 → (RIGHT, UP)
Agent 2 joint action: 18 → (RIGHT, UP)
Executed: Agent 1: RIGHT, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 6:1.00, 8:0.00, 5:0.00
    agent2_pos: 4:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:0.33, 1:0.33, 2:0.33
    blue_button_pos: 7:0.33, 1:0.33, 2:0.33
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 6:1.00, 8:0.00, 5:0.00
    agent2_pos: 4:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:0.33, 1:0.33, 2:0.33
    blue_button_pos: 7:0.33, 1:0.33, 2:0.33
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 676:0.28; 675:0.06; 677:0.06; 682:0.06; 658:0.06
  Agent2 top policies: 676:0.28; 675:0.06; 677:0.06; 682:0.06; 658:0.06
. 2 r
. . .
. 1 .

Reward: +0.00, Result: neutral

--- Step 4 ---
Agent 1 joint action: 3 → (UP, RIGHT)
Agent 2 joint action: 3 → (UP, RIGHT)
Executed: Agent 1: UP, Agent 2: RIGHT
  Agent1 beliefs:
    agent1_pos: 7:1.00, 8:0.00, 6:0.00
    agent2_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 2:1.00, 8:0.00, 0:0.00
    blue_button_pos: 1:1.00, 2:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 7:1.00, 8:0.00, 6:0.00
    agent2_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 2:1.00, 8:0.00, 0:0.00
    blue_button_pos: 1:1.00, 2:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 112:0.00; 352:0.00; 772:0.00; 118:0.00; 778:0.00
  Agent2 top policies: 112:0.00; 352:0.00; 772:0.00; 118:0.00; 778:0.00
. b 2
. 1 .
. . .

Reward: +0.00, Result: neutral

--- Step 5 ---
Agent 1 joint action: 4 → (UP, PRESS)
Agent 2 joint action: 4 → (UP, PRESS)
Executed: Agent 1: UP, Agent 2: PRESS
  Agent1 beliefs:
    agent1_pos: 4:1.00, 8:0.00, 7:0.00
    agent2_pos: 2:1.00, 8:0.00, 7:0.00
    red_button_pos: 2:1.00, 8:0.00, 0:0.00
    blue_button_pos: 1:1.00, 7:0.00, 8:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 4:1.00, 8:0.00, 7:0.00
    agent2_pos: 2:1.00, 8:0.00, 7:0.00
    red_button_pos: 2:1.00, 8:0.00, 0:0.00
    blue_button_pos: 1:1.00, 7:0.00, 8:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 171:0.16; 172:0.16; 168:0.16; 169:0.16; 173:0.16
  Agent2 top policies: 171:0.16; 172:0.16; 168:0.16; 169:0.16; 173:0.16
. 1 2
. . .
. . .

Reward: +0.00, Result: neutral
Button pressed: red by Agent 2

--- Step 6 ---
Agent 1 joint action: 24 → (PRESS, UP)
Agent 2 joint action: 24 → (PRESS, UP)
Executed: Agent 1: PRESS, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 1:1.00, 8:0.00, 7:0.00
    agent2_pos: 2:1.00, 8:0.00, 7:0.00
    red_button_pos: 2:1.00, 8:0.00, 7:0.00
    blue_button_pos: 1:1.00, 7:0.00, 8:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 1:1.00, 8:0.00, 7:0.00
    agent2_pos: 2:1.00, 8:0.00, 7:0.00
    red_button_pos: 2:1.00, 8:0.00, 7:0.00
    blue_button_pos: 1:1.00, 7:0.00, 8:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 982:0.00; 983:0.00; 984:0.00; 985:0.00; 986:0.00
  Agent2 top policies: 982:0.00; 983:0.00; 984:0.00; 985:0.00; 986:0.00
. 1 2
. . .
. . .

Reward: +1.00, Result: win
Button pressed: blue by Agent 1

Result: ✅ WIN - win (steps: 6, reward: +1.00)

================================================================================
EPISODE 27
================================================================================
Environment: Red at (2, 0), Blue at (1, 0)

Initial state:
1 b r
. . .
. . 2


--- Step 1 ---
Agent 1 joint action: 6 → (DOWN, UP)
Agent 2 joint action: 6 → (DOWN, UP)
Executed: Agent 1: DOWN, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 0:1.00, 8:0.00, 7:0.00
    agent2_pos: 8:1.00, 0:0.00, 7:0.00
    red_button_pos: 7:0.14, 3:0.14, 6:0.14
    blue_button_pos: 7:0.14, 3:0.14, 6:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 0:1.00, 8:0.00, 7:0.00
    agent2_pos: 8:1.00, 0:0.00, 7:0.00
    red_button_pos: 7:0.14, 3:0.14, 6:0.14
    blue_button_pos: 7:0.14, 3:0.14, 6:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 244:0.02; 676:0.02; 316:0.02; 748:0.02; 677:0.01
  Agent2 top policies: 244:0.02; 676:0.02; 316:0.02; 748:0.02; 677:0.01
. b r
1 . 2
. . .

Reward: +0.00, Result: neutral

--- Step 2 ---
Agent 1 joint action: 8 → (DOWN, LEFT)
Agent 2 joint action: 8 → (DOWN, LEFT)
Executed: Agent 1: DOWN, Agent 2: LEFT
  Agent1 beliefs:
    agent1_pos: 3:1.00, 8:0.00, 5:0.00
    agent2_pos: 5:1.00, 8:0.00, 3:0.00
    red_button_pos: 7:0.20, 1:0.20, 6:0.20
    blue_button_pos: 7:0.20, 1:0.20, 6:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 3:1.00, 8:0.00, 5:0.00
    agent2_pos: 5:1.00, 8:0.00, 3:0.00
    red_button_pos: 7:0.20, 1:0.20, 6:0.20
    blue_button_pos: 7:0.20, 1:0.20, 6:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 316:0.05; 676:0.05; 244:0.05; 313:0.02; 243:0.02
  Agent2 top policies: 316:0.05; 676:0.05; 244:0.05; 313:0.02; 243:0.02
. b r
. 2 .
1 . .

Reward: +0.00, Result: neutral

--- Step 3 ---
Agent 1 joint action: 18 → (RIGHT, UP)
Agent 2 joint action: 18 → (RIGHT, UP)
Executed: Agent 1: RIGHT, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 6:1.00, 8:0.00, 5:0.00
    agent2_pos: 4:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:0.33, 1:0.33, 2:0.33
    blue_button_pos: 7:0.33, 1:0.33, 2:0.33
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 6:1.00, 8:0.00, 5:0.00
    agent2_pos: 4:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:0.33, 1:0.33, 2:0.33
    blue_button_pos: 7:0.33, 1:0.33, 2:0.33
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 676:0.28; 675:0.06; 677:0.06; 682:0.06; 658:0.06
  Agent2 top policies: 676:0.28; 675:0.06; 677:0.06; 682:0.06; 658:0.06
. 2 r
. . .
. 1 .

Reward: +0.00, Result: neutral

--- Step 4 ---
Agent 1 joint action: 3 → (UP, RIGHT)
Agent 2 joint action: 3 → (UP, RIGHT)
Executed: Agent 1: UP, Agent 2: RIGHT
  Agent1 beliefs:
    agent1_pos: 7:1.00, 8:0.00, 6:0.00
    agent2_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 2:1.00, 8:0.00, 0:0.00
    blue_button_pos: 1:1.00, 2:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 7:1.00, 8:0.00, 6:0.00
    agent2_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 2:1.00, 8:0.00, 0:0.00
    blue_button_pos: 1:1.00, 2:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 112:0.00; 352:0.00; 772:0.00; 118:0.00; 778:0.00
  Agent2 top policies: 112:0.00; 352:0.00; 772:0.00; 118:0.00; 778:0.00
. b 2
. 1 .
. . .

Reward: +0.00, Result: neutral

--- Step 5 ---
Agent 1 joint action: 4 → (UP, PRESS)
Agent 2 joint action: 4 → (UP, PRESS)
Executed: Agent 1: UP, Agent 2: PRESS
  Agent1 beliefs:
    agent1_pos: 4:1.00, 8:0.00, 7:0.00
    agent2_pos: 2:1.00, 8:0.00, 7:0.00
    red_button_pos: 2:1.00, 8:0.00, 0:0.00
    blue_button_pos: 1:1.00, 7:0.00, 8:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 4:1.00, 8:0.00, 7:0.00
    agent2_pos: 2:1.00, 8:0.00, 7:0.00
    red_button_pos: 2:1.00, 8:0.00, 0:0.00
    blue_button_pos: 1:1.00, 7:0.00, 8:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 171:0.16; 172:0.16; 168:0.16; 169:0.16; 173:0.16
  Agent2 top policies: 171:0.16; 172:0.16; 168:0.16; 169:0.16; 173:0.16
. 1 2
. . .
. . .

Reward: +0.00, Result: neutral
Button pressed: red by Agent 2

--- Step 6 ---
Agent 1 joint action: 24 → (PRESS, UP)
Agent 2 joint action: 24 → (PRESS, UP)
Executed: Agent 1: PRESS, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 1:1.00, 8:0.00, 7:0.00
    agent2_pos: 2:1.00, 8:0.00, 7:0.00
    red_button_pos: 2:1.00, 8:0.00, 7:0.00
    blue_button_pos: 1:1.00, 7:0.00, 8:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 1:1.00, 8:0.00, 7:0.00
    agent2_pos: 2:1.00, 8:0.00, 7:0.00
    red_button_pos: 2:1.00, 8:0.00, 7:0.00
    blue_button_pos: 1:1.00, 7:0.00, 8:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 982:0.00; 983:0.00; 984:0.00; 985:0.00; 986:0.00
  Agent2 top policies: 982:0.00; 983:0.00; 984:0.00; 985:0.00; 986:0.00
. 1 2
. . .
. . .

Reward: +1.00, Result: win
Button pressed: blue by Agent 1

Result: ✅ WIN - win (steps: 6, reward: +1.00)

================================================================================
EPISODE 28
================================================================================
Environment: Red at (2, 0), Blue at (1, 0)

Initial state:
1 b r
. . .
. . 2


--- Step 1 ---
Agent 1 joint action: 6 → (DOWN, UP)
Agent 2 joint action: 6 → (DOWN, UP)
Executed: Agent 1: DOWN, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 0:1.00, 8:0.00, 7:0.00
    agent2_pos: 8:1.00, 0:0.00, 7:0.00
    red_button_pos: 7:0.14, 3:0.14, 6:0.14
    blue_button_pos: 7:0.14, 3:0.14, 6:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 0:1.00, 8:0.00, 7:0.00
    agent2_pos: 8:1.00, 0:0.00, 7:0.00
    red_button_pos: 7:0.14, 3:0.14, 6:0.14
    blue_button_pos: 7:0.14, 3:0.14, 6:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 244:0.02; 676:0.02; 316:0.02; 748:0.02; 677:0.01
  Agent2 top policies: 244:0.02; 676:0.02; 316:0.02; 748:0.02; 677:0.01
. b r
1 . 2
. . .

Reward: +0.00, Result: neutral

--- Step 2 ---
Agent 1 joint action: 8 → (DOWN, LEFT)
Agent 2 joint action: 8 → (DOWN, LEFT)
Executed: Agent 1: DOWN, Agent 2: LEFT
  Agent1 beliefs:
    agent1_pos: 3:1.00, 8:0.00, 5:0.00
    agent2_pos: 5:1.00, 8:0.00, 3:0.00
    red_button_pos: 7:0.20, 1:0.20, 6:0.20
    blue_button_pos: 7:0.20, 1:0.20, 6:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 3:1.00, 8:0.00, 5:0.00
    agent2_pos: 5:1.00, 8:0.00, 3:0.00
    red_button_pos: 7:0.20, 1:0.20, 6:0.20
    blue_button_pos: 7:0.20, 1:0.20, 6:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 316:0.05; 676:0.05; 244:0.05; 313:0.02; 243:0.02
  Agent2 top policies: 316:0.05; 676:0.05; 244:0.05; 313:0.02; 243:0.02
. b r
. 2 .
1 . .

Reward: +0.00, Result: neutral

--- Step 3 ---
Agent 1 joint action: 18 → (RIGHT, UP)
Agent 2 joint action: 18 → (RIGHT, UP)
Executed: Agent 1: RIGHT, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 6:1.00, 8:0.00, 5:0.00
    agent2_pos: 4:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:0.33, 1:0.33, 2:0.33
    blue_button_pos: 7:0.33, 1:0.33, 2:0.33
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 6:1.00, 8:0.00, 5:0.00
    agent2_pos: 4:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:0.33, 1:0.33, 2:0.33
    blue_button_pos: 7:0.33, 1:0.33, 2:0.33
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 676:0.28; 675:0.06; 677:0.06; 682:0.06; 658:0.06
  Agent2 top policies: 676:0.28; 675:0.06; 677:0.06; 682:0.06; 658:0.06
. 2 r
. . .
. 1 .

Reward: +0.00, Result: neutral

--- Step 4 ---
Agent 1 joint action: 3 → (UP, RIGHT)
Agent 2 joint action: 3 → (UP, RIGHT)
Executed: Agent 1: UP, Agent 2: RIGHT
  Agent1 beliefs:
    agent1_pos: 7:1.00, 8:0.00, 6:0.00
    agent2_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 2:1.00, 8:0.00, 0:0.00
    blue_button_pos: 1:1.00, 2:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 7:1.00, 8:0.00, 6:0.00
    agent2_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 2:1.00, 8:0.00, 0:0.00
    blue_button_pos: 1:1.00, 2:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 112:0.00; 352:0.00; 772:0.00; 118:0.00; 778:0.00
  Agent2 top policies: 112:0.00; 352:0.00; 772:0.00; 118:0.00; 778:0.00
. b 2
. 1 .
. . .

Reward: +0.00, Result: neutral

--- Step 5 ---
Agent 1 joint action: 4 → (UP, PRESS)
Agent 2 joint action: 4 → (UP, PRESS)
Executed: Agent 1: UP, Agent 2: PRESS
  Agent1 beliefs:
    agent1_pos: 4:1.00, 8:0.00, 7:0.00
    agent2_pos: 2:1.00, 8:0.00, 7:0.00
    red_button_pos: 2:1.00, 8:0.00, 0:0.00
    blue_button_pos: 1:1.00, 7:0.00, 8:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 4:1.00, 8:0.00, 7:0.00
    agent2_pos: 2:1.00, 8:0.00, 7:0.00
    red_button_pos: 2:1.00, 8:0.00, 0:0.00
    blue_button_pos: 1:1.00, 7:0.00, 8:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 171:0.16; 172:0.16; 168:0.16; 169:0.16; 173:0.16
  Agent2 top policies: 171:0.16; 172:0.16; 168:0.16; 169:0.16; 173:0.16
. 1 2
. . .
. . .

Reward: +0.00, Result: neutral
Button pressed: red by Agent 2

--- Step 6 ---
Agent 1 joint action: 24 → (PRESS, UP)
Agent 2 joint action: 24 → (PRESS, UP)
Executed: Agent 1: PRESS, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 1:1.00, 8:0.00, 7:0.00
    agent2_pos: 2:1.00, 8:0.00, 7:0.00
    red_button_pos: 2:1.00, 8:0.00, 7:0.00
    blue_button_pos: 1:1.00, 7:0.00, 8:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 1:1.00, 8:0.00, 7:0.00
    agent2_pos: 2:1.00, 8:0.00, 7:0.00
    red_button_pos: 2:1.00, 8:0.00, 7:0.00
    blue_button_pos: 1:1.00, 7:0.00, 8:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 982:0.00; 983:0.00; 984:0.00; 985:0.00; 986:0.00
  Agent2 top policies: 982:0.00; 983:0.00; 984:0.00; 985:0.00; 986:0.00
. 1 2
. . .
. . .

Reward: +1.00, Result: win
Button pressed: blue by Agent 1

Result: ✅ WIN - win (steps: 6, reward: +1.00)

================================================================================
EPISODE 29
================================================================================
Environment: Red at (2, 0), Blue at (1, 0)

Initial state:
1 b r
. . .
. . 2


--- Step 1 ---
Agent 1 joint action: 6 → (DOWN, UP)
Agent 2 joint action: 6 → (DOWN, UP)
Executed: Agent 1: DOWN, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 0:1.00, 8:0.00, 7:0.00
    agent2_pos: 8:1.00, 0:0.00, 7:0.00
    red_button_pos: 7:0.14, 3:0.14, 6:0.14
    blue_button_pos: 7:0.14, 3:0.14, 6:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 0:1.00, 8:0.00, 7:0.00
    agent2_pos: 8:1.00, 0:0.00, 7:0.00
    red_button_pos: 7:0.14, 3:0.14, 6:0.14
    blue_button_pos: 7:0.14, 3:0.14, 6:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 244:0.02; 676:0.02; 316:0.02; 748:0.02; 677:0.01
  Agent2 top policies: 244:0.02; 676:0.02; 316:0.02; 748:0.02; 677:0.01
. b r
1 . 2
. . .

Reward: +0.00, Result: neutral

--- Step 2 ---
Agent 1 joint action: 8 → (DOWN, LEFT)
Agent 2 joint action: 8 → (DOWN, LEFT)
Executed: Agent 1: DOWN, Agent 2: LEFT
  Agent1 beliefs:
    agent1_pos: 3:1.00, 8:0.00, 5:0.00
    agent2_pos: 5:1.00, 8:0.00, 3:0.00
    red_button_pos: 7:0.20, 1:0.20, 6:0.20
    blue_button_pos: 7:0.20, 1:0.20, 6:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 3:1.00, 8:0.00, 5:0.00
    agent2_pos: 5:1.00, 8:0.00, 3:0.00
    red_button_pos: 7:0.20, 1:0.20, 6:0.20
    blue_button_pos: 7:0.20, 1:0.20, 6:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 316:0.05; 676:0.05; 244:0.05; 313:0.02; 243:0.02
  Agent2 top policies: 316:0.05; 676:0.05; 244:0.05; 313:0.02; 243:0.02
. b r
. 2 .
1 . .

Reward: +0.00, Result: neutral

--- Step 3 ---
Agent 1 joint action: 18 → (RIGHT, UP)
Agent 2 joint action: 18 → (RIGHT, UP)
Executed: Agent 1: RIGHT, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 6:1.00, 8:0.00, 5:0.00
    agent2_pos: 4:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:0.33, 1:0.33, 2:0.33
    blue_button_pos: 7:0.33, 1:0.33, 2:0.33
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 6:1.00, 8:0.00, 5:0.00
    agent2_pos: 4:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:0.33, 1:0.33, 2:0.33
    blue_button_pos: 7:0.33, 1:0.33, 2:0.33
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 676:0.28; 675:0.06; 677:0.06; 682:0.06; 658:0.06
  Agent2 top policies: 676:0.28; 675:0.06; 677:0.06; 682:0.06; 658:0.06
. 2 r
. . .
. 1 .

Reward: +0.00, Result: neutral

--- Step 4 ---
Agent 1 joint action: 3 → (UP, RIGHT)
Agent 2 joint action: 3 → (UP, RIGHT)
Executed: Agent 1: UP, Agent 2: RIGHT
  Agent1 beliefs:
    agent1_pos: 7:1.00, 8:0.00, 6:0.00
    agent2_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 2:1.00, 8:0.00, 0:0.00
    blue_button_pos: 1:1.00, 2:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 7:1.00, 8:0.00, 6:0.00
    agent2_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 2:1.00, 8:0.00, 0:0.00
    blue_button_pos: 1:1.00, 2:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 112:0.00; 352:0.00; 772:0.00; 118:0.00; 778:0.00
  Agent2 top policies: 112:0.00; 352:0.00; 772:0.00; 118:0.00; 778:0.00
. b 2
. 1 .
. . .

Reward: +0.00, Result: neutral

--- Step 5 ---
Agent 1 joint action: 4 → (UP, PRESS)
Agent 2 joint action: 4 → (UP, PRESS)
Executed: Agent 1: UP, Agent 2: PRESS
  Agent1 beliefs:
    agent1_pos: 4:1.00, 8:0.00, 7:0.00
    agent2_pos: 2:1.00, 8:0.00, 7:0.00
    red_button_pos: 2:1.00, 8:0.00, 0:0.00
    blue_button_pos: 1:1.00, 7:0.00, 8:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 4:1.00, 8:0.00, 7:0.00
    agent2_pos: 2:1.00, 8:0.00, 7:0.00
    red_button_pos: 2:1.00, 8:0.00, 0:0.00
    blue_button_pos: 1:1.00, 7:0.00, 8:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 171:0.16; 172:0.16; 168:0.16; 169:0.16; 173:0.16
  Agent2 top policies: 171:0.16; 172:0.16; 168:0.16; 169:0.16; 173:0.16
. 1 2
. . .
. . .

Reward: +0.00, Result: neutral
Button pressed: red by Agent 2

--- Step 6 ---
Agent 1 joint action: 24 → (PRESS, UP)
Agent 2 joint action: 24 → (PRESS, UP)
Executed: Agent 1: PRESS, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 1:1.00, 8:0.00, 7:0.00
    agent2_pos: 2:1.00, 8:0.00, 7:0.00
    red_button_pos: 2:1.00, 8:0.00, 7:0.00
    blue_button_pos: 1:1.00, 7:0.00, 8:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 1:1.00, 8:0.00, 7:0.00
    agent2_pos: 2:1.00, 8:0.00, 7:0.00
    red_button_pos: 2:1.00, 8:0.00, 7:0.00
    blue_button_pos: 1:1.00, 7:0.00, 8:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 982:0.00; 983:0.00; 984:0.00; 985:0.00; 986:0.00
  Agent2 top policies: 982:0.00; 983:0.00; 984:0.00; 985:0.00; 986:0.00
. 1 2
. . .
. . .

Reward: +1.00, Result: win
Button pressed: blue by Agent 1

Result: ✅ WIN - win (steps: 6, reward: +1.00)

================================================================================
EPISODE 30
================================================================================
Environment: Red at (2, 0), Blue at (1, 0)

Initial state:
1 b r
. . .
. . 2


--- Step 1 ---
Agent 1 joint action: 6 → (DOWN, UP)
Agent 2 joint action: 6 → (DOWN, UP)
Executed: Agent 1: DOWN, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 0:1.00, 8:0.00, 7:0.00
    agent2_pos: 8:1.00, 0:0.00, 7:0.00
    red_button_pos: 7:0.14, 3:0.14, 6:0.14
    blue_button_pos: 7:0.14, 3:0.14, 6:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 0:1.00, 8:0.00, 7:0.00
    agent2_pos: 8:1.00, 0:0.00, 7:0.00
    red_button_pos: 7:0.14, 3:0.14, 6:0.14
    blue_button_pos: 7:0.14, 3:0.14, 6:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 244:0.02; 676:0.02; 316:0.02; 748:0.02; 677:0.01
  Agent2 top policies: 244:0.02; 676:0.02; 316:0.02; 748:0.02; 677:0.01
. b r
1 . 2
. . .

Reward: +0.00, Result: neutral

--- Step 2 ---
Agent 1 joint action: 8 → (DOWN, LEFT)
Agent 2 joint action: 8 → (DOWN, LEFT)
Executed: Agent 1: DOWN, Agent 2: LEFT
  Agent1 beliefs:
    agent1_pos: 3:1.00, 8:0.00, 5:0.00
    agent2_pos: 5:1.00, 8:0.00, 3:0.00
    red_button_pos: 7:0.20, 1:0.20, 6:0.20
    blue_button_pos: 7:0.20, 1:0.20, 6:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 3:1.00, 8:0.00, 5:0.00
    agent2_pos: 5:1.00, 8:0.00, 3:0.00
    red_button_pos: 7:0.20, 1:0.20, 6:0.20
    blue_button_pos: 7:0.20, 1:0.20, 6:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 316:0.05; 676:0.05; 244:0.05; 313:0.02; 243:0.02
  Agent2 top policies: 316:0.05; 676:0.05; 244:0.05; 313:0.02; 243:0.02
. b r
. 2 .
1 . .

Reward: +0.00, Result: neutral

--- Step 3 ---
Agent 1 joint action: 18 → (RIGHT, UP)
Agent 2 joint action: 18 → (RIGHT, UP)
Executed: Agent 1: RIGHT, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 6:1.00, 8:0.00, 5:0.00
    agent2_pos: 4:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:0.33, 1:0.33, 2:0.33
    blue_button_pos: 7:0.33, 1:0.33, 2:0.33
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 6:1.00, 8:0.00, 5:0.00
    agent2_pos: 4:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:0.33, 1:0.33, 2:0.33
    blue_button_pos: 7:0.33, 1:0.33, 2:0.33
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 676:0.28; 675:0.06; 677:0.06; 682:0.06; 658:0.06
  Agent2 top policies: 676:0.28; 675:0.06; 677:0.06; 682:0.06; 658:0.06
. 2 r
. . .
. 1 .

Reward: +0.00, Result: neutral

--- Step 4 ---
Agent 1 joint action: 3 → (UP, RIGHT)
Agent 2 joint action: 3 → (UP, RIGHT)
Executed: Agent 1: UP, Agent 2: RIGHT
  Agent1 beliefs:
    agent1_pos: 7:1.00, 8:0.00, 6:0.00
    agent2_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 2:1.00, 8:0.00, 0:0.00
    blue_button_pos: 1:1.00, 2:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 7:1.00, 8:0.00, 6:0.00
    agent2_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 2:1.00, 8:0.00, 0:0.00
    blue_button_pos: 1:1.00, 2:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 112:0.00; 352:0.00; 772:0.00; 118:0.00; 778:0.00
  Agent2 top policies: 112:0.00; 352:0.00; 772:0.00; 118:0.00; 778:0.00
. b 2
. 1 .
. . .

Reward: +0.00, Result: neutral

--- Step 5 ---
Agent 1 joint action: 4 → (UP, PRESS)
Agent 2 joint action: 4 → (UP, PRESS)
Executed: Agent 1: UP, Agent 2: PRESS
  Agent1 beliefs:
    agent1_pos: 4:1.00, 8:0.00, 7:0.00
    agent2_pos: 2:1.00, 8:0.00, 7:0.00
    red_button_pos: 2:1.00, 8:0.00, 0:0.00
    blue_button_pos: 1:1.00, 7:0.00, 8:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 4:1.00, 8:0.00, 7:0.00
    agent2_pos: 2:1.00, 8:0.00, 7:0.00
    red_button_pos: 2:1.00, 8:0.00, 0:0.00
    blue_button_pos: 1:1.00, 7:0.00, 8:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 171:0.16; 172:0.16; 168:0.16; 169:0.16; 173:0.16
  Agent2 top policies: 171:0.16; 172:0.16; 168:0.16; 169:0.16; 173:0.16
. 1 2
. . .
. . .

Reward: +0.00, Result: neutral
Button pressed: red by Agent 2

--- Step 6 ---
Agent 1 joint action: 24 → (PRESS, UP)
Agent 2 joint action: 24 → (PRESS, UP)
Executed: Agent 1: PRESS, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 1:1.00, 8:0.00, 7:0.00
    agent2_pos: 2:1.00, 8:0.00, 7:0.00
    red_button_pos: 2:1.00, 8:0.00, 7:0.00
    blue_button_pos: 1:1.00, 7:0.00, 8:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 1:1.00, 8:0.00, 7:0.00
    agent2_pos: 2:1.00, 8:0.00, 7:0.00
    red_button_pos: 2:1.00, 8:0.00, 7:0.00
    blue_button_pos: 1:1.00, 7:0.00, 8:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 982:0.00; 983:0.00; 984:0.00; 985:0.00; 986:0.00
  Agent2 top policies: 982:0.00; 983:0.00; 984:0.00; 985:0.00; 986:0.00
. 1 2
. . .
. . .

Reward: +1.00, Result: win
Button pressed: blue by Agent 1

Result: ✅ WIN - win (steps: 6, reward: +1.00)

================================================================================
EPISODE 31
================================================================================
Environment: Red at (2, 0), Blue at (1, 0)

Initial state:
1 b r
. . .
. . 2


--- Step 1 ---
Agent 1 joint action: 6 → (DOWN, UP)
Agent 2 joint action: 6 → (DOWN, UP)
Executed: Agent 1: DOWN, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 0:1.00, 8:0.00, 7:0.00
    agent2_pos: 8:1.00, 0:0.00, 7:0.00
    red_button_pos: 7:0.14, 3:0.14, 6:0.14
    blue_button_pos: 7:0.14, 3:0.14, 6:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 0:1.00, 8:0.00, 7:0.00
    agent2_pos: 8:1.00, 0:0.00, 7:0.00
    red_button_pos: 7:0.14, 3:0.14, 6:0.14
    blue_button_pos: 7:0.14, 3:0.14, 6:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 244:0.02; 676:0.02; 316:0.02; 748:0.02; 677:0.01
  Agent2 top policies: 244:0.02; 676:0.02; 316:0.02; 748:0.02; 677:0.01
. b r
1 . 2
. . .

Reward: +0.00, Result: neutral

--- Step 2 ---
Agent 1 joint action: 8 → (DOWN, LEFT)
Agent 2 joint action: 8 → (DOWN, LEFT)
Executed: Agent 1: DOWN, Agent 2: LEFT
  Agent1 beliefs:
    agent1_pos: 3:1.00, 8:0.00, 5:0.00
    agent2_pos: 5:1.00, 8:0.00, 3:0.00
    red_button_pos: 7:0.20, 1:0.20, 6:0.20
    blue_button_pos: 7:0.20, 1:0.20, 6:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 3:1.00, 8:0.00, 5:0.00
    agent2_pos: 5:1.00, 8:0.00, 3:0.00
    red_button_pos: 7:0.20, 1:0.20, 6:0.20
    blue_button_pos: 7:0.20, 1:0.20, 6:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 316:0.05; 676:0.05; 244:0.05; 313:0.02; 243:0.02
  Agent2 top policies: 316:0.05; 676:0.05; 244:0.05; 313:0.02; 243:0.02
. b r
. 2 .
1 . .

Reward: +0.00, Result: neutral

--- Step 3 ---
Agent 1 joint action: 18 → (RIGHT, UP)
Agent 2 joint action: 18 → (RIGHT, UP)
Executed: Agent 1: RIGHT, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 6:1.00, 8:0.00, 5:0.00
    agent2_pos: 4:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:0.33, 1:0.33, 2:0.33
    blue_button_pos: 7:0.33, 1:0.33, 2:0.33
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 6:1.00, 8:0.00, 5:0.00
    agent2_pos: 4:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:0.33, 1:0.33, 2:0.33
    blue_button_pos: 7:0.33, 1:0.33, 2:0.33
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 676:0.28; 675:0.06; 677:0.06; 682:0.06; 658:0.06
  Agent2 top policies: 676:0.28; 675:0.06; 677:0.06; 682:0.06; 658:0.06
. 2 r
. . .
. 1 .

Reward: +0.00, Result: neutral

--- Step 4 ---
Agent 1 joint action: 3 → (UP, RIGHT)
Agent 2 joint action: 3 → (UP, RIGHT)
Executed: Agent 1: UP, Agent 2: RIGHT
  Agent1 beliefs:
    agent1_pos: 7:1.00, 8:0.00, 6:0.00
    agent2_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 2:1.00, 8:0.00, 0:0.00
    blue_button_pos: 1:1.00, 2:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 7:1.00, 8:0.00, 6:0.00
    agent2_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 2:1.00, 8:0.00, 0:0.00
    blue_button_pos: 1:1.00, 2:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 112:0.00; 352:0.00; 772:0.00; 118:0.00; 778:0.00
  Agent2 top policies: 112:0.00; 352:0.00; 772:0.00; 118:0.00; 778:0.00
. b 2
. 1 .
. . .

Reward: +0.00, Result: neutral

--- Step 5 ---
Agent 1 joint action: 4 → (UP, PRESS)
Agent 2 joint action: 4 → (UP, PRESS)
Executed: Agent 1: UP, Agent 2: PRESS
  Agent1 beliefs:
    agent1_pos: 4:1.00, 8:0.00, 7:0.00
    agent2_pos: 2:1.00, 8:0.00, 7:0.00
    red_button_pos: 2:1.00, 8:0.00, 0:0.00
    blue_button_pos: 1:1.00, 7:0.00, 8:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 4:1.00, 8:0.00, 7:0.00
    agent2_pos: 2:1.00, 8:0.00, 7:0.00
    red_button_pos: 2:1.00, 8:0.00, 0:0.00
    blue_button_pos: 1:1.00, 7:0.00, 8:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 171:0.16; 172:0.16; 168:0.16; 169:0.16; 173:0.16
  Agent2 top policies: 171:0.16; 172:0.16; 168:0.16; 169:0.16; 173:0.16
. 1 2
. . .
. . .

Reward: +0.00, Result: neutral
Button pressed: red by Agent 2

--- Step 6 ---
Agent 1 joint action: 24 → (PRESS, UP)
Agent 2 joint action: 24 → (PRESS, UP)
Executed: Agent 1: PRESS, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 1:1.00, 8:0.00, 7:0.00
    agent2_pos: 2:1.00, 8:0.00, 7:0.00
    red_button_pos: 2:1.00, 8:0.00, 7:0.00
    blue_button_pos: 1:1.00, 7:0.00, 8:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 1:1.00, 8:0.00, 7:0.00
    agent2_pos: 2:1.00, 8:0.00, 7:0.00
    red_button_pos: 2:1.00, 8:0.00, 7:0.00
    blue_button_pos: 1:1.00, 7:0.00, 8:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 982:0.00; 983:0.00; 984:0.00; 985:0.00; 986:0.00
  Agent2 top policies: 982:0.00; 983:0.00; 984:0.00; 985:0.00; 986:0.00
. 1 2
. . .
. . .

Reward: +1.00, Result: win
Button pressed: blue by Agent 1

Result: ✅ WIN - win (steps: 6, reward: +1.00)

================================================================================
EPISODE 32
================================================================================
Environment: Red at (2, 0), Blue at (1, 0)

Initial state:
1 b r
. . .
. . 2


--- Step 1 ---
Agent 1 joint action: 6 → (DOWN, UP)
Agent 2 joint action: 6 → (DOWN, UP)
Executed: Agent 1: DOWN, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 0:1.00, 8:0.00, 7:0.00
    agent2_pos: 8:1.00, 0:0.00, 7:0.00
    red_button_pos: 7:0.14, 3:0.14, 6:0.14
    blue_button_pos: 7:0.14, 3:0.14, 6:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 0:1.00, 8:0.00, 7:0.00
    agent2_pos: 8:1.00, 0:0.00, 7:0.00
    red_button_pos: 7:0.14, 3:0.14, 6:0.14
    blue_button_pos: 7:0.14, 3:0.14, 6:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 244:0.02; 676:0.02; 316:0.02; 748:0.02; 677:0.01
  Agent2 top policies: 244:0.02; 676:0.02; 316:0.02; 748:0.02; 677:0.01
. b r
1 . 2
. . .

Reward: +0.00, Result: neutral

--- Step 2 ---
Agent 1 joint action: 8 → (DOWN, LEFT)
Agent 2 joint action: 8 → (DOWN, LEFT)
Executed: Agent 1: DOWN, Agent 2: LEFT
  Agent1 beliefs:
    agent1_pos: 3:1.00, 8:0.00, 5:0.00
    agent2_pos: 5:1.00, 8:0.00, 3:0.00
    red_button_pos: 7:0.20, 1:0.20, 6:0.20
    blue_button_pos: 7:0.20, 1:0.20, 6:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 3:1.00, 8:0.00, 5:0.00
    agent2_pos: 5:1.00, 8:0.00, 3:0.00
    red_button_pos: 7:0.20, 1:0.20, 6:0.20
    blue_button_pos: 7:0.20, 1:0.20, 6:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 316:0.05; 676:0.05; 244:0.05; 313:0.02; 243:0.02
  Agent2 top policies: 316:0.05; 676:0.05; 244:0.05; 313:0.02; 243:0.02
. b r
. 2 .
1 . .

Reward: +0.00, Result: neutral

--- Step 3 ---
Agent 1 joint action: 18 → (RIGHT, UP)
Agent 2 joint action: 18 → (RIGHT, UP)
Executed: Agent 1: RIGHT, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 6:1.00, 8:0.00, 5:0.00
    agent2_pos: 4:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:0.33, 1:0.33, 2:0.33
    blue_button_pos: 7:0.33, 1:0.33, 2:0.33
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 6:1.00, 8:0.00, 5:0.00
    agent2_pos: 4:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:0.33, 1:0.33, 2:0.33
    blue_button_pos: 7:0.33, 1:0.33, 2:0.33
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 676:0.28; 675:0.06; 677:0.06; 682:0.06; 658:0.06
  Agent2 top policies: 676:0.28; 675:0.06; 677:0.06; 682:0.06; 658:0.06
. 2 r
. . .
. 1 .

Reward: +0.00, Result: neutral

--- Step 4 ---
Agent 1 joint action: 3 → (UP, RIGHT)
Agent 2 joint action: 3 → (UP, RIGHT)
Executed: Agent 1: UP, Agent 2: RIGHT
  Agent1 beliefs:
    agent1_pos: 7:1.00, 8:0.00, 6:0.00
    agent2_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 2:1.00, 8:0.00, 0:0.00
    blue_button_pos: 1:1.00, 2:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 7:1.00, 8:0.00, 6:0.00
    agent2_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 2:1.00, 8:0.00, 0:0.00
    blue_button_pos: 1:1.00, 2:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 112:0.00; 352:0.00; 772:0.00; 118:0.00; 778:0.00
  Agent2 top policies: 112:0.00; 352:0.00; 772:0.00; 118:0.00; 778:0.00
. b 2
. 1 .
. . .

Reward: +0.00, Result: neutral

--- Step 5 ---
Agent 1 joint action: 4 → (UP, PRESS)
Agent 2 joint action: 4 → (UP, PRESS)
Executed: Agent 1: UP, Agent 2: PRESS
  Agent1 beliefs:
    agent1_pos: 4:1.00, 8:0.00, 7:0.00
    agent2_pos: 2:1.00, 8:0.00, 7:0.00
    red_button_pos: 2:1.00, 8:0.00, 0:0.00
    blue_button_pos: 1:1.00, 7:0.00, 8:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 4:1.00, 8:0.00, 7:0.00
    agent2_pos: 2:1.00, 8:0.00, 7:0.00
    red_button_pos: 2:1.00, 8:0.00, 0:0.00
    blue_button_pos: 1:1.00, 7:0.00, 8:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 171:0.16; 172:0.16; 168:0.16; 169:0.16; 173:0.16
  Agent2 top policies: 171:0.16; 172:0.16; 168:0.16; 169:0.16; 173:0.16
. 1 2
. . .
. . .

Reward: +0.00, Result: neutral
Button pressed: red by Agent 2

--- Step 6 ---
Agent 1 joint action: 24 → (PRESS, UP)
Agent 2 joint action: 24 → (PRESS, UP)
Executed: Agent 1: PRESS, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 1:1.00, 8:0.00, 7:0.00
    agent2_pos: 2:1.00, 8:0.00, 7:0.00
    red_button_pos: 2:1.00, 8:0.00, 7:0.00
    blue_button_pos: 1:1.00, 7:0.00, 8:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 1:1.00, 8:0.00, 7:0.00
    agent2_pos: 2:1.00, 8:0.00, 7:0.00
    red_button_pos: 2:1.00, 8:0.00, 7:0.00
    blue_button_pos: 1:1.00, 7:0.00, 8:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 982:0.00; 983:0.00; 984:0.00; 985:0.00; 986:0.00
  Agent2 top policies: 982:0.00; 983:0.00; 984:0.00; 985:0.00; 986:0.00
. 1 2
. . .
. . .

Reward: +1.00, Result: win
Button pressed: blue by Agent 1

Result: ✅ WIN - win (steps: 6, reward: +1.00)

================================================================================
EPISODE 33
================================================================================
Environment: Red at (2, 0), Blue at (1, 0)

Initial state:
1 b r
. . .
. . 2


--- Step 1 ---
Agent 1 joint action: 6 → (DOWN, UP)
Agent 2 joint action: 6 → (DOWN, UP)
Executed: Agent 1: DOWN, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 0:1.00, 8:0.00, 7:0.00
    agent2_pos: 8:1.00, 0:0.00, 7:0.00
    red_button_pos: 7:0.14, 3:0.14, 6:0.14
    blue_button_pos: 7:0.14, 3:0.14, 6:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 0:1.00, 8:0.00, 7:0.00
    agent2_pos: 8:1.00, 0:0.00, 7:0.00
    red_button_pos: 7:0.14, 3:0.14, 6:0.14
    blue_button_pos: 7:0.14, 3:0.14, 6:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 244:0.02; 676:0.02; 316:0.02; 748:0.02; 677:0.01
  Agent2 top policies: 244:0.02; 676:0.02; 316:0.02; 748:0.02; 677:0.01
. b r
1 . 2
. . .

Reward: +0.00, Result: neutral

--- Step 2 ---
Agent 1 joint action: 8 → (DOWN, LEFT)
Agent 2 joint action: 8 → (DOWN, LEFT)
Executed: Agent 1: DOWN, Agent 2: LEFT
  Agent1 beliefs:
    agent1_pos: 3:1.00, 8:0.00, 5:0.00
    agent2_pos: 5:1.00, 8:0.00, 3:0.00
    red_button_pos: 7:0.20, 1:0.20, 6:0.20
    blue_button_pos: 7:0.20, 1:0.20, 6:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 3:1.00, 8:0.00, 5:0.00
    agent2_pos: 5:1.00, 8:0.00, 3:0.00
    red_button_pos: 7:0.20, 1:0.20, 6:0.20
    blue_button_pos: 7:0.20, 1:0.20, 6:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 316:0.05; 676:0.05; 244:0.05; 313:0.02; 243:0.02
  Agent2 top policies: 316:0.05; 676:0.05; 244:0.05; 313:0.02; 243:0.02
. b r
. 2 .
1 . .

Reward: +0.00, Result: neutral

--- Step 3 ---
Agent 1 joint action: 18 → (RIGHT, UP)
Agent 2 joint action: 18 → (RIGHT, UP)
Executed: Agent 1: RIGHT, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 6:1.00, 8:0.00, 5:0.00
    agent2_pos: 4:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:0.33, 1:0.33, 2:0.33
    blue_button_pos: 7:0.33, 1:0.33, 2:0.33
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 6:1.00, 8:0.00, 5:0.00
    agent2_pos: 4:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:0.33, 1:0.33, 2:0.33
    blue_button_pos: 7:0.33, 1:0.33, 2:0.33
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 676:0.28; 675:0.06; 677:0.06; 682:0.06; 658:0.06
  Agent2 top policies: 676:0.28; 675:0.06; 677:0.06; 682:0.06; 658:0.06
. 2 r
. . .
. 1 .

Reward: +0.00, Result: neutral

--- Step 4 ---
Agent 1 joint action: 3 → (UP, RIGHT)
Agent 2 joint action: 3 → (UP, RIGHT)
Executed: Agent 1: UP, Agent 2: RIGHT
  Agent1 beliefs:
    agent1_pos: 7:1.00, 8:0.00, 6:0.00
    agent2_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 2:1.00, 8:0.00, 0:0.00
    blue_button_pos: 1:1.00, 2:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 7:1.00, 8:0.00, 6:0.00
    agent2_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 2:1.00, 8:0.00, 0:0.00
    blue_button_pos: 1:1.00, 2:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 112:0.00; 352:0.00; 772:0.00; 118:0.00; 778:0.00
  Agent2 top policies: 112:0.00; 352:0.00; 772:0.00; 118:0.00; 778:0.00
. b 2
. 1 .
. . .

Reward: +0.00, Result: neutral

--- Step 5 ---
Agent 1 joint action: 4 → (UP, PRESS)
Agent 2 joint action: 4 → (UP, PRESS)
Executed: Agent 1: UP, Agent 2: PRESS
  Agent1 beliefs:
    agent1_pos: 4:1.00, 8:0.00, 7:0.00
    agent2_pos: 2:1.00, 8:0.00, 7:0.00
    red_button_pos: 2:1.00, 8:0.00, 0:0.00
    blue_button_pos: 1:1.00, 7:0.00, 8:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 4:1.00, 8:0.00, 7:0.00
    agent2_pos: 2:1.00, 8:0.00, 7:0.00
    red_button_pos: 2:1.00, 8:0.00, 0:0.00
    blue_button_pos: 1:1.00, 7:0.00, 8:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 171:0.16; 172:0.16; 168:0.16; 169:0.16; 173:0.16
  Agent2 top policies: 171:0.16; 172:0.16; 168:0.16; 169:0.16; 173:0.16
. 1 2
. . .
. . .

Reward: +0.00, Result: neutral
Button pressed: red by Agent 2

--- Step 6 ---
Agent 1 joint action: 24 → (PRESS, UP)
Agent 2 joint action: 24 → (PRESS, UP)
Executed: Agent 1: PRESS, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 1:1.00, 8:0.00, 7:0.00
    agent2_pos: 2:1.00, 8:0.00, 7:0.00
    red_button_pos: 2:1.00, 8:0.00, 7:0.00
    blue_button_pos: 1:1.00, 7:0.00, 8:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 1:1.00, 8:0.00, 7:0.00
    agent2_pos: 2:1.00, 8:0.00, 7:0.00
    red_button_pos: 2:1.00, 8:0.00, 7:0.00
    blue_button_pos: 1:1.00, 7:0.00, 8:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 982:0.00; 983:0.00; 984:0.00; 985:0.00; 986:0.00
  Agent2 top policies: 982:0.00; 983:0.00; 984:0.00; 985:0.00; 986:0.00
. 1 2
. . .
. . .

Reward: +1.00, Result: win
Button pressed: blue by Agent 1

Result: ✅ WIN - win (steps: 6, reward: +1.00)

================================================================================
EPISODE 34
================================================================================
Environment: Red at (2, 0), Blue at (1, 0)

Initial state:
1 b r
. . .
. . 2


--- Step 1 ---
Agent 1 joint action: 6 → (DOWN, UP)
Agent 2 joint action: 6 → (DOWN, UP)
Executed: Agent 1: DOWN, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 0:1.00, 8:0.00, 7:0.00
    agent2_pos: 8:1.00, 0:0.00, 7:0.00
    red_button_pos: 7:0.14, 3:0.14, 6:0.14
    blue_button_pos: 7:0.14, 3:0.14, 6:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 0:1.00, 8:0.00, 7:0.00
    agent2_pos: 8:1.00, 0:0.00, 7:0.00
    red_button_pos: 7:0.14, 3:0.14, 6:0.14
    blue_button_pos: 7:0.14, 3:0.14, 6:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 244:0.02; 676:0.02; 316:0.02; 748:0.02; 677:0.01
  Agent2 top policies: 244:0.02; 676:0.02; 316:0.02; 748:0.02; 677:0.01
. b r
1 . 2
. . .

Reward: +0.00, Result: neutral

--- Step 2 ---
Agent 1 joint action: 8 → (DOWN, LEFT)
Agent 2 joint action: 8 → (DOWN, LEFT)
Executed: Agent 1: DOWN, Agent 2: LEFT
  Agent1 beliefs:
    agent1_pos: 3:1.00, 8:0.00, 5:0.00
    agent2_pos: 5:1.00, 8:0.00, 3:0.00
    red_button_pos: 7:0.20, 1:0.20, 6:0.20
    blue_button_pos: 7:0.20, 1:0.20, 6:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 3:1.00, 8:0.00, 5:0.00
    agent2_pos: 5:1.00, 8:0.00, 3:0.00
    red_button_pos: 7:0.20, 1:0.20, 6:0.20
    blue_button_pos: 7:0.20, 1:0.20, 6:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 316:0.05; 676:0.05; 244:0.05; 313:0.02; 243:0.02
  Agent2 top policies: 316:0.05; 676:0.05; 244:0.05; 313:0.02; 243:0.02
. b r
. 2 .
1 . .

Reward: +0.00, Result: neutral

--- Step 3 ---
Agent 1 joint action: 18 → (RIGHT, UP)
Agent 2 joint action: 18 → (RIGHT, UP)
Executed: Agent 1: RIGHT, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 6:1.00, 8:0.00, 5:0.00
    agent2_pos: 4:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:0.33, 1:0.33, 2:0.33
    blue_button_pos: 7:0.33, 1:0.33, 2:0.33
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 6:1.00, 8:0.00, 5:0.00
    agent2_pos: 4:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:0.33, 1:0.33, 2:0.33
    blue_button_pos: 7:0.33, 1:0.33, 2:0.33
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 676:0.28; 675:0.06; 677:0.06; 682:0.06; 658:0.06
  Agent2 top policies: 676:0.28; 675:0.06; 677:0.06; 682:0.06; 658:0.06
. 2 r
. . .
. 1 .

Reward: +0.00, Result: neutral

--- Step 4 ---
Agent 1 joint action: 3 → (UP, RIGHT)
Agent 2 joint action: 3 → (UP, RIGHT)
Executed: Agent 1: UP, Agent 2: RIGHT
  Agent1 beliefs:
    agent1_pos: 7:1.00, 8:0.00, 6:0.00
    agent2_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 2:1.00, 8:0.00, 0:0.00
    blue_button_pos: 1:1.00, 2:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 7:1.00, 8:0.00, 6:0.00
    agent2_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 2:1.00, 8:0.00, 0:0.00
    blue_button_pos: 1:1.00, 2:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 112:0.00; 352:0.00; 772:0.00; 118:0.00; 778:0.00
  Agent2 top policies: 112:0.00; 352:0.00; 772:0.00; 118:0.00; 778:0.00
. b 2
. 1 .
. . .

Reward: +0.00, Result: neutral

--- Step 5 ---
Agent 1 joint action: 4 → (UP, PRESS)
Agent 2 joint action: 4 → (UP, PRESS)
Executed: Agent 1: UP, Agent 2: PRESS
  Agent1 beliefs:
    agent1_pos: 4:1.00, 8:0.00, 7:0.00
    agent2_pos: 2:1.00, 8:0.00, 7:0.00
    red_button_pos: 2:1.00, 8:0.00, 0:0.00
    blue_button_pos: 1:1.00, 7:0.00, 8:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 4:1.00, 8:0.00, 7:0.00
    agent2_pos: 2:1.00, 8:0.00, 7:0.00
    red_button_pos: 2:1.00, 8:0.00, 0:0.00
    blue_button_pos: 1:1.00, 7:0.00, 8:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 171:0.16; 172:0.16; 168:0.16; 169:0.16; 173:0.16
  Agent2 top policies: 171:0.16; 172:0.16; 168:0.16; 169:0.16; 173:0.16
. 1 2
. . .
. . .

Reward: +0.00, Result: neutral
Button pressed: red by Agent 2

--- Step 6 ---
Agent 1 joint action: 24 → (PRESS, UP)
Agent 2 joint action: 24 → (PRESS, UP)
Executed: Agent 1: PRESS, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 1:1.00, 8:0.00, 7:0.00
    agent2_pos: 2:1.00, 8:0.00, 7:0.00
    red_button_pos: 2:1.00, 8:0.00, 7:0.00
    blue_button_pos: 1:1.00, 7:0.00, 8:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 1:1.00, 8:0.00, 7:0.00
    agent2_pos: 2:1.00, 8:0.00, 7:0.00
    red_button_pos: 2:1.00, 8:0.00, 7:0.00
    blue_button_pos: 1:1.00, 7:0.00, 8:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 982:0.00; 983:0.00; 984:0.00; 985:0.00; 986:0.00
  Agent2 top policies: 982:0.00; 983:0.00; 984:0.00; 985:0.00; 986:0.00
. 1 2
. . .
. . .

Reward: +1.00, Result: win
Button pressed: blue by Agent 1

Result: ✅ WIN - win (steps: 6, reward: +1.00)

================================================================================
EPISODE 35
================================================================================
Environment: Red at (2, 0), Blue at (1, 0)

Initial state:
1 b r
. . .
. . 2


--- Step 1 ---
Agent 1 joint action: 6 → (DOWN, UP)
Agent 2 joint action: 6 → (DOWN, UP)
Executed: Agent 1: DOWN, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 0:1.00, 8:0.00, 7:0.00
    agent2_pos: 8:1.00, 0:0.00, 7:0.00
    red_button_pos: 7:0.14, 3:0.14, 6:0.14
    blue_button_pos: 7:0.14, 3:0.14, 6:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 0:1.00, 8:0.00, 7:0.00
    agent2_pos: 8:1.00, 0:0.00, 7:0.00
    red_button_pos: 7:0.14, 3:0.14, 6:0.14
    blue_button_pos: 7:0.14, 3:0.14, 6:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 244:0.02; 676:0.02; 316:0.02; 748:0.02; 677:0.01
  Agent2 top policies: 244:0.02; 676:0.02; 316:0.02; 748:0.02; 677:0.01
. b r
1 . 2
. . .

Reward: +0.00, Result: neutral

--- Step 2 ---
Agent 1 joint action: 8 → (DOWN, LEFT)
Agent 2 joint action: 8 → (DOWN, LEFT)
Executed: Agent 1: DOWN, Agent 2: LEFT
  Agent1 beliefs:
    agent1_pos: 3:1.00, 8:0.00, 5:0.00
    agent2_pos: 5:1.00, 8:0.00, 3:0.00
    red_button_pos: 7:0.20, 1:0.20, 6:0.20
    blue_button_pos: 7:0.20, 1:0.20, 6:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 3:1.00, 8:0.00, 5:0.00
    agent2_pos: 5:1.00, 8:0.00, 3:0.00
    red_button_pos: 7:0.20, 1:0.20, 6:0.20
    blue_button_pos: 7:0.20, 1:0.20, 6:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 316:0.05; 676:0.05; 244:0.05; 313:0.02; 243:0.02
  Agent2 top policies: 316:0.05; 676:0.05; 244:0.05; 313:0.02; 243:0.02
. b r
. 2 .
1 . .

Reward: +0.00, Result: neutral

--- Step 3 ---
Agent 1 joint action: 18 → (RIGHT, UP)
Agent 2 joint action: 18 → (RIGHT, UP)
Executed: Agent 1: RIGHT, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 6:1.00, 8:0.00, 5:0.00
    agent2_pos: 4:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:0.33, 1:0.33, 2:0.33
    blue_button_pos: 7:0.33, 1:0.33, 2:0.33
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 6:1.00, 8:0.00, 5:0.00
    agent2_pos: 4:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:0.33, 1:0.33, 2:0.33
    blue_button_pos: 7:0.33, 1:0.33, 2:0.33
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 676:0.28; 675:0.06; 677:0.06; 682:0.06; 658:0.06
  Agent2 top policies: 676:0.28; 675:0.06; 677:0.06; 682:0.06; 658:0.06
. 2 r
. . .
. 1 .

Reward: +0.00, Result: neutral

--- Step 4 ---
Agent 1 joint action: 3 → (UP, RIGHT)
Agent 2 joint action: 3 → (UP, RIGHT)
Executed: Agent 1: UP, Agent 2: RIGHT
  Agent1 beliefs:
    agent1_pos: 7:1.00, 8:0.00, 6:0.00
    agent2_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 2:1.00, 8:0.00, 0:0.00
    blue_button_pos: 1:1.00, 2:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 7:1.00, 8:0.00, 6:0.00
    agent2_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 2:1.00, 8:0.00, 0:0.00
    blue_button_pos: 1:1.00, 2:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 112:0.00; 352:0.00; 772:0.00; 118:0.00; 778:0.00
  Agent2 top policies: 112:0.00; 352:0.00; 772:0.00; 118:0.00; 778:0.00
. b 2
. 1 .
. . .

Reward: +0.00, Result: neutral

--- Step 5 ---
Agent 1 joint action: 4 → (UP, PRESS)
Agent 2 joint action: 4 → (UP, PRESS)
Executed: Agent 1: UP, Agent 2: PRESS
  Agent1 beliefs:
    agent1_pos: 4:1.00, 8:0.00, 7:0.00
    agent2_pos: 2:1.00, 8:0.00, 7:0.00
    red_button_pos: 2:1.00, 8:0.00, 0:0.00
    blue_button_pos: 1:1.00, 7:0.00, 8:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 4:1.00, 8:0.00, 7:0.00
    agent2_pos: 2:1.00, 8:0.00, 7:0.00
    red_button_pos: 2:1.00, 8:0.00, 0:0.00
    blue_button_pos: 1:1.00, 7:0.00, 8:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 171:0.16; 172:0.16; 168:0.16; 169:0.16; 173:0.16
  Agent2 top policies: 171:0.16; 172:0.16; 168:0.16; 169:0.16; 173:0.16
. 1 2
. . .
. . .

Reward: +0.00, Result: neutral
Button pressed: red by Agent 2

--- Step 6 ---
Agent 1 joint action: 24 → (PRESS, UP)
Agent 2 joint action: 24 → (PRESS, UP)
Executed: Agent 1: PRESS, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 1:1.00, 8:0.00, 7:0.00
    agent2_pos: 2:1.00, 8:0.00, 7:0.00
    red_button_pos: 2:1.00, 8:0.00, 7:0.00
    blue_button_pos: 1:1.00, 7:0.00, 8:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 1:1.00, 8:0.00, 7:0.00
    agent2_pos: 2:1.00, 8:0.00, 7:0.00
    red_button_pos: 2:1.00, 8:0.00, 7:0.00
    blue_button_pos: 1:1.00, 7:0.00, 8:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 982:0.00; 983:0.00; 984:0.00; 985:0.00; 986:0.00
  Agent2 top policies: 982:0.00; 983:0.00; 984:0.00; 985:0.00; 986:0.00
. 1 2
. . .
. . .

Reward: +1.00, Result: win
Button pressed: blue by Agent 1

Result: ✅ WIN - win (steps: 6, reward: +1.00)

================================================================================
EPISODE 36
================================================================================
Environment: Red at (2, 0), Blue at (1, 0)

Initial state:
1 b r
. . .
. . 2


--- Step 1 ---
Agent 1 joint action: 6 → (DOWN, UP)
Agent 2 joint action: 6 → (DOWN, UP)
Executed: Agent 1: DOWN, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 0:1.00, 8:0.00, 7:0.00
    agent2_pos: 8:1.00, 0:0.00, 7:0.00
    red_button_pos: 7:0.14, 3:0.14, 6:0.14
    blue_button_pos: 7:0.14, 3:0.14, 6:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 0:1.00, 8:0.00, 7:0.00
    agent2_pos: 8:1.00, 0:0.00, 7:0.00
    red_button_pos: 7:0.14, 3:0.14, 6:0.14
    blue_button_pos: 7:0.14, 3:0.14, 6:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 244:0.02; 676:0.02; 316:0.02; 748:0.02; 677:0.01
  Agent2 top policies: 244:0.02; 676:0.02; 316:0.02; 748:0.02; 677:0.01
. b r
1 . 2
. . .

Reward: +0.00, Result: neutral

--- Step 2 ---
Agent 1 joint action: 8 → (DOWN, LEFT)
Agent 2 joint action: 8 → (DOWN, LEFT)
Executed: Agent 1: DOWN, Agent 2: LEFT
  Agent1 beliefs:
    agent1_pos: 3:1.00, 8:0.00, 5:0.00
    agent2_pos: 5:1.00, 8:0.00, 3:0.00
    red_button_pos: 7:0.20, 1:0.20, 6:0.20
    blue_button_pos: 7:0.20, 1:0.20, 6:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 3:1.00, 8:0.00, 5:0.00
    agent2_pos: 5:1.00, 8:0.00, 3:0.00
    red_button_pos: 7:0.20, 1:0.20, 6:0.20
    blue_button_pos: 7:0.20, 1:0.20, 6:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 316:0.05; 676:0.05; 244:0.05; 313:0.02; 243:0.02
  Agent2 top policies: 316:0.05; 676:0.05; 244:0.05; 313:0.02; 243:0.02
. b r
. 2 .
1 . .

Reward: +0.00, Result: neutral

--- Step 3 ---
Agent 1 joint action: 18 → (RIGHT, UP)
Agent 2 joint action: 18 → (RIGHT, UP)
Executed: Agent 1: RIGHT, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 6:1.00, 8:0.00, 5:0.00
    agent2_pos: 4:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:0.33, 1:0.33, 2:0.33
    blue_button_pos: 7:0.33, 1:0.33, 2:0.33
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 6:1.00, 8:0.00, 5:0.00
    agent2_pos: 4:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:0.33, 1:0.33, 2:0.33
    blue_button_pos: 7:0.33, 1:0.33, 2:0.33
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 676:0.28; 675:0.06; 677:0.06; 682:0.06; 658:0.06
  Agent2 top policies: 676:0.28; 675:0.06; 677:0.06; 682:0.06; 658:0.06
. 2 r
. . .
. 1 .

Reward: +0.00, Result: neutral

--- Step 4 ---
Agent 1 joint action: 3 → (UP, RIGHT)
Agent 2 joint action: 3 → (UP, RIGHT)
Executed: Agent 1: UP, Agent 2: RIGHT
  Agent1 beliefs:
    agent1_pos: 7:1.00, 8:0.00, 6:0.00
    agent2_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 2:1.00, 8:0.00, 0:0.00
    blue_button_pos: 1:1.00, 2:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 7:1.00, 8:0.00, 6:0.00
    agent2_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 2:1.00, 8:0.00, 0:0.00
    blue_button_pos: 1:1.00, 2:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 112:0.00; 352:0.00; 772:0.00; 118:0.00; 778:0.00
  Agent2 top policies: 112:0.00; 352:0.00; 772:0.00; 118:0.00; 778:0.00
. b 2
. 1 .
. . .

Reward: +0.00, Result: neutral

--- Step 5 ---
Agent 1 joint action: 4 → (UP, PRESS)
Agent 2 joint action: 4 → (UP, PRESS)
Executed: Agent 1: UP, Agent 2: PRESS
  Agent1 beliefs:
    agent1_pos: 4:1.00, 8:0.00, 7:0.00
    agent2_pos: 2:1.00, 8:0.00, 7:0.00
    red_button_pos: 2:1.00, 8:0.00, 0:0.00
    blue_button_pos: 1:1.00, 7:0.00, 8:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 4:1.00, 8:0.00, 7:0.00
    agent2_pos: 2:1.00, 8:0.00, 7:0.00
    red_button_pos: 2:1.00, 8:0.00, 0:0.00
    blue_button_pos: 1:1.00, 7:0.00, 8:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 171:0.16; 172:0.16; 168:0.16; 169:0.16; 173:0.16
  Agent2 top policies: 171:0.16; 172:0.16; 168:0.16; 169:0.16; 173:0.16
. 1 2
. . .
. . .

Reward: +0.00, Result: neutral
Button pressed: red by Agent 2

--- Step 6 ---
Agent 1 joint action: 24 → (PRESS, UP)
Agent 2 joint action: 24 → (PRESS, UP)
Executed: Agent 1: PRESS, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 1:1.00, 8:0.00, 7:0.00
    agent2_pos: 2:1.00, 8:0.00, 7:0.00
    red_button_pos: 2:1.00, 8:0.00, 7:0.00
    blue_button_pos: 1:1.00, 7:0.00, 8:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 1:1.00, 8:0.00, 7:0.00
    agent2_pos: 2:1.00, 8:0.00, 7:0.00
    red_button_pos: 2:1.00, 8:0.00, 7:0.00
    blue_button_pos: 1:1.00, 7:0.00, 8:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 982:0.00; 983:0.00; 984:0.00; 985:0.00; 986:0.00
  Agent2 top policies: 982:0.00; 983:0.00; 984:0.00; 985:0.00; 986:0.00
. 1 2
. . .
. . .

Reward: +1.00, Result: win
Button pressed: blue by Agent 1

Result: ✅ WIN - win (steps: 6, reward: +1.00)

================================================================================
EPISODE 37
================================================================================
Environment: Red at (2, 0), Blue at (1, 0)

Initial state:
1 b r
. . .
. . 2


--- Step 1 ---
Agent 1 joint action: 6 → (DOWN, UP)
Agent 2 joint action: 6 → (DOWN, UP)
Executed: Agent 1: DOWN, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 0:1.00, 8:0.00, 7:0.00
    agent2_pos: 8:1.00, 0:0.00, 7:0.00
    red_button_pos: 7:0.14, 3:0.14, 6:0.14
    blue_button_pos: 7:0.14, 3:0.14, 6:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 0:1.00, 8:0.00, 7:0.00
    agent2_pos: 8:1.00, 0:0.00, 7:0.00
    red_button_pos: 7:0.14, 3:0.14, 6:0.14
    blue_button_pos: 7:0.14, 3:0.14, 6:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 244:0.02; 676:0.02; 316:0.02; 748:0.02; 677:0.01
  Agent2 top policies: 244:0.02; 676:0.02; 316:0.02; 748:0.02; 677:0.01
. b r
1 . 2
. . .

Reward: +0.00, Result: neutral

--- Step 2 ---
Agent 1 joint action: 8 → (DOWN, LEFT)
Agent 2 joint action: 8 → (DOWN, LEFT)
Executed: Agent 1: DOWN, Agent 2: LEFT
  Agent1 beliefs:
    agent1_pos: 3:1.00, 8:0.00, 5:0.00
    agent2_pos: 5:1.00, 8:0.00, 3:0.00
    red_button_pos: 7:0.20, 1:0.20, 6:0.20
    blue_button_pos: 7:0.20, 1:0.20, 6:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 3:1.00, 8:0.00, 5:0.00
    agent2_pos: 5:1.00, 8:0.00, 3:0.00
    red_button_pos: 7:0.20, 1:0.20, 6:0.20
    blue_button_pos: 7:0.20, 1:0.20, 6:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 316:0.05; 676:0.05; 244:0.05; 313:0.02; 243:0.02
  Agent2 top policies: 316:0.05; 676:0.05; 244:0.05; 313:0.02; 243:0.02
. b r
. 2 .
1 . .

Reward: +0.00, Result: neutral

--- Step 3 ---
Agent 1 joint action: 18 → (RIGHT, UP)
Agent 2 joint action: 18 → (RIGHT, UP)
Executed: Agent 1: RIGHT, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 6:1.00, 8:0.00, 5:0.00
    agent2_pos: 4:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:0.33, 1:0.33, 2:0.33
    blue_button_pos: 7:0.33, 1:0.33, 2:0.33
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 6:1.00, 8:0.00, 5:0.00
    agent2_pos: 4:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:0.33, 1:0.33, 2:0.33
    blue_button_pos: 7:0.33, 1:0.33, 2:0.33
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 676:0.28; 675:0.06; 677:0.06; 682:0.06; 658:0.06
  Agent2 top policies: 676:0.28; 675:0.06; 677:0.06; 682:0.06; 658:0.06
. 2 r
. . .
. 1 .

Reward: +0.00, Result: neutral

--- Step 4 ---
Agent 1 joint action: 3 → (UP, RIGHT)
Agent 2 joint action: 3 → (UP, RIGHT)
Executed: Agent 1: UP, Agent 2: RIGHT
  Agent1 beliefs:
    agent1_pos: 7:1.00, 8:0.00, 6:0.00
    agent2_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 2:1.00, 8:0.00, 0:0.00
    blue_button_pos: 1:1.00, 2:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 7:1.00, 8:0.00, 6:0.00
    agent2_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 2:1.00, 8:0.00, 0:0.00
    blue_button_pos: 1:1.00, 2:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 112:0.00; 352:0.00; 772:0.00; 118:0.00; 778:0.00
  Agent2 top policies: 112:0.00; 352:0.00; 772:0.00; 118:0.00; 778:0.00
. b 2
. 1 .
. . .

Reward: +0.00, Result: neutral

--- Step 5 ---
Agent 1 joint action: 4 → (UP, PRESS)
Agent 2 joint action: 4 → (UP, PRESS)
Executed: Agent 1: UP, Agent 2: PRESS
  Agent1 beliefs:
    agent1_pos: 4:1.00, 8:0.00, 7:0.00
    agent2_pos: 2:1.00, 8:0.00, 7:0.00
    red_button_pos: 2:1.00, 8:0.00, 0:0.00
    blue_button_pos: 1:1.00, 7:0.00, 8:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 4:1.00, 8:0.00, 7:0.00
    agent2_pos: 2:1.00, 8:0.00, 7:0.00
    red_button_pos: 2:1.00, 8:0.00, 0:0.00
    blue_button_pos: 1:1.00, 7:0.00, 8:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 171:0.16; 172:0.16; 168:0.16; 169:0.16; 173:0.16
  Agent2 top policies: 171:0.16; 172:0.16; 168:0.16; 169:0.16; 173:0.16
. 1 2
. . .
. . .

Reward: +0.00, Result: neutral
Button pressed: red by Agent 2

--- Step 6 ---
Agent 1 joint action: 24 → (PRESS, UP)
Agent 2 joint action: 24 → (PRESS, UP)
Executed: Agent 1: PRESS, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 1:1.00, 8:0.00, 7:0.00
    agent2_pos: 2:1.00, 8:0.00, 7:0.00
    red_button_pos: 2:1.00, 8:0.00, 7:0.00
    blue_button_pos: 1:1.00, 7:0.00, 8:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 1:1.00, 8:0.00, 7:0.00
    agent2_pos: 2:1.00, 8:0.00, 7:0.00
    red_button_pos: 2:1.00, 8:0.00, 7:0.00
    blue_button_pos: 1:1.00, 7:0.00, 8:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 982:0.00; 983:0.00; 984:0.00; 985:0.00; 986:0.00
  Agent2 top policies: 982:0.00; 983:0.00; 984:0.00; 985:0.00; 986:0.00
. 1 2
. . .
. . .

Reward: +1.00, Result: win
Button pressed: blue by Agent 1

Result: ✅ WIN - win (steps: 6, reward: +1.00)

================================================================================
EPISODE 38
================================================================================
Environment: Red at (2, 0), Blue at (1, 0)

Initial state:
1 b r
. . .
. . 2


--- Step 1 ---
Agent 1 joint action: 6 → (DOWN, UP)
Agent 2 joint action: 6 → (DOWN, UP)
Executed: Agent 1: DOWN, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 0:1.00, 8:0.00, 7:0.00
    agent2_pos: 8:1.00, 0:0.00, 7:0.00
    red_button_pos: 7:0.14, 3:0.14, 6:0.14
    blue_button_pos: 7:0.14, 3:0.14, 6:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 0:1.00, 8:0.00, 7:0.00
    agent2_pos: 8:1.00, 0:0.00, 7:0.00
    red_button_pos: 7:0.14, 3:0.14, 6:0.14
    blue_button_pos: 7:0.14, 3:0.14, 6:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 244:0.02; 676:0.02; 316:0.02; 748:0.02; 677:0.01
  Agent2 top policies: 244:0.02; 676:0.02; 316:0.02; 748:0.02; 677:0.01
. b r
1 . 2
. . .

Reward: +0.00, Result: neutral

--- Step 2 ---
Agent 1 joint action: 8 → (DOWN, LEFT)
Agent 2 joint action: 8 → (DOWN, LEFT)
Executed: Agent 1: DOWN, Agent 2: LEFT
  Agent1 beliefs:
    agent1_pos: 3:1.00, 8:0.00, 5:0.00
    agent2_pos: 5:1.00, 8:0.00, 3:0.00
    red_button_pos: 7:0.20, 1:0.20, 6:0.20
    blue_button_pos: 7:0.20, 1:0.20, 6:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 3:1.00, 8:0.00, 5:0.00
    agent2_pos: 5:1.00, 8:0.00, 3:0.00
    red_button_pos: 7:0.20, 1:0.20, 6:0.20
    blue_button_pos: 7:0.20, 1:0.20, 6:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 316:0.05; 676:0.05; 244:0.05; 313:0.02; 243:0.02
  Agent2 top policies: 316:0.05; 676:0.05; 244:0.05; 313:0.02; 243:0.02
. b r
. 2 .
1 . .

Reward: +0.00, Result: neutral

--- Step 3 ---
Agent 1 joint action: 18 → (RIGHT, UP)
Agent 2 joint action: 18 → (RIGHT, UP)
Executed: Agent 1: RIGHT, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 6:1.00, 8:0.00, 5:0.00
    agent2_pos: 4:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:0.33, 1:0.33, 2:0.33
    blue_button_pos: 7:0.33, 1:0.33, 2:0.33
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 6:1.00, 8:0.00, 5:0.00
    agent2_pos: 4:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:0.33, 1:0.33, 2:0.33
    blue_button_pos: 7:0.33, 1:0.33, 2:0.33
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 676:0.28; 675:0.06; 677:0.06; 682:0.06; 658:0.06
  Agent2 top policies: 676:0.28; 675:0.06; 677:0.06; 682:0.06; 658:0.06
. 2 r
. . .
. 1 .

Reward: +0.00, Result: neutral

--- Step 4 ---
Agent 1 joint action: 3 → (UP, RIGHT)
Agent 2 joint action: 3 → (UP, RIGHT)
Executed: Agent 1: UP, Agent 2: RIGHT
  Agent1 beliefs:
    agent1_pos: 7:1.00, 8:0.00, 6:0.00
    agent2_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 2:1.00, 8:0.00, 0:0.00
    blue_button_pos: 1:1.00, 2:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 7:1.00, 8:0.00, 6:0.00
    agent2_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 2:1.00, 8:0.00, 0:0.00
    blue_button_pos: 1:1.00, 2:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 112:0.00; 352:0.00; 772:0.00; 118:0.00; 778:0.00
  Agent2 top policies: 112:0.00; 352:0.00; 772:0.00; 118:0.00; 778:0.00
. b 2
. 1 .
. . .

Reward: +0.00, Result: neutral

--- Step 5 ---
Agent 1 joint action: 4 → (UP, PRESS)
Agent 2 joint action: 4 → (UP, PRESS)
Executed: Agent 1: UP, Agent 2: PRESS
  Agent1 beliefs:
    agent1_pos: 4:1.00, 8:0.00, 7:0.00
    agent2_pos: 2:1.00, 8:0.00, 7:0.00
    red_button_pos: 2:1.00, 8:0.00, 0:0.00
    blue_button_pos: 1:1.00, 7:0.00, 8:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 4:1.00, 8:0.00, 7:0.00
    agent2_pos: 2:1.00, 8:0.00, 7:0.00
    red_button_pos: 2:1.00, 8:0.00, 0:0.00
    blue_button_pos: 1:1.00, 7:0.00, 8:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 171:0.16; 172:0.16; 168:0.16; 169:0.16; 173:0.16
  Agent2 top policies: 171:0.16; 172:0.16; 168:0.16; 169:0.16; 173:0.16
. 1 2
. . .
. . .

Reward: +0.00, Result: neutral
Button pressed: red by Agent 2

--- Step 6 ---
Agent 1 joint action: 24 → (PRESS, UP)
Agent 2 joint action: 24 → (PRESS, UP)
Executed: Agent 1: PRESS, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 1:1.00, 8:0.00, 7:0.00
    agent2_pos: 2:1.00, 8:0.00, 7:0.00
    red_button_pos: 2:1.00, 8:0.00, 7:0.00
    blue_button_pos: 1:1.00, 7:0.00, 8:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 1:1.00, 8:0.00, 7:0.00
    agent2_pos: 2:1.00, 8:0.00, 7:0.00
    red_button_pos: 2:1.00, 8:0.00, 7:0.00
    blue_button_pos: 1:1.00, 7:0.00, 8:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 982:0.00; 983:0.00; 984:0.00; 985:0.00; 986:0.00
  Agent2 top policies: 982:0.00; 983:0.00; 984:0.00; 985:0.00; 986:0.00
. 1 2
. . .
. . .

Reward: +1.00, Result: win
Button pressed: blue by Agent 1

Result: ✅ WIN - win (steps: 6, reward: +1.00)

================================================================================
EPISODE 39
================================================================================
Environment: Red at (2, 0), Blue at (1, 0)

Initial state:
1 b r
. . .
. . 2


--- Step 1 ---
Agent 1 joint action: 6 → (DOWN, UP)
Agent 2 joint action: 6 → (DOWN, UP)
Executed: Agent 1: DOWN, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 0:1.00, 8:0.00, 7:0.00
    agent2_pos: 8:1.00, 0:0.00, 7:0.00
    red_button_pos: 7:0.14, 3:0.14, 6:0.14
    blue_button_pos: 7:0.14, 3:0.14, 6:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 0:1.00, 8:0.00, 7:0.00
    agent2_pos: 8:1.00, 0:0.00, 7:0.00
    red_button_pos: 7:0.14, 3:0.14, 6:0.14
    blue_button_pos: 7:0.14, 3:0.14, 6:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 244:0.02; 676:0.02; 316:0.02; 748:0.02; 677:0.01
  Agent2 top policies: 244:0.02; 676:0.02; 316:0.02; 748:0.02; 677:0.01
. b r
1 . 2
. . .

Reward: +0.00, Result: neutral

--- Step 2 ---
Agent 1 joint action: 8 → (DOWN, LEFT)
Agent 2 joint action: 8 → (DOWN, LEFT)
Executed: Agent 1: DOWN, Agent 2: LEFT
  Agent1 beliefs:
    agent1_pos: 3:1.00, 8:0.00, 5:0.00
    agent2_pos: 5:1.00, 8:0.00, 3:0.00
    red_button_pos: 7:0.20, 1:0.20, 6:0.20
    blue_button_pos: 7:0.20, 1:0.20, 6:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 3:1.00, 8:0.00, 5:0.00
    agent2_pos: 5:1.00, 8:0.00, 3:0.00
    red_button_pos: 7:0.20, 1:0.20, 6:0.20
    blue_button_pos: 7:0.20, 1:0.20, 6:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 316:0.05; 676:0.05; 244:0.05; 313:0.02; 243:0.02
  Agent2 top policies: 316:0.05; 676:0.05; 244:0.05; 313:0.02; 243:0.02
. b r
. 2 .
1 . .

Reward: +0.00, Result: neutral

--- Step 3 ---
Agent 1 joint action: 18 → (RIGHT, UP)
Agent 2 joint action: 18 → (RIGHT, UP)
Executed: Agent 1: RIGHT, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 6:1.00, 8:0.00, 5:0.00
    agent2_pos: 4:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:0.33, 1:0.33, 2:0.33
    blue_button_pos: 7:0.33, 1:0.33, 2:0.33
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 6:1.00, 8:0.00, 5:0.00
    agent2_pos: 4:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:0.33, 1:0.33, 2:0.33
    blue_button_pos: 7:0.33, 1:0.33, 2:0.33
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 676:0.28; 675:0.06; 677:0.06; 682:0.06; 658:0.06
  Agent2 top policies: 676:0.28; 675:0.06; 677:0.06; 682:0.06; 658:0.06
. 2 r
. . .
. 1 .

Reward: +0.00, Result: neutral

--- Step 4 ---
Agent 1 joint action: 3 → (UP, RIGHT)
Agent 2 joint action: 3 → (UP, RIGHT)
Executed: Agent 1: UP, Agent 2: RIGHT
  Agent1 beliefs:
    agent1_pos: 7:1.00, 8:0.00, 6:0.00
    agent2_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 2:1.00, 8:0.00, 0:0.00
    blue_button_pos: 1:1.00, 2:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 7:1.00, 8:0.00, 6:0.00
    agent2_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 2:1.00, 8:0.00, 0:0.00
    blue_button_pos: 1:1.00, 2:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 112:0.00; 352:0.00; 772:0.00; 118:0.00; 778:0.00
  Agent2 top policies: 112:0.00; 352:0.00; 772:0.00; 118:0.00; 778:0.00
. b 2
. 1 .
. . .

Reward: +0.00, Result: neutral

--- Step 5 ---
Agent 1 joint action: 4 → (UP, PRESS)
Agent 2 joint action: 4 → (UP, PRESS)
Executed: Agent 1: UP, Agent 2: PRESS
  Agent1 beliefs:
    agent1_pos: 4:1.00, 8:0.00, 7:0.00
    agent2_pos: 2:1.00, 8:0.00, 7:0.00
    red_button_pos: 2:1.00, 8:0.00, 0:0.00
    blue_button_pos: 1:1.00, 7:0.00, 8:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 4:1.00, 8:0.00, 7:0.00
    agent2_pos: 2:1.00, 8:0.00, 7:0.00
    red_button_pos: 2:1.00, 8:0.00, 0:0.00
    blue_button_pos: 1:1.00, 7:0.00, 8:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 171:0.16; 172:0.16; 168:0.16; 169:0.16; 173:0.16
  Agent2 top policies: 171:0.16; 172:0.16; 168:0.16; 169:0.16; 173:0.16
. 1 2
. . .
. . .

Reward: +0.00, Result: neutral
Button pressed: red by Agent 2

--- Step 6 ---
Agent 1 joint action: 24 → (PRESS, UP)
Agent 2 joint action: 24 → (PRESS, UP)
Executed: Agent 1: PRESS, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 1:1.00, 8:0.00, 7:0.00
    agent2_pos: 2:1.00, 8:0.00, 7:0.00
    red_button_pos: 2:1.00, 8:0.00, 7:0.00
    blue_button_pos: 1:1.00, 7:0.00, 8:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 1:1.00, 8:0.00, 7:0.00
    agent2_pos: 2:1.00, 8:0.00, 7:0.00
    red_button_pos: 2:1.00, 8:0.00, 7:0.00
    blue_button_pos: 1:1.00, 7:0.00, 8:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 982:0.00; 983:0.00; 984:0.00; 985:0.00; 986:0.00
  Agent2 top policies: 982:0.00; 983:0.00; 984:0.00; 985:0.00; 986:0.00
. 1 2
. . .
. . .

Reward: +1.00, Result: win
Button pressed: blue by Agent 1

Result: ✅ WIN - win (steps: 6, reward: +1.00)

================================================================================
EPISODE 40
================================================================================
Environment: Red at (2, 0), Blue at (1, 0)

Initial state:
1 b r
. . .
. . 2


--- Step 1 ---
Agent 1 joint action: 6 → (DOWN, UP)
Agent 2 joint action: 6 → (DOWN, UP)
Executed: Agent 1: DOWN, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 0:1.00, 8:0.00, 7:0.00
    agent2_pos: 8:1.00, 0:0.00, 7:0.00
    red_button_pos: 7:0.14, 3:0.14, 6:0.14
    blue_button_pos: 7:0.14, 3:0.14, 6:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 0:1.00, 8:0.00, 7:0.00
    agent2_pos: 8:1.00, 0:0.00, 7:0.00
    red_button_pos: 7:0.14, 3:0.14, 6:0.14
    blue_button_pos: 7:0.14, 3:0.14, 6:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 244:0.02; 676:0.02; 316:0.02; 748:0.02; 677:0.01
  Agent2 top policies: 244:0.02; 676:0.02; 316:0.02; 748:0.02; 677:0.01
. b r
1 . 2
. . .

Reward: +0.00, Result: neutral

--- Step 2 ---
Agent 1 joint action: 8 → (DOWN, LEFT)
Agent 2 joint action: 8 → (DOWN, LEFT)
Executed: Agent 1: DOWN, Agent 2: LEFT
  Agent1 beliefs:
    agent1_pos: 3:1.00, 8:0.00, 5:0.00
    agent2_pos: 5:1.00, 8:0.00, 3:0.00
    red_button_pos: 7:0.20, 1:0.20, 6:0.20
    blue_button_pos: 7:0.20, 1:0.20, 6:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 3:1.00, 8:0.00, 5:0.00
    agent2_pos: 5:1.00, 8:0.00, 3:0.00
    red_button_pos: 7:0.20, 1:0.20, 6:0.20
    blue_button_pos: 7:0.20, 1:0.20, 6:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 316:0.05; 676:0.05; 244:0.05; 313:0.02; 243:0.02
  Agent2 top policies: 316:0.05; 676:0.05; 244:0.05; 313:0.02; 243:0.02
. b r
. 2 .
1 . .

Reward: +0.00, Result: neutral

--- Step 3 ---
Agent 1 joint action: 18 → (RIGHT, UP)
Agent 2 joint action: 18 → (RIGHT, UP)
Executed: Agent 1: RIGHT, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 6:1.00, 8:0.00, 5:0.00
    agent2_pos: 4:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:0.33, 1:0.33, 2:0.33
    blue_button_pos: 7:0.33, 1:0.33, 2:0.33
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 6:1.00, 8:0.00, 5:0.00
    agent2_pos: 4:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:0.33, 1:0.33, 2:0.33
    blue_button_pos: 7:0.33, 1:0.33, 2:0.33
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 676:0.28; 675:0.06; 677:0.06; 682:0.06; 658:0.06
  Agent2 top policies: 676:0.28; 675:0.06; 677:0.06; 682:0.06; 658:0.06
. 2 r
. . .
. 1 .

Reward: +0.00, Result: neutral

--- Step 4 ---
Agent 1 joint action: 3 → (UP, RIGHT)
Agent 2 joint action: 3 → (UP, RIGHT)
Executed: Agent 1: UP, Agent 2: RIGHT
  Agent1 beliefs:
    agent1_pos: 7:1.00, 8:0.00, 6:0.00
    agent2_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 2:1.00, 8:0.00, 0:0.00
    blue_button_pos: 1:1.00, 2:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 7:1.00, 8:0.00, 6:0.00
    agent2_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 2:1.00, 8:0.00, 0:0.00
    blue_button_pos: 1:1.00, 2:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 112:0.00; 352:0.00; 772:0.00; 118:0.00; 778:0.00
  Agent2 top policies: 112:0.00; 352:0.00; 772:0.00; 118:0.00; 778:0.00
. b 2
. 1 .
. . .

Reward: +0.00, Result: neutral

--- Step 5 ---
Agent 1 joint action: 4 → (UP, PRESS)
Agent 2 joint action: 4 → (UP, PRESS)
Executed: Agent 1: UP, Agent 2: PRESS
  Agent1 beliefs:
    agent1_pos: 4:1.00, 8:0.00, 7:0.00
    agent2_pos: 2:1.00, 8:0.00, 7:0.00
    red_button_pos: 2:1.00, 8:0.00, 0:0.00
    blue_button_pos: 1:1.00, 7:0.00, 8:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 4:1.00, 8:0.00, 7:0.00
    agent2_pos: 2:1.00, 8:0.00, 7:0.00
    red_button_pos: 2:1.00, 8:0.00, 0:0.00
    blue_button_pos: 1:1.00, 7:0.00, 8:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 171:0.16; 172:0.16; 168:0.16; 169:0.16; 173:0.16
  Agent2 top policies: 171:0.16; 172:0.16; 168:0.16; 169:0.16; 173:0.16
. 1 2
. . .
. . .

Reward: +0.00, Result: neutral
Button pressed: red by Agent 2

--- Step 6 ---
Agent 1 joint action: 24 → (PRESS, UP)
Agent 2 joint action: 24 → (PRESS, UP)
Executed: Agent 1: PRESS, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 1:1.00, 8:0.00, 7:0.00
    agent2_pos: 2:1.00, 8:0.00, 7:0.00
    red_button_pos: 2:1.00, 8:0.00, 7:0.00
    blue_button_pos: 1:1.00, 7:0.00, 8:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 1:1.00, 8:0.00, 7:0.00
    agent2_pos: 2:1.00, 8:0.00, 7:0.00
    red_button_pos: 2:1.00, 8:0.00, 7:0.00
    blue_button_pos: 1:1.00, 7:0.00, 8:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 982:0.00; 983:0.00; 984:0.00; 985:0.00; 986:0.00
  Agent2 top policies: 982:0.00; 983:0.00; 984:0.00; 985:0.00; 986:0.00
. 1 2
. . .
. . .

Reward: +1.00, Result: win
Button pressed: blue by Agent 1

Result: ✅ WIN - win (steps: 6, reward: +1.00)

================================================================================
SEED 0 - CONFIG 3
Red at (1, 0), Blue at (0, 2)
Episodes 41-60
================================================================================

================================================================================
EPISODE 41
================================================================================
Environment: Red at (1, 0), Blue at (0, 2)

Initial state:
1 r .
. . .
b . 2


--- Step 1 ---
Agent 1 joint action: 6 → (DOWN, UP)
Agent 2 joint action: 6 → (DOWN, UP)
Executed: Agent 1: DOWN, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 0:1.00, 8:0.00, 7:0.00
    agent2_pos: 8:1.00, 0:0.00, 7:0.00
    red_button_pos: 7:0.14, 3:0.14, 6:0.14
    blue_button_pos: 7:0.14, 3:0.14, 6:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 0:1.00, 8:0.00, 7:0.00
    agent2_pos: 8:1.00, 0:0.00, 7:0.00
    red_button_pos: 7:0.14, 3:0.14, 6:0.14
    blue_button_pos: 7:0.14, 3:0.14, 6:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 244:0.02; 676:0.02; 316:0.02; 748:0.02; 677:0.01
  Agent2 top policies: 244:0.02; 676:0.02; 316:0.02; 748:0.02; 677:0.01
. r .
1 . 2
b . .

Reward: +0.00, Result: neutral

--- Step 2 ---
Agent 1 joint action: 8 → (DOWN, LEFT)
Agent 2 joint action: 8 → (DOWN, LEFT)
Executed: Agent 1: DOWN, Agent 2: LEFT
  Agent1 beliefs:
    agent1_pos: 3:1.00, 8:0.00, 5:0.00
    agent2_pos: 5:1.00, 8:0.00, 3:0.00
    red_button_pos: 7:0.20, 1:0.20, 6:0.20
    blue_button_pos: 7:0.20, 1:0.20, 6:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 3:1.00, 8:0.00, 5:0.00
    agent2_pos: 5:1.00, 8:0.00, 3:0.00
    red_button_pos: 7:0.20, 1:0.20, 6:0.20
    blue_button_pos: 7:0.20, 1:0.20, 6:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 316:0.05; 676:0.05; 244:0.05; 313:0.02; 243:0.02
  Agent2 top policies: 316:0.05; 676:0.05; 244:0.05; 313:0.02; 243:0.02
. r .
. 2 .
1 . .

Reward: +0.00, Result: neutral

--- Step 3 ---
Agent 1 joint action: 18 → (RIGHT, UP)
Agent 2 joint action: 18 → (RIGHT, UP)
Executed: Agent 1: RIGHT, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 6:1.00, 8:0.00, 7:0.00
    agent2_pos: 4:1.00, 8:0.00, 5:0.00
    red_button_pos: 7:0.33, 1:0.33, 2:0.33
    blue_button_pos: 6:1.00, 1:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 6:1.00, 8:0.00, 7:0.00
    agent2_pos: 4:1.00, 8:0.00, 5:0.00
    red_button_pos: 7:0.33, 1:0.33, 2:0.33
    blue_button_pos: 6:1.00, 1:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 676:0.04; 677:0.03; 682:0.03; 675:0.03; 672:0.03
  Agent2 top policies: 676:0.04; 677:0.03; 682:0.03; 675:0.03; 672:0.03
. 2 .
. . .
b 1 .

Reward: +0.00, Result: neutral

--- Step 4 ---
Agent 1 joint action: 16 → (LEFT, PRESS)
Agent 2 joint action: 16 → (LEFT, PRESS)
Executed: Agent 1: LEFT, Agent 2: PRESS
  Agent1 beliefs:
    agent1_pos: 7:1.00, 8:0.00, 5:0.00
    agent2_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 2:0.00, 7:0.00
    blue_button_pos: 6:1.00, 2:0.00, 4:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 7:1.00, 8:0.00, 5:0.00
    agent2_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 2:0.00, 7:0.00
    blue_button_pos: 6:1.00, 2:0.00, 4:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 602:0.16; 601:0.16; 600:0.16; 604:0.16; 605:0.16
  Agent2 top policies: 602:0.16; 601:0.16; 600:0.16; 604:0.16; 605:0.16
. 2 .
. . .
1 . .

Reward: +0.00, Result: neutral
Button pressed: red by Agent 2

--- Step 5 ---
Agent 1 joint action: 24 → (PRESS, UP)
Agent 2 joint action: 24 → (PRESS, UP)
Executed: Agent 1: PRESS, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 6:1.00, 8:0.00, 7:0.00
    agent2_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 2:0.00, 7:0.00
    blue_button_pos: 6:1.00, 2:0.00, 4:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 6:1.00, 8:0.00, 7:0.00
    agent2_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 2:0.00, 7:0.00
    blue_button_pos: 6:1.00, 2:0.00, 4:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 1031:0.00; 1032:0.00; 1033:0.00; 1034:0.00; 1035:0.00
  Agent2 top policies: 1031:0.00; 1032:0.00; 1033:0.00; 1034:0.00; 1035:0.00
. 2 .
. . .
1 . .

Reward: +1.00, Result: win
Button pressed: blue by Agent 1

Result: ✅ WIN - win (steps: 5, reward: +1.00)

================================================================================
EPISODE 42
================================================================================
Environment: Red at (1, 0), Blue at (0, 2)

Initial state:
1 r .
. . .
b . 2


--- Step 1 ---
Agent 1 joint action: 6 → (DOWN, UP)
Agent 2 joint action: 6 → (DOWN, UP)
Executed: Agent 1: DOWN, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 0:1.00, 8:0.00, 7:0.00
    agent2_pos: 8:1.00, 0:0.00, 7:0.00
    red_button_pos: 7:0.14, 3:0.14, 6:0.14
    blue_button_pos: 7:0.14, 3:0.14, 6:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 0:1.00, 8:0.00, 7:0.00
    agent2_pos: 8:1.00, 0:0.00, 7:0.00
    red_button_pos: 7:0.14, 3:0.14, 6:0.14
    blue_button_pos: 7:0.14, 3:0.14, 6:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 244:0.02; 676:0.02; 316:0.02; 748:0.02; 677:0.01
  Agent2 top policies: 244:0.02; 676:0.02; 316:0.02; 748:0.02; 677:0.01
. r .
1 . 2
b . .

Reward: +0.00, Result: neutral

--- Step 2 ---
Agent 1 joint action: 8 → (DOWN, LEFT)
Agent 2 joint action: 8 → (DOWN, LEFT)
Executed: Agent 1: DOWN, Agent 2: LEFT
  Agent1 beliefs:
    agent1_pos: 3:1.00, 8:0.00, 5:0.00
    agent2_pos: 5:1.00, 8:0.00, 3:0.00
    red_button_pos: 7:0.20, 1:0.20, 6:0.20
    blue_button_pos: 7:0.20, 1:0.20, 6:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 3:1.00, 8:0.00, 5:0.00
    agent2_pos: 5:1.00, 8:0.00, 3:0.00
    red_button_pos: 7:0.20, 1:0.20, 6:0.20
    blue_button_pos: 7:0.20, 1:0.20, 6:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 316:0.05; 676:0.05; 244:0.05; 313:0.02; 243:0.02
  Agent2 top policies: 316:0.05; 676:0.05; 244:0.05; 313:0.02; 243:0.02
. r .
. 2 .
1 . .

Reward: +0.00, Result: neutral

--- Step 3 ---
Agent 1 joint action: 18 → (RIGHT, UP)
Agent 2 joint action: 18 → (RIGHT, UP)
Executed: Agent 1: RIGHT, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 6:1.00, 8:0.00, 7:0.00
    agent2_pos: 4:1.00, 8:0.00, 5:0.00
    red_button_pos: 7:0.33, 1:0.33, 2:0.33
    blue_button_pos: 6:1.00, 1:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 6:1.00, 8:0.00, 7:0.00
    agent2_pos: 4:1.00, 8:0.00, 5:0.00
    red_button_pos: 7:0.33, 1:0.33, 2:0.33
    blue_button_pos: 6:1.00, 1:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 676:0.04; 677:0.03; 682:0.03; 675:0.03; 672:0.03
  Agent2 top policies: 676:0.04; 677:0.03; 682:0.03; 675:0.03; 672:0.03
. 2 .
. . .
b 1 .

Reward: +0.00, Result: neutral

--- Step 4 ---
Agent 1 joint action: 16 → (LEFT, PRESS)
Agent 2 joint action: 16 → (LEFT, PRESS)
Executed: Agent 1: LEFT, Agent 2: PRESS
  Agent1 beliefs:
    agent1_pos: 7:1.00, 8:0.00, 5:0.00
    agent2_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 2:0.00, 7:0.00
    blue_button_pos: 6:1.00, 2:0.00, 4:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 7:1.00, 8:0.00, 5:0.00
    agent2_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 2:0.00, 7:0.00
    blue_button_pos: 6:1.00, 2:0.00, 4:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 602:0.16; 601:0.16; 600:0.16; 604:0.16; 605:0.16
  Agent2 top policies: 602:0.16; 601:0.16; 600:0.16; 604:0.16; 605:0.16
. 2 .
. . .
1 . .

Reward: +0.00, Result: neutral
Button pressed: red by Agent 2

--- Step 5 ---
Agent 1 joint action: 24 → (PRESS, UP)
Agent 2 joint action: 24 → (PRESS, UP)
Executed: Agent 1: PRESS, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 6:1.00, 8:0.00, 7:0.00
    agent2_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 2:0.00, 7:0.00
    blue_button_pos: 6:1.00, 2:0.00, 4:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 6:1.00, 8:0.00, 7:0.00
    agent2_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 2:0.00, 7:0.00
    blue_button_pos: 6:1.00, 2:0.00, 4:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 1031:0.00; 1032:0.00; 1033:0.00; 1034:0.00; 1035:0.00
  Agent2 top policies: 1031:0.00; 1032:0.00; 1033:0.00; 1034:0.00; 1035:0.00
. 2 .
. . .
1 . .

Reward: +1.00, Result: win
Button pressed: blue by Agent 1

Result: ✅ WIN - win (steps: 5, reward: +1.00)

================================================================================
EPISODE 43
================================================================================
Environment: Red at (1, 0), Blue at (0, 2)

Initial state:
1 r .
. . .
b . 2


--- Step 1 ---
Agent 1 joint action: 6 → (DOWN, UP)
Agent 2 joint action: 6 → (DOWN, UP)
Executed: Agent 1: DOWN, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 0:1.00, 8:0.00, 7:0.00
    agent2_pos: 8:1.00, 0:0.00, 7:0.00
    red_button_pos: 7:0.14, 3:0.14, 6:0.14
    blue_button_pos: 7:0.14, 3:0.14, 6:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 0:1.00, 8:0.00, 7:0.00
    agent2_pos: 8:1.00, 0:0.00, 7:0.00
    red_button_pos: 7:0.14, 3:0.14, 6:0.14
    blue_button_pos: 7:0.14, 3:0.14, 6:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 244:0.02; 676:0.02; 316:0.02; 748:0.02; 677:0.01
  Agent2 top policies: 244:0.02; 676:0.02; 316:0.02; 748:0.02; 677:0.01
. r .
1 . 2
b . .

Reward: +0.00, Result: neutral

--- Step 2 ---
Agent 1 joint action: 8 → (DOWN, LEFT)
Agent 2 joint action: 8 → (DOWN, LEFT)
Executed: Agent 1: DOWN, Agent 2: LEFT
  Agent1 beliefs:
    agent1_pos: 3:1.00, 8:0.00, 5:0.00
    agent2_pos: 5:1.00, 8:0.00, 3:0.00
    red_button_pos: 7:0.20, 1:0.20, 6:0.20
    blue_button_pos: 7:0.20, 1:0.20, 6:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 3:1.00, 8:0.00, 5:0.00
    agent2_pos: 5:1.00, 8:0.00, 3:0.00
    red_button_pos: 7:0.20, 1:0.20, 6:0.20
    blue_button_pos: 7:0.20, 1:0.20, 6:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 316:0.05; 676:0.05; 244:0.05; 313:0.02; 243:0.02
  Agent2 top policies: 316:0.05; 676:0.05; 244:0.05; 313:0.02; 243:0.02
. r .
. 2 .
1 . .

Reward: +0.00, Result: neutral

--- Step 3 ---
Agent 1 joint action: 18 → (RIGHT, UP)
Agent 2 joint action: 18 → (RIGHT, UP)
Executed: Agent 1: RIGHT, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 6:1.00, 8:0.00, 7:0.00
    agent2_pos: 4:1.00, 8:0.00, 5:0.00
    red_button_pos: 7:0.33, 1:0.33, 2:0.33
    blue_button_pos: 6:1.00, 1:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 6:1.00, 8:0.00, 7:0.00
    agent2_pos: 4:1.00, 8:0.00, 5:0.00
    red_button_pos: 7:0.33, 1:0.33, 2:0.33
    blue_button_pos: 6:1.00, 1:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 676:0.04; 677:0.03; 682:0.03; 675:0.03; 672:0.03
  Agent2 top policies: 676:0.04; 677:0.03; 682:0.03; 675:0.03; 672:0.03
. 2 .
. . .
b 1 .

Reward: +0.00, Result: neutral

--- Step 4 ---
Agent 1 joint action: 16 → (LEFT, PRESS)
Agent 2 joint action: 16 → (LEFT, PRESS)
Executed: Agent 1: LEFT, Agent 2: PRESS
  Agent1 beliefs:
    agent1_pos: 7:1.00, 8:0.00, 5:0.00
    agent2_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 2:0.00, 7:0.00
    blue_button_pos: 6:1.00, 2:0.00, 4:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 7:1.00, 8:0.00, 5:0.00
    agent2_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 2:0.00, 7:0.00
    blue_button_pos: 6:1.00, 2:0.00, 4:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 602:0.16; 601:0.16; 600:0.16; 604:0.16; 605:0.16
  Agent2 top policies: 602:0.16; 601:0.16; 600:0.16; 604:0.16; 605:0.16
. 2 .
. . .
1 . .

Reward: +0.00, Result: neutral
Button pressed: red by Agent 2

--- Step 5 ---
Agent 1 joint action: 24 → (PRESS, UP)
Agent 2 joint action: 24 → (PRESS, UP)
Executed: Agent 1: PRESS, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 6:1.00, 8:0.00, 7:0.00
    agent2_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 2:0.00, 7:0.00
    blue_button_pos: 6:1.00, 2:0.00, 4:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 6:1.00, 8:0.00, 7:0.00
    agent2_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 2:0.00, 7:0.00
    blue_button_pos: 6:1.00, 2:0.00, 4:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 1031:0.00; 1032:0.00; 1033:0.00; 1034:0.00; 1035:0.00
  Agent2 top policies: 1031:0.00; 1032:0.00; 1033:0.00; 1034:0.00; 1035:0.00
. 2 .
. . .
1 . .

Reward: +1.00, Result: win
Button pressed: blue by Agent 1

Result: ✅ WIN - win (steps: 5, reward: +1.00)

================================================================================
EPISODE 44
================================================================================
Environment: Red at (1, 0), Blue at (0, 2)

Initial state:
1 r .
. . .
b . 2


--- Step 1 ---
Agent 1 joint action: 6 → (DOWN, UP)
Agent 2 joint action: 6 → (DOWN, UP)
Executed: Agent 1: DOWN, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 0:1.00, 8:0.00, 7:0.00
    agent2_pos: 8:1.00, 0:0.00, 7:0.00
    red_button_pos: 7:0.14, 3:0.14, 6:0.14
    blue_button_pos: 7:0.14, 3:0.14, 6:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 0:1.00, 8:0.00, 7:0.00
    agent2_pos: 8:1.00, 0:0.00, 7:0.00
    red_button_pos: 7:0.14, 3:0.14, 6:0.14
    blue_button_pos: 7:0.14, 3:0.14, 6:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 244:0.02; 676:0.02; 316:0.02; 748:0.02; 677:0.01
  Agent2 top policies: 244:0.02; 676:0.02; 316:0.02; 748:0.02; 677:0.01
. r .
1 . 2
b . .

Reward: +0.00, Result: neutral

--- Step 2 ---
Agent 1 joint action: 8 → (DOWN, LEFT)
Agent 2 joint action: 8 → (DOWN, LEFT)
Executed: Agent 1: DOWN, Agent 2: LEFT
  Agent1 beliefs:
    agent1_pos: 3:1.00, 8:0.00, 5:0.00
    agent2_pos: 5:1.00, 8:0.00, 3:0.00
    red_button_pos: 7:0.20, 1:0.20, 6:0.20
    blue_button_pos: 7:0.20, 1:0.20, 6:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 3:1.00, 8:0.00, 5:0.00
    agent2_pos: 5:1.00, 8:0.00, 3:0.00
    red_button_pos: 7:0.20, 1:0.20, 6:0.20
    blue_button_pos: 7:0.20, 1:0.20, 6:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 316:0.05; 676:0.05; 244:0.05; 313:0.02; 243:0.02
  Agent2 top policies: 316:0.05; 676:0.05; 244:0.05; 313:0.02; 243:0.02
. r .
. 2 .
1 . .

Reward: +0.00, Result: neutral

--- Step 3 ---
Agent 1 joint action: 18 → (RIGHT, UP)
Agent 2 joint action: 18 → (RIGHT, UP)
Executed: Agent 1: RIGHT, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 6:1.00, 8:0.00, 7:0.00
    agent2_pos: 4:1.00, 8:0.00, 5:0.00
    red_button_pos: 7:0.33, 1:0.33, 2:0.33
    blue_button_pos: 6:1.00, 1:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 6:1.00, 8:0.00, 7:0.00
    agent2_pos: 4:1.00, 8:0.00, 5:0.00
    red_button_pos: 7:0.33, 1:0.33, 2:0.33
    blue_button_pos: 6:1.00, 1:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 676:0.04; 677:0.03; 682:0.03; 675:0.03; 672:0.03
  Agent2 top policies: 676:0.04; 677:0.03; 682:0.03; 675:0.03; 672:0.03
. 2 .
. . .
b 1 .

Reward: +0.00, Result: neutral

--- Step 4 ---
Agent 1 joint action: 16 → (LEFT, PRESS)
Agent 2 joint action: 16 → (LEFT, PRESS)
Executed: Agent 1: LEFT, Agent 2: PRESS
  Agent1 beliefs:
    agent1_pos: 7:1.00, 8:0.00, 5:0.00
    agent2_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 2:0.00, 7:0.00
    blue_button_pos: 6:1.00, 2:0.00, 4:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 7:1.00, 8:0.00, 5:0.00
    agent2_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 2:0.00, 7:0.00
    blue_button_pos: 6:1.00, 2:0.00, 4:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 602:0.16; 601:0.16; 600:0.16; 604:0.16; 605:0.16
  Agent2 top policies: 602:0.16; 601:0.16; 600:0.16; 604:0.16; 605:0.16
. 2 .
. . .
1 . .

Reward: +0.00, Result: neutral
Button pressed: red by Agent 2

--- Step 5 ---
Agent 1 joint action: 24 → (PRESS, UP)
Agent 2 joint action: 24 → (PRESS, UP)
Executed: Agent 1: PRESS, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 6:1.00, 8:0.00, 7:0.00
    agent2_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 2:0.00, 7:0.00
    blue_button_pos: 6:1.00, 2:0.00, 4:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 6:1.00, 8:0.00, 7:0.00
    agent2_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 2:0.00, 7:0.00
    blue_button_pos: 6:1.00, 2:0.00, 4:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 1031:0.00; 1032:0.00; 1033:0.00; 1034:0.00; 1035:0.00
  Agent2 top policies: 1031:0.00; 1032:0.00; 1033:0.00; 1034:0.00; 1035:0.00
. 2 .
. . .
1 . .

Reward: +1.00, Result: win
Button pressed: blue by Agent 1

Result: ✅ WIN - win (steps: 5, reward: +1.00)

================================================================================
EPISODE 45
================================================================================
Environment: Red at (1, 0), Blue at (0, 2)

Initial state:
1 r .
. . .
b . 2


--- Step 1 ---
Agent 1 joint action: 6 → (DOWN, UP)
Agent 2 joint action: 6 → (DOWN, UP)
Executed: Agent 1: DOWN, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 0:1.00, 8:0.00, 7:0.00
    agent2_pos: 8:1.00, 0:0.00, 7:0.00
    red_button_pos: 7:0.14, 3:0.14, 6:0.14
    blue_button_pos: 7:0.14, 3:0.14, 6:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 0:1.00, 8:0.00, 7:0.00
    agent2_pos: 8:1.00, 0:0.00, 7:0.00
    red_button_pos: 7:0.14, 3:0.14, 6:0.14
    blue_button_pos: 7:0.14, 3:0.14, 6:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 244:0.02; 676:0.02; 316:0.02; 748:0.02; 677:0.01
  Agent2 top policies: 244:0.02; 676:0.02; 316:0.02; 748:0.02; 677:0.01
. r .
1 . 2
b . .

Reward: +0.00, Result: neutral

--- Step 2 ---
Agent 1 joint action: 8 → (DOWN, LEFT)
Agent 2 joint action: 8 → (DOWN, LEFT)
Executed: Agent 1: DOWN, Agent 2: LEFT
  Agent1 beliefs:
    agent1_pos: 3:1.00, 8:0.00, 5:0.00
    agent2_pos: 5:1.00, 8:0.00, 3:0.00
    red_button_pos: 7:0.20, 1:0.20, 6:0.20
    blue_button_pos: 7:0.20, 1:0.20, 6:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 3:1.00, 8:0.00, 5:0.00
    agent2_pos: 5:1.00, 8:0.00, 3:0.00
    red_button_pos: 7:0.20, 1:0.20, 6:0.20
    blue_button_pos: 7:0.20, 1:0.20, 6:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 316:0.05; 676:0.05; 244:0.05; 313:0.02; 243:0.02
  Agent2 top policies: 316:0.05; 676:0.05; 244:0.05; 313:0.02; 243:0.02
. r .
. 2 .
1 . .

Reward: +0.00, Result: neutral

--- Step 3 ---
Agent 1 joint action: 18 → (RIGHT, UP)
Agent 2 joint action: 18 → (RIGHT, UP)
Executed: Agent 1: RIGHT, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 6:1.00, 8:0.00, 7:0.00
    agent2_pos: 4:1.00, 8:0.00, 5:0.00
    red_button_pos: 7:0.33, 1:0.33, 2:0.33
    blue_button_pos: 6:1.00, 1:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 6:1.00, 8:0.00, 7:0.00
    agent2_pos: 4:1.00, 8:0.00, 5:0.00
    red_button_pos: 7:0.33, 1:0.33, 2:0.33
    blue_button_pos: 6:1.00, 1:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 676:0.04; 677:0.03; 682:0.03; 675:0.03; 672:0.03
  Agent2 top policies: 676:0.04; 677:0.03; 682:0.03; 675:0.03; 672:0.03
. 2 .
. . .
b 1 .

Reward: +0.00, Result: neutral

--- Step 4 ---
Agent 1 joint action: 16 → (LEFT, PRESS)
Agent 2 joint action: 16 → (LEFT, PRESS)
Executed: Agent 1: LEFT, Agent 2: PRESS
  Agent1 beliefs:
    agent1_pos: 7:1.00, 8:0.00, 5:0.00
    agent2_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 2:0.00, 7:0.00
    blue_button_pos: 6:1.00, 2:0.00, 4:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 7:1.00, 8:0.00, 5:0.00
    agent2_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 2:0.00, 7:0.00
    blue_button_pos: 6:1.00, 2:0.00, 4:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 602:0.16; 601:0.16; 600:0.16; 604:0.16; 605:0.16
  Agent2 top policies: 602:0.16; 601:0.16; 600:0.16; 604:0.16; 605:0.16
. 2 .
. . .
1 . .

Reward: +0.00, Result: neutral
Button pressed: red by Agent 2

--- Step 5 ---
Agent 1 joint action: 24 → (PRESS, UP)
Agent 2 joint action: 24 → (PRESS, UP)
Executed: Agent 1: PRESS, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 6:1.00, 8:0.00, 7:0.00
    agent2_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 2:0.00, 7:0.00
    blue_button_pos: 6:1.00, 2:0.00, 4:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 6:1.00, 8:0.00, 7:0.00
    agent2_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 2:0.00, 7:0.00
    blue_button_pos: 6:1.00, 2:0.00, 4:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 1031:0.00; 1032:0.00; 1033:0.00; 1034:0.00; 1035:0.00
  Agent2 top policies: 1031:0.00; 1032:0.00; 1033:0.00; 1034:0.00; 1035:0.00
. 2 .
. . .
1 . .

Reward: +1.00, Result: win
Button pressed: blue by Agent 1

Result: ✅ WIN - win (steps: 5, reward: +1.00)

================================================================================
EPISODE 46
================================================================================
Environment: Red at (1, 0), Blue at (0, 2)

Initial state:
1 r .
. . .
b . 2


--- Step 1 ---
Agent 1 joint action: 6 → (DOWN, UP)
Agent 2 joint action: 6 → (DOWN, UP)
Executed: Agent 1: DOWN, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 0:1.00, 8:0.00, 7:0.00
    agent2_pos: 8:1.00, 0:0.00, 7:0.00
    red_button_pos: 7:0.14, 3:0.14, 6:0.14
    blue_button_pos: 7:0.14, 3:0.14, 6:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 0:1.00, 8:0.00, 7:0.00
    agent2_pos: 8:1.00, 0:0.00, 7:0.00
    red_button_pos: 7:0.14, 3:0.14, 6:0.14
    blue_button_pos: 7:0.14, 3:0.14, 6:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 244:0.02; 676:0.02; 316:0.02; 748:0.02; 677:0.01
  Agent2 top policies: 244:0.02; 676:0.02; 316:0.02; 748:0.02; 677:0.01
. r .
1 . 2
b . .

Reward: +0.00, Result: neutral

--- Step 2 ---
Agent 1 joint action: 8 → (DOWN, LEFT)
Agent 2 joint action: 8 → (DOWN, LEFT)
Executed: Agent 1: DOWN, Agent 2: LEFT
  Agent1 beliefs:
    agent1_pos: 3:1.00, 8:0.00, 5:0.00
    agent2_pos: 5:1.00, 8:0.00, 3:0.00
    red_button_pos: 7:0.20, 1:0.20, 6:0.20
    blue_button_pos: 7:0.20, 1:0.20, 6:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 3:1.00, 8:0.00, 5:0.00
    agent2_pos: 5:1.00, 8:0.00, 3:0.00
    red_button_pos: 7:0.20, 1:0.20, 6:0.20
    blue_button_pos: 7:0.20, 1:0.20, 6:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 316:0.05; 676:0.05; 244:0.05; 313:0.02; 243:0.02
  Agent2 top policies: 316:0.05; 676:0.05; 244:0.05; 313:0.02; 243:0.02
. r .
. 2 .
1 . .

Reward: +0.00, Result: neutral

--- Step 3 ---
Agent 1 joint action: 18 → (RIGHT, UP)
Agent 2 joint action: 18 → (RIGHT, UP)
Executed: Agent 1: RIGHT, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 6:1.00, 8:0.00, 7:0.00
    agent2_pos: 4:1.00, 8:0.00, 5:0.00
    red_button_pos: 7:0.33, 1:0.33, 2:0.33
    blue_button_pos: 6:1.00, 1:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 6:1.00, 8:0.00, 7:0.00
    agent2_pos: 4:1.00, 8:0.00, 5:0.00
    red_button_pos: 7:0.33, 1:0.33, 2:0.33
    blue_button_pos: 6:1.00, 1:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 676:0.04; 677:0.03; 682:0.03; 675:0.03; 672:0.03
  Agent2 top policies: 676:0.04; 677:0.03; 682:0.03; 675:0.03; 672:0.03
. 2 .
. . .
b 1 .

Reward: +0.00, Result: neutral

--- Step 4 ---
Agent 1 joint action: 16 → (LEFT, PRESS)
Agent 2 joint action: 16 → (LEFT, PRESS)
Executed: Agent 1: LEFT, Agent 2: PRESS
  Agent1 beliefs:
    agent1_pos: 7:1.00, 8:0.00, 5:0.00
    agent2_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 2:0.00, 7:0.00
    blue_button_pos: 6:1.00, 2:0.00, 4:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 7:1.00, 8:0.00, 5:0.00
    agent2_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 2:0.00, 7:0.00
    blue_button_pos: 6:1.00, 2:0.00, 4:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 602:0.16; 601:0.16; 600:0.16; 604:0.16; 605:0.16
  Agent2 top policies: 602:0.16; 601:0.16; 600:0.16; 604:0.16; 605:0.16
. 2 .
. . .
1 . .

Reward: +0.00, Result: neutral
Button pressed: red by Agent 2

--- Step 5 ---
Agent 1 joint action: 24 → (PRESS, UP)
Agent 2 joint action: 24 → (PRESS, UP)
Executed: Agent 1: PRESS, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 6:1.00, 8:0.00, 7:0.00
    agent2_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 2:0.00, 7:0.00
    blue_button_pos: 6:1.00, 2:0.00, 4:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 6:1.00, 8:0.00, 7:0.00
    agent2_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 2:0.00, 7:0.00
    blue_button_pos: 6:1.00, 2:0.00, 4:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 1031:0.00; 1032:0.00; 1033:0.00; 1034:0.00; 1035:0.00
  Agent2 top policies: 1031:0.00; 1032:0.00; 1033:0.00; 1034:0.00; 1035:0.00
. 2 .
. . .
1 . .

Reward: +1.00, Result: win
Button pressed: blue by Agent 1

Result: ✅ WIN - win (steps: 5, reward: +1.00)

================================================================================
EPISODE 47
================================================================================
Environment: Red at (1, 0), Blue at (0, 2)

Initial state:
1 r .
. . .
b . 2


--- Step 1 ---
Agent 1 joint action: 6 → (DOWN, UP)
Agent 2 joint action: 6 → (DOWN, UP)
Executed: Agent 1: DOWN, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 0:1.00, 8:0.00, 7:0.00
    agent2_pos: 8:1.00, 0:0.00, 7:0.00
    red_button_pos: 7:0.14, 3:0.14, 6:0.14
    blue_button_pos: 7:0.14, 3:0.14, 6:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 0:1.00, 8:0.00, 7:0.00
    agent2_pos: 8:1.00, 0:0.00, 7:0.00
    red_button_pos: 7:0.14, 3:0.14, 6:0.14
    blue_button_pos: 7:0.14, 3:0.14, 6:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 244:0.02; 676:0.02; 316:0.02; 748:0.02; 677:0.01
  Agent2 top policies: 244:0.02; 676:0.02; 316:0.02; 748:0.02; 677:0.01
. r .
1 . 2
b . .

Reward: +0.00, Result: neutral

--- Step 2 ---
Agent 1 joint action: 8 → (DOWN, LEFT)
Agent 2 joint action: 8 → (DOWN, LEFT)
Executed: Agent 1: DOWN, Agent 2: LEFT
  Agent1 beliefs:
    agent1_pos: 3:1.00, 8:0.00, 5:0.00
    agent2_pos: 5:1.00, 8:0.00, 3:0.00
    red_button_pos: 7:0.20, 1:0.20, 6:0.20
    blue_button_pos: 7:0.20, 1:0.20, 6:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 3:1.00, 8:0.00, 5:0.00
    agent2_pos: 5:1.00, 8:0.00, 3:0.00
    red_button_pos: 7:0.20, 1:0.20, 6:0.20
    blue_button_pos: 7:0.20, 1:0.20, 6:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 316:0.05; 676:0.05; 244:0.05; 313:0.02; 243:0.02
  Agent2 top policies: 316:0.05; 676:0.05; 244:0.05; 313:0.02; 243:0.02
. r .
. 2 .
1 . .

Reward: +0.00, Result: neutral

--- Step 3 ---
Agent 1 joint action: 18 → (RIGHT, UP)
Agent 2 joint action: 18 → (RIGHT, UP)
Executed: Agent 1: RIGHT, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 6:1.00, 8:0.00, 7:0.00
    agent2_pos: 4:1.00, 8:0.00, 5:0.00
    red_button_pos: 7:0.33, 1:0.33, 2:0.33
    blue_button_pos: 6:1.00, 1:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 6:1.00, 8:0.00, 7:0.00
    agent2_pos: 4:1.00, 8:0.00, 5:0.00
    red_button_pos: 7:0.33, 1:0.33, 2:0.33
    blue_button_pos: 6:1.00, 1:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 676:0.04; 677:0.03; 682:0.03; 675:0.03; 672:0.03
  Agent2 top policies: 676:0.04; 677:0.03; 682:0.03; 675:0.03; 672:0.03
. 2 .
. . .
b 1 .

Reward: +0.00, Result: neutral

--- Step 4 ---
Agent 1 joint action: 16 → (LEFT, PRESS)
Agent 2 joint action: 16 → (LEFT, PRESS)
Executed: Agent 1: LEFT, Agent 2: PRESS
  Agent1 beliefs:
    agent1_pos: 7:1.00, 8:0.00, 5:0.00
    agent2_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 2:0.00, 7:0.00
    blue_button_pos: 6:1.00, 2:0.00, 4:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 7:1.00, 8:0.00, 5:0.00
    agent2_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 2:0.00, 7:0.00
    blue_button_pos: 6:1.00, 2:0.00, 4:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 602:0.16; 601:0.16; 600:0.16; 604:0.16; 605:0.16
  Agent2 top policies: 602:0.16; 601:0.16; 600:0.16; 604:0.16; 605:0.16
. 2 .
. . .
1 . .

Reward: +0.00, Result: neutral
Button pressed: red by Agent 2

--- Step 5 ---
Agent 1 joint action: 24 → (PRESS, UP)
Agent 2 joint action: 24 → (PRESS, UP)
Executed: Agent 1: PRESS, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 6:1.00, 8:0.00, 7:0.00
    agent2_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 2:0.00, 7:0.00
    blue_button_pos: 6:1.00, 2:0.00, 4:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 6:1.00, 8:0.00, 7:0.00
    agent2_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 2:0.00, 7:0.00
    blue_button_pos: 6:1.00, 2:0.00, 4:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 1031:0.00; 1032:0.00; 1033:0.00; 1034:0.00; 1035:0.00
  Agent2 top policies: 1031:0.00; 1032:0.00; 1033:0.00; 1034:0.00; 1035:0.00
. 2 .
. . .
1 . .

Reward: +1.00, Result: win
Button pressed: blue by Agent 1

Result: ✅ WIN - win (steps: 5, reward: +1.00)

================================================================================
EPISODE 48
================================================================================
Environment: Red at (1, 0), Blue at (0, 2)

Initial state:
1 r .
. . .
b . 2


--- Step 1 ---
Agent 1 joint action: 6 → (DOWN, UP)
Agent 2 joint action: 6 → (DOWN, UP)
Executed: Agent 1: DOWN, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 0:1.00, 8:0.00, 7:0.00
    agent2_pos: 8:1.00, 0:0.00, 7:0.00
    red_button_pos: 7:0.14, 3:0.14, 6:0.14
    blue_button_pos: 7:0.14, 3:0.14, 6:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 0:1.00, 8:0.00, 7:0.00
    agent2_pos: 8:1.00, 0:0.00, 7:0.00
    red_button_pos: 7:0.14, 3:0.14, 6:0.14
    blue_button_pos: 7:0.14, 3:0.14, 6:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 244:0.02; 676:0.02; 316:0.02; 748:0.02; 677:0.01
  Agent2 top policies: 244:0.02; 676:0.02; 316:0.02; 748:0.02; 677:0.01
. r .
1 . 2
b . .

Reward: +0.00, Result: neutral

--- Step 2 ---
Agent 1 joint action: 8 → (DOWN, LEFT)
Agent 2 joint action: 8 → (DOWN, LEFT)
Executed: Agent 1: DOWN, Agent 2: LEFT
  Agent1 beliefs:
    agent1_pos: 3:1.00, 8:0.00, 5:0.00
    agent2_pos: 5:1.00, 8:0.00, 3:0.00
    red_button_pos: 7:0.20, 1:0.20, 6:0.20
    blue_button_pos: 7:0.20, 1:0.20, 6:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 3:1.00, 8:0.00, 5:0.00
    agent2_pos: 5:1.00, 8:0.00, 3:0.00
    red_button_pos: 7:0.20, 1:0.20, 6:0.20
    blue_button_pos: 7:0.20, 1:0.20, 6:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 316:0.05; 676:0.05; 244:0.05; 313:0.02; 243:0.02
  Agent2 top policies: 316:0.05; 676:0.05; 244:0.05; 313:0.02; 243:0.02
. r .
. 2 .
1 . .

Reward: +0.00, Result: neutral

--- Step 3 ---
Agent 1 joint action: 18 → (RIGHT, UP)
Agent 2 joint action: 18 → (RIGHT, UP)
Executed: Agent 1: RIGHT, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 6:1.00, 8:0.00, 7:0.00
    agent2_pos: 4:1.00, 8:0.00, 5:0.00
    red_button_pos: 7:0.33, 1:0.33, 2:0.33
    blue_button_pos: 6:1.00, 1:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 6:1.00, 8:0.00, 7:0.00
    agent2_pos: 4:1.00, 8:0.00, 5:0.00
    red_button_pos: 7:0.33, 1:0.33, 2:0.33
    blue_button_pos: 6:1.00, 1:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 676:0.04; 677:0.03; 682:0.03; 675:0.03; 672:0.03
  Agent2 top policies: 676:0.04; 677:0.03; 682:0.03; 675:0.03; 672:0.03
. 2 .
. . .
b 1 .

Reward: +0.00, Result: neutral

--- Step 4 ---
Agent 1 joint action: 16 → (LEFT, PRESS)
Agent 2 joint action: 16 → (LEFT, PRESS)
Executed: Agent 1: LEFT, Agent 2: PRESS
  Agent1 beliefs:
    agent1_pos: 7:1.00, 8:0.00, 5:0.00
    agent2_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 2:0.00, 7:0.00
    blue_button_pos: 6:1.00, 2:0.00, 4:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 7:1.00, 8:0.00, 5:0.00
    agent2_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 2:0.00, 7:0.00
    blue_button_pos: 6:1.00, 2:0.00, 4:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 602:0.16; 601:0.16; 600:0.16; 604:0.16; 605:0.16
  Agent2 top policies: 602:0.16; 601:0.16; 600:0.16; 604:0.16; 605:0.16
. 2 .
. . .
1 . .

Reward: +0.00, Result: neutral
Button pressed: red by Agent 2

--- Step 5 ---
Agent 1 joint action: 24 → (PRESS, UP)
Agent 2 joint action: 24 → (PRESS, UP)
Executed: Agent 1: PRESS, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 6:1.00, 8:0.00, 7:0.00
    agent2_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 2:0.00, 7:0.00
    blue_button_pos: 6:1.00, 2:0.00, 4:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 6:1.00, 8:0.00, 7:0.00
    agent2_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 2:0.00, 7:0.00
    blue_button_pos: 6:1.00, 2:0.00, 4:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 1031:0.00; 1032:0.00; 1033:0.00; 1034:0.00; 1035:0.00
  Agent2 top policies: 1031:0.00; 1032:0.00; 1033:0.00; 1034:0.00; 1035:0.00
. 2 .
. . .
1 . .

Reward: +1.00, Result: win
Button pressed: blue by Agent 1

Result: ✅ WIN - win (steps: 5, reward: +1.00)

================================================================================
EPISODE 49
================================================================================
Environment: Red at (1, 0), Blue at (0, 2)

Initial state:
1 r .
. . .
b . 2


--- Step 1 ---
Agent 1 joint action: 6 → (DOWN, UP)
Agent 2 joint action: 6 → (DOWN, UP)
Executed: Agent 1: DOWN, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 0:1.00, 8:0.00, 7:0.00
    agent2_pos: 8:1.00, 0:0.00, 7:0.00
    red_button_pos: 7:0.14, 3:0.14, 6:0.14
    blue_button_pos: 7:0.14, 3:0.14, 6:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 0:1.00, 8:0.00, 7:0.00
    agent2_pos: 8:1.00, 0:0.00, 7:0.00
    red_button_pos: 7:0.14, 3:0.14, 6:0.14
    blue_button_pos: 7:0.14, 3:0.14, 6:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 244:0.02; 676:0.02; 316:0.02; 748:0.02; 677:0.01
  Agent2 top policies: 244:0.02; 676:0.02; 316:0.02; 748:0.02; 677:0.01
. r .
1 . 2
b . .

Reward: +0.00, Result: neutral

--- Step 2 ---
Agent 1 joint action: 8 → (DOWN, LEFT)
Agent 2 joint action: 8 → (DOWN, LEFT)
Executed: Agent 1: DOWN, Agent 2: LEFT
  Agent1 beliefs:
    agent1_pos: 3:1.00, 8:0.00, 5:0.00
    agent2_pos: 5:1.00, 8:0.00, 3:0.00
    red_button_pos: 7:0.20, 1:0.20, 6:0.20
    blue_button_pos: 7:0.20, 1:0.20, 6:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 3:1.00, 8:0.00, 5:0.00
    agent2_pos: 5:1.00, 8:0.00, 3:0.00
    red_button_pos: 7:0.20, 1:0.20, 6:0.20
    blue_button_pos: 7:0.20, 1:0.20, 6:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 316:0.05; 676:0.05; 244:0.05; 313:0.02; 243:0.02
  Agent2 top policies: 316:0.05; 676:0.05; 244:0.05; 313:0.02; 243:0.02
. r .
. 2 .
1 . .

Reward: +0.00, Result: neutral

--- Step 3 ---
Agent 1 joint action: 18 → (RIGHT, UP)
Agent 2 joint action: 18 → (RIGHT, UP)
Executed: Agent 1: RIGHT, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 6:1.00, 8:0.00, 7:0.00
    agent2_pos: 4:1.00, 8:0.00, 5:0.00
    red_button_pos: 7:0.33, 1:0.33, 2:0.33
    blue_button_pos: 6:1.00, 1:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 6:1.00, 8:0.00, 7:0.00
    agent2_pos: 4:1.00, 8:0.00, 5:0.00
    red_button_pos: 7:0.33, 1:0.33, 2:0.33
    blue_button_pos: 6:1.00, 1:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 676:0.04; 677:0.03; 682:0.03; 675:0.03; 672:0.03
  Agent2 top policies: 676:0.04; 677:0.03; 682:0.03; 675:0.03; 672:0.03
. 2 .
. . .
b 1 .

Reward: +0.00, Result: neutral

--- Step 4 ---
Agent 1 joint action: 16 → (LEFT, PRESS)
Agent 2 joint action: 16 → (LEFT, PRESS)
Executed: Agent 1: LEFT, Agent 2: PRESS
  Agent1 beliefs:
    agent1_pos: 7:1.00, 8:0.00, 5:0.00
    agent2_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 2:0.00, 7:0.00
    blue_button_pos: 6:1.00, 2:0.00, 4:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 7:1.00, 8:0.00, 5:0.00
    agent2_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 2:0.00, 7:0.00
    blue_button_pos: 6:1.00, 2:0.00, 4:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 602:0.16; 601:0.16; 600:0.16; 604:0.16; 605:0.16
  Agent2 top policies: 602:0.16; 601:0.16; 600:0.16; 604:0.16; 605:0.16
. 2 .
. . .
1 . .

Reward: +0.00, Result: neutral
Button pressed: red by Agent 2

--- Step 5 ---
Agent 1 joint action: 24 → (PRESS, UP)
Agent 2 joint action: 24 → (PRESS, UP)
Executed: Agent 1: PRESS, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 6:1.00, 8:0.00, 7:0.00
    agent2_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 2:0.00, 7:0.00
    blue_button_pos: 6:1.00, 2:0.00, 4:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 6:1.00, 8:0.00, 7:0.00
    agent2_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 2:0.00, 7:0.00
    blue_button_pos: 6:1.00, 2:0.00, 4:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 1031:0.00; 1032:0.00; 1033:0.00; 1034:0.00; 1035:0.00
  Agent2 top policies: 1031:0.00; 1032:0.00; 1033:0.00; 1034:0.00; 1035:0.00
. 2 .
. . .
1 . .

Reward: +1.00, Result: win
Button pressed: blue by Agent 1

Result: ✅ WIN - win (steps: 5, reward: +1.00)

================================================================================
EPISODE 50
================================================================================
Environment: Red at (1, 0), Blue at (0, 2)

Initial state:
1 r .
. . .
b . 2


--- Step 1 ---
Agent 1 joint action: 6 → (DOWN, UP)
Agent 2 joint action: 6 → (DOWN, UP)
Executed: Agent 1: DOWN, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 0:1.00, 8:0.00, 7:0.00
    agent2_pos: 8:1.00, 0:0.00, 7:0.00
    red_button_pos: 7:0.14, 3:0.14, 6:0.14
    blue_button_pos: 7:0.14, 3:0.14, 6:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 0:1.00, 8:0.00, 7:0.00
    agent2_pos: 8:1.00, 0:0.00, 7:0.00
    red_button_pos: 7:0.14, 3:0.14, 6:0.14
    blue_button_pos: 7:0.14, 3:0.14, 6:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 244:0.02; 676:0.02; 316:0.02; 748:0.02; 677:0.01
  Agent2 top policies: 244:0.02; 676:0.02; 316:0.02; 748:0.02; 677:0.01
. r .
1 . 2
b . .

Reward: +0.00, Result: neutral

--- Step 2 ---
Agent 1 joint action: 8 → (DOWN, LEFT)
Agent 2 joint action: 8 → (DOWN, LEFT)
Executed: Agent 1: DOWN, Agent 2: LEFT
  Agent1 beliefs:
    agent1_pos: 3:1.00, 8:0.00, 5:0.00
    agent2_pos: 5:1.00, 8:0.00, 3:0.00
    red_button_pos: 7:0.20, 1:0.20, 6:0.20
    blue_button_pos: 7:0.20, 1:0.20, 6:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 3:1.00, 8:0.00, 5:0.00
    agent2_pos: 5:1.00, 8:0.00, 3:0.00
    red_button_pos: 7:0.20, 1:0.20, 6:0.20
    blue_button_pos: 7:0.20, 1:0.20, 6:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 316:0.05; 676:0.05; 244:0.05; 313:0.02; 243:0.02
  Agent2 top policies: 316:0.05; 676:0.05; 244:0.05; 313:0.02; 243:0.02
. r .
. 2 .
1 . .

Reward: +0.00, Result: neutral

--- Step 3 ---
Agent 1 joint action: 18 → (RIGHT, UP)
Agent 2 joint action: 18 → (RIGHT, UP)
Executed: Agent 1: RIGHT, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 6:1.00, 8:0.00, 7:0.00
    agent2_pos: 4:1.00, 8:0.00, 5:0.00
    red_button_pos: 7:0.33, 1:0.33, 2:0.33
    blue_button_pos: 6:1.00, 1:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 6:1.00, 8:0.00, 7:0.00
    agent2_pos: 4:1.00, 8:0.00, 5:0.00
    red_button_pos: 7:0.33, 1:0.33, 2:0.33
    blue_button_pos: 6:1.00, 1:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 676:0.04; 677:0.03; 682:0.03; 675:0.03; 672:0.03
  Agent2 top policies: 676:0.04; 677:0.03; 682:0.03; 675:0.03; 672:0.03
. 2 .
. . .
b 1 .

Reward: +0.00, Result: neutral

--- Step 4 ---
Agent 1 joint action: 16 → (LEFT, PRESS)
Agent 2 joint action: 16 → (LEFT, PRESS)
Executed: Agent 1: LEFT, Agent 2: PRESS
  Agent1 beliefs:
    agent1_pos: 7:1.00, 8:0.00, 5:0.00
    agent2_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 2:0.00, 7:0.00
    blue_button_pos: 6:1.00, 2:0.00, 4:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 7:1.00, 8:0.00, 5:0.00
    agent2_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 2:0.00, 7:0.00
    blue_button_pos: 6:1.00, 2:0.00, 4:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 602:0.16; 601:0.16; 600:0.16; 604:0.16; 605:0.16
  Agent2 top policies: 602:0.16; 601:0.16; 600:0.16; 604:0.16; 605:0.16
. 2 .
. . .
1 . .

Reward: +0.00, Result: neutral
Button pressed: red by Agent 2

--- Step 5 ---
Agent 1 joint action: 24 → (PRESS, UP)
Agent 2 joint action: 24 → (PRESS, UP)
Executed: Agent 1: PRESS, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 6:1.00, 8:0.00, 7:0.00
    agent2_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 2:0.00, 7:0.00
    blue_button_pos: 6:1.00, 2:0.00, 4:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 6:1.00, 8:0.00, 7:0.00
    agent2_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 2:0.00, 7:0.00
    blue_button_pos: 6:1.00, 2:0.00, 4:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 1031:0.00; 1032:0.00; 1033:0.00; 1034:0.00; 1035:0.00
  Agent2 top policies: 1031:0.00; 1032:0.00; 1033:0.00; 1034:0.00; 1035:0.00
. 2 .
. . .
1 . .

Reward: +1.00, Result: win
Button pressed: blue by Agent 1

Result: ✅ WIN - win (steps: 5, reward: +1.00)

================================================================================
EPISODE 51
================================================================================
Environment: Red at (1, 0), Blue at (0, 2)

Initial state:
1 r .
. . .
b . 2


--- Step 1 ---
Agent 1 joint action: 6 → (DOWN, UP)
Agent 2 joint action: 6 → (DOWN, UP)
Executed: Agent 1: DOWN, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 0:1.00, 8:0.00, 7:0.00
    agent2_pos: 8:1.00, 0:0.00, 7:0.00
    red_button_pos: 7:0.14, 3:0.14, 6:0.14
    blue_button_pos: 7:0.14, 3:0.14, 6:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 0:1.00, 8:0.00, 7:0.00
    agent2_pos: 8:1.00, 0:0.00, 7:0.00
    red_button_pos: 7:0.14, 3:0.14, 6:0.14
    blue_button_pos: 7:0.14, 3:0.14, 6:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 244:0.02; 676:0.02; 316:0.02; 748:0.02; 677:0.01
  Agent2 top policies: 244:0.02; 676:0.02; 316:0.02; 748:0.02; 677:0.01
. r .
1 . 2
b . .

Reward: +0.00, Result: neutral

--- Step 2 ---
Agent 1 joint action: 8 → (DOWN, LEFT)
Agent 2 joint action: 8 → (DOWN, LEFT)
Executed: Agent 1: DOWN, Agent 2: LEFT
  Agent1 beliefs:
    agent1_pos: 3:1.00, 8:0.00, 5:0.00
    agent2_pos: 5:1.00, 8:0.00, 3:0.00
    red_button_pos: 7:0.20, 1:0.20, 6:0.20
    blue_button_pos: 7:0.20, 1:0.20, 6:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 3:1.00, 8:0.00, 5:0.00
    agent2_pos: 5:1.00, 8:0.00, 3:0.00
    red_button_pos: 7:0.20, 1:0.20, 6:0.20
    blue_button_pos: 7:0.20, 1:0.20, 6:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 316:0.05; 676:0.05; 244:0.05; 313:0.02; 243:0.02
  Agent2 top policies: 316:0.05; 676:0.05; 244:0.05; 313:0.02; 243:0.02
. r .
. 2 .
1 . .

Reward: +0.00, Result: neutral

--- Step 3 ---
Agent 1 joint action: 18 → (RIGHT, UP)
Agent 2 joint action: 18 → (RIGHT, UP)
Executed: Agent 1: RIGHT, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 6:1.00, 8:0.00, 7:0.00
    agent2_pos: 4:1.00, 8:0.00, 5:0.00
    red_button_pos: 7:0.33, 1:0.33, 2:0.33
    blue_button_pos: 6:1.00, 1:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 6:1.00, 8:0.00, 7:0.00
    agent2_pos: 4:1.00, 8:0.00, 5:0.00
    red_button_pos: 7:0.33, 1:0.33, 2:0.33
    blue_button_pos: 6:1.00, 1:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 676:0.04; 677:0.03; 682:0.03; 675:0.03; 672:0.03
  Agent2 top policies: 676:0.04; 677:0.03; 682:0.03; 675:0.03; 672:0.03
. 2 .
. . .
b 1 .

Reward: +0.00, Result: neutral

--- Step 4 ---
Agent 1 joint action: 16 → (LEFT, PRESS)
Agent 2 joint action: 16 → (LEFT, PRESS)
Executed: Agent 1: LEFT, Agent 2: PRESS
  Agent1 beliefs:
    agent1_pos: 7:1.00, 8:0.00, 5:0.00
    agent2_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 2:0.00, 7:0.00
    blue_button_pos: 6:1.00, 2:0.00, 4:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 7:1.00, 8:0.00, 5:0.00
    agent2_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 2:0.00, 7:0.00
    blue_button_pos: 6:1.00, 2:0.00, 4:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 602:0.16; 601:0.16; 600:0.16; 604:0.16; 605:0.16
  Agent2 top policies: 602:0.16; 601:0.16; 600:0.16; 604:0.16; 605:0.16
. 2 .
. . .
1 . .

Reward: +0.00, Result: neutral
Button pressed: red by Agent 2

--- Step 5 ---
Agent 1 joint action: 24 → (PRESS, UP)
Agent 2 joint action: 24 → (PRESS, UP)
Executed: Agent 1: PRESS, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 6:1.00, 8:0.00, 7:0.00
    agent2_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 2:0.00, 7:0.00
    blue_button_pos: 6:1.00, 2:0.00, 4:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 6:1.00, 8:0.00, 7:0.00
    agent2_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 2:0.00, 7:0.00
    blue_button_pos: 6:1.00, 2:0.00, 4:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 1031:0.00; 1032:0.00; 1033:0.00; 1034:0.00; 1035:0.00
  Agent2 top policies: 1031:0.00; 1032:0.00; 1033:0.00; 1034:0.00; 1035:0.00
. 2 .
. . .
1 . .

Reward: +1.00, Result: win
Button pressed: blue by Agent 1

Result: ✅ WIN - win (steps: 5, reward: +1.00)

================================================================================
EPISODE 52
================================================================================
Environment: Red at (1, 0), Blue at (0, 2)

Initial state:
1 r .
. . .
b . 2


--- Step 1 ---
Agent 1 joint action: 6 → (DOWN, UP)
Agent 2 joint action: 6 → (DOWN, UP)
Executed: Agent 1: DOWN, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 0:1.00, 8:0.00, 7:0.00
    agent2_pos: 8:1.00, 0:0.00, 7:0.00
    red_button_pos: 7:0.14, 3:0.14, 6:0.14
    blue_button_pos: 7:0.14, 3:0.14, 6:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 0:1.00, 8:0.00, 7:0.00
    agent2_pos: 8:1.00, 0:0.00, 7:0.00
    red_button_pos: 7:0.14, 3:0.14, 6:0.14
    blue_button_pos: 7:0.14, 3:0.14, 6:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 244:0.02; 676:0.02; 316:0.02; 748:0.02; 677:0.01
  Agent2 top policies: 244:0.02; 676:0.02; 316:0.02; 748:0.02; 677:0.01
. r .
1 . 2
b . .

Reward: +0.00, Result: neutral

--- Step 2 ---
Agent 1 joint action: 8 → (DOWN, LEFT)
Agent 2 joint action: 8 → (DOWN, LEFT)
Executed: Agent 1: DOWN, Agent 2: LEFT
  Agent1 beliefs:
    agent1_pos: 3:1.00, 8:0.00, 5:0.00
    agent2_pos: 5:1.00, 8:0.00, 3:0.00
    red_button_pos: 7:0.20, 1:0.20, 6:0.20
    blue_button_pos: 7:0.20, 1:0.20, 6:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 3:1.00, 8:0.00, 5:0.00
    agent2_pos: 5:1.00, 8:0.00, 3:0.00
    red_button_pos: 7:0.20, 1:0.20, 6:0.20
    blue_button_pos: 7:0.20, 1:0.20, 6:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 316:0.05; 676:0.05; 244:0.05; 313:0.02; 243:0.02
  Agent2 top policies: 316:0.05; 676:0.05; 244:0.05; 313:0.02; 243:0.02
. r .
. 2 .
1 . .

Reward: +0.00, Result: neutral

--- Step 3 ---
Agent 1 joint action: 18 → (RIGHT, UP)
Agent 2 joint action: 18 → (RIGHT, UP)
Executed: Agent 1: RIGHT, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 6:1.00, 8:0.00, 7:0.00
    agent2_pos: 4:1.00, 8:0.00, 5:0.00
    red_button_pos: 7:0.33, 1:0.33, 2:0.33
    blue_button_pos: 6:1.00, 1:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 6:1.00, 8:0.00, 7:0.00
    agent2_pos: 4:1.00, 8:0.00, 5:0.00
    red_button_pos: 7:0.33, 1:0.33, 2:0.33
    blue_button_pos: 6:1.00, 1:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 676:0.04; 677:0.03; 682:0.03; 675:0.03; 672:0.03
  Agent2 top policies: 676:0.04; 677:0.03; 682:0.03; 675:0.03; 672:0.03
. 2 .
. . .
b 1 .

Reward: +0.00, Result: neutral

--- Step 4 ---
Agent 1 joint action: 16 → (LEFT, PRESS)
Agent 2 joint action: 16 → (LEFT, PRESS)
Executed: Agent 1: LEFT, Agent 2: PRESS
  Agent1 beliefs:
    agent1_pos: 7:1.00, 8:0.00, 5:0.00
    agent2_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 2:0.00, 7:0.00
    blue_button_pos: 6:1.00, 2:0.00, 4:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 7:1.00, 8:0.00, 5:0.00
    agent2_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 2:0.00, 7:0.00
    blue_button_pos: 6:1.00, 2:0.00, 4:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 602:0.16; 601:0.16; 600:0.16; 604:0.16; 605:0.16
  Agent2 top policies: 602:0.16; 601:0.16; 600:0.16; 604:0.16; 605:0.16
. 2 .
. . .
1 . .

Reward: +0.00, Result: neutral
Button pressed: red by Agent 2

--- Step 5 ---
Agent 1 joint action: 24 → (PRESS, UP)
Agent 2 joint action: 24 → (PRESS, UP)
Executed: Agent 1: PRESS, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 6:1.00, 8:0.00, 7:0.00
    agent2_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 2:0.00, 7:0.00
    blue_button_pos: 6:1.00, 2:0.00, 4:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 6:1.00, 8:0.00, 7:0.00
    agent2_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 2:0.00, 7:0.00
    blue_button_pos: 6:1.00, 2:0.00, 4:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 1031:0.00; 1032:0.00; 1033:0.00; 1034:0.00; 1035:0.00
  Agent2 top policies: 1031:0.00; 1032:0.00; 1033:0.00; 1034:0.00; 1035:0.00
. 2 .
. . .
1 . .

Reward: +1.00, Result: win
Button pressed: blue by Agent 1

Result: ✅ WIN - win (steps: 5, reward: +1.00)

================================================================================
EPISODE 53
================================================================================
Environment: Red at (1, 0), Blue at (0, 2)

Initial state:
1 r .
. . .
b . 2


--- Step 1 ---
Agent 1 joint action: 6 → (DOWN, UP)
Agent 2 joint action: 6 → (DOWN, UP)
Executed: Agent 1: DOWN, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 0:1.00, 8:0.00, 7:0.00
    agent2_pos: 8:1.00, 0:0.00, 7:0.00
    red_button_pos: 7:0.14, 3:0.14, 6:0.14
    blue_button_pos: 7:0.14, 3:0.14, 6:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 0:1.00, 8:0.00, 7:0.00
    agent2_pos: 8:1.00, 0:0.00, 7:0.00
    red_button_pos: 7:0.14, 3:0.14, 6:0.14
    blue_button_pos: 7:0.14, 3:0.14, 6:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 244:0.02; 676:0.02; 316:0.02; 748:0.02; 677:0.01
  Agent2 top policies: 244:0.02; 676:0.02; 316:0.02; 748:0.02; 677:0.01
. r .
1 . 2
b . .

Reward: +0.00, Result: neutral

--- Step 2 ---
Agent 1 joint action: 8 → (DOWN, LEFT)
Agent 2 joint action: 8 → (DOWN, LEFT)
Executed: Agent 1: DOWN, Agent 2: LEFT
  Agent1 beliefs:
    agent1_pos: 3:1.00, 8:0.00, 5:0.00
    agent2_pos: 5:1.00, 8:0.00, 3:0.00
    red_button_pos: 7:0.20, 1:0.20, 6:0.20
    blue_button_pos: 7:0.20, 1:0.20, 6:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 3:1.00, 8:0.00, 5:0.00
    agent2_pos: 5:1.00, 8:0.00, 3:0.00
    red_button_pos: 7:0.20, 1:0.20, 6:0.20
    blue_button_pos: 7:0.20, 1:0.20, 6:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 316:0.05; 676:0.05; 244:0.05; 313:0.02; 243:0.02
  Agent2 top policies: 316:0.05; 676:0.05; 244:0.05; 313:0.02; 243:0.02
. r .
. 2 .
1 . .

Reward: +0.00, Result: neutral

--- Step 3 ---
Agent 1 joint action: 18 → (RIGHT, UP)
Agent 2 joint action: 18 → (RIGHT, UP)
Executed: Agent 1: RIGHT, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 6:1.00, 8:0.00, 7:0.00
    agent2_pos: 4:1.00, 8:0.00, 5:0.00
    red_button_pos: 7:0.33, 1:0.33, 2:0.33
    blue_button_pos: 6:1.00, 1:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 6:1.00, 8:0.00, 7:0.00
    agent2_pos: 4:1.00, 8:0.00, 5:0.00
    red_button_pos: 7:0.33, 1:0.33, 2:0.33
    blue_button_pos: 6:1.00, 1:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 676:0.04; 677:0.03; 682:0.03; 675:0.03; 672:0.03
  Agent2 top policies: 676:0.04; 677:0.03; 682:0.03; 675:0.03; 672:0.03
. 2 .
. . .
b 1 .

Reward: +0.00, Result: neutral

--- Step 4 ---
Agent 1 joint action: 16 → (LEFT, PRESS)
Agent 2 joint action: 16 → (LEFT, PRESS)
Executed: Agent 1: LEFT, Agent 2: PRESS
  Agent1 beliefs:
    agent1_pos: 7:1.00, 8:0.00, 5:0.00
    agent2_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 2:0.00, 7:0.00
    blue_button_pos: 6:1.00, 2:0.00, 4:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 7:1.00, 8:0.00, 5:0.00
    agent2_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 2:0.00, 7:0.00
    blue_button_pos: 6:1.00, 2:0.00, 4:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 602:0.16; 601:0.16; 600:0.16; 604:0.16; 605:0.16
  Agent2 top policies: 602:0.16; 601:0.16; 600:0.16; 604:0.16; 605:0.16
. 2 .
. . .
1 . .

Reward: +0.00, Result: neutral
Button pressed: red by Agent 2

--- Step 5 ---
Agent 1 joint action: 24 → (PRESS, UP)
Agent 2 joint action: 24 → (PRESS, UP)
Executed: Agent 1: PRESS, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 6:1.00, 8:0.00, 7:0.00
    agent2_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 2:0.00, 7:0.00
    blue_button_pos: 6:1.00, 2:0.00, 4:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 6:1.00, 8:0.00, 7:0.00
    agent2_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 2:0.00, 7:0.00
    blue_button_pos: 6:1.00, 2:0.00, 4:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 1031:0.00; 1032:0.00; 1033:0.00; 1034:0.00; 1035:0.00
  Agent2 top policies: 1031:0.00; 1032:0.00; 1033:0.00; 1034:0.00; 1035:0.00
. 2 .
. . .
1 . .

Reward: +1.00, Result: win
Button pressed: blue by Agent 1

Result: ✅ WIN - win (steps: 5, reward: +1.00)

================================================================================
EPISODE 54
================================================================================
Environment: Red at (1, 0), Blue at (0, 2)

Initial state:
1 r .
. . .
b . 2


--- Step 1 ---
Agent 1 joint action: 6 → (DOWN, UP)
Agent 2 joint action: 6 → (DOWN, UP)
Executed: Agent 1: DOWN, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 0:1.00, 8:0.00, 7:0.00
    agent2_pos: 8:1.00, 0:0.00, 7:0.00
    red_button_pos: 7:0.14, 3:0.14, 6:0.14
    blue_button_pos: 7:0.14, 3:0.14, 6:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 0:1.00, 8:0.00, 7:0.00
    agent2_pos: 8:1.00, 0:0.00, 7:0.00
    red_button_pos: 7:0.14, 3:0.14, 6:0.14
    blue_button_pos: 7:0.14, 3:0.14, 6:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 244:0.02; 676:0.02; 316:0.02; 748:0.02; 677:0.01
  Agent2 top policies: 244:0.02; 676:0.02; 316:0.02; 748:0.02; 677:0.01
. r .
1 . 2
b . .

Reward: +0.00, Result: neutral

--- Step 2 ---
Agent 1 joint action: 8 → (DOWN, LEFT)
Agent 2 joint action: 8 → (DOWN, LEFT)
Executed: Agent 1: DOWN, Agent 2: LEFT
  Agent1 beliefs:
    agent1_pos: 3:1.00, 8:0.00, 5:0.00
    agent2_pos: 5:1.00, 8:0.00, 3:0.00
    red_button_pos: 7:0.20, 1:0.20, 6:0.20
    blue_button_pos: 7:0.20, 1:0.20, 6:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 3:1.00, 8:0.00, 5:0.00
    agent2_pos: 5:1.00, 8:0.00, 3:0.00
    red_button_pos: 7:0.20, 1:0.20, 6:0.20
    blue_button_pos: 7:0.20, 1:0.20, 6:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 316:0.05; 676:0.05; 244:0.05; 313:0.02; 243:0.02
  Agent2 top policies: 316:0.05; 676:0.05; 244:0.05; 313:0.02; 243:0.02
. r .
. 2 .
1 . .

Reward: +0.00, Result: neutral

--- Step 3 ---
Agent 1 joint action: 18 → (RIGHT, UP)
Agent 2 joint action: 18 → (RIGHT, UP)
Executed: Agent 1: RIGHT, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 6:1.00, 8:0.00, 7:0.00
    agent2_pos: 4:1.00, 8:0.00, 5:0.00
    red_button_pos: 7:0.33, 1:0.33, 2:0.33
    blue_button_pos: 6:1.00, 1:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 6:1.00, 8:0.00, 7:0.00
    agent2_pos: 4:1.00, 8:0.00, 5:0.00
    red_button_pos: 7:0.33, 1:0.33, 2:0.33
    blue_button_pos: 6:1.00, 1:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 676:0.04; 677:0.03; 682:0.03; 675:0.03; 672:0.03
  Agent2 top policies: 676:0.04; 677:0.03; 682:0.03; 675:0.03; 672:0.03
. 2 .
. . .
b 1 .

Reward: +0.00, Result: neutral

--- Step 4 ---
Agent 1 joint action: 16 → (LEFT, PRESS)
Agent 2 joint action: 16 → (LEFT, PRESS)
Executed: Agent 1: LEFT, Agent 2: PRESS
  Agent1 beliefs:
    agent1_pos: 7:1.00, 8:0.00, 5:0.00
    agent2_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 2:0.00, 7:0.00
    blue_button_pos: 6:1.00, 2:0.00, 4:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 7:1.00, 8:0.00, 5:0.00
    agent2_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 2:0.00, 7:0.00
    blue_button_pos: 6:1.00, 2:0.00, 4:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 602:0.16; 601:0.16; 600:0.16; 604:0.16; 605:0.16
  Agent2 top policies: 602:0.16; 601:0.16; 600:0.16; 604:0.16; 605:0.16
. 2 .
. . .
1 . .

Reward: +0.00, Result: neutral
Button pressed: red by Agent 2

--- Step 5 ---
Agent 1 joint action: 24 → (PRESS, UP)
Agent 2 joint action: 24 → (PRESS, UP)
Executed: Agent 1: PRESS, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 6:1.00, 8:0.00, 7:0.00
    agent2_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 2:0.00, 7:0.00
    blue_button_pos: 6:1.00, 2:0.00, 4:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 6:1.00, 8:0.00, 7:0.00
    agent2_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 2:0.00, 7:0.00
    blue_button_pos: 6:1.00, 2:0.00, 4:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 1031:0.00; 1032:0.00; 1033:0.00; 1034:0.00; 1035:0.00
  Agent2 top policies: 1031:0.00; 1032:0.00; 1033:0.00; 1034:0.00; 1035:0.00
. 2 .
. . .
1 . .

Reward: +1.00, Result: win
Button pressed: blue by Agent 1

Result: ✅ WIN - win (steps: 5, reward: +1.00)

================================================================================
EPISODE 55
================================================================================
Environment: Red at (1, 0), Blue at (0, 2)

Initial state:
1 r .
. . .
b . 2


--- Step 1 ---
Agent 1 joint action: 6 → (DOWN, UP)
Agent 2 joint action: 6 → (DOWN, UP)
Executed: Agent 1: DOWN, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 0:1.00, 8:0.00, 7:0.00
    agent2_pos: 8:1.00, 0:0.00, 7:0.00
    red_button_pos: 7:0.14, 3:0.14, 6:0.14
    blue_button_pos: 7:0.14, 3:0.14, 6:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 0:1.00, 8:0.00, 7:0.00
    agent2_pos: 8:1.00, 0:0.00, 7:0.00
    red_button_pos: 7:0.14, 3:0.14, 6:0.14
    blue_button_pos: 7:0.14, 3:0.14, 6:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 244:0.02; 676:0.02; 316:0.02; 748:0.02; 677:0.01
  Agent2 top policies: 244:0.02; 676:0.02; 316:0.02; 748:0.02; 677:0.01
. r .
1 . 2
b . .

Reward: +0.00, Result: neutral

--- Step 2 ---
Agent 1 joint action: 8 → (DOWN, LEFT)
Agent 2 joint action: 8 → (DOWN, LEFT)
Executed: Agent 1: DOWN, Agent 2: LEFT
  Agent1 beliefs:
    agent1_pos: 3:1.00, 8:0.00, 5:0.00
    agent2_pos: 5:1.00, 8:0.00, 3:0.00
    red_button_pos: 7:0.20, 1:0.20, 6:0.20
    blue_button_pos: 7:0.20, 1:0.20, 6:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 3:1.00, 8:0.00, 5:0.00
    agent2_pos: 5:1.00, 8:0.00, 3:0.00
    red_button_pos: 7:0.20, 1:0.20, 6:0.20
    blue_button_pos: 7:0.20, 1:0.20, 6:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 316:0.05; 676:0.05; 244:0.05; 313:0.02; 243:0.02
  Agent2 top policies: 316:0.05; 676:0.05; 244:0.05; 313:0.02; 243:0.02
. r .
. 2 .
1 . .

Reward: +0.00, Result: neutral

--- Step 3 ---
Agent 1 joint action: 18 → (RIGHT, UP)
Agent 2 joint action: 18 → (RIGHT, UP)
Executed: Agent 1: RIGHT, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 6:1.00, 8:0.00, 7:0.00
    agent2_pos: 4:1.00, 8:0.00, 5:0.00
    red_button_pos: 7:0.33, 1:0.33, 2:0.33
    blue_button_pos: 6:1.00, 1:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 6:1.00, 8:0.00, 7:0.00
    agent2_pos: 4:1.00, 8:0.00, 5:0.00
    red_button_pos: 7:0.33, 1:0.33, 2:0.33
    blue_button_pos: 6:1.00, 1:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 676:0.04; 677:0.03; 682:0.03; 675:0.03; 672:0.03
  Agent2 top policies: 676:0.04; 677:0.03; 682:0.03; 675:0.03; 672:0.03
. 2 .
. . .
b 1 .

Reward: +0.00, Result: neutral

--- Step 4 ---
Agent 1 joint action: 16 → (LEFT, PRESS)
Agent 2 joint action: 16 → (LEFT, PRESS)
Executed: Agent 1: LEFT, Agent 2: PRESS
  Agent1 beliefs:
    agent1_pos: 7:1.00, 8:0.00, 5:0.00
    agent2_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 2:0.00, 7:0.00
    blue_button_pos: 6:1.00, 2:0.00, 4:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 7:1.00, 8:0.00, 5:0.00
    agent2_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 2:0.00, 7:0.00
    blue_button_pos: 6:1.00, 2:0.00, 4:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 602:0.16; 601:0.16; 600:0.16; 604:0.16; 605:0.16
  Agent2 top policies: 602:0.16; 601:0.16; 600:0.16; 604:0.16; 605:0.16
. 2 .
. . .
1 . .

Reward: +0.00, Result: neutral
Button pressed: red by Agent 2

--- Step 5 ---
Agent 1 joint action: 24 → (PRESS, UP)
Agent 2 joint action: 24 → (PRESS, UP)
Executed: Agent 1: PRESS, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 6:1.00, 8:0.00, 7:0.00
    agent2_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 2:0.00, 7:0.00
    blue_button_pos: 6:1.00, 2:0.00, 4:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 6:1.00, 8:0.00, 7:0.00
    agent2_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 2:0.00, 7:0.00
    blue_button_pos: 6:1.00, 2:0.00, 4:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 1031:0.00; 1032:0.00; 1033:0.00; 1034:0.00; 1035:0.00
  Agent2 top policies: 1031:0.00; 1032:0.00; 1033:0.00; 1034:0.00; 1035:0.00
. 2 .
. . .
1 . .

Reward: +1.00, Result: win
Button pressed: blue by Agent 1

Result: ✅ WIN - win (steps: 5, reward: +1.00)

================================================================================
EPISODE 56
================================================================================
Environment: Red at (1, 0), Blue at (0, 2)

Initial state:
1 r .
. . .
b . 2


--- Step 1 ---
Agent 1 joint action: 6 → (DOWN, UP)
Agent 2 joint action: 6 → (DOWN, UP)
Executed: Agent 1: DOWN, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 0:1.00, 8:0.00, 7:0.00
    agent2_pos: 8:1.00, 0:0.00, 7:0.00
    red_button_pos: 7:0.14, 3:0.14, 6:0.14
    blue_button_pos: 7:0.14, 3:0.14, 6:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 0:1.00, 8:0.00, 7:0.00
    agent2_pos: 8:1.00, 0:0.00, 7:0.00
    red_button_pos: 7:0.14, 3:0.14, 6:0.14
    blue_button_pos: 7:0.14, 3:0.14, 6:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 244:0.02; 676:0.02; 316:0.02; 748:0.02; 677:0.01
  Agent2 top policies: 244:0.02; 676:0.02; 316:0.02; 748:0.02; 677:0.01
. r .
1 . 2
b . .

Reward: +0.00, Result: neutral

--- Step 2 ---
Agent 1 joint action: 8 → (DOWN, LEFT)
Agent 2 joint action: 8 → (DOWN, LEFT)
Executed: Agent 1: DOWN, Agent 2: LEFT
  Agent1 beliefs:
    agent1_pos: 3:1.00, 8:0.00, 5:0.00
    agent2_pos: 5:1.00, 8:0.00, 3:0.00
    red_button_pos: 7:0.20, 1:0.20, 6:0.20
    blue_button_pos: 7:0.20, 1:0.20, 6:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 3:1.00, 8:0.00, 5:0.00
    agent2_pos: 5:1.00, 8:0.00, 3:0.00
    red_button_pos: 7:0.20, 1:0.20, 6:0.20
    blue_button_pos: 7:0.20, 1:0.20, 6:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 316:0.05; 676:0.05; 244:0.05; 313:0.02; 243:0.02
  Agent2 top policies: 316:0.05; 676:0.05; 244:0.05; 313:0.02; 243:0.02
. r .
. 2 .
1 . .

Reward: +0.00, Result: neutral

--- Step 3 ---
Agent 1 joint action: 18 → (RIGHT, UP)
Agent 2 joint action: 18 → (RIGHT, UP)
Executed: Agent 1: RIGHT, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 6:1.00, 8:0.00, 7:0.00
    agent2_pos: 4:1.00, 8:0.00, 5:0.00
    red_button_pos: 7:0.33, 1:0.33, 2:0.33
    blue_button_pos: 6:1.00, 1:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 6:1.00, 8:0.00, 7:0.00
    agent2_pos: 4:1.00, 8:0.00, 5:0.00
    red_button_pos: 7:0.33, 1:0.33, 2:0.33
    blue_button_pos: 6:1.00, 1:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 676:0.04; 677:0.03; 682:0.03; 675:0.03; 672:0.03
  Agent2 top policies: 676:0.04; 677:0.03; 682:0.03; 675:0.03; 672:0.03
. 2 .
. . .
b 1 .

Reward: +0.00, Result: neutral

--- Step 4 ---
Agent 1 joint action: 16 → (LEFT, PRESS)
Agent 2 joint action: 16 → (LEFT, PRESS)
Executed: Agent 1: LEFT, Agent 2: PRESS
  Agent1 beliefs:
    agent1_pos: 7:1.00, 8:0.00, 5:0.00
    agent2_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 2:0.00, 7:0.00
    blue_button_pos: 6:1.00, 2:0.00, 4:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 7:1.00, 8:0.00, 5:0.00
    agent2_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 2:0.00, 7:0.00
    blue_button_pos: 6:1.00, 2:0.00, 4:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 602:0.16; 601:0.16; 600:0.16; 604:0.16; 605:0.16
  Agent2 top policies: 602:0.16; 601:0.16; 600:0.16; 604:0.16; 605:0.16
. 2 .
. . .
1 . .

Reward: +0.00, Result: neutral
Button pressed: red by Agent 2

--- Step 5 ---
Agent 1 joint action: 24 → (PRESS, UP)
Agent 2 joint action: 24 → (PRESS, UP)
Executed: Agent 1: PRESS, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 6:1.00, 8:0.00, 7:0.00
    agent2_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 2:0.00, 7:0.00
    blue_button_pos: 6:1.00, 2:0.00, 4:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 6:1.00, 8:0.00, 7:0.00
    agent2_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 2:0.00, 7:0.00
    blue_button_pos: 6:1.00, 2:0.00, 4:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 1031:0.00; 1032:0.00; 1033:0.00; 1034:0.00; 1035:0.00
  Agent2 top policies: 1031:0.00; 1032:0.00; 1033:0.00; 1034:0.00; 1035:0.00
. 2 .
. . .
1 . .

Reward: +1.00, Result: win
Button pressed: blue by Agent 1

Result: ✅ WIN - win (steps: 5, reward: +1.00)

================================================================================
EPISODE 57
================================================================================
Environment: Red at (1, 0), Blue at (0, 2)

Initial state:
1 r .
. . .
b . 2


--- Step 1 ---
Agent 1 joint action: 6 → (DOWN, UP)
Agent 2 joint action: 6 → (DOWN, UP)
Executed: Agent 1: DOWN, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 0:1.00, 8:0.00, 7:0.00
    agent2_pos: 8:1.00, 0:0.00, 7:0.00
    red_button_pos: 7:0.14, 3:0.14, 6:0.14
    blue_button_pos: 7:0.14, 3:0.14, 6:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 0:1.00, 8:0.00, 7:0.00
    agent2_pos: 8:1.00, 0:0.00, 7:0.00
    red_button_pos: 7:0.14, 3:0.14, 6:0.14
    blue_button_pos: 7:0.14, 3:0.14, 6:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 244:0.02; 676:0.02; 316:0.02; 748:0.02; 677:0.01
  Agent2 top policies: 244:0.02; 676:0.02; 316:0.02; 748:0.02; 677:0.01
. r .
1 . 2
b . .

Reward: +0.00, Result: neutral

--- Step 2 ---
Agent 1 joint action: 8 → (DOWN, LEFT)
Agent 2 joint action: 8 → (DOWN, LEFT)
Executed: Agent 1: DOWN, Agent 2: LEFT
  Agent1 beliefs:
    agent1_pos: 3:1.00, 8:0.00, 5:0.00
    agent2_pos: 5:1.00, 8:0.00, 3:0.00
    red_button_pos: 7:0.20, 1:0.20, 6:0.20
    blue_button_pos: 7:0.20, 1:0.20, 6:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 3:1.00, 8:0.00, 5:0.00
    agent2_pos: 5:1.00, 8:0.00, 3:0.00
    red_button_pos: 7:0.20, 1:0.20, 6:0.20
    blue_button_pos: 7:0.20, 1:0.20, 6:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 316:0.05; 676:0.05; 244:0.05; 313:0.02; 243:0.02
  Agent2 top policies: 316:0.05; 676:0.05; 244:0.05; 313:0.02; 243:0.02
. r .
. 2 .
1 . .

Reward: +0.00, Result: neutral

--- Step 3 ---
Agent 1 joint action: 18 → (RIGHT, UP)
Agent 2 joint action: 18 → (RIGHT, UP)
Executed: Agent 1: RIGHT, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 6:1.00, 8:0.00, 7:0.00
    agent2_pos: 4:1.00, 8:0.00, 5:0.00
    red_button_pos: 7:0.33, 1:0.33, 2:0.33
    blue_button_pos: 6:1.00, 1:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 6:1.00, 8:0.00, 7:0.00
    agent2_pos: 4:1.00, 8:0.00, 5:0.00
    red_button_pos: 7:0.33, 1:0.33, 2:0.33
    blue_button_pos: 6:1.00, 1:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 676:0.04; 677:0.03; 682:0.03; 675:0.03; 672:0.03
  Agent2 top policies: 676:0.04; 677:0.03; 682:0.03; 675:0.03; 672:0.03
. 2 .
. . .
b 1 .

Reward: +0.00, Result: neutral

--- Step 4 ---
Agent 1 joint action: 16 → (LEFT, PRESS)
Agent 2 joint action: 16 → (LEFT, PRESS)
Executed: Agent 1: LEFT, Agent 2: PRESS
  Agent1 beliefs:
    agent1_pos: 7:1.00, 8:0.00, 5:0.00
    agent2_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 2:0.00, 7:0.00
    blue_button_pos: 6:1.00, 2:0.00, 4:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 7:1.00, 8:0.00, 5:0.00
    agent2_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 2:0.00, 7:0.00
    blue_button_pos: 6:1.00, 2:0.00, 4:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 602:0.16; 601:0.16; 600:0.16; 604:0.16; 605:0.16
  Agent2 top policies: 602:0.16; 601:0.16; 600:0.16; 604:0.16; 605:0.16
. 2 .
. . .
1 . .

Reward: +0.00, Result: neutral
Button pressed: red by Agent 2

--- Step 5 ---
Agent 1 joint action: 24 → (PRESS, UP)
Agent 2 joint action: 24 → (PRESS, UP)
Executed: Agent 1: PRESS, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 6:1.00, 8:0.00, 7:0.00
    agent2_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 2:0.00, 7:0.00
    blue_button_pos: 6:1.00, 2:0.00, 4:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 6:1.00, 8:0.00, 7:0.00
    agent2_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 2:0.00, 7:0.00
    blue_button_pos: 6:1.00, 2:0.00, 4:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 1031:0.00; 1032:0.00; 1033:0.00; 1034:0.00; 1035:0.00
  Agent2 top policies: 1031:0.00; 1032:0.00; 1033:0.00; 1034:0.00; 1035:0.00
. 2 .
. . .
1 . .

Reward: +1.00, Result: win
Button pressed: blue by Agent 1

Result: ✅ WIN - win (steps: 5, reward: +1.00)

================================================================================
EPISODE 58
================================================================================
Environment: Red at (1, 0), Blue at (0, 2)

Initial state:
1 r .
. . .
b . 2


--- Step 1 ---
Agent 1 joint action: 6 → (DOWN, UP)
Agent 2 joint action: 6 → (DOWN, UP)
Executed: Agent 1: DOWN, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 0:1.00, 8:0.00, 7:0.00
    agent2_pos: 8:1.00, 0:0.00, 7:0.00
    red_button_pos: 7:0.14, 3:0.14, 6:0.14
    blue_button_pos: 7:0.14, 3:0.14, 6:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 0:1.00, 8:0.00, 7:0.00
    agent2_pos: 8:1.00, 0:0.00, 7:0.00
    red_button_pos: 7:0.14, 3:0.14, 6:0.14
    blue_button_pos: 7:0.14, 3:0.14, 6:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 244:0.02; 676:0.02; 316:0.02; 748:0.02; 677:0.01
  Agent2 top policies: 244:0.02; 676:0.02; 316:0.02; 748:0.02; 677:0.01
. r .
1 . 2
b . .

Reward: +0.00, Result: neutral

--- Step 2 ---
Agent 1 joint action: 8 → (DOWN, LEFT)
Agent 2 joint action: 8 → (DOWN, LEFT)
Executed: Agent 1: DOWN, Agent 2: LEFT
  Agent1 beliefs:
    agent1_pos: 3:1.00, 8:0.00, 5:0.00
    agent2_pos: 5:1.00, 8:0.00, 3:0.00
    red_button_pos: 7:0.20, 1:0.20, 6:0.20
    blue_button_pos: 7:0.20, 1:0.20, 6:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 3:1.00, 8:0.00, 5:0.00
    agent2_pos: 5:1.00, 8:0.00, 3:0.00
    red_button_pos: 7:0.20, 1:0.20, 6:0.20
    blue_button_pos: 7:0.20, 1:0.20, 6:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 316:0.05; 676:0.05; 244:0.05; 313:0.02; 243:0.02
  Agent2 top policies: 316:0.05; 676:0.05; 244:0.05; 313:0.02; 243:0.02
. r .
. 2 .
1 . .

Reward: +0.00, Result: neutral

--- Step 3 ---
Agent 1 joint action: 18 → (RIGHT, UP)
Agent 2 joint action: 18 → (RIGHT, UP)
Executed: Agent 1: RIGHT, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 6:1.00, 8:0.00, 7:0.00
    agent2_pos: 4:1.00, 8:0.00, 5:0.00
    red_button_pos: 7:0.33, 1:0.33, 2:0.33
    blue_button_pos: 6:1.00, 1:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 6:1.00, 8:0.00, 7:0.00
    agent2_pos: 4:1.00, 8:0.00, 5:0.00
    red_button_pos: 7:0.33, 1:0.33, 2:0.33
    blue_button_pos: 6:1.00, 1:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 676:0.04; 677:0.03; 682:0.03; 675:0.03; 672:0.03
  Agent2 top policies: 676:0.04; 677:0.03; 682:0.03; 675:0.03; 672:0.03
. 2 .
. . .
b 1 .

Reward: +0.00, Result: neutral

--- Step 4 ---
Agent 1 joint action: 16 → (LEFT, PRESS)
Agent 2 joint action: 16 → (LEFT, PRESS)
Executed: Agent 1: LEFT, Agent 2: PRESS
  Agent1 beliefs:
    agent1_pos: 7:1.00, 8:0.00, 5:0.00
    agent2_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 2:0.00, 7:0.00
    blue_button_pos: 6:1.00, 2:0.00, 4:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 7:1.00, 8:0.00, 5:0.00
    agent2_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 2:0.00, 7:0.00
    blue_button_pos: 6:1.00, 2:0.00, 4:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 602:0.16; 601:0.16; 600:0.16; 604:0.16; 605:0.16
  Agent2 top policies: 602:0.16; 601:0.16; 600:0.16; 604:0.16; 605:0.16
. 2 .
. . .
1 . .

Reward: +0.00, Result: neutral
Button pressed: red by Agent 2

--- Step 5 ---
Agent 1 joint action: 24 → (PRESS, UP)
Agent 2 joint action: 24 → (PRESS, UP)
Executed: Agent 1: PRESS, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 6:1.00, 8:0.00, 7:0.00
    agent2_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 2:0.00, 7:0.00
    blue_button_pos: 6:1.00, 2:0.00, 4:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 6:1.00, 8:0.00, 7:0.00
    agent2_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 2:0.00, 7:0.00
    blue_button_pos: 6:1.00, 2:0.00, 4:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 1031:0.00; 1032:0.00; 1033:0.00; 1034:0.00; 1035:0.00
  Agent2 top policies: 1031:0.00; 1032:0.00; 1033:0.00; 1034:0.00; 1035:0.00
. 2 .
. . .
1 . .

Reward: +1.00, Result: win
Button pressed: blue by Agent 1

Result: ✅ WIN - win (steps: 5, reward: +1.00)

================================================================================
EPISODE 59
================================================================================
Environment: Red at (1, 0), Blue at (0, 2)

Initial state:
1 r .
. . .
b . 2


--- Step 1 ---
Agent 1 joint action: 6 → (DOWN, UP)
Agent 2 joint action: 6 → (DOWN, UP)
Executed: Agent 1: DOWN, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 0:1.00, 8:0.00, 7:0.00
    agent2_pos: 8:1.00, 0:0.00, 7:0.00
    red_button_pos: 7:0.14, 3:0.14, 6:0.14
    blue_button_pos: 7:0.14, 3:0.14, 6:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 0:1.00, 8:0.00, 7:0.00
    agent2_pos: 8:1.00, 0:0.00, 7:0.00
    red_button_pos: 7:0.14, 3:0.14, 6:0.14
    blue_button_pos: 7:0.14, 3:0.14, 6:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 244:0.02; 676:0.02; 316:0.02; 748:0.02; 677:0.01
  Agent2 top policies: 244:0.02; 676:0.02; 316:0.02; 748:0.02; 677:0.01
. r .
1 . 2
b . .

Reward: +0.00, Result: neutral

--- Step 2 ---
Agent 1 joint action: 8 → (DOWN, LEFT)
Agent 2 joint action: 8 → (DOWN, LEFT)
Executed: Agent 1: DOWN, Agent 2: LEFT
  Agent1 beliefs:
    agent1_pos: 3:1.00, 8:0.00, 5:0.00
    agent2_pos: 5:1.00, 8:0.00, 3:0.00
    red_button_pos: 7:0.20, 1:0.20, 6:0.20
    blue_button_pos: 7:0.20, 1:0.20, 6:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 3:1.00, 8:0.00, 5:0.00
    agent2_pos: 5:1.00, 8:0.00, 3:0.00
    red_button_pos: 7:0.20, 1:0.20, 6:0.20
    blue_button_pos: 7:0.20, 1:0.20, 6:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 316:0.05; 676:0.05; 244:0.05; 313:0.02; 243:0.02
  Agent2 top policies: 316:0.05; 676:0.05; 244:0.05; 313:0.02; 243:0.02
. r .
. 2 .
1 . .

Reward: +0.00, Result: neutral

--- Step 3 ---
Agent 1 joint action: 18 → (RIGHT, UP)
Agent 2 joint action: 18 → (RIGHT, UP)
Executed: Agent 1: RIGHT, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 6:1.00, 8:0.00, 7:0.00
    agent2_pos: 4:1.00, 8:0.00, 5:0.00
    red_button_pos: 7:0.33, 1:0.33, 2:0.33
    blue_button_pos: 6:1.00, 1:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 6:1.00, 8:0.00, 7:0.00
    agent2_pos: 4:1.00, 8:0.00, 5:0.00
    red_button_pos: 7:0.33, 1:0.33, 2:0.33
    blue_button_pos: 6:1.00, 1:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 676:0.04; 677:0.03; 682:0.03; 675:0.03; 672:0.03
  Agent2 top policies: 676:0.04; 677:0.03; 682:0.03; 675:0.03; 672:0.03
. 2 .
. . .
b 1 .

Reward: +0.00, Result: neutral

--- Step 4 ---
Agent 1 joint action: 16 → (LEFT, PRESS)
Agent 2 joint action: 16 → (LEFT, PRESS)
Executed: Agent 1: LEFT, Agent 2: PRESS
  Agent1 beliefs:
    agent1_pos: 7:1.00, 8:0.00, 5:0.00
    agent2_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 2:0.00, 7:0.00
    blue_button_pos: 6:1.00, 2:0.00, 4:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 7:1.00, 8:0.00, 5:0.00
    agent2_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 2:0.00, 7:0.00
    blue_button_pos: 6:1.00, 2:0.00, 4:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 602:0.16; 601:0.16; 600:0.16; 604:0.16; 605:0.16
  Agent2 top policies: 602:0.16; 601:0.16; 600:0.16; 604:0.16; 605:0.16
. 2 .
. . .
1 . .

Reward: +0.00, Result: neutral
Button pressed: red by Agent 2

--- Step 5 ---
Agent 1 joint action: 24 → (PRESS, UP)
Agent 2 joint action: 24 → (PRESS, UP)
Executed: Agent 1: PRESS, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 6:1.00, 8:0.00, 7:0.00
    agent2_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 2:0.00, 7:0.00
    blue_button_pos: 6:1.00, 2:0.00, 4:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 6:1.00, 8:0.00, 7:0.00
    agent2_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 2:0.00, 7:0.00
    blue_button_pos: 6:1.00, 2:0.00, 4:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 1031:0.00; 1032:0.00; 1033:0.00; 1034:0.00; 1035:0.00
  Agent2 top policies: 1031:0.00; 1032:0.00; 1033:0.00; 1034:0.00; 1035:0.00
. 2 .
. . .
1 . .

Reward: +1.00, Result: win
Button pressed: blue by Agent 1

Result: ✅ WIN - win (steps: 5, reward: +1.00)

================================================================================
EPISODE 60
================================================================================
Environment: Red at (1, 0), Blue at (0, 2)

Initial state:
1 r .
. . .
b . 2


--- Step 1 ---
Agent 1 joint action: 6 → (DOWN, UP)
Agent 2 joint action: 6 → (DOWN, UP)
Executed: Agent 1: DOWN, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 0:1.00, 8:0.00, 7:0.00
    agent2_pos: 8:1.00, 0:0.00, 7:0.00
    red_button_pos: 7:0.14, 3:0.14, 6:0.14
    blue_button_pos: 7:0.14, 3:0.14, 6:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 0:1.00, 8:0.00, 7:0.00
    agent2_pos: 8:1.00, 0:0.00, 7:0.00
    red_button_pos: 7:0.14, 3:0.14, 6:0.14
    blue_button_pos: 7:0.14, 3:0.14, 6:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 244:0.02; 676:0.02; 316:0.02; 748:0.02; 677:0.01
  Agent2 top policies: 244:0.02; 676:0.02; 316:0.02; 748:0.02; 677:0.01
. r .
1 . 2
b . .

Reward: +0.00, Result: neutral

--- Step 2 ---
Agent 1 joint action: 8 → (DOWN, LEFT)
Agent 2 joint action: 8 → (DOWN, LEFT)
Executed: Agent 1: DOWN, Agent 2: LEFT
  Agent1 beliefs:
    agent1_pos: 3:1.00, 8:0.00, 5:0.00
    agent2_pos: 5:1.00, 8:0.00, 3:0.00
    red_button_pos: 7:0.20, 1:0.20, 6:0.20
    blue_button_pos: 7:0.20, 1:0.20, 6:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 3:1.00, 8:0.00, 5:0.00
    agent2_pos: 5:1.00, 8:0.00, 3:0.00
    red_button_pos: 7:0.20, 1:0.20, 6:0.20
    blue_button_pos: 7:0.20, 1:0.20, 6:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 316:0.05; 676:0.05; 244:0.05; 313:0.02; 243:0.02
  Agent2 top policies: 316:0.05; 676:0.05; 244:0.05; 313:0.02; 243:0.02
. r .
. 2 .
1 . .

Reward: +0.00, Result: neutral

--- Step 3 ---
Agent 1 joint action: 18 → (RIGHT, UP)
Agent 2 joint action: 18 → (RIGHT, UP)
Executed: Agent 1: RIGHT, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 6:1.00, 8:0.00, 7:0.00
    agent2_pos: 4:1.00, 8:0.00, 5:0.00
    red_button_pos: 7:0.33, 1:0.33, 2:0.33
    blue_button_pos: 6:1.00, 1:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 6:1.00, 8:0.00, 7:0.00
    agent2_pos: 4:1.00, 8:0.00, 5:0.00
    red_button_pos: 7:0.33, 1:0.33, 2:0.33
    blue_button_pos: 6:1.00, 1:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 676:0.04; 677:0.03; 682:0.03; 675:0.03; 672:0.03
  Agent2 top policies: 676:0.04; 677:0.03; 682:0.03; 675:0.03; 672:0.03
. 2 .
. . .
b 1 .

Reward: +0.00, Result: neutral

--- Step 4 ---
Agent 1 joint action: 16 → (LEFT, PRESS)
Agent 2 joint action: 16 → (LEFT, PRESS)
Executed: Agent 1: LEFT, Agent 2: PRESS
  Agent1 beliefs:
    agent1_pos: 7:1.00, 8:0.00, 5:0.00
    agent2_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 2:0.00, 7:0.00
    blue_button_pos: 6:1.00, 2:0.00, 4:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 7:1.00, 8:0.00, 5:0.00
    agent2_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 2:0.00, 7:0.00
    blue_button_pos: 6:1.00, 2:0.00, 4:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 602:0.16; 601:0.16; 600:0.16; 604:0.16; 605:0.16
  Agent2 top policies: 602:0.16; 601:0.16; 600:0.16; 604:0.16; 605:0.16
. 2 .
. . .
1 . .

Reward: +0.00, Result: neutral
Button pressed: red by Agent 2

--- Step 5 ---
Agent 1 joint action: 24 → (PRESS, UP)
Agent 2 joint action: 24 → (PRESS, UP)
Executed: Agent 1: PRESS, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 6:1.00, 8:0.00, 7:0.00
    agent2_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 2:0.00, 7:0.00
    blue_button_pos: 6:1.00, 2:0.00, 4:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 6:1.00, 8:0.00, 7:0.00
    agent2_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 2:0.00, 7:0.00
    blue_button_pos: 6:1.00, 2:0.00, 4:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 1031:0.00; 1032:0.00; 1033:0.00; 1034:0.00; 1035:0.00
  Agent2 top policies: 1031:0.00; 1032:0.00; 1033:0.00; 1034:0.00; 1035:0.00
. 2 .
. . .
1 . .

Reward: +1.00, Result: win
Button pressed: blue by Agent 1

Result: ✅ WIN - win (steps: 5, reward: +1.00)

================================================================================
SEED 0 - CONFIG 4
Red at (1, 2), Blue at (0, 1)
Episodes 61-80
================================================================================

================================================================================
EPISODE 61
================================================================================
Environment: Red at (1, 2), Blue at (0, 1)

Initial state:
1 . .
b . .
. r 2


--- Step 1 ---
Agent 1 joint action: 6 → (DOWN, UP)
Agent 2 joint action: 6 → (DOWN, UP)
Executed: Agent 1: DOWN, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 0:1.00, 8:0.00, 7:0.00
    agent2_pos: 8:1.00, 0:0.00, 7:0.00
    red_button_pos: 7:0.14, 3:0.14, 6:0.14
    blue_button_pos: 7:0.14, 3:0.14, 6:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 0:1.00, 8:0.00, 7:0.00
    agent2_pos: 8:1.00, 0:0.00, 7:0.00
    red_button_pos: 7:0.14, 3:0.14, 6:0.14
    blue_button_pos: 7:0.14, 3:0.14, 6:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 244:0.02; 676:0.02; 316:0.02; 748:0.02; 677:0.01
  Agent2 top policies: 244:0.02; 676:0.02; 316:0.02; 748:0.02; 677:0.01
. . .
1 . 2
. r .

Reward: +0.00, Result: neutral

--- Step 2 ---
Agent 1 joint action: 18 → (RIGHT, UP)
Agent 2 joint action: 18 → (RIGHT, UP)
Executed: Agent 1: RIGHT, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 3:1.00, 8:0.00, 7:0.00
    agent2_pos: 5:1.00, 8:0.00, 0:0.00
    red_button_pos: 7:0.20, 1:0.20, 6:0.20
    blue_button_pos: 3:1.00, 4:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 3:1.00, 8:0.00, 7:0.00
    agent2_pos: 5:1.00, 8:0.00, 0:0.00
    red_button_pos: 7:0.20, 1:0.20, 6:0.20
    blue_button_pos: 3:1.00, 4:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 676:0.02; 316:0.02; 244:0.02; 674:0.01; 322:0.01
  Agent2 top policies: 676:0.02; 316:0.02; 244:0.02; 674:0.01; 322:0.01
. . 2
b 1 .
. r .

Reward: +0.00, Result: neutral

--- Step 3 ---
Agent 1 joint action: 8 → (DOWN, LEFT)
Agent 2 joint action: 8 → (DOWN, LEFT)
Executed: Agent 1: DOWN, Agent 2: LEFT
  Agent1 beliefs:
    agent1_pos: 4:1.00, 8:0.00, 5:0.00
    agent2_pos: 2:1.00, 8:0.00, 4:0.00
    red_button_pos: 7:0.33, 1:0.33, 6:0.33
    blue_button_pos: 3:1.00, 1:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 4:1.00, 8:0.00, 5:0.00
    agent2_pos: 2:1.00, 8:0.00, 4:0.00
    red_button_pos: 7:0.33, 1:0.33, 6:0.33
    blue_button_pos: 3:1.00, 1:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 316:0.03; 317:0.02; 322:0.02; 304:0.02; 298:0.02
  Agent2 top policies: 316:0.03; 317:0.02; 322:0.02; 304:0.02; 298:0.02
. 2 .
b . .
. 1 .

Reward: +0.00, Result: neutral

--- Step 4 ---
Agent 1 joint action: 24 → (PRESS, UP)
Agent 2 joint action: 24 → (PRESS, UP)
Executed: Agent 1: PRESS, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 7:1.00, 8:0.00, 6:0.00
    agent2_pos: 1:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:1.00, 1:0.00, 6:0.00
    blue_button_pos: 3:1.00, 5:0.00, 6:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 7:1.00, 8:0.00, 6:0.00
    agent2_pos: 1:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:1.00, 1:0.00, 6:0.00
    blue_button_pos: 3:1.00, 5:0.00, 6:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 1051:0.00; 1052:0.00; 1053:0.00; 1054:0.00; 1055:0.00
  Agent2 top policies: 1051:0.00; 1052:0.00; 1053:0.00; 1054:0.00; 1055:0.00
. 2 .
b . .
. 1 .

Reward: +0.00, Result: neutral
Button pressed: red by Agent 1

--- Step 5 ---
Agent 1 joint action: 0 → (UP, UP)
Agent 2 joint action: 0 → (UP, UP)
Executed: Agent 1: UP, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 7:1.00, 8:0.00, 6:0.00
    agent2_pos: 1:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:1.00, 1:0.00, 6:0.00
    blue_button_pos: 3:1.00, 5:0.00, 6:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 7:1.00, 8:0.00, 6:0.00
    agent2_pos: 1:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:1.00, 1:0.00, 6:0.00
    blue_button_pos: 3:1.00, 5:0.00, 6:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 0:0.00; 1295:0.00; 1294:0.00; 1293:0.00; 1292:0.00
  Agent2 top policies: 0:0.00; 1295:0.00; 1294:0.00; 1293:0.00; 1292:0.00
. 2 .
b 1 .
. R .

Reward: +0.00, Result: neutral

--- Step 6 ---
Agent 1 joint action: 12 → (LEFT, UP)
Agent 2 joint action: 12 → (LEFT, UP)
Executed: Agent 1: LEFT, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 4:1.00, 8:0.00, 6:0.00
    agent2_pos: 1:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:1.00, 8:0.00, 6:0.00
    blue_button_pos: 3:1.00, 5:0.00, 6:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 4:1.00, 8:0.00, 6:0.00
    agent2_pos: 1:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:1.00, 8:0.00, 6:0.00
    blue_button_pos: 3:1.00, 5:0.00, 6:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 532:0.03; 531:0.03; 564:0.03; 492:0.03; 493:0.03
  Agent2 top policies: 532:0.03; 531:0.03; 564:0.03; 492:0.03; 493:0.03
. 2 .
1 . .
. R .

Reward: +0.00, Result: neutral

--- Step 7 ---
Agent 1 joint action: 24 → (PRESS, UP)
Agent 2 joint action: 24 → (PRESS, UP)
Executed: Agent 1: PRESS, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 3:1.00, 8:0.00, 7:0.00
    agent2_pos: 1:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:1.00, 8:0.00, 6:0.00
    blue_button_pos: 3:1.00, 5:0.00, 6:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 3:1.00, 8:0.00, 7:0.00
    agent2_pos: 1:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:1.00, 8:0.00, 6:0.00
    blue_button_pos: 3:1.00, 5:0.00, 6:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 1040:0.00; 1041:0.00; 1042:0.00; 1043:0.00; 1044:0.00
  Agent2 top policies: 1040:0.00; 1041:0.00; 1042:0.00; 1043:0.00; 1044:0.00
. 2 .
1 . .
. R .

Reward: +1.00, Result: win
Button pressed: blue by Agent 1

Result: ✅ WIN - win (steps: 7, reward: +1.00)

================================================================================
EPISODE 62
================================================================================
Environment: Red at (1, 2), Blue at (0, 1)

Initial state:
1 . .
b . .
. r 2


--- Step 1 ---
Agent 1 joint action: 6 → (DOWN, UP)
Agent 2 joint action: 6 → (DOWN, UP)
Executed: Agent 1: DOWN, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 0:1.00, 8:0.00, 7:0.00
    agent2_pos: 8:1.00, 0:0.00, 7:0.00
    red_button_pos: 7:0.14, 3:0.14, 6:0.14
    blue_button_pos: 7:0.14, 3:0.14, 6:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 0:1.00, 8:0.00, 7:0.00
    agent2_pos: 8:1.00, 0:0.00, 7:0.00
    red_button_pos: 7:0.14, 3:0.14, 6:0.14
    blue_button_pos: 7:0.14, 3:0.14, 6:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 244:0.02; 676:0.02; 316:0.02; 748:0.02; 677:0.01
  Agent2 top policies: 244:0.02; 676:0.02; 316:0.02; 748:0.02; 677:0.01
. . .
1 . 2
. r .

Reward: +0.00, Result: neutral

--- Step 2 ---
Agent 1 joint action: 18 → (RIGHT, UP)
Agent 2 joint action: 18 → (RIGHT, UP)
Executed: Agent 1: RIGHT, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 3:1.00, 8:0.00, 7:0.00
    agent2_pos: 5:1.00, 8:0.00, 0:0.00
    red_button_pos: 7:0.20, 1:0.20, 6:0.20
    blue_button_pos: 3:1.00, 4:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 3:1.00, 8:0.00, 7:0.00
    agent2_pos: 5:1.00, 8:0.00, 0:0.00
    red_button_pos: 7:0.20, 1:0.20, 6:0.20
    blue_button_pos: 3:1.00, 4:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 676:0.02; 316:0.02; 244:0.02; 674:0.01; 322:0.01
  Agent2 top policies: 676:0.02; 316:0.02; 244:0.02; 674:0.01; 322:0.01
. . 2
b 1 .
. r .

Reward: +0.00, Result: neutral

--- Step 3 ---
Agent 1 joint action: 8 → (DOWN, LEFT)
Agent 2 joint action: 8 → (DOWN, LEFT)
Executed: Agent 1: DOWN, Agent 2: LEFT
  Agent1 beliefs:
    agent1_pos: 4:1.00, 8:0.00, 5:0.00
    agent2_pos: 2:1.00, 8:0.00, 4:0.00
    red_button_pos: 7:0.33, 1:0.33, 6:0.33
    blue_button_pos: 3:1.00, 1:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 4:1.00, 8:0.00, 5:0.00
    agent2_pos: 2:1.00, 8:0.00, 4:0.00
    red_button_pos: 7:0.33, 1:0.33, 6:0.33
    blue_button_pos: 3:1.00, 1:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 316:0.03; 317:0.02; 322:0.02; 304:0.02; 298:0.02
  Agent2 top policies: 316:0.03; 317:0.02; 322:0.02; 304:0.02; 298:0.02
. 2 .
b . .
. 1 .

Reward: +0.00, Result: neutral

--- Step 4 ---
Agent 1 joint action: 24 → (PRESS, UP)
Agent 2 joint action: 24 → (PRESS, UP)
Executed: Agent 1: PRESS, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 7:1.00, 8:0.00, 6:0.00
    agent2_pos: 1:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:1.00, 1:0.00, 6:0.00
    blue_button_pos: 3:1.00, 5:0.00, 6:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 7:1.00, 8:0.00, 6:0.00
    agent2_pos: 1:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:1.00, 1:0.00, 6:0.00
    blue_button_pos: 3:1.00, 5:0.00, 6:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 1051:0.00; 1052:0.00; 1053:0.00; 1054:0.00; 1055:0.00
  Agent2 top policies: 1051:0.00; 1052:0.00; 1053:0.00; 1054:0.00; 1055:0.00
. 2 .
b . .
. 1 .

Reward: +0.00, Result: neutral
Button pressed: red by Agent 1

--- Step 5 ---
Agent 1 joint action: 0 → (UP, UP)
Agent 2 joint action: 0 → (UP, UP)
Executed: Agent 1: UP, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 7:1.00, 8:0.00, 6:0.00
    agent2_pos: 1:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:1.00, 1:0.00, 6:0.00
    blue_button_pos: 3:1.00, 5:0.00, 6:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 7:1.00, 8:0.00, 6:0.00
    agent2_pos: 1:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:1.00, 1:0.00, 6:0.00
    blue_button_pos: 3:1.00, 5:0.00, 6:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 0:0.00; 1295:0.00; 1294:0.00; 1293:0.00; 1292:0.00
  Agent2 top policies: 0:0.00; 1295:0.00; 1294:0.00; 1293:0.00; 1292:0.00
. 2 .
b 1 .
. R .

Reward: +0.00, Result: neutral

--- Step 6 ---
Agent 1 joint action: 12 → (LEFT, UP)
Agent 2 joint action: 12 → (LEFT, UP)
Executed: Agent 1: LEFT, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 4:1.00, 8:0.00, 6:0.00
    agent2_pos: 1:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:1.00, 8:0.00, 6:0.00
    blue_button_pos: 3:1.00, 5:0.00, 6:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 4:1.00, 8:0.00, 6:0.00
    agent2_pos: 1:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:1.00, 8:0.00, 6:0.00
    blue_button_pos: 3:1.00, 5:0.00, 6:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 532:0.03; 531:0.03; 564:0.03; 492:0.03; 493:0.03
  Agent2 top policies: 532:0.03; 531:0.03; 564:0.03; 492:0.03; 493:0.03
. 2 .
1 . .
. R .

Reward: +0.00, Result: neutral

--- Step 7 ---
Agent 1 joint action: 24 → (PRESS, UP)
Agent 2 joint action: 24 → (PRESS, UP)
Executed: Agent 1: PRESS, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 3:1.00, 8:0.00, 7:0.00
    agent2_pos: 1:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:1.00, 8:0.00, 6:0.00
    blue_button_pos: 3:1.00, 5:0.00, 6:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 3:1.00, 8:0.00, 7:0.00
    agent2_pos: 1:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:1.00, 8:0.00, 6:0.00
    blue_button_pos: 3:1.00, 5:0.00, 6:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 1040:0.00; 1041:0.00; 1042:0.00; 1043:0.00; 1044:0.00
  Agent2 top policies: 1040:0.00; 1041:0.00; 1042:0.00; 1043:0.00; 1044:0.00
. 2 .
1 . .
. R .

Reward: +1.00, Result: win
Button pressed: blue by Agent 1

Result: ✅ WIN - win (steps: 7, reward: +1.00)

================================================================================
EPISODE 63
================================================================================
Environment: Red at (1, 2), Blue at (0, 1)

Initial state:
1 . .
b . .
. r 2


--- Step 1 ---
Agent 1 joint action: 6 → (DOWN, UP)
Agent 2 joint action: 6 → (DOWN, UP)
Executed: Agent 1: DOWN, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 0:1.00, 8:0.00, 7:0.00
    agent2_pos: 8:1.00, 0:0.00, 7:0.00
    red_button_pos: 7:0.14, 3:0.14, 6:0.14
    blue_button_pos: 7:0.14, 3:0.14, 6:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 0:1.00, 8:0.00, 7:0.00
    agent2_pos: 8:1.00, 0:0.00, 7:0.00
    red_button_pos: 7:0.14, 3:0.14, 6:0.14
    blue_button_pos: 7:0.14, 3:0.14, 6:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 244:0.02; 676:0.02; 316:0.02; 748:0.02; 677:0.01
  Agent2 top policies: 244:0.02; 676:0.02; 316:0.02; 748:0.02; 677:0.01
. . .
1 . 2
. r .

Reward: +0.00, Result: neutral

--- Step 2 ---
Agent 1 joint action: 18 → (RIGHT, UP)
Agent 2 joint action: 18 → (RIGHT, UP)
Executed: Agent 1: RIGHT, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 3:1.00, 8:0.00, 7:0.00
    agent2_pos: 5:1.00, 8:0.00, 0:0.00
    red_button_pos: 7:0.20, 1:0.20, 6:0.20
    blue_button_pos: 3:1.00, 4:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 3:1.00, 8:0.00, 7:0.00
    agent2_pos: 5:1.00, 8:0.00, 0:0.00
    red_button_pos: 7:0.20, 1:0.20, 6:0.20
    blue_button_pos: 3:1.00, 4:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 676:0.02; 316:0.02; 244:0.02; 674:0.01; 322:0.01
  Agent2 top policies: 676:0.02; 316:0.02; 244:0.02; 674:0.01; 322:0.01
. . 2
b 1 .
. r .

Reward: +0.00, Result: neutral

--- Step 3 ---
Agent 1 joint action: 8 → (DOWN, LEFT)
Agent 2 joint action: 8 → (DOWN, LEFT)
Executed: Agent 1: DOWN, Agent 2: LEFT
  Agent1 beliefs:
    agent1_pos: 4:1.00, 8:0.00, 5:0.00
    agent2_pos: 2:1.00, 8:0.00, 4:0.00
    red_button_pos: 7:0.33, 1:0.33, 6:0.33
    blue_button_pos: 3:1.00, 1:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 4:1.00, 8:0.00, 5:0.00
    agent2_pos: 2:1.00, 8:0.00, 4:0.00
    red_button_pos: 7:0.33, 1:0.33, 6:0.33
    blue_button_pos: 3:1.00, 1:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 316:0.03; 317:0.02; 322:0.02; 304:0.02; 298:0.02
  Agent2 top policies: 316:0.03; 317:0.02; 322:0.02; 304:0.02; 298:0.02
. 2 .
b . .
. 1 .

Reward: +0.00, Result: neutral

--- Step 4 ---
Agent 1 joint action: 24 → (PRESS, UP)
Agent 2 joint action: 24 → (PRESS, UP)
Executed: Agent 1: PRESS, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 7:1.00, 8:0.00, 6:0.00
    agent2_pos: 1:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:1.00, 1:0.00, 6:0.00
    blue_button_pos: 3:1.00, 5:0.00, 6:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 7:1.00, 8:0.00, 6:0.00
    agent2_pos: 1:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:1.00, 1:0.00, 6:0.00
    blue_button_pos: 3:1.00, 5:0.00, 6:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 1051:0.00; 1052:0.00; 1053:0.00; 1054:0.00; 1055:0.00
  Agent2 top policies: 1051:0.00; 1052:0.00; 1053:0.00; 1054:0.00; 1055:0.00
. 2 .
b . .
. 1 .

Reward: +0.00, Result: neutral
Button pressed: red by Agent 1

--- Step 5 ---
Agent 1 joint action: 0 → (UP, UP)
Agent 2 joint action: 0 → (UP, UP)
Executed: Agent 1: UP, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 7:1.00, 8:0.00, 6:0.00
    agent2_pos: 1:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:1.00, 1:0.00, 6:0.00
    blue_button_pos: 3:1.00, 5:0.00, 6:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 7:1.00, 8:0.00, 6:0.00
    agent2_pos: 1:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:1.00, 1:0.00, 6:0.00
    blue_button_pos: 3:1.00, 5:0.00, 6:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 0:0.00; 1295:0.00; 1294:0.00; 1293:0.00; 1292:0.00
  Agent2 top policies: 0:0.00; 1295:0.00; 1294:0.00; 1293:0.00; 1292:0.00
. 2 .
b 1 .
. R .

Reward: +0.00, Result: neutral

--- Step 6 ---
Agent 1 joint action: 12 → (LEFT, UP)
Agent 2 joint action: 12 → (LEFT, UP)
Executed: Agent 1: LEFT, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 4:1.00, 8:0.00, 6:0.00
    agent2_pos: 1:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:1.00, 8:0.00, 6:0.00
    blue_button_pos: 3:1.00, 5:0.00, 6:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 4:1.00, 8:0.00, 6:0.00
    agent2_pos: 1:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:1.00, 8:0.00, 6:0.00
    blue_button_pos: 3:1.00, 5:0.00, 6:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 532:0.03; 531:0.03; 564:0.03; 492:0.03; 493:0.03
  Agent2 top policies: 532:0.03; 531:0.03; 564:0.03; 492:0.03; 493:0.03
. 2 .
1 . .
. R .

Reward: +0.00, Result: neutral

--- Step 7 ---
Agent 1 joint action: 24 → (PRESS, UP)
Agent 2 joint action: 24 → (PRESS, UP)
Executed: Agent 1: PRESS, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 3:1.00, 8:0.00, 7:0.00
    agent2_pos: 1:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:1.00, 8:0.00, 6:0.00
    blue_button_pos: 3:1.00, 5:0.00, 6:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 3:1.00, 8:0.00, 7:0.00
    agent2_pos: 1:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:1.00, 8:0.00, 6:0.00
    blue_button_pos: 3:1.00, 5:0.00, 6:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 1040:0.00; 1041:0.00; 1042:0.00; 1043:0.00; 1044:0.00
  Agent2 top policies: 1040:0.00; 1041:0.00; 1042:0.00; 1043:0.00; 1044:0.00
. 2 .
1 . .
. R .

Reward: +1.00, Result: win
Button pressed: blue by Agent 1

Result: ✅ WIN - win (steps: 7, reward: +1.00)

================================================================================
EPISODE 64
================================================================================
Environment: Red at (1, 2), Blue at (0, 1)

Initial state:
1 . .
b . .
. r 2


--- Step 1 ---
Agent 1 joint action: 6 → (DOWN, UP)
Agent 2 joint action: 6 → (DOWN, UP)
Executed: Agent 1: DOWN, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 0:1.00, 8:0.00, 7:0.00
    agent2_pos: 8:1.00, 0:0.00, 7:0.00
    red_button_pos: 7:0.14, 3:0.14, 6:0.14
    blue_button_pos: 7:0.14, 3:0.14, 6:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 0:1.00, 8:0.00, 7:0.00
    agent2_pos: 8:1.00, 0:0.00, 7:0.00
    red_button_pos: 7:0.14, 3:0.14, 6:0.14
    blue_button_pos: 7:0.14, 3:0.14, 6:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 244:0.02; 676:0.02; 316:0.02; 748:0.02; 677:0.01
  Agent2 top policies: 244:0.02; 676:0.02; 316:0.02; 748:0.02; 677:0.01
. . .
1 . 2
. r .

Reward: +0.00, Result: neutral

--- Step 2 ---
Agent 1 joint action: 18 → (RIGHT, UP)
Agent 2 joint action: 18 → (RIGHT, UP)
Executed: Agent 1: RIGHT, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 3:1.00, 8:0.00, 7:0.00
    agent2_pos: 5:1.00, 8:0.00, 0:0.00
    red_button_pos: 7:0.20, 1:0.20, 6:0.20
    blue_button_pos: 3:1.00, 4:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 3:1.00, 8:0.00, 7:0.00
    agent2_pos: 5:1.00, 8:0.00, 0:0.00
    red_button_pos: 7:0.20, 1:0.20, 6:0.20
    blue_button_pos: 3:1.00, 4:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 676:0.02; 316:0.02; 244:0.02; 674:0.01; 322:0.01
  Agent2 top policies: 676:0.02; 316:0.02; 244:0.02; 674:0.01; 322:0.01
. . 2
b 1 .
. r .

Reward: +0.00, Result: neutral

--- Step 3 ---
Agent 1 joint action: 8 → (DOWN, LEFT)
Agent 2 joint action: 8 → (DOWN, LEFT)
Executed: Agent 1: DOWN, Agent 2: LEFT
  Agent1 beliefs:
    agent1_pos: 4:1.00, 8:0.00, 5:0.00
    agent2_pos: 2:1.00, 8:0.00, 4:0.00
    red_button_pos: 7:0.33, 1:0.33, 6:0.33
    blue_button_pos: 3:1.00, 1:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 4:1.00, 8:0.00, 5:0.00
    agent2_pos: 2:1.00, 8:0.00, 4:0.00
    red_button_pos: 7:0.33, 1:0.33, 6:0.33
    blue_button_pos: 3:1.00, 1:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 316:0.03; 317:0.02; 322:0.02; 304:0.02; 298:0.02
  Agent2 top policies: 316:0.03; 317:0.02; 322:0.02; 304:0.02; 298:0.02
. 2 .
b . .
. 1 .

Reward: +0.00, Result: neutral

--- Step 4 ---
Agent 1 joint action: 24 → (PRESS, UP)
Agent 2 joint action: 24 → (PRESS, UP)
Executed: Agent 1: PRESS, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 7:1.00, 8:0.00, 6:0.00
    agent2_pos: 1:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:1.00, 1:0.00, 6:0.00
    blue_button_pos: 3:1.00, 5:0.00, 6:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 7:1.00, 8:0.00, 6:0.00
    agent2_pos: 1:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:1.00, 1:0.00, 6:0.00
    blue_button_pos: 3:1.00, 5:0.00, 6:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 1051:0.00; 1052:0.00; 1053:0.00; 1054:0.00; 1055:0.00
  Agent2 top policies: 1051:0.00; 1052:0.00; 1053:0.00; 1054:0.00; 1055:0.00
. 2 .
b . .
. 1 .

Reward: +0.00, Result: neutral
Button pressed: red by Agent 1

--- Step 5 ---
Agent 1 joint action: 0 → (UP, UP)
Agent 2 joint action: 0 → (UP, UP)
Executed: Agent 1: UP, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 7:1.00, 8:0.00, 6:0.00
    agent2_pos: 1:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:1.00, 1:0.00, 6:0.00
    blue_button_pos: 3:1.00, 5:0.00, 6:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 7:1.00, 8:0.00, 6:0.00
    agent2_pos: 1:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:1.00, 1:0.00, 6:0.00
    blue_button_pos: 3:1.00, 5:0.00, 6:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 0:0.00; 1295:0.00; 1294:0.00; 1293:0.00; 1292:0.00
  Agent2 top policies: 0:0.00; 1295:0.00; 1294:0.00; 1293:0.00; 1292:0.00
. 2 .
b 1 .
. R .

Reward: +0.00, Result: neutral

--- Step 6 ---
Agent 1 joint action: 12 → (LEFT, UP)
Agent 2 joint action: 12 → (LEFT, UP)
Executed: Agent 1: LEFT, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 4:1.00, 8:0.00, 6:0.00
    agent2_pos: 1:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:1.00, 8:0.00, 6:0.00
    blue_button_pos: 3:1.00, 5:0.00, 6:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 4:1.00, 8:0.00, 6:0.00
    agent2_pos: 1:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:1.00, 8:0.00, 6:0.00
    blue_button_pos: 3:1.00, 5:0.00, 6:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 532:0.03; 531:0.03; 564:0.03; 492:0.03; 493:0.03
  Agent2 top policies: 532:0.03; 531:0.03; 564:0.03; 492:0.03; 493:0.03
. 2 .
1 . .
. R .

Reward: +0.00, Result: neutral

--- Step 7 ---
Agent 1 joint action: 24 → (PRESS, UP)
Agent 2 joint action: 24 → (PRESS, UP)
Executed: Agent 1: PRESS, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 3:1.00, 8:0.00, 7:0.00
    agent2_pos: 1:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:1.00, 8:0.00, 6:0.00
    blue_button_pos: 3:1.00, 5:0.00, 6:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 3:1.00, 8:0.00, 7:0.00
    agent2_pos: 1:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:1.00, 8:0.00, 6:0.00
    blue_button_pos: 3:1.00, 5:0.00, 6:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 1040:0.00; 1041:0.00; 1042:0.00; 1043:0.00; 1044:0.00
  Agent2 top policies: 1040:0.00; 1041:0.00; 1042:0.00; 1043:0.00; 1044:0.00
. 2 .
1 . .
. R .

Reward: +1.00, Result: win
Button pressed: blue by Agent 1

Result: ✅ WIN - win (steps: 7, reward: +1.00)

================================================================================
EPISODE 65
================================================================================
Environment: Red at (1, 2), Blue at (0, 1)

Initial state:
1 . .
b . .
. r 2


--- Step 1 ---
Agent 1 joint action: 6 → (DOWN, UP)
Agent 2 joint action: 6 → (DOWN, UP)
Executed: Agent 1: DOWN, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 0:1.00, 8:0.00, 7:0.00
    agent2_pos: 8:1.00, 0:0.00, 7:0.00
    red_button_pos: 7:0.14, 3:0.14, 6:0.14
    blue_button_pos: 7:0.14, 3:0.14, 6:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 0:1.00, 8:0.00, 7:0.00
    agent2_pos: 8:1.00, 0:0.00, 7:0.00
    red_button_pos: 7:0.14, 3:0.14, 6:0.14
    blue_button_pos: 7:0.14, 3:0.14, 6:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 244:0.02; 676:0.02; 316:0.02; 748:0.02; 677:0.01
  Agent2 top policies: 244:0.02; 676:0.02; 316:0.02; 748:0.02; 677:0.01
. . .
1 . 2
. r .

Reward: +0.00, Result: neutral

--- Step 2 ---
Agent 1 joint action: 18 → (RIGHT, UP)
Agent 2 joint action: 18 → (RIGHT, UP)
Executed: Agent 1: RIGHT, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 3:1.00, 8:0.00, 7:0.00
    agent2_pos: 5:1.00, 8:0.00, 0:0.00
    red_button_pos: 7:0.20, 1:0.20, 6:0.20
    blue_button_pos: 3:1.00, 4:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 3:1.00, 8:0.00, 7:0.00
    agent2_pos: 5:1.00, 8:0.00, 0:0.00
    red_button_pos: 7:0.20, 1:0.20, 6:0.20
    blue_button_pos: 3:1.00, 4:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 676:0.02; 316:0.02; 244:0.02; 674:0.01; 322:0.01
  Agent2 top policies: 676:0.02; 316:0.02; 244:0.02; 674:0.01; 322:0.01
. . 2
b 1 .
. r .

Reward: +0.00, Result: neutral

--- Step 3 ---
Agent 1 joint action: 8 → (DOWN, LEFT)
Agent 2 joint action: 8 → (DOWN, LEFT)
Executed: Agent 1: DOWN, Agent 2: LEFT
  Agent1 beliefs:
    agent1_pos: 4:1.00, 8:0.00, 5:0.00
    agent2_pos: 2:1.00, 8:0.00, 4:0.00
    red_button_pos: 7:0.33, 1:0.33, 6:0.33
    blue_button_pos: 3:1.00, 1:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 4:1.00, 8:0.00, 5:0.00
    agent2_pos: 2:1.00, 8:0.00, 4:0.00
    red_button_pos: 7:0.33, 1:0.33, 6:0.33
    blue_button_pos: 3:1.00, 1:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 316:0.03; 317:0.02; 322:0.02; 304:0.02; 298:0.02
  Agent2 top policies: 316:0.03; 317:0.02; 322:0.02; 304:0.02; 298:0.02
. 2 .
b . .
. 1 .

Reward: +0.00, Result: neutral

--- Step 4 ---
Agent 1 joint action: 24 → (PRESS, UP)
Agent 2 joint action: 24 → (PRESS, UP)
Executed: Agent 1: PRESS, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 7:1.00, 8:0.00, 6:0.00
    agent2_pos: 1:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:1.00, 1:0.00, 6:0.00
    blue_button_pos: 3:1.00, 5:0.00, 6:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 7:1.00, 8:0.00, 6:0.00
    agent2_pos: 1:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:1.00, 1:0.00, 6:0.00
    blue_button_pos: 3:1.00, 5:0.00, 6:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 1051:0.00; 1052:0.00; 1053:0.00; 1054:0.00; 1055:0.00
  Agent2 top policies: 1051:0.00; 1052:0.00; 1053:0.00; 1054:0.00; 1055:0.00
. 2 .
b . .
. 1 .

Reward: +0.00, Result: neutral
Button pressed: red by Agent 1

--- Step 5 ---
Agent 1 joint action: 0 → (UP, UP)
Agent 2 joint action: 0 → (UP, UP)
Executed: Agent 1: UP, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 7:1.00, 8:0.00, 6:0.00
    agent2_pos: 1:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:1.00, 1:0.00, 6:0.00
    blue_button_pos: 3:1.00, 5:0.00, 6:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 7:1.00, 8:0.00, 6:0.00
    agent2_pos: 1:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:1.00, 1:0.00, 6:0.00
    blue_button_pos: 3:1.00, 5:0.00, 6:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 0:0.00; 1295:0.00; 1294:0.00; 1293:0.00; 1292:0.00
  Agent2 top policies: 0:0.00; 1295:0.00; 1294:0.00; 1293:0.00; 1292:0.00
. 2 .
b 1 .
. R .

Reward: +0.00, Result: neutral

--- Step 6 ---
Agent 1 joint action: 12 → (LEFT, UP)
Agent 2 joint action: 12 → (LEFT, UP)
Executed: Agent 1: LEFT, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 4:1.00, 8:0.00, 6:0.00
    agent2_pos: 1:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:1.00, 8:0.00, 6:0.00
    blue_button_pos: 3:1.00, 5:0.00, 6:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 4:1.00, 8:0.00, 6:0.00
    agent2_pos: 1:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:1.00, 8:0.00, 6:0.00
    blue_button_pos: 3:1.00, 5:0.00, 6:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 532:0.03; 531:0.03; 564:0.03; 492:0.03; 493:0.03
  Agent2 top policies: 532:0.03; 531:0.03; 564:0.03; 492:0.03; 493:0.03
. 2 .
1 . .
. R .

Reward: +0.00, Result: neutral

--- Step 7 ---
Agent 1 joint action: 24 → (PRESS, UP)
Agent 2 joint action: 24 → (PRESS, UP)
Executed: Agent 1: PRESS, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 3:1.00, 8:0.00, 7:0.00
    agent2_pos: 1:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:1.00, 8:0.00, 6:0.00
    blue_button_pos: 3:1.00, 5:0.00, 6:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 3:1.00, 8:0.00, 7:0.00
    agent2_pos: 1:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:1.00, 8:0.00, 6:0.00
    blue_button_pos: 3:1.00, 5:0.00, 6:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 1040:0.00; 1041:0.00; 1042:0.00; 1043:0.00; 1044:0.00
  Agent2 top policies: 1040:0.00; 1041:0.00; 1042:0.00; 1043:0.00; 1044:0.00
. 2 .
1 . .
. R .

Reward: +1.00, Result: win
Button pressed: blue by Agent 1

Result: ✅ WIN - win (steps: 7, reward: +1.00)

================================================================================
EPISODE 66
================================================================================
Environment: Red at (1, 2), Blue at (0, 1)

Initial state:
1 . .
b . .
. r 2


--- Step 1 ---
Agent 1 joint action: 6 → (DOWN, UP)
Agent 2 joint action: 6 → (DOWN, UP)
Executed: Agent 1: DOWN, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 0:1.00, 8:0.00, 7:0.00
    agent2_pos: 8:1.00, 0:0.00, 7:0.00
    red_button_pos: 7:0.14, 3:0.14, 6:0.14
    blue_button_pos: 7:0.14, 3:0.14, 6:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 0:1.00, 8:0.00, 7:0.00
    agent2_pos: 8:1.00, 0:0.00, 7:0.00
    red_button_pos: 7:0.14, 3:0.14, 6:0.14
    blue_button_pos: 7:0.14, 3:0.14, 6:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 244:0.02; 676:0.02; 316:0.02; 748:0.02; 677:0.01
  Agent2 top policies: 244:0.02; 676:0.02; 316:0.02; 748:0.02; 677:0.01
. . .
1 . 2
. r .

Reward: +0.00, Result: neutral

--- Step 2 ---
Agent 1 joint action: 18 → (RIGHT, UP)
Agent 2 joint action: 18 → (RIGHT, UP)
Executed: Agent 1: RIGHT, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 3:1.00, 8:0.00, 7:0.00
    agent2_pos: 5:1.00, 8:0.00, 0:0.00
    red_button_pos: 7:0.20, 1:0.20, 6:0.20
    blue_button_pos: 3:1.00, 4:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 3:1.00, 8:0.00, 7:0.00
    agent2_pos: 5:1.00, 8:0.00, 0:0.00
    red_button_pos: 7:0.20, 1:0.20, 6:0.20
    blue_button_pos: 3:1.00, 4:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 676:0.02; 316:0.02; 244:0.02; 674:0.01; 322:0.01
  Agent2 top policies: 676:0.02; 316:0.02; 244:0.02; 674:0.01; 322:0.01
. . 2
b 1 .
. r .

Reward: +0.00, Result: neutral

--- Step 3 ---
Agent 1 joint action: 8 → (DOWN, LEFT)
Agent 2 joint action: 8 → (DOWN, LEFT)
Executed: Agent 1: DOWN, Agent 2: LEFT
  Agent1 beliefs:
    agent1_pos: 4:1.00, 8:0.00, 5:0.00
    agent2_pos: 2:1.00, 8:0.00, 4:0.00
    red_button_pos: 7:0.33, 1:0.33, 6:0.33
    blue_button_pos: 3:1.00, 1:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 4:1.00, 8:0.00, 5:0.00
    agent2_pos: 2:1.00, 8:0.00, 4:0.00
    red_button_pos: 7:0.33, 1:0.33, 6:0.33
    blue_button_pos: 3:1.00, 1:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 316:0.03; 317:0.02; 322:0.02; 304:0.02; 298:0.02
  Agent2 top policies: 316:0.03; 317:0.02; 322:0.02; 304:0.02; 298:0.02
. 2 .
b . .
. 1 .

Reward: +0.00, Result: neutral

--- Step 4 ---
Agent 1 joint action: 24 → (PRESS, UP)
Agent 2 joint action: 24 → (PRESS, UP)
Executed: Agent 1: PRESS, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 7:1.00, 8:0.00, 6:0.00
    agent2_pos: 1:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:1.00, 1:0.00, 6:0.00
    blue_button_pos: 3:1.00, 5:0.00, 6:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 7:1.00, 8:0.00, 6:0.00
    agent2_pos: 1:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:1.00, 1:0.00, 6:0.00
    blue_button_pos: 3:1.00, 5:0.00, 6:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 1051:0.00; 1052:0.00; 1053:0.00; 1054:0.00; 1055:0.00
  Agent2 top policies: 1051:0.00; 1052:0.00; 1053:0.00; 1054:0.00; 1055:0.00
. 2 .
b . .
. 1 .

Reward: +0.00, Result: neutral
Button pressed: red by Agent 1

--- Step 5 ---
Agent 1 joint action: 0 → (UP, UP)
Agent 2 joint action: 0 → (UP, UP)
Executed: Agent 1: UP, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 7:1.00, 8:0.00, 6:0.00
    agent2_pos: 1:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:1.00, 1:0.00, 6:0.00
    blue_button_pos: 3:1.00, 5:0.00, 6:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 7:1.00, 8:0.00, 6:0.00
    agent2_pos: 1:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:1.00, 1:0.00, 6:0.00
    blue_button_pos: 3:1.00, 5:0.00, 6:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 0:0.00; 1295:0.00; 1294:0.00; 1293:0.00; 1292:0.00
  Agent2 top policies: 0:0.00; 1295:0.00; 1294:0.00; 1293:0.00; 1292:0.00
. 2 .
b 1 .
. R .

Reward: +0.00, Result: neutral

--- Step 6 ---
Agent 1 joint action: 12 → (LEFT, UP)
Agent 2 joint action: 12 → (LEFT, UP)
Executed: Agent 1: LEFT, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 4:1.00, 8:0.00, 6:0.00
    agent2_pos: 1:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:1.00, 8:0.00, 6:0.00
    blue_button_pos: 3:1.00, 5:0.00, 6:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 4:1.00, 8:0.00, 6:0.00
    agent2_pos: 1:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:1.00, 8:0.00, 6:0.00
    blue_button_pos: 3:1.00, 5:0.00, 6:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 532:0.03; 531:0.03; 564:0.03; 492:0.03; 493:0.03
  Agent2 top policies: 532:0.03; 531:0.03; 564:0.03; 492:0.03; 493:0.03
. 2 .
1 . .
. R .

Reward: +0.00, Result: neutral

--- Step 7 ---
Agent 1 joint action: 24 → (PRESS, UP)
Agent 2 joint action: 24 → (PRESS, UP)
Executed: Agent 1: PRESS, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 3:1.00, 8:0.00, 7:0.00
    agent2_pos: 1:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:1.00, 8:0.00, 6:0.00
    blue_button_pos: 3:1.00, 5:0.00, 6:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 3:1.00, 8:0.00, 7:0.00
    agent2_pos: 1:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:1.00, 8:0.00, 6:0.00
    blue_button_pos: 3:1.00, 5:0.00, 6:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 1040:0.00; 1041:0.00; 1042:0.00; 1043:0.00; 1044:0.00
  Agent2 top policies: 1040:0.00; 1041:0.00; 1042:0.00; 1043:0.00; 1044:0.00
. 2 .
1 . .
. R .

Reward: +1.00, Result: win
Button pressed: blue by Agent 1

Result: ✅ WIN - win (steps: 7, reward: +1.00)

================================================================================
EPISODE 67
================================================================================
Environment: Red at (1, 2), Blue at (0, 1)

Initial state:
1 . .
b . .
. r 2


--- Step 1 ---
Agent 1 joint action: 6 → (DOWN, UP)
Agent 2 joint action: 6 → (DOWN, UP)
Executed: Agent 1: DOWN, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 0:1.00, 8:0.00, 7:0.00
    agent2_pos: 8:1.00, 0:0.00, 7:0.00
    red_button_pos: 7:0.14, 3:0.14, 6:0.14
    blue_button_pos: 7:0.14, 3:0.14, 6:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 0:1.00, 8:0.00, 7:0.00
    agent2_pos: 8:1.00, 0:0.00, 7:0.00
    red_button_pos: 7:0.14, 3:0.14, 6:0.14
    blue_button_pos: 7:0.14, 3:0.14, 6:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 244:0.02; 676:0.02; 316:0.02; 748:0.02; 677:0.01
  Agent2 top policies: 244:0.02; 676:0.02; 316:0.02; 748:0.02; 677:0.01
. . .
1 . 2
. r .

Reward: +0.00, Result: neutral

--- Step 2 ---
Agent 1 joint action: 18 → (RIGHT, UP)
Agent 2 joint action: 18 → (RIGHT, UP)
Executed: Agent 1: RIGHT, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 3:1.00, 8:0.00, 7:0.00
    agent2_pos: 5:1.00, 8:0.00, 0:0.00
    red_button_pos: 7:0.20, 1:0.20, 6:0.20
    blue_button_pos: 3:1.00, 4:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 3:1.00, 8:0.00, 7:0.00
    agent2_pos: 5:1.00, 8:0.00, 0:0.00
    red_button_pos: 7:0.20, 1:0.20, 6:0.20
    blue_button_pos: 3:1.00, 4:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 676:0.02; 316:0.02; 244:0.02; 674:0.01; 322:0.01
  Agent2 top policies: 676:0.02; 316:0.02; 244:0.02; 674:0.01; 322:0.01
. . 2
b 1 .
. r .

Reward: +0.00, Result: neutral

--- Step 3 ---
Agent 1 joint action: 8 → (DOWN, LEFT)
Agent 2 joint action: 8 → (DOWN, LEFT)
Executed: Agent 1: DOWN, Agent 2: LEFT
  Agent1 beliefs:
    agent1_pos: 4:1.00, 8:0.00, 5:0.00
    agent2_pos: 2:1.00, 8:0.00, 4:0.00
    red_button_pos: 7:0.33, 1:0.33, 6:0.33
    blue_button_pos: 3:1.00, 1:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 4:1.00, 8:0.00, 5:0.00
    agent2_pos: 2:1.00, 8:0.00, 4:0.00
    red_button_pos: 7:0.33, 1:0.33, 6:0.33
    blue_button_pos: 3:1.00, 1:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 316:0.03; 317:0.02; 322:0.02; 304:0.02; 298:0.02
  Agent2 top policies: 316:0.03; 317:0.02; 322:0.02; 304:0.02; 298:0.02
. 2 .
b . .
. 1 .

Reward: +0.00, Result: neutral

--- Step 4 ---
Agent 1 joint action: 24 → (PRESS, UP)
Agent 2 joint action: 24 → (PRESS, UP)
Executed: Agent 1: PRESS, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 7:1.00, 8:0.00, 6:0.00
    agent2_pos: 1:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:1.00, 1:0.00, 6:0.00
    blue_button_pos: 3:1.00, 5:0.00, 6:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 7:1.00, 8:0.00, 6:0.00
    agent2_pos: 1:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:1.00, 1:0.00, 6:0.00
    blue_button_pos: 3:1.00, 5:0.00, 6:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 1051:0.00; 1052:0.00; 1053:0.00; 1054:0.00; 1055:0.00
  Agent2 top policies: 1051:0.00; 1052:0.00; 1053:0.00; 1054:0.00; 1055:0.00
. 2 .
b . .
. 1 .

Reward: +0.00, Result: neutral
Button pressed: red by Agent 1

--- Step 5 ---
Agent 1 joint action: 0 → (UP, UP)
Agent 2 joint action: 0 → (UP, UP)
Executed: Agent 1: UP, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 7:1.00, 8:0.00, 6:0.00
    agent2_pos: 1:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:1.00, 1:0.00, 6:0.00
    blue_button_pos: 3:1.00, 5:0.00, 6:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 7:1.00, 8:0.00, 6:0.00
    agent2_pos: 1:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:1.00, 1:0.00, 6:0.00
    blue_button_pos: 3:1.00, 5:0.00, 6:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 0:0.00; 1295:0.00; 1294:0.00; 1293:0.00; 1292:0.00
  Agent2 top policies: 0:0.00; 1295:0.00; 1294:0.00; 1293:0.00; 1292:0.00
. 2 .
b 1 .
. R .

Reward: +0.00, Result: neutral

--- Step 6 ---
Agent 1 joint action: 12 → (LEFT, UP)
Agent 2 joint action: 12 → (LEFT, UP)
Executed: Agent 1: LEFT, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 4:1.00, 8:0.00, 6:0.00
    agent2_pos: 1:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:1.00, 8:0.00, 6:0.00
    blue_button_pos: 3:1.00, 5:0.00, 6:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 4:1.00, 8:0.00, 6:0.00
    agent2_pos: 1:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:1.00, 8:0.00, 6:0.00
    blue_button_pos: 3:1.00, 5:0.00, 6:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 532:0.03; 531:0.03; 564:0.03; 492:0.03; 493:0.03
  Agent2 top policies: 532:0.03; 531:0.03; 564:0.03; 492:0.03; 493:0.03
. 2 .
1 . .
. R .

Reward: +0.00, Result: neutral

--- Step 7 ---
Agent 1 joint action: 24 → (PRESS, UP)
Agent 2 joint action: 24 → (PRESS, UP)
Executed: Agent 1: PRESS, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 3:1.00, 8:0.00, 7:0.00
    agent2_pos: 1:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:1.00, 8:0.00, 6:0.00
    blue_button_pos: 3:1.00, 5:0.00, 6:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 3:1.00, 8:0.00, 7:0.00
    agent2_pos: 1:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:1.00, 8:0.00, 6:0.00
    blue_button_pos: 3:1.00, 5:0.00, 6:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 1040:0.00; 1041:0.00; 1042:0.00; 1043:0.00; 1044:0.00
  Agent2 top policies: 1040:0.00; 1041:0.00; 1042:0.00; 1043:0.00; 1044:0.00
. 2 .
1 . .
. R .

Reward: +1.00, Result: win
Button pressed: blue by Agent 1

Result: ✅ WIN - win (steps: 7, reward: +1.00)

================================================================================
EPISODE 68
================================================================================
Environment: Red at (1, 2), Blue at (0, 1)

Initial state:
1 . .
b . .
. r 2


--- Step 1 ---
Agent 1 joint action: 6 → (DOWN, UP)
Agent 2 joint action: 6 → (DOWN, UP)
Executed: Agent 1: DOWN, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 0:1.00, 8:0.00, 7:0.00
    agent2_pos: 8:1.00, 0:0.00, 7:0.00
    red_button_pos: 7:0.14, 3:0.14, 6:0.14
    blue_button_pos: 7:0.14, 3:0.14, 6:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 0:1.00, 8:0.00, 7:0.00
    agent2_pos: 8:1.00, 0:0.00, 7:0.00
    red_button_pos: 7:0.14, 3:0.14, 6:0.14
    blue_button_pos: 7:0.14, 3:0.14, 6:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 244:0.02; 676:0.02; 316:0.02; 748:0.02; 677:0.01
  Agent2 top policies: 244:0.02; 676:0.02; 316:0.02; 748:0.02; 677:0.01
. . .
1 . 2
. r .

Reward: +0.00, Result: neutral

--- Step 2 ---
Agent 1 joint action: 18 → (RIGHT, UP)
Agent 2 joint action: 18 → (RIGHT, UP)
Executed: Agent 1: RIGHT, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 3:1.00, 8:0.00, 7:0.00
    agent2_pos: 5:1.00, 8:0.00, 0:0.00
    red_button_pos: 7:0.20, 1:0.20, 6:0.20
    blue_button_pos: 3:1.00, 4:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 3:1.00, 8:0.00, 7:0.00
    agent2_pos: 5:1.00, 8:0.00, 0:0.00
    red_button_pos: 7:0.20, 1:0.20, 6:0.20
    blue_button_pos: 3:1.00, 4:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 676:0.02; 316:0.02; 244:0.02; 674:0.01; 322:0.01
  Agent2 top policies: 676:0.02; 316:0.02; 244:0.02; 674:0.01; 322:0.01
. . 2
b 1 .
. r .

Reward: +0.00, Result: neutral

--- Step 3 ---
Agent 1 joint action: 8 → (DOWN, LEFT)
Agent 2 joint action: 8 → (DOWN, LEFT)
Executed: Agent 1: DOWN, Agent 2: LEFT
  Agent1 beliefs:
    agent1_pos: 4:1.00, 8:0.00, 5:0.00
    agent2_pos: 2:1.00, 8:0.00, 4:0.00
    red_button_pos: 7:0.33, 1:0.33, 6:0.33
    blue_button_pos: 3:1.00, 1:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 4:1.00, 8:0.00, 5:0.00
    agent2_pos: 2:1.00, 8:0.00, 4:0.00
    red_button_pos: 7:0.33, 1:0.33, 6:0.33
    blue_button_pos: 3:1.00, 1:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 316:0.03; 317:0.02; 322:0.02; 304:0.02; 298:0.02
  Agent2 top policies: 316:0.03; 317:0.02; 322:0.02; 304:0.02; 298:0.02
. 2 .
b . .
. 1 .

Reward: +0.00, Result: neutral

--- Step 4 ---
Agent 1 joint action: 24 → (PRESS, UP)
Agent 2 joint action: 24 → (PRESS, UP)
Executed: Agent 1: PRESS, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 7:1.00, 8:0.00, 6:0.00
    agent2_pos: 1:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:1.00, 1:0.00, 6:0.00
    blue_button_pos: 3:1.00, 5:0.00, 6:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 7:1.00, 8:0.00, 6:0.00
    agent2_pos: 1:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:1.00, 1:0.00, 6:0.00
    blue_button_pos: 3:1.00, 5:0.00, 6:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 1051:0.00; 1052:0.00; 1053:0.00; 1054:0.00; 1055:0.00
  Agent2 top policies: 1051:0.00; 1052:0.00; 1053:0.00; 1054:0.00; 1055:0.00
. 2 .
b . .
. 1 .

Reward: +0.00, Result: neutral
Button pressed: red by Agent 1

--- Step 5 ---
Agent 1 joint action: 0 → (UP, UP)
Agent 2 joint action: 0 → (UP, UP)
Executed: Agent 1: UP, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 7:1.00, 8:0.00, 6:0.00
    agent2_pos: 1:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:1.00, 1:0.00, 6:0.00
    blue_button_pos: 3:1.00, 5:0.00, 6:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 7:1.00, 8:0.00, 6:0.00
    agent2_pos: 1:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:1.00, 1:0.00, 6:0.00
    blue_button_pos: 3:1.00, 5:0.00, 6:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 0:0.00; 1295:0.00; 1294:0.00; 1293:0.00; 1292:0.00
  Agent2 top policies: 0:0.00; 1295:0.00; 1294:0.00; 1293:0.00; 1292:0.00
. 2 .
b 1 .
. R .

Reward: +0.00, Result: neutral

--- Step 6 ---
Agent 1 joint action: 12 → (LEFT, UP)
Agent 2 joint action: 12 → (LEFT, UP)
Executed: Agent 1: LEFT, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 4:1.00, 8:0.00, 6:0.00
    agent2_pos: 1:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:1.00, 8:0.00, 6:0.00
    blue_button_pos: 3:1.00, 5:0.00, 6:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 4:1.00, 8:0.00, 6:0.00
    agent2_pos: 1:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:1.00, 8:0.00, 6:0.00
    blue_button_pos: 3:1.00, 5:0.00, 6:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 532:0.03; 531:0.03; 564:0.03; 492:0.03; 493:0.03
  Agent2 top policies: 532:0.03; 531:0.03; 564:0.03; 492:0.03; 493:0.03
. 2 .
1 . .
. R .

Reward: +0.00, Result: neutral

--- Step 7 ---
Agent 1 joint action: 24 → (PRESS, UP)
Agent 2 joint action: 24 → (PRESS, UP)
Executed: Agent 1: PRESS, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 3:1.00, 8:0.00, 7:0.00
    agent2_pos: 1:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:1.00, 8:0.00, 6:0.00
    blue_button_pos: 3:1.00, 5:0.00, 6:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 3:1.00, 8:0.00, 7:0.00
    agent2_pos: 1:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:1.00, 8:0.00, 6:0.00
    blue_button_pos: 3:1.00, 5:0.00, 6:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 1040:0.00; 1041:0.00; 1042:0.00; 1043:0.00; 1044:0.00
  Agent2 top policies: 1040:0.00; 1041:0.00; 1042:0.00; 1043:0.00; 1044:0.00
. 2 .
1 . .
. R .

Reward: +1.00, Result: win
Button pressed: blue by Agent 1

Result: ✅ WIN - win (steps: 7, reward: +1.00)

================================================================================
EPISODE 69
================================================================================
Environment: Red at (1, 2), Blue at (0, 1)

Initial state:
1 . .
b . .
. r 2


--- Step 1 ---
Agent 1 joint action: 6 → (DOWN, UP)
Agent 2 joint action: 6 → (DOWN, UP)
Executed: Agent 1: DOWN, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 0:1.00, 8:0.00, 7:0.00
    agent2_pos: 8:1.00, 0:0.00, 7:0.00
    red_button_pos: 7:0.14, 3:0.14, 6:0.14
    blue_button_pos: 7:0.14, 3:0.14, 6:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 0:1.00, 8:0.00, 7:0.00
    agent2_pos: 8:1.00, 0:0.00, 7:0.00
    red_button_pos: 7:0.14, 3:0.14, 6:0.14
    blue_button_pos: 7:0.14, 3:0.14, 6:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 244:0.02; 676:0.02; 316:0.02; 748:0.02; 677:0.01
  Agent2 top policies: 244:0.02; 676:0.02; 316:0.02; 748:0.02; 677:0.01
. . .
1 . 2
. r .

Reward: +0.00, Result: neutral

--- Step 2 ---
Agent 1 joint action: 18 → (RIGHT, UP)
Agent 2 joint action: 18 → (RIGHT, UP)
Executed: Agent 1: RIGHT, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 3:1.00, 8:0.00, 7:0.00
    agent2_pos: 5:1.00, 8:0.00, 0:0.00
    red_button_pos: 7:0.20, 1:0.20, 6:0.20
    blue_button_pos: 3:1.00, 4:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 3:1.00, 8:0.00, 7:0.00
    agent2_pos: 5:1.00, 8:0.00, 0:0.00
    red_button_pos: 7:0.20, 1:0.20, 6:0.20
    blue_button_pos: 3:1.00, 4:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 676:0.02; 316:0.02; 244:0.02; 674:0.01; 322:0.01
  Agent2 top policies: 676:0.02; 316:0.02; 244:0.02; 674:0.01; 322:0.01
. . 2
b 1 .
. r .

Reward: +0.00, Result: neutral

--- Step 3 ---
Agent 1 joint action: 8 → (DOWN, LEFT)
Agent 2 joint action: 8 → (DOWN, LEFT)
Executed: Agent 1: DOWN, Agent 2: LEFT
  Agent1 beliefs:
    agent1_pos: 4:1.00, 8:0.00, 5:0.00
    agent2_pos: 2:1.00, 8:0.00, 4:0.00
    red_button_pos: 7:0.33, 1:0.33, 6:0.33
    blue_button_pos: 3:1.00, 1:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 4:1.00, 8:0.00, 5:0.00
    agent2_pos: 2:1.00, 8:0.00, 4:0.00
    red_button_pos: 7:0.33, 1:0.33, 6:0.33
    blue_button_pos: 3:1.00, 1:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 316:0.03; 317:0.02; 322:0.02; 304:0.02; 298:0.02
  Agent2 top policies: 316:0.03; 317:0.02; 322:0.02; 304:0.02; 298:0.02
. 2 .
b . .
. 1 .

Reward: +0.00, Result: neutral

--- Step 4 ---
Agent 1 joint action: 24 → (PRESS, UP)
Agent 2 joint action: 24 → (PRESS, UP)
Executed: Agent 1: PRESS, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 7:1.00, 8:0.00, 6:0.00
    agent2_pos: 1:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:1.00, 1:0.00, 6:0.00
    blue_button_pos: 3:1.00, 5:0.00, 6:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 7:1.00, 8:0.00, 6:0.00
    agent2_pos: 1:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:1.00, 1:0.00, 6:0.00
    blue_button_pos: 3:1.00, 5:0.00, 6:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 1051:0.00; 1052:0.00; 1053:0.00; 1054:0.00; 1055:0.00
  Agent2 top policies: 1051:0.00; 1052:0.00; 1053:0.00; 1054:0.00; 1055:0.00
. 2 .
b . .
. 1 .

Reward: +0.00, Result: neutral
Button pressed: red by Agent 1

--- Step 5 ---
Agent 1 joint action: 0 → (UP, UP)
Agent 2 joint action: 0 → (UP, UP)
Executed: Agent 1: UP, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 7:1.00, 8:0.00, 6:0.00
    agent2_pos: 1:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:1.00, 1:0.00, 6:0.00
    blue_button_pos: 3:1.00, 5:0.00, 6:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 7:1.00, 8:0.00, 6:0.00
    agent2_pos: 1:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:1.00, 1:0.00, 6:0.00
    blue_button_pos: 3:1.00, 5:0.00, 6:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 0:0.00; 1295:0.00; 1294:0.00; 1293:0.00; 1292:0.00
  Agent2 top policies: 0:0.00; 1295:0.00; 1294:0.00; 1293:0.00; 1292:0.00
. 2 .
b 1 .
. R .

Reward: +0.00, Result: neutral

--- Step 6 ---
Agent 1 joint action: 12 → (LEFT, UP)
Agent 2 joint action: 12 → (LEFT, UP)
Executed: Agent 1: LEFT, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 4:1.00, 8:0.00, 6:0.00
    agent2_pos: 1:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:1.00, 8:0.00, 6:0.00
    blue_button_pos: 3:1.00, 5:0.00, 6:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 4:1.00, 8:0.00, 6:0.00
    agent2_pos: 1:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:1.00, 8:0.00, 6:0.00
    blue_button_pos: 3:1.00, 5:0.00, 6:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 532:0.03; 531:0.03; 564:0.03; 492:0.03; 493:0.03
  Agent2 top policies: 532:0.03; 531:0.03; 564:0.03; 492:0.03; 493:0.03
. 2 .
1 . .
. R .

Reward: +0.00, Result: neutral

--- Step 7 ---
Agent 1 joint action: 24 → (PRESS, UP)
Agent 2 joint action: 24 → (PRESS, UP)
Executed: Agent 1: PRESS, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 3:1.00, 8:0.00, 7:0.00
    agent2_pos: 1:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:1.00, 8:0.00, 6:0.00
    blue_button_pos: 3:1.00, 5:0.00, 6:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 3:1.00, 8:0.00, 7:0.00
    agent2_pos: 1:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:1.00, 8:0.00, 6:0.00
    blue_button_pos: 3:1.00, 5:0.00, 6:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 1040:0.00; 1041:0.00; 1042:0.00; 1043:0.00; 1044:0.00
  Agent2 top policies: 1040:0.00; 1041:0.00; 1042:0.00; 1043:0.00; 1044:0.00
. 2 .
1 . .
. R .

Reward: +1.00, Result: win
Button pressed: blue by Agent 1

Result: ✅ WIN - win (steps: 7, reward: +1.00)

================================================================================
EPISODE 70
================================================================================
Environment: Red at (1, 2), Blue at (0, 1)

Initial state:
1 . .
b . .
. r 2


--- Step 1 ---
Agent 1 joint action: 6 → (DOWN, UP)
Agent 2 joint action: 6 → (DOWN, UP)
Executed: Agent 1: DOWN, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 0:1.00, 8:0.00, 7:0.00
    agent2_pos: 8:1.00, 0:0.00, 7:0.00
    red_button_pos: 7:0.14, 3:0.14, 6:0.14
    blue_button_pos: 7:0.14, 3:0.14, 6:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 0:1.00, 8:0.00, 7:0.00
    agent2_pos: 8:1.00, 0:0.00, 7:0.00
    red_button_pos: 7:0.14, 3:0.14, 6:0.14
    blue_button_pos: 7:0.14, 3:0.14, 6:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 244:0.02; 676:0.02; 316:0.02; 748:0.02; 677:0.01
  Agent2 top policies: 244:0.02; 676:0.02; 316:0.02; 748:0.02; 677:0.01
. . .
1 . 2
. r .

Reward: +0.00, Result: neutral

--- Step 2 ---
Agent 1 joint action: 18 → (RIGHT, UP)
Agent 2 joint action: 18 → (RIGHT, UP)
Executed: Agent 1: RIGHT, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 3:1.00, 8:0.00, 7:0.00
    agent2_pos: 5:1.00, 8:0.00, 0:0.00
    red_button_pos: 7:0.20, 1:0.20, 6:0.20
    blue_button_pos: 3:1.00, 4:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 3:1.00, 8:0.00, 7:0.00
    agent2_pos: 5:1.00, 8:0.00, 0:0.00
    red_button_pos: 7:0.20, 1:0.20, 6:0.20
    blue_button_pos: 3:1.00, 4:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 676:0.02; 316:0.02; 244:0.02; 674:0.01; 322:0.01
  Agent2 top policies: 676:0.02; 316:0.02; 244:0.02; 674:0.01; 322:0.01
. . 2
b 1 .
. r .

Reward: +0.00, Result: neutral

--- Step 3 ---
Agent 1 joint action: 8 → (DOWN, LEFT)
Agent 2 joint action: 8 → (DOWN, LEFT)
Executed: Agent 1: DOWN, Agent 2: LEFT
  Agent1 beliefs:
    agent1_pos: 4:1.00, 8:0.00, 5:0.00
    agent2_pos: 2:1.00, 8:0.00, 4:0.00
    red_button_pos: 7:0.33, 1:0.33, 6:0.33
    blue_button_pos: 3:1.00, 1:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 4:1.00, 8:0.00, 5:0.00
    agent2_pos: 2:1.00, 8:0.00, 4:0.00
    red_button_pos: 7:0.33, 1:0.33, 6:0.33
    blue_button_pos: 3:1.00, 1:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 316:0.03; 317:0.02; 322:0.02; 304:0.02; 298:0.02
  Agent2 top policies: 316:0.03; 317:0.02; 322:0.02; 304:0.02; 298:0.02
. 2 .
b . .
. 1 .

Reward: +0.00, Result: neutral

--- Step 4 ---
Agent 1 joint action: 24 → (PRESS, UP)
Agent 2 joint action: 24 → (PRESS, UP)
Executed: Agent 1: PRESS, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 7:1.00, 8:0.00, 6:0.00
    agent2_pos: 1:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:1.00, 1:0.00, 6:0.00
    blue_button_pos: 3:1.00, 5:0.00, 6:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 7:1.00, 8:0.00, 6:0.00
    agent2_pos: 1:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:1.00, 1:0.00, 6:0.00
    blue_button_pos: 3:1.00, 5:0.00, 6:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 1051:0.00; 1052:0.00; 1053:0.00; 1054:0.00; 1055:0.00
  Agent2 top policies: 1051:0.00; 1052:0.00; 1053:0.00; 1054:0.00; 1055:0.00
. 2 .
b . .
. 1 .

Reward: +0.00, Result: neutral
Button pressed: red by Agent 1

--- Step 5 ---
Agent 1 joint action: 0 → (UP, UP)
Agent 2 joint action: 0 → (UP, UP)
Executed: Agent 1: UP, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 7:1.00, 8:0.00, 6:0.00
    agent2_pos: 1:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:1.00, 1:0.00, 6:0.00
    blue_button_pos: 3:1.00, 5:0.00, 6:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 7:1.00, 8:0.00, 6:0.00
    agent2_pos: 1:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:1.00, 1:0.00, 6:0.00
    blue_button_pos: 3:1.00, 5:0.00, 6:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 0:0.00; 1295:0.00; 1294:0.00; 1293:0.00; 1292:0.00
  Agent2 top policies: 0:0.00; 1295:0.00; 1294:0.00; 1293:0.00; 1292:0.00
. 2 .
b 1 .
. R .

Reward: +0.00, Result: neutral

--- Step 6 ---
Agent 1 joint action: 12 → (LEFT, UP)
Agent 2 joint action: 12 → (LEFT, UP)
Executed: Agent 1: LEFT, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 4:1.00, 8:0.00, 6:0.00
    agent2_pos: 1:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:1.00, 8:0.00, 6:0.00
    blue_button_pos: 3:1.00, 5:0.00, 6:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 4:1.00, 8:0.00, 6:0.00
    agent2_pos: 1:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:1.00, 8:0.00, 6:0.00
    blue_button_pos: 3:1.00, 5:0.00, 6:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 532:0.03; 531:0.03; 564:0.03; 492:0.03; 493:0.03
  Agent2 top policies: 532:0.03; 531:0.03; 564:0.03; 492:0.03; 493:0.03
. 2 .
1 . .
. R .

Reward: +0.00, Result: neutral

--- Step 7 ---
Agent 1 joint action: 24 → (PRESS, UP)
Agent 2 joint action: 24 → (PRESS, UP)
Executed: Agent 1: PRESS, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 3:1.00, 8:0.00, 7:0.00
    agent2_pos: 1:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:1.00, 8:0.00, 6:0.00
    blue_button_pos: 3:1.00, 5:0.00, 6:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 3:1.00, 8:0.00, 7:0.00
    agent2_pos: 1:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:1.00, 8:0.00, 6:0.00
    blue_button_pos: 3:1.00, 5:0.00, 6:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 1040:0.00; 1041:0.00; 1042:0.00; 1043:0.00; 1044:0.00
  Agent2 top policies: 1040:0.00; 1041:0.00; 1042:0.00; 1043:0.00; 1044:0.00
. 2 .
1 . .
. R .

Reward: +1.00, Result: win
Button pressed: blue by Agent 1

Result: ✅ WIN - win (steps: 7, reward: +1.00)

================================================================================
EPISODE 71
================================================================================
Environment: Red at (1, 2), Blue at (0, 1)

Initial state:
1 . .
b . .
. r 2


--- Step 1 ---
Agent 1 joint action: 6 → (DOWN, UP)
Agent 2 joint action: 6 → (DOWN, UP)
Executed: Agent 1: DOWN, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 0:1.00, 8:0.00, 7:0.00
    agent2_pos: 8:1.00, 0:0.00, 7:0.00
    red_button_pos: 7:0.14, 3:0.14, 6:0.14
    blue_button_pos: 7:0.14, 3:0.14, 6:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 0:1.00, 8:0.00, 7:0.00
    agent2_pos: 8:1.00, 0:0.00, 7:0.00
    red_button_pos: 7:0.14, 3:0.14, 6:0.14
    blue_button_pos: 7:0.14, 3:0.14, 6:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 244:0.02; 676:0.02; 316:0.02; 748:0.02; 677:0.01
  Agent2 top policies: 244:0.02; 676:0.02; 316:0.02; 748:0.02; 677:0.01
. . .
1 . 2
. r .

Reward: +0.00, Result: neutral

--- Step 2 ---
Agent 1 joint action: 18 → (RIGHT, UP)
Agent 2 joint action: 18 → (RIGHT, UP)
Executed: Agent 1: RIGHT, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 3:1.00, 8:0.00, 7:0.00
    agent2_pos: 5:1.00, 8:0.00, 0:0.00
    red_button_pos: 7:0.20, 1:0.20, 6:0.20
    blue_button_pos: 3:1.00, 4:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 3:1.00, 8:0.00, 7:0.00
    agent2_pos: 5:1.00, 8:0.00, 0:0.00
    red_button_pos: 7:0.20, 1:0.20, 6:0.20
    blue_button_pos: 3:1.00, 4:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 676:0.02; 316:0.02; 244:0.02; 674:0.01; 322:0.01
  Agent2 top policies: 676:0.02; 316:0.02; 244:0.02; 674:0.01; 322:0.01
. . 2
b 1 .
. r .

Reward: +0.00, Result: neutral

--- Step 3 ---
Agent 1 joint action: 8 → (DOWN, LEFT)
Agent 2 joint action: 8 → (DOWN, LEFT)
Executed: Agent 1: DOWN, Agent 2: LEFT
  Agent1 beliefs:
    agent1_pos: 4:1.00, 8:0.00, 5:0.00
    agent2_pos: 2:1.00, 8:0.00, 4:0.00
    red_button_pos: 7:0.33, 1:0.33, 6:0.33
    blue_button_pos: 3:1.00, 1:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 4:1.00, 8:0.00, 5:0.00
    agent2_pos: 2:1.00, 8:0.00, 4:0.00
    red_button_pos: 7:0.33, 1:0.33, 6:0.33
    blue_button_pos: 3:1.00, 1:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 316:0.03; 317:0.02; 322:0.02; 304:0.02; 298:0.02
  Agent2 top policies: 316:0.03; 317:0.02; 322:0.02; 304:0.02; 298:0.02
. 2 .
b . .
. 1 .

Reward: +0.00, Result: neutral

--- Step 4 ---
Agent 1 joint action: 24 → (PRESS, UP)
Agent 2 joint action: 24 → (PRESS, UP)
Executed: Agent 1: PRESS, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 7:1.00, 8:0.00, 6:0.00
    agent2_pos: 1:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:1.00, 1:0.00, 6:0.00
    blue_button_pos: 3:1.00, 5:0.00, 6:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 7:1.00, 8:0.00, 6:0.00
    agent2_pos: 1:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:1.00, 1:0.00, 6:0.00
    blue_button_pos: 3:1.00, 5:0.00, 6:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 1051:0.00; 1052:0.00; 1053:0.00; 1054:0.00; 1055:0.00
  Agent2 top policies: 1051:0.00; 1052:0.00; 1053:0.00; 1054:0.00; 1055:0.00
. 2 .
b . .
. 1 .

Reward: +0.00, Result: neutral
Button pressed: red by Agent 1

--- Step 5 ---
Agent 1 joint action: 0 → (UP, UP)
Agent 2 joint action: 0 → (UP, UP)
Executed: Agent 1: UP, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 7:1.00, 8:0.00, 6:0.00
    agent2_pos: 1:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:1.00, 1:0.00, 6:0.00
    blue_button_pos: 3:1.00, 5:0.00, 6:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 7:1.00, 8:0.00, 6:0.00
    agent2_pos: 1:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:1.00, 1:0.00, 6:0.00
    blue_button_pos: 3:1.00, 5:0.00, 6:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 0:0.00; 1295:0.00; 1294:0.00; 1293:0.00; 1292:0.00
  Agent2 top policies: 0:0.00; 1295:0.00; 1294:0.00; 1293:0.00; 1292:0.00
. 2 .
b 1 .
. R .

Reward: +0.00, Result: neutral

--- Step 6 ---
Agent 1 joint action: 12 → (LEFT, UP)
Agent 2 joint action: 12 → (LEFT, UP)
Executed: Agent 1: LEFT, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 4:1.00, 8:0.00, 6:0.00
    agent2_pos: 1:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:1.00, 8:0.00, 6:0.00
    blue_button_pos: 3:1.00, 5:0.00, 6:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 4:1.00, 8:0.00, 6:0.00
    agent2_pos: 1:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:1.00, 8:0.00, 6:0.00
    blue_button_pos: 3:1.00, 5:0.00, 6:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 532:0.03; 531:0.03; 564:0.03; 492:0.03; 493:0.03
  Agent2 top policies: 532:0.03; 531:0.03; 564:0.03; 492:0.03; 493:0.03
. 2 .
1 . .
. R .

Reward: +0.00, Result: neutral

--- Step 7 ---
Agent 1 joint action: 24 → (PRESS, UP)
Agent 2 joint action: 24 → (PRESS, UP)
Executed: Agent 1: PRESS, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 3:1.00, 8:0.00, 7:0.00
    agent2_pos: 1:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:1.00, 8:0.00, 6:0.00
    blue_button_pos: 3:1.00, 5:0.00, 6:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 3:1.00, 8:0.00, 7:0.00
    agent2_pos: 1:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:1.00, 8:0.00, 6:0.00
    blue_button_pos: 3:1.00, 5:0.00, 6:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 1040:0.00; 1041:0.00; 1042:0.00; 1043:0.00; 1044:0.00
  Agent2 top policies: 1040:0.00; 1041:0.00; 1042:0.00; 1043:0.00; 1044:0.00
. 2 .
1 . .
. R .

Reward: +1.00, Result: win
Button pressed: blue by Agent 1

Result: ✅ WIN - win (steps: 7, reward: +1.00)

================================================================================
EPISODE 72
================================================================================
Environment: Red at (1, 2), Blue at (0, 1)

Initial state:
1 . .
b . .
. r 2


--- Step 1 ---
Agent 1 joint action: 6 → (DOWN, UP)
Agent 2 joint action: 6 → (DOWN, UP)
Executed: Agent 1: DOWN, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 0:1.00, 8:0.00, 7:0.00
    agent2_pos: 8:1.00, 0:0.00, 7:0.00
    red_button_pos: 7:0.14, 3:0.14, 6:0.14
    blue_button_pos: 7:0.14, 3:0.14, 6:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 0:1.00, 8:0.00, 7:0.00
    agent2_pos: 8:1.00, 0:0.00, 7:0.00
    red_button_pos: 7:0.14, 3:0.14, 6:0.14
    blue_button_pos: 7:0.14, 3:0.14, 6:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 244:0.02; 676:0.02; 316:0.02; 748:0.02; 677:0.01
  Agent2 top policies: 244:0.02; 676:0.02; 316:0.02; 748:0.02; 677:0.01
. . .
1 . 2
. r .

Reward: +0.00, Result: neutral

--- Step 2 ---
Agent 1 joint action: 18 → (RIGHT, UP)
Agent 2 joint action: 18 → (RIGHT, UP)
Executed: Agent 1: RIGHT, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 3:1.00, 8:0.00, 7:0.00
    agent2_pos: 5:1.00, 8:0.00, 0:0.00
    red_button_pos: 7:0.20, 1:0.20, 6:0.20
    blue_button_pos: 3:1.00, 4:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 3:1.00, 8:0.00, 7:0.00
    agent2_pos: 5:1.00, 8:0.00, 0:0.00
    red_button_pos: 7:0.20, 1:0.20, 6:0.20
    blue_button_pos: 3:1.00, 4:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 676:0.02; 316:0.02; 244:0.02; 674:0.01; 322:0.01
  Agent2 top policies: 676:0.02; 316:0.02; 244:0.02; 674:0.01; 322:0.01
. . 2
b 1 .
. r .

Reward: +0.00, Result: neutral

--- Step 3 ---
Agent 1 joint action: 8 → (DOWN, LEFT)
Agent 2 joint action: 8 → (DOWN, LEFT)
Executed: Agent 1: DOWN, Agent 2: LEFT
  Agent1 beliefs:
    agent1_pos: 4:1.00, 8:0.00, 5:0.00
    agent2_pos: 2:1.00, 8:0.00, 4:0.00
    red_button_pos: 7:0.33, 1:0.33, 6:0.33
    blue_button_pos: 3:1.00, 1:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 4:1.00, 8:0.00, 5:0.00
    agent2_pos: 2:1.00, 8:0.00, 4:0.00
    red_button_pos: 7:0.33, 1:0.33, 6:0.33
    blue_button_pos: 3:1.00, 1:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 316:0.03; 317:0.02; 322:0.02; 304:0.02; 298:0.02
  Agent2 top policies: 316:0.03; 317:0.02; 322:0.02; 304:0.02; 298:0.02
. 2 .
b . .
. 1 .

Reward: +0.00, Result: neutral

--- Step 4 ---
Agent 1 joint action: 24 → (PRESS, UP)
Agent 2 joint action: 24 → (PRESS, UP)
Executed: Agent 1: PRESS, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 7:1.00, 8:0.00, 6:0.00
    agent2_pos: 1:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:1.00, 1:0.00, 6:0.00
    blue_button_pos: 3:1.00, 5:0.00, 6:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 7:1.00, 8:0.00, 6:0.00
    agent2_pos: 1:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:1.00, 1:0.00, 6:0.00
    blue_button_pos: 3:1.00, 5:0.00, 6:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 1051:0.00; 1052:0.00; 1053:0.00; 1054:0.00; 1055:0.00
  Agent2 top policies: 1051:0.00; 1052:0.00; 1053:0.00; 1054:0.00; 1055:0.00
. 2 .
b . .
. 1 .

Reward: +0.00, Result: neutral
Button pressed: red by Agent 1

--- Step 5 ---
Agent 1 joint action: 0 → (UP, UP)
Agent 2 joint action: 0 → (UP, UP)
Executed: Agent 1: UP, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 7:1.00, 8:0.00, 6:0.00
    agent2_pos: 1:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:1.00, 1:0.00, 6:0.00
    blue_button_pos: 3:1.00, 5:0.00, 6:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 7:1.00, 8:0.00, 6:0.00
    agent2_pos: 1:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:1.00, 1:0.00, 6:0.00
    blue_button_pos: 3:1.00, 5:0.00, 6:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 0:0.00; 1295:0.00; 1294:0.00; 1293:0.00; 1292:0.00
  Agent2 top policies: 0:0.00; 1295:0.00; 1294:0.00; 1293:0.00; 1292:0.00
. 2 .
b 1 .
. R .

Reward: +0.00, Result: neutral

--- Step 6 ---
Agent 1 joint action: 12 → (LEFT, UP)
Agent 2 joint action: 12 → (LEFT, UP)
Executed: Agent 1: LEFT, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 4:1.00, 8:0.00, 6:0.00
    agent2_pos: 1:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:1.00, 8:0.00, 6:0.00
    blue_button_pos: 3:1.00, 5:0.00, 6:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 4:1.00, 8:0.00, 6:0.00
    agent2_pos: 1:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:1.00, 8:0.00, 6:0.00
    blue_button_pos: 3:1.00, 5:0.00, 6:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 532:0.03; 531:0.03; 564:0.03; 492:0.03; 493:0.03
  Agent2 top policies: 532:0.03; 531:0.03; 564:0.03; 492:0.03; 493:0.03
. 2 .
1 . .
. R .

Reward: +0.00, Result: neutral

--- Step 7 ---
Agent 1 joint action: 24 → (PRESS, UP)
Agent 2 joint action: 24 → (PRESS, UP)
Executed: Agent 1: PRESS, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 3:1.00, 8:0.00, 7:0.00
    agent2_pos: 1:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:1.00, 8:0.00, 6:0.00
    blue_button_pos: 3:1.00, 5:0.00, 6:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 3:1.00, 8:0.00, 7:0.00
    agent2_pos: 1:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:1.00, 8:0.00, 6:0.00
    blue_button_pos: 3:1.00, 5:0.00, 6:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 1040:0.00; 1041:0.00; 1042:0.00; 1043:0.00; 1044:0.00
  Agent2 top policies: 1040:0.00; 1041:0.00; 1042:0.00; 1043:0.00; 1044:0.00
. 2 .
1 . .
. R .

Reward: +1.00, Result: win
Button pressed: blue by Agent 1

Result: ✅ WIN - win (steps: 7, reward: +1.00)

================================================================================
EPISODE 73
================================================================================
Environment: Red at (1, 2), Blue at (0, 1)

Initial state:
1 . .
b . .
. r 2


--- Step 1 ---
Agent 1 joint action: 6 → (DOWN, UP)
Agent 2 joint action: 6 → (DOWN, UP)
Executed: Agent 1: DOWN, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 0:1.00, 8:0.00, 7:0.00
    agent2_pos: 8:1.00, 0:0.00, 7:0.00
    red_button_pos: 7:0.14, 3:0.14, 6:0.14
    blue_button_pos: 7:0.14, 3:0.14, 6:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 0:1.00, 8:0.00, 7:0.00
    agent2_pos: 8:1.00, 0:0.00, 7:0.00
    red_button_pos: 7:0.14, 3:0.14, 6:0.14
    blue_button_pos: 7:0.14, 3:0.14, 6:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 244:0.02; 676:0.02; 316:0.02; 748:0.02; 677:0.01
  Agent2 top policies: 244:0.02; 676:0.02; 316:0.02; 748:0.02; 677:0.01
. . .
1 . 2
. r .

Reward: +0.00, Result: neutral

--- Step 2 ---
Agent 1 joint action: 18 → (RIGHT, UP)
Agent 2 joint action: 18 → (RIGHT, UP)
Executed: Agent 1: RIGHT, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 3:1.00, 8:0.00, 7:0.00
    agent2_pos: 5:1.00, 8:0.00, 0:0.00
    red_button_pos: 7:0.20, 1:0.20, 6:0.20
    blue_button_pos: 3:1.00, 4:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 3:1.00, 8:0.00, 7:0.00
    agent2_pos: 5:1.00, 8:0.00, 0:0.00
    red_button_pos: 7:0.20, 1:0.20, 6:0.20
    blue_button_pos: 3:1.00, 4:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 676:0.02; 316:0.02; 244:0.02; 674:0.01; 322:0.01
  Agent2 top policies: 676:0.02; 316:0.02; 244:0.02; 674:0.01; 322:0.01
. . 2
b 1 .
. r .

Reward: +0.00, Result: neutral

--- Step 3 ---
Agent 1 joint action: 8 → (DOWN, LEFT)
Agent 2 joint action: 8 → (DOWN, LEFT)
Executed: Agent 1: DOWN, Agent 2: LEFT
  Agent1 beliefs:
    agent1_pos: 4:1.00, 8:0.00, 5:0.00
    agent2_pos: 2:1.00, 8:0.00, 4:0.00
    red_button_pos: 7:0.33, 1:0.33, 6:0.33
    blue_button_pos: 3:1.00, 1:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 4:1.00, 8:0.00, 5:0.00
    agent2_pos: 2:1.00, 8:0.00, 4:0.00
    red_button_pos: 7:0.33, 1:0.33, 6:0.33
    blue_button_pos: 3:1.00, 1:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 316:0.03; 317:0.02; 322:0.02; 304:0.02; 298:0.02
  Agent2 top policies: 316:0.03; 317:0.02; 322:0.02; 304:0.02; 298:0.02
. 2 .
b . .
. 1 .

Reward: +0.00, Result: neutral

--- Step 4 ---
Agent 1 joint action: 24 → (PRESS, UP)
Agent 2 joint action: 24 → (PRESS, UP)
Executed: Agent 1: PRESS, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 7:1.00, 8:0.00, 6:0.00
    agent2_pos: 1:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:1.00, 1:0.00, 6:0.00
    blue_button_pos: 3:1.00, 5:0.00, 6:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 7:1.00, 8:0.00, 6:0.00
    agent2_pos: 1:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:1.00, 1:0.00, 6:0.00
    blue_button_pos: 3:1.00, 5:0.00, 6:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 1051:0.00; 1052:0.00; 1053:0.00; 1054:0.00; 1055:0.00
  Agent2 top policies: 1051:0.00; 1052:0.00; 1053:0.00; 1054:0.00; 1055:0.00
. 2 .
b . .
. 1 .

Reward: +0.00, Result: neutral
Button pressed: red by Agent 1

--- Step 5 ---
Agent 1 joint action: 0 → (UP, UP)
Agent 2 joint action: 0 → (UP, UP)
Executed: Agent 1: UP, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 7:1.00, 8:0.00, 6:0.00
    agent2_pos: 1:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:1.00, 1:0.00, 6:0.00
    blue_button_pos: 3:1.00, 5:0.00, 6:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 7:1.00, 8:0.00, 6:0.00
    agent2_pos: 1:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:1.00, 1:0.00, 6:0.00
    blue_button_pos: 3:1.00, 5:0.00, 6:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 0:0.00; 1295:0.00; 1294:0.00; 1293:0.00; 1292:0.00
  Agent2 top policies: 0:0.00; 1295:0.00; 1294:0.00; 1293:0.00; 1292:0.00
. 2 .
b 1 .
. R .

Reward: +0.00, Result: neutral

--- Step 6 ---
Agent 1 joint action: 12 → (LEFT, UP)
Agent 2 joint action: 12 → (LEFT, UP)
Executed: Agent 1: LEFT, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 4:1.00, 8:0.00, 6:0.00
    agent2_pos: 1:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:1.00, 8:0.00, 6:0.00
    blue_button_pos: 3:1.00, 5:0.00, 6:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 4:1.00, 8:0.00, 6:0.00
    agent2_pos: 1:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:1.00, 8:0.00, 6:0.00
    blue_button_pos: 3:1.00, 5:0.00, 6:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 532:0.03; 531:0.03; 564:0.03; 492:0.03; 493:0.03
  Agent2 top policies: 532:0.03; 531:0.03; 564:0.03; 492:0.03; 493:0.03
. 2 .
1 . .
. R .

Reward: +0.00, Result: neutral

--- Step 7 ---
Agent 1 joint action: 24 → (PRESS, UP)
Agent 2 joint action: 24 → (PRESS, UP)
Executed: Agent 1: PRESS, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 3:1.00, 8:0.00, 7:0.00
    agent2_pos: 1:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:1.00, 8:0.00, 6:0.00
    blue_button_pos: 3:1.00, 5:0.00, 6:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 3:1.00, 8:0.00, 7:0.00
    agent2_pos: 1:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:1.00, 8:0.00, 6:0.00
    blue_button_pos: 3:1.00, 5:0.00, 6:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 1040:0.00; 1041:0.00; 1042:0.00; 1043:0.00; 1044:0.00
  Agent2 top policies: 1040:0.00; 1041:0.00; 1042:0.00; 1043:0.00; 1044:0.00
. 2 .
1 . .
. R .

Reward: +1.00, Result: win
Button pressed: blue by Agent 1

Result: ✅ WIN - win (steps: 7, reward: +1.00)

================================================================================
EPISODE 74
================================================================================
Environment: Red at (1, 2), Blue at (0, 1)

Initial state:
1 . .
b . .
. r 2


--- Step 1 ---
Agent 1 joint action: 6 → (DOWN, UP)
Agent 2 joint action: 6 → (DOWN, UP)
Executed: Agent 1: DOWN, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 0:1.00, 8:0.00, 7:0.00
    agent2_pos: 8:1.00, 0:0.00, 7:0.00
    red_button_pos: 7:0.14, 3:0.14, 6:0.14
    blue_button_pos: 7:0.14, 3:0.14, 6:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 0:1.00, 8:0.00, 7:0.00
    agent2_pos: 8:1.00, 0:0.00, 7:0.00
    red_button_pos: 7:0.14, 3:0.14, 6:0.14
    blue_button_pos: 7:0.14, 3:0.14, 6:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 244:0.02; 676:0.02; 316:0.02; 748:0.02; 677:0.01
  Agent2 top policies: 244:0.02; 676:0.02; 316:0.02; 748:0.02; 677:0.01
. . .
1 . 2
. r .

Reward: +0.00, Result: neutral

--- Step 2 ---
Agent 1 joint action: 18 → (RIGHT, UP)
Agent 2 joint action: 18 → (RIGHT, UP)
Executed: Agent 1: RIGHT, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 3:1.00, 8:0.00, 7:0.00
    agent2_pos: 5:1.00, 8:0.00, 0:0.00
    red_button_pos: 7:0.20, 1:0.20, 6:0.20
    blue_button_pos: 3:1.00, 4:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 3:1.00, 8:0.00, 7:0.00
    agent2_pos: 5:1.00, 8:0.00, 0:0.00
    red_button_pos: 7:0.20, 1:0.20, 6:0.20
    blue_button_pos: 3:1.00, 4:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 676:0.02; 316:0.02; 244:0.02; 674:0.01; 322:0.01
  Agent2 top policies: 676:0.02; 316:0.02; 244:0.02; 674:0.01; 322:0.01
. . 2
b 1 .
. r .

Reward: +0.00, Result: neutral

--- Step 3 ---
Agent 1 joint action: 8 → (DOWN, LEFT)
Agent 2 joint action: 8 → (DOWN, LEFT)
Executed: Agent 1: DOWN, Agent 2: LEFT
  Agent1 beliefs:
    agent1_pos: 4:1.00, 8:0.00, 5:0.00
    agent2_pos: 2:1.00, 8:0.00, 4:0.00
    red_button_pos: 7:0.33, 1:0.33, 6:0.33
    blue_button_pos: 3:1.00, 1:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 4:1.00, 8:0.00, 5:0.00
    agent2_pos: 2:1.00, 8:0.00, 4:0.00
    red_button_pos: 7:0.33, 1:0.33, 6:0.33
    blue_button_pos: 3:1.00, 1:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 316:0.03; 317:0.02; 322:0.02; 304:0.02; 298:0.02
  Agent2 top policies: 316:0.03; 317:0.02; 322:0.02; 304:0.02; 298:0.02
. 2 .
b . .
. 1 .

Reward: +0.00, Result: neutral

--- Step 4 ---
Agent 1 joint action: 24 → (PRESS, UP)
Agent 2 joint action: 24 → (PRESS, UP)
Executed: Agent 1: PRESS, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 7:1.00, 8:0.00, 6:0.00
    agent2_pos: 1:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:1.00, 1:0.00, 6:0.00
    blue_button_pos: 3:1.00, 5:0.00, 6:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 7:1.00, 8:0.00, 6:0.00
    agent2_pos: 1:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:1.00, 1:0.00, 6:0.00
    blue_button_pos: 3:1.00, 5:0.00, 6:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 1051:0.00; 1052:0.00; 1053:0.00; 1054:0.00; 1055:0.00
  Agent2 top policies: 1051:0.00; 1052:0.00; 1053:0.00; 1054:0.00; 1055:0.00
. 2 .
b . .
. 1 .

Reward: +0.00, Result: neutral
Button pressed: red by Agent 1

--- Step 5 ---
Agent 1 joint action: 0 → (UP, UP)
Agent 2 joint action: 0 → (UP, UP)
Executed: Agent 1: UP, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 7:1.00, 8:0.00, 6:0.00
    agent2_pos: 1:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:1.00, 1:0.00, 6:0.00
    blue_button_pos: 3:1.00, 5:0.00, 6:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 7:1.00, 8:0.00, 6:0.00
    agent2_pos: 1:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:1.00, 1:0.00, 6:0.00
    blue_button_pos: 3:1.00, 5:0.00, 6:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 0:0.00; 1295:0.00; 1294:0.00; 1293:0.00; 1292:0.00
  Agent2 top policies: 0:0.00; 1295:0.00; 1294:0.00; 1293:0.00; 1292:0.00
. 2 .
b 1 .
. R .

Reward: +0.00, Result: neutral

--- Step 6 ---
Agent 1 joint action: 12 → (LEFT, UP)
Agent 2 joint action: 12 → (LEFT, UP)
Executed: Agent 1: LEFT, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 4:1.00, 8:0.00, 6:0.00
    agent2_pos: 1:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:1.00, 8:0.00, 6:0.00
    blue_button_pos: 3:1.00, 5:0.00, 6:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 4:1.00, 8:0.00, 6:0.00
    agent2_pos: 1:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:1.00, 8:0.00, 6:0.00
    blue_button_pos: 3:1.00, 5:0.00, 6:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 532:0.03; 531:0.03; 564:0.03; 492:0.03; 493:0.03
  Agent2 top policies: 532:0.03; 531:0.03; 564:0.03; 492:0.03; 493:0.03
. 2 .
1 . .
. R .

Reward: +0.00, Result: neutral

--- Step 7 ---
Agent 1 joint action: 24 → (PRESS, UP)
Agent 2 joint action: 24 → (PRESS, UP)
Executed: Agent 1: PRESS, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 3:1.00, 8:0.00, 7:0.00
    agent2_pos: 1:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:1.00, 8:0.00, 6:0.00
    blue_button_pos: 3:1.00, 5:0.00, 6:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 3:1.00, 8:0.00, 7:0.00
    agent2_pos: 1:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:1.00, 8:0.00, 6:0.00
    blue_button_pos: 3:1.00, 5:0.00, 6:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 1040:0.00; 1041:0.00; 1042:0.00; 1043:0.00; 1044:0.00
  Agent2 top policies: 1040:0.00; 1041:0.00; 1042:0.00; 1043:0.00; 1044:0.00
. 2 .
1 . .
. R .

Reward: +1.00, Result: win
Button pressed: blue by Agent 1

Result: ✅ WIN - win (steps: 7, reward: +1.00)

================================================================================
EPISODE 75
================================================================================
Environment: Red at (1, 2), Blue at (0, 1)

Initial state:
1 . .
b . .
. r 2


--- Step 1 ---
Agent 1 joint action: 6 → (DOWN, UP)
Agent 2 joint action: 6 → (DOWN, UP)
Executed: Agent 1: DOWN, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 0:1.00, 8:0.00, 7:0.00
    agent2_pos: 8:1.00, 0:0.00, 7:0.00
    red_button_pos: 7:0.14, 3:0.14, 6:0.14
    blue_button_pos: 7:0.14, 3:0.14, 6:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 0:1.00, 8:0.00, 7:0.00
    agent2_pos: 8:1.00, 0:0.00, 7:0.00
    red_button_pos: 7:0.14, 3:0.14, 6:0.14
    blue_button_pos: 7:0.14, 3:0.14, 6:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 244:0.02; 676:0.02; 316:0.02; 748:0.02; 677:0.01
  Agent2 top policies: 244:0.02; 676:0.02; 316:0.02; 748:0.02; 677:0.01
. . .
1 . 2
. r .

Reward: +0.00, Result: neutral

--- Step 2 ---
Agent 1 joint action: 18 → (RIGHT, UP)
Agent 2 joint action: 18 → (RIGHT, UP)
Executed: Agent 1: RIGHT, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 3:1.00, 8:0.00, 7:0.00
    agent2_pos: 5:1.00, 8:0.00, 0:0.00
    red_button_pos: 7:0.20, 1:0.20, 6:0.20
    blue_button_pos: 3:1.00, 4:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 3:1.00, 8:0.00, 7:0.00
    agent2_pos: 5:1.00, 8:0.00, 0:0.00
    red_button_pos: 7:0.20, 1:0.20, 6:0.20
    blue_button_pos: 3:1.00, 4:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 676:0.02; 316:0.02; 244:0.02; 674:0.01; 322:0.01
  Agent2 top policies: 676:0.02; 316:0.02; 244:0.02; 674:0.01; 322:0.01
. . 2
b 1 .
. r .

Reward: +0.00, Result: neutral

--- Step 3 ---
Agent 1 joint action: 8 → (DOWN, LEFT)
Agent 2 joint action: 8 → (DOWN, LEFT)
Executed: Agent 1: DOWN, Agent 2: LEFT
  Agent1 beliefs:
    agent1_pos: 4:1.00, 8:0.00, 5:0.00
    agent2_pos: 2:1.00, 8:0.00, 4:0.00
    red_button_pos: 7:0.33, 1:0.33, 6:0.33
    blue_button_pos: 3:1.00, 1:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 4:1.00, 8:0.00, 5:0.00
    agent2_pos: 2:1.00, 8:0.00, 4:0.00
    red_button_pos: 7:0.33, 1:0.33, 6:0.33
    blue_button_pos: 3:1.00, 1:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 316:0.03; 317:0.02; 322:0.02; 304:0.02; 298:0.02
  Agent2 top policies: 316:0.03; 317:0.02; 322:0.02; 304:0.02; 298:0.02
. 2 .
b . .
. 1 .

Reward: +0.00, Result: neutral

--- Step 4 ---
Agent 1 joint action: 24 → (PRESS, UP)
Agent 2 joint action: 24 → (PRESS, UP)
Executed: Agent 1: PRESS, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 7:1.00, 8:0.00, 6:0.00
    agent2_pos: 1:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:1.00, 1:0.00, 6:0.00
    blue_button_pos: 3:1.00, 5:0.00, 6:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 7:1.00, 8:0.00, 6:0.00
    agent2_pos: 1:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:1.00, 1:0.00, 6:0.00
    blue_button_pos: 3:1.00, 5:0.00, 6:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 1051:0.00; 1052:0.00; 1053:0.00; 1054:0.00; 1055:0.00
  Agent2 top policies: 1051:0.00; 1052:0.00; 1053:0.00; 1054:0.00; 1055:0.00
. 2 .
b . .
. 1 .

Reward: +0.00, Result: neutral
Button pressed: red by Agent 1

--- Step 5 ---
Agent 1 joint action: 0 → (UP, UP)
Agent 2 joint action: 0 → (UP, UP)
Executed: Agent 1: UP, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 7:1.00, 8:0.00, 6:0.00
    agent2_pos: 1:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:1.00, 1:0.00, 6:0.00
    blue_button_pos: 3:1.00, 5:0.00, 6:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 7:1.00, 8:0.00, 6:0.00
    agent2_pos: 1:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:1.00, 1:0.00, 6:0.00
    blue_button_pos: 3:1.00, 5:0.00, 6:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 0:0.00; 1295:0.00; 1294:0.00; 1293:0.00; 1292:0.00
  Agent2 top policies: 0:0.00; 1295:0.00; 1294:0.00; 1293:0.00; 1292:0.00
. 2 .
b 1 .
. R .

Reward: +0.00, Result: neutral

--- Step 6 ---
Agent 1 joint action: 12 → (LEFT, UP)
Agent 2 joint action: 12 → (LEFT, UP)
Executed: Agent 1: LEFT, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 4:1.00, 8:0.00, 6:0.00
    agent2_pos: 1:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:1.00, 8:0.00, 6:0.00
    blue_button_pos: 3:1.00, 5:0.00, 6:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 4:1.00, 8:0.00, 6:0.00
    agent2_pos: 1:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:1.00, 8:0.00, 6:0.00
    blue_button_pos: 3:1.00, 5:0.00, 6:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 532:0.03; 531:0.03; 564:0.03; 492:0.03; 493:0.03
  Agent2 top policies: 532:0.03; 531:0.03; 564:0.03; 492:0.03; 493:0.03
. 2 .
1 . .
. R .

Reward: +0.00, Result: neutral

--- Step 7 ---
Agent 1 joint action: 24 → (PRESS, UP)
Agent 2 joint action: 24 → (PRESS, UP)
Executed: Agent 1: PRESS, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 3:1.00, 8:0.00, 7:0.00
    agent2_pos: 1:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:1.00, 8:0.00, 6:0.00
    blue_button_pos: 3:1.00, 5:0.00, 6:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 3:1.00, 8:0.00, 7:0.00
    agent2_pos: 1:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:1.00, 8:0.00, 6:0.00
    blue_button_pos: 3:1.00, 5:0.00, 6:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 1040:0.00; 1041:0.00; 1042:0.00; 1043:0.00; 1044:0.00
  Agent2 top policies: 1040:0.00; 1041:0.00; 1042:0.00; 1043:0.00; 1044:0.00
. 2 .
1 . .
. R .

Reward: +1.00, Result: win
Button pressed: blue by Agent 1

Result: ✅ WIN - win (steps: 7, reward: +1.00)

================================================================================
EPISODE 76
================================================================================
Environment: Red at (1, 2), Blue at (0, 1)

Initial state:
1 . .
b . .
. r 2


--- Step 1 ---
Agent 1 joint action: 6 → (DOWN, UP)
Agent 2 joint action: 6 → (DOWN, UP)
Executed: Agent 1: DOWN, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 0:1.00, 8:0.00, 7:0.00
    agent2_pos: 8:1.00, 0:0.00, 7:0.00
    red_button_pos: 7:0.14, 3:0.14, 6:0.14
    blue_button_pos: 7:0.14, 3:0.14, 6:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 0:1.00, 8:0.00, 7:0.00
    agent2_pos: 8:1.00, 0:0.00, 7:0.00
    red_button_pos: 7:0.14, 3:0.14, 6:0.14
    blue_button_pos: 7:0.14, 3:0.14, 6:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 244:0.02; 676:0.02; 316:0.02; 748:0.02; 677:0.01
  Agent2 top policies: 244:0.02; 676:0.02; 316:0.02; 748:0.02; 677:0.01
. . .
1 . 2
. r .

Reward: +0.00, Result: neutral

--- Step 2 ---
Agent 1 joint action: 18 → (RIGHT, UP)
Agent 2 joint action: 18 → (RIGHT, UP)
Executed: Agent 1: RIGHT, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 3:1.00, 8:0.00, 7:0.00
    agent2_pos: 5:1.00, 8:0.00, 0:0.00
    red_button_pos: 7:0.20, 1:0.20, 6:0.20
    blue_button_pos: 3:1.00, 4:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 3:1.00, 8:0.00, 7:0.00
    agent2_pos: 5:1.00, 8:0.00, 0:0.00
    red_button_pos: 7:0.20, 1:0.20, 6:0.20
    blue_button_pos: 3:1.00, 4:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 676:0.02; 316:0.02; 244:0.02; 674:0.01; 322:0.01
  Agent2 top policies: 676:0.02; 316:0.02; 244:0.02; 674:0.01; 322:0.01
. . 2
b 1 .
. r .

Reward: +0.00, Result: neutral

--- Step 3 ---
Agent 1 joint action: 8 → (DOWN, LEFT)
Agent 2 joint action: 8 → (DOWN, LEFT)
Executed: Agent 1: DOWN, Agent 2: LEFT
  Agent1 beliefs:
    agent1_pos: 4:1.00, 8:0.00, 5:0.00
    agent2_pos: 2:1.00, 8:0.00, 4:0.00
    red_button_pos: 7:0.33, 1:0.33, 6:0.33
    blue_button_pos: 3:1.00, 1:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 4:1.00, 8:0.00, 5:0.00
    agent2_pos: 2:1.00, 8:0.00, 4:0.00
    red_button_pos: 7:0.33, 1:0.33, 6:0.33
    blue_button_pos: 3:1.00, 1:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 316:0.03; 317:0.02; 322:0.02; 304:0.02; 298:0.02
  Agent2 top policies: 316:0.03; 317:0.02; 322:0.02; 304:0.02; 298:0.02
. 2 .
b . .
. 1 .

Reward: +0.00, Result: neutral

--- Step 4 ---
Agent 1 joint action: 24 → (PRESS, UP)
Agent 2 joint action: 24 → (PRESS, UP)
Executed: Agent 1: PRESS, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 7:1.00, 8:0.00, 6:0.00
    agent2_pos: 1:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:1.00, 1:0.00, 6:0.00
    blue_button_pos: 3:1.00, 5:0.00, 6:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 7:1.00, 8:0.00, 6:0.00
    agent2_pos: 1:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:1.00, 1:0.00, 6:0.00
    blue_button_pos: 3:1.00, 5:0.00, 6:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 1051:0.00; 1052:0.00; 1053:0.00; 1054:0.00; 1055:0.00
  Agent2 top policies: 1051:0.00; 1052:0.00; 1053:0.00; 1054:0.00; 1055:0.00
. 2 .
b . .
. 1 .

Reward: +0.00, Result: neutral
Button pressed: red by Agent 1

--- Step 5 ---
Agent 1 joint action: 0 → (UP, UP)
Agent 2 joint action: 0 → (UP, UP)
Executed: Agent 1: UP, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 7:1.00, 8:0.00, 6:0.00
    agent2_pos: 1:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:1.00, 1:0.00, 6:0.00
    blue_button_pos: 3:1.00, 5:0.00, 6:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 7:1.00, 8:0.00, 6:0.00
    agent2_pos: 1:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:1.00, 1:0.00, 6:0.00
    blue_button_pos: 3:1.00, 5:0.00, 6:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 0:0.00; 1295:0.00; 1294:0.00; 1293:0.00; 1292:0.00
  Agent2 top policies: 0:0.00; 1295:0.00; 1294:0.00; 1293:0.00; 1292:0.00
. 2 .
b 1 .
. R .

Reward: +0.00, Result: neutral

--- Step 6 ---
Agent 1 joint action: 12 → (LEFT, UP)
Agent 2 joint action: 12 → (LEFT, UP)
Executed: Agent 1: LEFT, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 4:1.00, 8:0.00, 6:0.00
    agent2_pos: 1:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:1.00, 8:0.00, 6:0.00
    blue_button_pos: 3:1.00, 5:0.00, 6:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 4:1.00, 8:0.00, 6:0.00
    agent2_pos: 1:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:1.00, 8:0.00, 6:0.00
    blue_button_pos: 3:1.00, 5:0.00, 6:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 532:0.03; 531:0.03; 564:0.03; 492:0.03; 493:0.03
  Agent2 top policies: 532:0.03; 531:0.03; 564:0.03; 492:0.03; 493:0.03
. 2 .
1 . .
. R .

Reward: +0.00, Result: neutral

--- Step 7 ---
Agent 1 joint action: 24 → (PRESS, UP)
Agent 2 joint action: 24 → (PRESS, UP)
Executed: Agent 1: PRESS, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 3:1.00, 8:0.00, 7:0.00
    agent2_pos: 1:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:1.00, 8:0.00, 6:0.00
    blue_button_pos: 3:1.00, 5:0.00, 6:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 3:1.00, 8:0.00, 7:0.00
    agent2_pos: 1:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:1.00, 8:0.00, 6:0.00
    blue_button_pos: 3:1.00, 5:0.00, 6:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 1040:0.00; 1041:0.00; 1042:0.00; 1043:0.00; 1044:0.00
  Agent2 top policies: 1040:0.00; 1041:0.00; 1042:0.00; 1043:0.00; 1044:0.00
. 2 .
1 . .
. R .

Reward: +1.00, Result: win
Button pressed: blue by Agent 1

Result: ✅ WIN - win (steps: 7, reward: +1.00)

================================================================================
EPISODE 77
================================================================================
Environment: Red at (1, 2), Blue at (0, 1)

Initial state:
1 . .
b . .
. r 2


--- Step 1 ---
Agent 1 joint action: 6 → (DOWN, UP)
Agent 2 joint action: 6 → (DOWN, UP)
Executed: Agent 1: DOWN, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 0:1.00, 8:0.00, 7:0.00
    agent2_pos: 8:1.00, 0:0.00, 7:0.00
    red_button_pos: 7:0.14, 3:0.14, 6:0.14
    blue_button_pos: 7:0.14, 3:0.14, 6:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 0:1.00, 8:0.00, 7:0.00
    agent2_pos: 8:1.00, 0:0.00, 7:0.00
    red_button_pos: 7:0.14, 3:0.14, 6:0.14
    blue_button_pos: 7:0.14, 3:0.14, 6:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 244:0.02; 676:0.02; 316:0.02; 748:0.02; 677:0.01
  Agent2 top policies: 244:0.02; 676:0.02; 316:0.02; 748:0.02; 677:0.01
. . .
1 . 2
. r .

Reward: +0.00, Result: neutral

--- Step 2 ---
Agent 1 joint action: 18 → (RIGHT, UP)
Agent 2 joint action: 18 → (RIGHT, UP)
Executed: Agent 1: RIGHT, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 3:1.00, 8:0.00, 7:0.00
    agent2_pos: 5:1.00, 8:0.00, 0:0.00
    red_button_pos: 7:0.20, 1:0.20, 6:0.20
    blue_button_pos: 3:1.00, 4:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 3:1.00, 8:0.00, 7:0.00
    agent2_pos: 5:1.00, 8:0.00, 0:0.00
    red_button_pos: 7:0.20, 1:0.20, 6:0.20
    blue_button_pos: 3:1.00, 4:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 676:0.02; 316:0.02; 244:0.02; 674:0.01; 322:0.01
  Agent2 top policies: 676:0.02; 316:0.02; 244:0.02; 674:0.01; 322:0.01
. . 2
b 1 .
. r .

Reward: +0.00, Result: neutral

--- Step 3 ---
Agent 1 joint action: 8 → (DOWN, LEFT)
Agent 2 joint action: 8 → (DOWN, LEFT)
Executed: Agent 1: DOWN, Agent 2: LEFT
  Agent1 beliefs:
    agent1_pos: 4:1.00, 8:0.00, 5:0.00
    agent2_pos: 2:1.00, 8:0.00, 4:0.00
    red_button_pos: 7:0.33, 1:0.33, 6:0.33
    blue_button_pos: 3:1.00, 1:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 4:1.00, 8:0.00, 5:0.00
    agent2_pos: 2:1.00, 8:0.00, 4:0.00
    red_button_pos: 7:0.33, 1:0.33, 6:0.33
    blue_button_pos: 3:1.00, 1:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 316:0.03; 317:0.02; 322:0.02; 304:0.02; 298:0.02
  Agent2 top policies: 316:0.03; 317:0.02; 322:0.02; 304:0.02; 298:0.02
. 2 .
b . .
. 1 .

Reward: +0.00, Result: neutral

--- Step 4 ---
Agent 1 joint action: 24 → (PRESS, UP)
Agent 2 joint action: 24 → (PRESS, UP)
Executed: Agent 1: PRESS, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 7:1.00, 8:0.00, 6:0.00
    agent2_pos: 1:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:1.00, 1:0.00, 6:0.00
    blue_button_pos: 3:1.00, 5:0.00, 6:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 7:1.00, 8:0.00, 6:0.00
    agent2_pos: 1:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:1.00, 1:0.00, 6:0.00
    blue_button_pos: 3:1.00, 5:0.00, 6:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 1051:0.00; 1052:0.00; 1053:0.00; 1054:0.00; 1055:0.00
  Agent2 top policies: 1051:0.00; 1052:0.00; 1053:0.00; 1054:0.00; 1055:0.00
. 2 .
b . .
. 1 .

Reward: +0.00, Result: neutral
Button pressed: red by Agent 1

--- Step 5 ---
Agent 1 joint action: 0 → (UP, UP)
Agent 2 joint action: 0 → (UP, UP)
Executed: Agent 1: UP, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 7:1.00, 8:0.00, 6:0.00
    agent2_pos: 1:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:1.00, 1:0.00, 6:0.00
    blue_button_pos: 3:1.00, 5:0.00, 6:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 7:1.00, 8:0.00, 6:0.00
    agent2_pos: 1:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:1.00, 1:0.00, 6:0.00
    blue_button_pos: 3:1.00, 5:0.00, 6:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 0:0.00; 1295:0.00; 1294:0.00; 1293:0.00; 1292:0.00
  Agent2 top policies: 0:0.00; 1295:0.00; 1294:0.00; 1293:0.00; 1292:0.00
. 2 .
b 1 .
. R .

Reward: +0.00, Result: neutral

--- Step 6 ---
Agent 1 joint action: 12 → (LEFT, UP)
Agent 2 joint action: 12 → (LEFT, UP)
Executed: Agent 1: LEFT, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 4:1.00, 8:0.00, 6:0.00
    agent2_pos: 1:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:1.00, 8:0.00, 6:0.00
    blue_button_pos: 3:1.00, 5:0.00, 6:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 4:1.00, 8:0.00, 6:0.00
    agent2_pos: 1:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:1.00, 8:0.00, 6:0.00
    blue_button_pos: 3:1.00, 5:0.00, 6:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 532:0.03; 531:0.03; 564:0.03; 492:0.03; 493:0.03
  Agent2 top policies: 532:0.03; 531:0.03; 564:0.03; 492:0.03; 493:0.03
. 2 .
1 . .
. R .

Reward: +0.00, Result: neutral

--- Step 7 ---
Agent 1 joint action: 24 → (PRESS, UP)
Agent 2 joint action: 24 → (PRESS, UP)
Executed: Agent 1: PRESS, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 3:1.00, 8:0.00, 7:0.00
    agent2_pos: 1:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:1.00, 8:0.00, 6:0.00
    blue_button_pos: 3:1.00, 5:0.00, 6:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 3:1.00, 8:0.00, 7:0.00
    agent2_pos: 1:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:1.00, 8:0.00, 6:0.00
    blue_button_pos: 3:1.00, 5:0.00, 6:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 1040:0.00; 1041:0.00; 1042:0.00; 1043:0.00; 1044:0.00
  Agent2 top policies: 1040:0.00; 1041:0.00; 1042:0.00; 1043:0.00; 1044:0.00
. 2 .
1 . .
. R .

Reward: +1.00, Result: win
Button pressed: blue by Agent 1

Result: ✅ WIN - win (steps: 7, reward: +1.00)

================================================================================
EPISODE 78
================================================================================
Environment: Red at (1, 2), Blue at (0, 1)

Initial state:
1 . .
b . .
. r 2


--- Step 1 ---
Agent 1 joint action: 6 → (DOWN, UP)
Agent 2 joint action: 6 → (DOWN, UP)
Executed: Agent 1: DOWN, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 0:1.00, 8:0.00, 7:0.00
    agent2_pos: 8:1.00, 0:0.00, 7:0.00
    red_button_pos: 7:0.14, 3:0.14, 6:0.14
    blue_button_pos: 7:0.14, 3:0.14, 6:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 0:1.00, 8:0.00, 7:0.00
    agent2_pos: 8:1.00, 0:0.00, 7:0.00
    red_button_pos: 7:0.14, 3:0.14, 6:0.14
    blue_button_pos: 7:0.14, 3:0.14, 6:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 244:0.02; 676:0.02; 316:0.02; 748:0.02; 677:0.01
  Agent2 top policies: 244:0.02; 676:0.02; 316:0.02; 748:0.02; 677:0.01
. . .
1 . 2
. r .

Reward: +0.00, Result: neutral

--- Step 2 ---
Agent 1 joint action: 18 → (RIGHT, UP)
Agent 2 joint action: 18 → (RIGHT, UP)
Executed: Agent 1: RIGHT, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 3:1.00, 8:0.00, 7:0.00
    agent2_pos: 5:1.00, 8:0.00, 0:0.00
    red_button_pos: 7:0.20, 1:0.20, 6:0.20
    blue_button_pos: 3:1.00, 4:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 3:1.00, 8:0.00, 7:0.00
    agent2_pos: 5:1.00, 8:0.00, 0:0.00
    red_button_pos: 7:0.20, 1:0.20, 6:0.20
    blue_button_pos: 3:1.00, 4:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 676:0.02; 316:0.02; 244:0.02; 674:0.01; 322:0.01
  Agent2 top policies: 676:0.02; 316:0.02; 244:0.02; 674:0.01; 322:0.01
. . 2
b 1 .
. r .

Reward: +0.00, Result: neutral

--- Step 3 ---
Agent 1 joint action: 8 → (DOWN, LEFT)
Agent 2 joint action: 8 → (DOWN, LEFT)
Executed: Agent 1: DOWN, Agent 2: LEFT
  Agent1 beliefs:
    agent1_pos: 4:1.00, 8:0.00, 5:0.00
    agent2_pos: 2:1.00, 8:0.00, 4:0.00
    red_button_pos: 7:0.33, 1:0.33, 6:0.33
    blue_button_pos: 3:1.00, 1:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 4:1.00, 8:0.00, 5:0.00
    agent2_pos: 2:1.00, 8:0.00, 4:0.00
    red_button_pos: 7:0.33, 1:0.33, 6:0.33
    blue_button_pos: 3:1.00, 1:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 316:0.03; 317:0.02; 322:0.02; 304:0.02; 298:0.02
  Agent2 top policies: 316:0.03; 317:0.02; 322:0.02; 304:0.02; 298:0.02
. 2 .
b . .
. 1 .

Reward: +0.00, Result: neutral

--- Step 4 ---
Agent 1 joint action: 24 → (PRESS, UP)
Agent 2 joint action: 24 → (PRESS, UP)
Executed: Agent 1: PRESS, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 7:1.00, 8:0.00, 6:0.00
    agent2_pos: 1:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:1.00, 1:0.00, 6:0.00
    blue_button_pos: 3:1.00, 5:0.00, 6:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 7:1.00, 8:0.00, 6:0.00
    agent2_pos: 1:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:1.00, 1:0.00, 6:0.00
    blue_button_pos: 3:1.00, 5:0.00, 6:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 1051:0.00; 1052:0.00; 1053:0.00; 1054:0.00; 1055:0.00
  Agent2 top policies: 1051:0.00; 1052:0.00; 1053:0.00; 1054:0.00; 1055:0.00
. 2 .
b . .
. 1 .

Reward: +0.00, Result: neutral
Button pressed: red by Agent 1

--- Step 5 ---
Agent 1 joint action: 0 → (UP, UP)
Agent 2 joint action: 0 → (UP, UP)
Executed: Agent 1: UP, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 7:1.00, 8:0.00, 6:0.00
    agent2_pos: 1:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:1.00, 1:0.00, 6:0.00
    blue_button_pos: 3:1.00, 5:0.00, 6:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 7:1.00, 8:0.00, 6:0.00
    agent2_pos: 1:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:1.00, 1:0.00, 6:0.00
    blue_button_pos: 3:1.00, 5:0.00, 6:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 0:0.00; 1295:0.00; 1294:0.00; 1293:0.00; 1292:0.00
  Agent2 top policies: 0:0.00; 1295:0.00; 1294:0.00; 1293:0.00; 1292:0.00
. 2 .
b 1 .
. R .

Reward: +0.00, Result: neutral

--- Step 6 ---
Agent 1 joint action: 12 → (LEFT, UP)
Agent 2 joint action: 12 → (LEFT, UP)
Executed: Agent 1: LEFT, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 4:1.00, 8:0.00, 6:0.00
    agent2_pos: 1:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:1.00, 8:0.00, 6:0.00
    blue_button_pos: 3:1.00, 5:0.00, 6:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 4:1.00, 8:0.00, 6:0.00
    agent2_pos: 1:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:1.00, 8:0.00, 6:0.00
    blue_button_pos: 3:1.00, 5:0.00, 6:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 532:0.03; 531:0.03; 564:0.03; 492:0.03; 493:0.03
  Agent2 top policies: 532:0.03; 531:0.03; 564:0.03; 492:0.03; 493:0.03
. 2 .
1 . .
. R .

Reward: +0.00, Result: neutral

--- Step 7 ---
Agent 1 joint action: 24 → (PRESS, UP)
Agent 2 joint action: 24 → (PRESS, UP)
Executed: Agent 1: PRESS, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 3:1.00, 8:0.00, 7:0.00
    agent2_pos: 1:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:1.00, 8:0.00, 6:0.00
    blue_button_pos: 3:1.00, 5:0.00, 6:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 3:1.00, 8:0.00, 7:0.00
    agent2_pos: 1:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:1.00, 8:0.00, 6:0.00
    blue_button_pos: 3:1.00, 5:0.00, 6:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 1040:0.00; 1041:0.00; 1042:0.00; 1043:0.00; 1044:0.00
  Agent2 top policies: 1040:0.00; 1041:0.00; 1042:0.00; 1043:0.00; 1044:0.00
. 2 .
1 . .
. R .

Reward: +1.00, Result: win
Button pressed: blue by Agent 1

Result: ✅ WIN - win (steps: 7, reward: +1.00)

================================================================================
EPISODE 79
================================================================================
Environment: Red at (1, 2), Blue at (0, 1)

Initial state:
1 . .
b . .
. r 2


--- Step 1 ---
Agent 1 joint action: 6 → (DOWN, UP)
Agent 2 joint action: 6 → (DOWN, UP)
Executed: Agent 1: DOWN, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 0:1.00, 8:0.00, 7:0.00
    agent2_pos: 8:1.00, 0:0.00, 7:0.00
    red_button_pos: 7:0.14, 3:0.14, 6:0.14
    blue_button_pos: 7:0.14, 3:0.14, 6:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 0:1.00, 8:0.00, 7:0.00
    agent2_pos: 8:1.00, 0:0.00, 7:0.00
    red_button_pos: 7:0.14, 3:0.14, 6:0.14
    blue_button_pos: 7:0.14, 3:0.14, 6:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 244:0.02; 676:0.02; 316:0.02; 748:0.02; 677:0.01
  Agent2 top policies: 244:0.02; 676:0.02; 316:0.02; 748:0.02; 677:0.01
. . .
1 . 2
. r .

Reward: +0.00, Result: neutral

--- Step 2 ---
Agent 1 joint action: 18 → (RIGHT, UP)
Agent 2 joint action: 18 → (RIGHT, UP)
Executed: Agent 1: RIGHT, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 3:1.00, 8:0.00, 7:0.00
    agent2_pos: 5:1.00, 8:0.00, 0:0.00
    red_button_pos: 7:0.20, 1:0.20, 6:0.20
    blue_button_pos: 3:1.00, 4:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 3:1.00, 8:0.00, 7:0.00
    agent2_pos: 5:1.00, 8:0.00, 0:0.00
    red_button_pos: 7:0.20, 1:0.20, 6:0.20
    blue_button_pos: 3:1.00, 4:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 676:0.02; 316:0.02; 244:0.02; 674:0.01; 322:0.01
  Agent2 top policies: 676:0.02; 316:0.02; 244:0.02; 674:0.01; 322:0.01
. . 2
b 1 .
. r .

Reward: +0.00, Result: neutral

--- Step 3 ---
Agent 1 joint action: 8 → (DOWN, LEFT)
Agent 2 joint action: 8 → (DOWN, LEFT)
Executed: Agent 1: DOWN, Agent 2: LEFT
  Agent1 beliefs:
    agent1_pos: 4:1.00, 8:0.00, 5:0.00
    agent2_pos: 2:1.00, 8:0.00, 4:0.00
    red_button_pos: 7:0.33, 1:0.33, 6:0.33
    blue_button_pos: 3:1.00, 1:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 4:1.00, 8:0.00, 5:0.00
    agent2_pos: 2:1.00, 8:0.00, 4:0.00
    red_button_pos: 7:0.33, 1:0.33, 6:0.33
    blue_button_pos: 3:1.00, 1:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 316:0.03; 317:0.02; 322:0.02; 304:0.02; 298:0.02
  Agent2 top policies: 316:0.03; 317:0.02; 322:0.02; 304:0.02; 298:0.02
. 2 .
b . .
. 1 .

Reward: +0.00, Result: neutral

--- Step 4 ---
Agent 1 joint action: 24 → (PRESS, UP)
Agent 2 joint action: 24 → (PRESS, UP)
Executed: Agent 1: PRESS, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 7:1.00, 8:0.00, 6:0.00
    agent2_pos: 1:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:1.00, 1:0.00, 6:0.00
    blue_button_pos: 3:1.00, 5:0.00, 6:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 7:1.00, 8:0.00, 6:0.00
    agent2_pos: 1:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:1.00, 1:0.00, 6:0.00
    blue_button_pos: 3:1.00, 5:0.00, 6:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 1051:0.00; 1052:0.00; 1053:0.00; 1054:0.00; 1055:0.00
  Agent2 top policies: 1051:0.00; 1052:0.00; 1053:0.00; 1054:0.00; 1055:0.00
. 2 .
b . .
. 1 .

Reward: +0.00, Result: neutral
Button pressed: red by Agent 1

--- Step 5 ---
Agent 1 joint action: 0 → (UP, UP)
Agent 2 joint action: 0 → (UP, UP)
Executed: Agent 1: UP, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 7:1.00, 8:0.00, 6:0.00
    agent2_pos: 1:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:1.00, 1:0.00, 6:0.00
    blue_button_pos: 3:1.00, 5:0.00, 6:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 7:1.00, 8:0.00, 6:0.00
    agent2_pos: 1:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:1.00, 1:0.00, 6:0.00
    blue_button_pos: 3:1.00, 5:0.00, 6:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 0:0.00; 1295:0.00; 1294:0.00; 1293:0.00; 1292:0.00
  Agent2 top policies: 0:0.00; 1295:0.00; 1294:0.00; 1293:0.00; 1292:0.00
. 2 .
b 1 .
. R .

Reward: +0.00, Result: neutral

--- Step 6 ---
Agent 1 joint action: 12 → (LEFT, UP)
Agent 2 joint action: 12 → (LEFT, UP)
Executed: Agent 1: LEFT, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 4:1.00, 8:0.00, 6:0.00
    agent2_pos: 1:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:1.00, 8:0.00, 6:0.00
    blue_button_pos: 3:1.00, 5:0.00, 6:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 4:1.00, 8:0.00, 6:0.00
    agent2_pos: 1:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:1.00, 8:0.00, 6:0.00
    blue_button_pos: 3:1.00, 5:0.00, 6:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 532:0.03; 531:0.03; 564:0.03; 492:0.03; 493:0.03
  Agent2 top policies: 532:0.03; 531:0.03; 564:0.03; 492:0.03; 493:0.03
. 2 .
1 . .
. R .

Reward: +0.00, Result: neutral

--- Step 7 ---
Agent 1 joint action: 24 → (PRESS, UP)
Agent 2 joint action: 24 → (PRESS, UP)
Executed: Agent 1: PRESS, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 3:1.00, 8:0.00, 7:0.00
    agent2_pos: 1:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:1.00, 8:0.00, 6:0.00
    blue_button_pos: 3:1.00, 5:0.00, 6:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 3:1.00, 8:0.00, 7:0.00
    agent2_pos: 1:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:1.00, 8:0.00, 6:0.00
    blue_button_pos: 3:1.00, 5:0.00, 6:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 1040:0.00; 1041:0.00; 1042:0.00; 1043:0.00; 1044:0.00
  Agent2 top policies: 1040:0.00; 1041:0.00; 1042:0.00; 1043:0.00; 1044:0.00
. 2 .
1 . .
. R .

Reward: +1.00, Result: win
Button pressed: blue by Agent 1

Result: ✅ WIN - win (steps: 7, reward: +1.00)

================================================================================
EPISODE 80
================================================================================
Environment: Red at (1, 2), Blue at (0, 1)

Initial state:
1 . .
b . .
. r 2


--- Step 1 ---
Agent 1 joint action: 6 → (DOWN, UP)
Agent 2 joint action: 6 → (DOWN, UP)
Executed: Agent 1: DOWN, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 0:1.00, 8:0.00, 7:0.00
    agent2_pos: 8:1.00, 0:0.00, 7:0.00
    red_button_pos: 7:0.14, 3:0.14, 6:0.14
    blue_button_pos: 7:0.14, 3:0.14, 6:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 0:1.00, 8:0.00, 7:0.00
    agent2_pos: 8:1.00, 0:0.00, 7:0.00
    red_button_pos: 7:0.14, 3:0.14, 6:0.14
    blue_button_pos: 7:0.14, 3:0.14, 6:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 244:0.02; 676:0.02; 316:0.02; 748:0.02; 677:0.01
  Agent2 top policies: 244:0.02; 676:0.02; 316:0.02; 748:0.02; 677:0.01
. . .
1 . 2
. r .

Reward: +0.00, Result: neutral

--- Step 2 ---
Agent 1 joint action: 18 → (RIGHT, UP)
Agent 2 joint action: 18 → (RIGHT, UP)
Executed: Agent 1: RIGHT, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 3:1.00, 8:0.00, 7:0.00
    agent2_pos: 5:1.00, 8:0.00, 0:0.00
    red_button_pos: 7:0.20, 1:0.20, 6:0.20
    blue_button_pos: 3:1.00, 4:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 3:1.00, 8:0.00, 7:0.00
    agent2_pos: 5:1.00, 8:0.00, 0:0.00
    red_button_pos: 7:0.20, 1:0.20, 6:0.20
    blue_button_pos: 3:1.00, 4:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 676:0.02; 316:0.02; 244:0.02; 674:0.01; 322:0.01
  Agent2 top policies: 676:0.02; 316:0.02; 244:0.02; 674:0.01; 322:0.01
. . 2
b 1 .
. r .

Reward: +0.00, Result: neutral

--- Step 3 ---
Agent 1 joint action: 8 → (DOWN, LEFT)
Agent 2 joint action: 8 → (DOWN, LEFT)
Executed: Agent 1: DOWN, Agent 2: LEFT
  Agent1 beliefs:
    agent1_pos: 4:1.00, 8:0.00, 5:0.00
    agent2_pos: 2:1.00, 8:0.00, 4:0.00
    red_button_pos: 7:0.33, 1:0.33, 6:0.33
    blue_button_pos: 3:1.00, 1:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 4:1.00, 8:0.00, 5:0.00
    agent2_pos: 2:1.00, 8:0.00, 4:0.00
    red_button_pos: 7:0.33, 1:0.33, 6:0.33
    blue_button_pos: 3:1.00, 1:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 316:0.03; 317:0.02; 322:0.02; 304:0.02; 298:0.02
  Agent2 top policies: 316:0.03; 317:0.02; 322:0.02; 304:0.02; 298:0.02
. 2 .
b . .
. 1 .

Reward: +0.00, Result: neutral

--- Step 4 ---
Agent 1 joint action: 24 → (PRESS, UP)
Agent 2 joint action: 24 → (PRESS, UP)
Executed: Agent 1: PRESS, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 7:1.00, 8:0.00, 6:0.00
    agent2_pos: 1:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:1.00, 1:0.00, 6:0.00
    blue_button_pos: 3:1.00, 5:0.00, 6:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 7:1.00, 8:0.00, 6:0.00
    agent2_pos: 1:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:1.00, 1:0.00, 6:0.00
    blue_button_pos: 3:1.00, 5:0.00, 6:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 1051:0.00; 1052:0.00; 1053:0.00; 1054:0.00; 1055:0.00
  Agent2 top policies: 1051:0.00; 1052:0.00; 1053:0.00; 1054:0.00; 1055:0.00
. 2 .
b . .
. 1 .

Reward: +0.00, Result: neutral
Button pressed: red by Agent 1

--- Step 5 ---
Agent 1 joint action: 0 → (UP, UP)
Agent 2 joint action: 0 → (UP, UP)
Executed: Agent 1: UP, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 7:1.00, 8:0.00, 6:0.00
    agent2_pos: 1:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:1.00, 1:0.00, 6:0.00
    blue_button_pos: 3:1.00, 5:0.00, 6:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 7:1.00, 8:0.00, 6:0.00
    agent2_pos: 1:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:1.00, 1:0.00, 6:0.00
    blue_button_pos: 3:1.00, 5:0.00, 6:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 0:0.00; 1295:0.00; 1294:0.00; 1293:0.00; 1292:0.00
  Agent2 top policies: 0:0.00; 1295:0.00; 1294:0.00; 1293:0.00; 1292:0.00
. 2 .
b 1 .
. R .

Reward: +0.00, Result: neutral

--- Step 6 ---
Agent 1 joint action: 12 → (LEFT, UP)
Agent 2 joint action: 12 → (LEFT, UP)
Executed: Agent 1: LEFT, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 4:1.00, 8:0.00, 6:0.00
    agent2_pos: 1:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:1.00, 8:0.00, 6:0.00
    blue_button_pos: 3:1.00, 5:0.00, 6:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 4:1.00, 8:0.00, 6:0.00
    agent2_pos: 1:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:1.00, 8:0.00, 6:0.00
    blue_button_pos: 3:1.00, 5:0.00, 6:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 532:0.03; 531:0.03; 564:0.03; 492:0.03; 493:0.03
  Agent2 top policies: 532:0.03; 531:0.03; 564:0.03; 492:0.03; 493:0.03
. 2 .
1 . .
. R .

Reward: +0.00, Result: neutral

--- Step 7 ---
Agent 1 joint action: 24 → (PRESS, UP)
Agent 2 joint action: 24 → (PRESS, UP)
Executed: Agent 1: PRESS, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 3:1.00, 8:0.00, 7:0.00
    agent2_pos: 1:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:1.00, 8:0.00, 6:0.00
    blue_button_pos: 3:1.00, 5:0.00, 6:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 3:1.00, 8:0.00, 7:0.00
    agent2_pos: 1:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:1.00, 8:0.00, 6:0.00
    blue_button_pos: 3:1.00, 5:0.00, 6:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 1040:0.00; 1041:0.00; 1042:0.00; 1043:0.00; 1044:0.00
  Agent2 top policies: 1040:0.00; 1041:0.00; 1042:0.00; 1043:0.00; 1044:0.00
. 2 .
1 . .
. R .

Reward: +1.00, Result: win
Button pressed: blue by Agent 1

Result: ✅ WIN - win (steps: 7, reward: +1.00)

================================================================================
SEED 0 - CONFIG 5
Red at (1, 0), Blue at (1, 1)
Episodes 81-100
================================================================================

================================================================================
EPISODE 81
================================================================================
Environment: Red at (1, 0), Blue at (1, 1)

Initial state:
1 r .
. b .
. . 2


--- Step 1 ---
Agent 1 joint action: 6 → (DOWN, UP)
Agent 2 joint action: 6 → (DOWN, UP)
Executed: Agent 1: DOWN, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 0:1.00, 8:0.00, 7:0.00
    agent2_pos: 8:1.00, 0:0.00, 7:0.00
    red_button_pos: 7:0.14, 3:0.14, 6:0.14
    blue_button_pos: 7:0.14, 3:0.14, 6:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 0:1.00, 8:0.00, 7:0.00
    agent2_pos: 8:1.00, 0:0.00, 7:0.00
    red_button_pos: 7:0.14, 3:0.14, 6:0.14
    blue_button_pos: 7:0.14, 3:0.14, 6:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 244:0.02; 676:0.02; 316:0.02; 748:0.02; 677:0.01
  Agent2 top policies: 244:0.02; 676:0.02; 316:0.02; 748:0.02; 677:0.01
. r .
1 b 2
. . .

Reward: +0.00, Result: neutral

--- Step 2 ---
Agent 1 joint action: 8 → (DOWN, LEFT)
Agent 2 joint action: 8 → (DOWN, LEFT)
Executed: Agent 1: DOWN, Agent 2: LEFT
  Agent1 beliefs:
    agent1_pos: 3:1.00, 8:0.00, 5:0.00
    agent2_pos: 5:1.00, 8:0.00, 3:0.00
    red_button_pos: 7:0.20, 1:0.20, 6:0.20
    blue_button_pos: 7:0.20, 1:0.20, 6:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 3:1.00, 8:0.00, 5:0.00
    agent2_pos: 5:1.00, 8:0.00, 3:0.00
    red_button_pos: 7:0.20, 1:0.20, 6:0.20
    blue_button_pos: 7:0.20, 1:0.20, 6:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 316:0.05; 676:0.05; 244:0.05; 313:0.02; 243:0.02
  Agent2 top policies: 316:0.05; 676:0.05; 244:0.05; 313:0.02; 243:0.02
. r .
. 2 .
1 . .

Reward: +0.00, Result: neutral

--- Step 3 ---
Agent 1 joint action: 18 → (RIGHT, UP)
Agent 2 joint action: 18 → (RIGHT, UP)
Executed: Agent 1: RIGHT, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 6:1.00, 8:0.00, 5:0.00
    agent2_pos: 4:1.00, 8:0.00, 7:0.00
    red_button_pos: 7:0.33, 1:0.33, 2:0.33
    blue_button_pos: 4:1.00, 1:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 6:1.00, 8:0.00, 5:0.00
    agent2_pos: 4:1.00, 8:0.00, 7:0.00
    red_button_pos: 7:0.33, 1:0.33, 2:0.33
    blue_button_pos: 4:1.00, 1:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 676:0.04; 672:0.03; 675:0.03; 677:0.03; 682:0.03
  Agent2 top policies: 676:0.04; 672:0.03; 675:0.03; 677:0.03; 682:0.03
. 2 .
. b .
. 1 .

Reward: +0.00, Result: neutral

--- Step 4 ---
Agent 1 joint action: 4 → (UP, PRESS)
Agent 2 joint action: 4 → (UP, PRESS)
Executed: Agent 1: UP, Agent 2: PRESS
  Agent1 beliefs:
    agent1_pos: 7:1.00, 8:0.00, 6:0.00
    agent2_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 2:0.00, 7:0.00
    blue_button_pos: 4:1.00, 2:0.00, 6:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 7:1.00, 8:0.00, 6:0.00
    agent2_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 2:0.00, 7:0.00
    blue_button_pos: 4:1.00, 2:0.00, 6:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 169:0.16; 168:0.16; 173:0.16; 172:0.16; 171:0.16
  Agent2 top policies: 169:0.16; 168:0.16; 173:0.16; 172:0.16; 171:0.16
. 2 .
. 1 .
. . .

Reward: +0.00, Result: neutral
Button pressed: red by Agent 2

--- Step 5 ---
Agent 1 joint action: 24 → (PRESS, UP)
Agent 2 joint action: 24 → (PRESS, UP)
Executed: Agent 1: PRESS, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 4:1.00, 8:0.00, 7:0.00
    agent2_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 2:0.00, 7:0.00
    blue_button_pos: 4:1.00, 2:0.00, 6:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 4:1.00, 8:0.00, 7:0.00
    agent2_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 2:0.00, 7:0.00
    blue_button_pos: 4:1.00, 2:0.00, 6:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 1027:0.00; 1028:0.00; 1029:0.00; 1030:0.00; 1031:0.00
  Agent2 top policies: 1027:0.00; 1028:0.00; 1029:0.00; 1030:0.00; 1031:0.00
. 2 .
. 1 .
. . .

Reward: +1.00, Result: win
Button pressed: blue by Agent 1

Result: ✅ WIN - win (steps: 5, reward: +1.00)

================================================================================
EPISODE 82
================================================================================
Environment: Red at (1, 0), Blue at (1, 1)

Initial state:
1 r .
. b .
. . 2


--- Step 1 ---
Agent 1 joint action: 6 → (DOWN, UP)
Agent 2 joint action: 6 → (DOWN, UP)
Executed: Agent 1: DOWN, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 0:1.00, 8:0.00, 7:0.00
    agent2_pos: 8:1.00, 0:0.00, 7:0.00
    red_button_pos: 7:0.14, 3:0.14, 6:0.14
    blue_button_pos: 7:0.14, 3:0.14, 6:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 0:1.00, 8:0.00, 7:0.00
    agent2_pos: 8:1.00, 0:0.00, 7:0.00
    red_button_pos: 7:0.14, 3:0.14, 6:0.14
    blue_button_pos: 7:0.14, 3:0.14, 6:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 244:0.02; 676:0.02; 316:0.02; 748:0.02; 677:0.01
  Agent2 top policies: 244:0.02; 676:0.02; 316:0.02; 748:0.02; 677:0.01
. r .
1 b 2
. . .

Reward: +0.00, Result: neutral

--- Step 2 ---
Agent 1 joint action: 8 → (DOWN, LEFT)
Agent 2 joint action: 8 → (DOWN, LEFT)
Executed: Agent 1: DOWN, Agent 2: LEFT
  Agent1 beliefs:
    agent1_pos: 3:1.00, 8:0.00, 5:0.00
    agent2_pos: 5:1.00, 8:0.00, 3:0.00
    red_button_pos: 7:0.20, 1:0.20, 6:0.20
    blue_button_pos: 7:0.20, 1:0.20, 6:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 3:1.00, 8:0.00, 5:0.00
    agent2_pos: 5:1.00, 8:0.00, 3:0.00
    red_button_pos: 7:0.20, 1:0.20, 6:0.20
    blue_button_pos: 7:0.20, 1:0.20, 6:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 316:0.05; 676:0.05; 244:0.05; 313:0.02; 243:0.02
  Agent2 top policies: 316:0.05; 676:0.05; 244:0.05; 313:0.02; 243:0.02
. r .
. 2 .
1 . .

Reward: +0.00, Result: neutral

--- Step 3 ---
Agent 1 joint action: 18 → (RIGHT, UP)
Agent 2 joint action: 18 → (RIGHT, UP)
Executed: Agent 1: RIGHT, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 6:1.00, 8:0.00, 5:0.00
    agent2_pos: 4:1.00, 8:0.00, 7:0.00
    red_button_pos: 7:0.33, 1:0.33, 2:0.33
    blue_button_pos: 4:1.00, 1:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 6:1.00, 8:0.00, 5:0.00
    agent2_pos: 4:1.00, 8:0.00, 7:0.00
    red_button_pos: 7:0.33, 1:0.33, 2:0.33
    blue_button_pos: 4:1.00, 1:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 676:0.04; 672:0.03; 675:0.03; 677:0.03; 682:0.03
  Agent2 top policies: 676:0.04; 672:0.03; 675:0.03; 677:0.03; 682:0.03
. 2 .
. b .
. 1 .

Reward: +0.00, Result: neutral

--- Step 4 ---
Agent 1 joint action: 4 → (UP, PRESS)
Agent 2 joint action: 4 → (UP, PRESS)
Executed: Agent 1: UP, Agent 2: PRESS
  Agent1 beliefs:
    agent1_pos: 7:1.00, 8:0.00, 6:0.00
    agent2_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 2:0.00, 7:0.00
    blue_button_pos: 4:1.00, 2:0.00, 6:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 7:1.00, 8:0.00, 6:0.00
    agent2_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 2:0.00, 7:0.00
    blue_button_pos: 4:1.00, 2:0.00, 6:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 169:0.16; 168:0.16; 173:0.16; 172:0.16; 171:0.16
  Agent2 top policies: 169:0.16; 168:0.16; 173:0.16; 172:0.16; 171:0.16
. 2 .
. 1 .
. . .

Reward: +0.00, Result: neutral
Button pressed: red by Agent 2

--- Step 5 ---
Agent 1 joint action: 24 → (PRESS, UP)
Agent 2 joint action: 24 → (PRESS, UP)
Executed: Agent 1: PRESS, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 4:1.00, 8:0.00, 7:0.00
    agent2_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 2:0.00, 7:0.00
    blue_button_pos: 4:1.00, 2:0.00, 6:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 4:1.00, 8:0.00, 7:0.00
    agent2_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 2:0.00, 7:0.00
    blue_button_pos: 4:1.00, 2:0.00, 6:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 1027:0.00; 1028:0.00; 1029:0.00; 1030:0.00; 1031:0.00
  Agent2 top policies: 1027:0.00; 1028:0.00; 1029:0.00; 1030:0.00; 1031:0.00
. 2 .
. 1 .
. . .

Reward: +1.00, Result: win
Button pressed: blue by Agent 1

Result: ✅ WIN - win (steps: 5, reward: +1.00)

================================================================================
EPISODE 83
================================================================================
Environment: Red at (1, 0), Blue at (1, 1)

Initial state:
1 r .
. b .
. . 2


--- Step 1 ---
Agent 1 joint action: 6 → (DOWN, UP)
Agent 2 joint action: 6 → (DOWN, UP)
Executed: Agent 1: DOWN, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 0:1.00, 8:0.00, 7:0.00
    agent2_pos: 8:1.00, 0:0.00, 7:0.00
    red_button_pos: 7:0.14, 3:0.14, 6:0.14
    blue_button_pos: 7:0.14, 3:0.14, 6:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 0:1.00, 8:0.00, 7:0.00
    agent2_pos: 8:1.00, 0:0.00, 7:0.00
    red_button_pos: 7:0.14, 3:0.14, 6:0.14
    blue_button_pos: 7:0.14, 3:0.14, 6:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 244:0.02; 676:0.02; 316:0.02; 748:0.02; 677:0.01
  Agent2 top policies: 244:0.02; 676:0.02; 316:0.02; 748:0.02; 677:0.01
. r .
1 b 2
. . .

Reward: +0.00, Result: neutral

--- Step 2 ---
Agent 1 joint action: 8 → (DOWN, LEFT)
Agent 2 joint action: 8 → (DOWN, LEFT)
Executed: Agent 1: DOWN, Agent 2: LEFT
  Agent1 beliefs:
    agent1_pos: 3:1.00, 8:0.00, 5:0.00
    agent2_pos: 5:1.00, 8:0.00, 3:0.00
    red_button_pos: 7:0.20, 1:0.20, 6:0.20
    blue_button_pos: 7:0.20, 1:0.20, 6:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 3:1.00, 8:0.00, 5:0.00
    agent2_pos: 5:1.00, 8:0.00, 3:0.00
    red_button_pos: 7:0.20, 1:0.20, 6:0.20
    blue_button_pos: 7:0.20, 1:0.20, 6:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 316:0.05; 676:0.05; 244:0.05; 313:0.02; 243:0.02
  Agent2 top policies: 316:0.05; 676:0.05; 244:0.05; 313:0.02; 243:0.02
. r .
. 2 .
1 . .

Reward: +0.00, Result: neutral

--- Step 3 ---
Agent 1 joint action: 18 → (RIGHT, UP)
Agent 2 joint action: 18 → (RIGHT, UP)
Executed: Agent 1: RIGHT, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 6:1.00, 8:0.00, 5:0.00
    agent2_pos: 4:1.00, 8:0.00, 7:0.00
    red_button_pos: 7:0.33, 1:0.33, 2:0.33
    blue_button_pos: 4:1.00, 1:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 6:1.00, 8:0.00, 5:0.00
    agent2_pos: 4:1.00, 8:0.00, 7:0.00
    red_button_pos: 7:0.33, 1:0.33, 2:0.33
    blue_button_pos: 4:1.00, 1:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 676:0.04; 672:0.03; 675:0.03; 677:0.03; 682:0.03
  Agent2 top policies: 676:0.04; 672:0.03; 675:0.03; 677:0.03; 682:0.03
. 2 .
. b .
. 1 .

Reward: +0.00, Result: neutral

--- Step 4 ---
Agent 1 joint action: 4 → (UP, PRESS)
Agent 2 joint action: 4 → (UP, PRESS)
Executed: Agent 1: UP, Agent 2: PRESS
  Agent1 beliefs:
    agent1_pos: 7:1.00, 8:0.00, 6:0.00
    agent2_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 2:0.00, 7:0.00
    blue_button_pos: 4:1.00, 2:0.00, 6:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 7:1.00, 8:0.00, 6:0.00
    agent2_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 2:0.00, 7:0.00
    blue_button_pos: 4:1.00, 2:0.00, 6:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 169:0.16; 168:0.16; 173:0.16; 172:0.16; 171:0.16
  Agent2 top policies: 169:0.16; 168:0.16; 173:0.16; 172:0.16; 171:0.16
. 2 .
. 1 .
. . .

Reward: +0.00, Result: neutral
Button pressed: red by Agent 2

--- Step 5 ---
Agent 1 joint action: 24 → (PRESS, UP)
Agent 2 joint action: 24 → (PRESS, UP)
Executed: Agent 1: PRESS, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 4:1.00, 8:0.00, 7:0.00
    agent2_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 2:0.00, 7:0.00
    blue_button_pos: 4:1.00, 2:0.00, 6:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 4:1.00, 8:0.00, 7:0.00
    agent2_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 2:0.00, 7:0.00
    blue_button_pos: 4:1.00, 2:0.00, 6:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 1027:0.00; 1028:0.00; 1029:0.00; 1030:0.00; 1031:0.00
  Agent2 top policies: 1027:0.00; 1028:0.00; 1029:0.00; 1030:0.00; 1031:0.00
. 2 .
. 1 .
. . .

Reward: +1.00, Result: win
Button pressed: blue by Agent 1

Result: ✅ WIN - win (steps: 5, reward: +1.00)

================================================================================
EPISODE 84
================================================================================
Environment: Red at (1, 0), Blue at (1, 1)

Initial state:
1 r .
. b .
. . 2


--- Step 1 ---
Agent 1 joint action: 6 → (DOWN, UP)
Agent 2 joint action: 6 → (DOWN, UP)
Executed: Agent 1: DOWN, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 0:1.00, 8:0.00, 7:0.00
    agent2_pos: 8:1.00, 0:0.00, 7:0.00
    red_button_pos: 7:0.14, 3:0.14, 6:0.14
    blue_button_pos: 7:0.14, 3:0.14, 6:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 0:1.00, 8:0.00, 7:0.00
    agent2_pos: 8:1.00, 0:0.00, 7:0.00
    red_button_pos: 7:0.14, 3:0.14, 6:0.14
    blue_button_pos: 7:0.14, 3:0.14, 6:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 244:0.02; 676:0.02; 316:0.02; 748:0.02; 677:0.01
  Agent2 top policies: 244:0.02; 676:0.02; 316:0.02; 748:0.02; 677:0.01
. r .
1 b 2
. . .

Reward: +0.00, Result: neutral

--- Step 2 ---
Agent 1 joint action: 8 → (DOWN, LEFT)
Agent 2 joint action: 8 → (DOWN, LEFT)
Executed: Agent 1: DOWN, Agent 2: LEFT
  Agent1 beliefs:
    agent1_pos: 3:1.00, 8:0.00, 5:0.00
    agent2_pos: 5:1.00, 8:0.00, 3:0.00
    red_button_pos: 7:0.20, 1:0.20, 6:0.20
    blue_button_pos: 7:0.20, 1:0.20, 6:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 3:1.00, 8:0.00, 5:0.00
    agent2_pos: 5:1.00, 8:0.00, 3:0.00
    red_button_pos: 7:0.20, 1:0.20, 6:0.20
    blue_button_pos: 7:0.20, 1:0.20, 6:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 316:0.05; 676:0.05; 244:0.05; 313:0.02; 243:0.02
  Agent2 top policies: 316:0.05; 676:0.05; 244:0.05; 313:0.02; 243:0.02
. r .
. 2 .
1 . .

Reward: +0.00, Result: neutral

--- Step 3 ---
Agent 1 joint action: 18 → (RIGHT, UP)
Agent 2 joint action: 18 → (RIGHT, UP)
Executed: Agent 1: RIGHT, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 6:1.00, 8:0.00, 5:0.00
    agent2_pos: 4:1.00, 8:0.00, 7:0.00
    red_button_pos: 7:0.33, 1:0.33, 2:0.33
    blue_button_pos: 4:1.00, 1:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 6:1.00, 8:0.00, 5:0.00
    agent2_pos: 4:1.00, 8:0.00, 7:0.00
    red_button_pos: 7:0.33, 1:0.33, 2:0.33
    blue_button_pos: 4:1.00, 1:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 676:0.04; 672:0.03; 675:0.03; 677:0.03; 682:0.03
  Agent2 top policies: 676:0.04; 672:0.03; 675:0.03; 677:0.03; 682:0.03
. 2 .
. b .
. 1 .

Reward: +0.00, Result: neutral

--- Step 4 ---
Agent 1 joint action: 4 → (UP, PRESS)
Agent 2 joint action: 4 → (UP, PRESS)
Executed: Agent 1: UP, Agent 2: PRESS
  Agent1 beliefs:
    agent1_pos: 7:1.00, 8:0.00, 6:0.00
    agent2_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 2:0.00, 7:0.00
    blue_button_pos: 4:1.00, 2:0.00, 6:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 7:1.00, 8:0.00, 6:0.00
    agent2_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 2:0.00, 7:0.00
    blue_button_pos: 4:1.00, 2:0.00, 6:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 169:0.16; 168:0.16; 173:0.16; 172:0.16; 171:0.16
  Agent2 top policies: 169:0.16; 168:0.16; 173:0.16; 172:0.16; 171:0.16
. 2 .
. 1 .
. . .

Reward: +0.00, Result: neutral
Button pressed: red by Agent 2

--- Step 5 ---
Agent 1 joint action: 24 → (PRESS, UP)
Agent 2 joint action: 24 → (PRESS, UP)
Executed: Agent 1: PRESS, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 4:1.00, 8:0.00, 7:0.00
    agent2_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 2:0.00, 7:0.00
    blue_button_pos: 4:1.00, 2:0.00, 6:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 4:1.00, 8:0.00, 7:0.00
    agent2_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 2:0.00, 7:0.00
    blue_button_pos: 4:1.00, 2:0.00, 6:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 1027:0.00; 1028:0.00; 1029:0.00; 1030:0.00; 1031:0.00
  Agent2 top policies: 1027:0.00; 1028:0.00; 1029:0.00; 1030:0.00; 1031:0.00
. 2 .
. 1 .
. . .

Reward: +1.00, Result: win
Button pressed: blue by Agent 1

Result: ✅ WIN - win (steps: 5, reward: +1.00)

================================================================================
EPISODE 85
================================================================================
Environment: Red at (1, 0), Blue at (1, 1)

Initial state:
1 r .
. b .
. . 2


--- Step 1 ---
Agent 1 joint action: 6 → (DOWN, UP)
Agent 2 joint action: 6 → (DOWN, UP)
Executed: Agent 1: DOWN, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 0:1.00, 8:0.00, 7:0.00
    agent2_pos: 8:1.00, 0:0.00, 7:0.00
    red_button_pos: 7:0.14, 3:0.14, 6:0.14
    blue_button_pos: 7:0.14, 3:0.14, 6:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 0:1.00, 8:0.00, 7:0.00
    agent2_pos: 8:1.00, 0:0.00, 7:0.00
    red_button_pos: 7:0.14, 3:0.14, 6:0.14
    blue_button_pos: 7:0.14, 3:0.14, 6:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 244:0.02; 676:0.02; 316:0.02; 748:0.02; 677:0.01
  Agent2 top policies: 244:0.02; 676:0.02; 316:0.02; 748:0.02; 677:0.01
. r .
1 b 2
. . .

Reward: +0.00, Result: neutral

--- Step 2 ---
Agent 1 joint action: 8 → (DOWN, LEFT)
Agent 2 joint action: 8 → (DOWN, LEFT)
Executed: Agent 1: DOWN, Agent 2: LEFT
  Agent1 beliefs:
    agent1_pos: 3:1.00, 8:0.00, 5:0.00
    agent2_pos: 5:1.00, 8:0.00, 3:0.00
    red_button_pos: 7:0.20, 1:0.20, 6:0.20
    blue_button_pos: 7:0.20, 1:0.20, 6:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 3:1.00, 8:0.00, 5:0.00
    agent2_pos: 5:1.00, 8:0.00, 3:0.00
    red_button_pos: 7:0.20, 1:0.20, 6:0.20
    blue_button_pos: 7:0.20, 1:0.20, 6:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 316:0.05; 676:0.05; 244:0.05; 313:0.02; 243:0.02
  Agent2 top policies: 316:0.05; 676:0.05; 244:0.05; 313:0.02; 243:0.02
. r .
. 2 .
1 . .

Reward: +0.00, Result: neutral

--- Step 3 ---
Agent 1 joint action: 18 → (RIGHT, UP)
Agent 2 joint action: 18 → (RIGHT, UP)
Executed: Agent 1: RIGHT, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 6:1.00, 8:0.00, 5:0.00
    agent2_pos: 4:1.00, 8:0.00, 7:0.00
    red_button_pos: 7:0.33, 1:0.33, 2:0.33
    blue_button_pos: 4:1.00, 1:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 6:1.00, 8:0.00, 5:0.00
    agent2_pos: 4:1.00, 8:0.00, 7:0.00
    red_button_pos: 7:0.33, 1:0.33, 2:0.33
    blue_button_pos: 4:1.00, 1:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 676:0.04; 672:0.03; 675:0.03; 677:0.03; 682:0.03
  Agent2 top policies: 676:0.04; 672:0.03; 675:0.03; 677:0.03; 682:0.03
. 2 .
. b .
. 1 .

Reward: +0.00, Result: neutral

--- Step 4 ---
Agent 1 joint action: 4 → (UP, PRESS)
Agent 2 joint action: 4 → (UP, PRESS)
Executed: Agent 1: UP, Agent 2: PRESS
  Agent1 beliefs:
    agent1_pos: 7:1.00, 8:0.00, 6:0.00
    agent2_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 2:0.00, 7:0.00
    blue_button_pos: 4:1.00, 2:0.00, 6:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 7:1.00, 8:0.00, 6:0.00
    agent2_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 2:0.00, 7:0.00
    blue_button_pos: 4:1.00, 2:0.00, 6:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 169:0.16; 168:0.16; 173:0.16; 172:0.16; 171:0.16
  Agent2 top policies: 169:0.16; 168:0.16; 173:0.16; 172:0.16; 171:0.16
. 2 .
. 1 .
. . .

Reward: +0.00, Result: neutral
Button pressed: red by Agent 2

--- Step 5 ---
Agent 1 joint action: 24 → (PRESS, UP)
Agent 2 joint action: 24 → (PRESS, UP)
Executed: Agent 1: PRESS, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 4:1.00, 8:0.00, 7:0.00
    agent2_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 2:0.00, 7:0.00
    blue_button_pos: 4:1.00, 2:0.00, 6:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 4:1.00, 8:0.00, 7:0.00
    agent2_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 2:0.00, 7:0.00
    blue_button_pos: 4:1.00, 2:0.00, 6:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 1027:0.00; 1028:0.00; 1029:0.00; 1030:0.00; 1031:0.00
  Agent2 top policies: 1027:0.00; 1028:0.00; 1029:0.00; 1030:0.00; 1031:0.00
. 2 .
. 1 .
. . .

Reward: +1.00, Result: win
Button pressed: blue by Agent 1

Result: ✅ WIN - win (steps: 5, reward: +1.00)

================================================================================
EPISODE 86
================================================================================
Environment: Red at (1, 0), Blue at (1, 1)

Initial state:
1 r .
. b .
. . 2


--- Step 1 ---
Agent 1 joint action: 6 → (DOWN, UP)
Agent 2 joint action: 6 → (DOWN, UP)
Executed: Agent 1: DOWN, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 0:1.00, 8:0.00, 7:0.00
    agent2_pos: 8:1.00, 0:0.00, 7:0.00
    red_button_pos: 7:0.14, 3:0.14, 6:0.14
    blue_button_pos: 7:0.14, 3:0.14, 6:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 0:1.00, 8:0.00, 7:0.00
    agent2_pos: 8:1.00, 0:0.00, 7:0.00
    red_button_pos: 7:0.14, 3:0.14, 6:0.14
    blue_button_pos: 7:0.14, 3:0.14, 6:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 244:0.02; 676:0.02; 316:0.02; 748:0.02; 677:0.01
  Agent2 top policies: 244:0.02; 676:0.02; 316:0.02; 748:0.02; 677:0.01
. r .
1 b 2
. . .

Reward: +0.00, Result: neutral

--- Step 2 ---
Agent 1 joint action: 8 → (DOWN, LEFT)
Agent 2 joint action: 8 → (DOWN, LEFT)
Executed: Agent 1: DOWN, Agent 2: LEFT
  Agent1 beliefs:
    agent1_pos: 3:1.00, 8:0.00, 5:0.00
    agent2_pos: 5:1.00, 8:0.00, 3:0.00
    red_button_pos: 7:0.20, 1:0.20, 6:0.20
    blue_button_pos: 7:0.20, 1:0.20, 6:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 3:1.00, 8:0.00, 5:0.00
    agent2_pos: 5:1.00, 8:0.00, 3:0.00
    red_button_pos: 7:0.20, 1:0.20, 6:0.20
    blue_button_pos: 7:0.20, 1:0.20, 6:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 316:0.05; 676:0.05; 244:0.05; 313:0.02; 243:0.02
  Agent2 top policies: 316:0.05; 676:0.05; 244:0.05; 313:0.02; 243:0.02
. r .
. 2 .
1 . .

Reward: +0.00, Result: neutral

--- Step 3 ---
Agent 1 joint action: 18 → (RIGHT, UP)
Agent 2 joint action: 18 → (RIGHT, UP)
Executed: Agent 1: RIGHT, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 6:1.00, 8:0.00, 5:0.00
    agent2_pos: 4:1.00, 8:0.00, 7:0.00
    red_button_pos: 7:0.33, 1:0.33, 2:0.33
    blue_button_pos: 4:1.00, 1:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 6:1.00, 8:0.00, 5:0.00
    agent2_pos: 4:1.00, 8:0.00, 7:0.00
    red_button_pos: 7:0.33, 1:0.33, 2:0.33
    blue_button_pos: 4:1.00, 1:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 676:0.04; 672:0.03; 675:0.03; 677:0.03; 682:0.03
  Agent2 top policies: 676:0.04; 672:0.03; 675:0.03; 677:0.03; 682:0.03
. 2 .
. b .
. 1 .

Reward: +0.00, Result: neutral

--- Step 4 ---
Agent 1 joint action: 4 → (UP, PRESS)
Agent 2 joint action: 4 → (UP, PRESS)
Executed: Agent 1: UP, Agent 2: PRESS
  Agent1 beliefs:
    agent1_pos: 7:1.00, 8:0.00, 6:0.00
    agent2_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 2:0.00, 7:0.00
    blue_button_pos: 4:1.00, 2:0.00, 6:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 7:1.00, 8:0.00, 6:0.00
    agent2_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 2:0.00, 7:0.00
    blue_button_pos: 4:1.00, 2:0.00, 6:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 169:0.16; 168:0.16; 173:0.16; 172:0.16; 171:0.16
  Agent2 top policies: 169:0.16; 168:0.16; 173:0.16; 172:0.16; 171:0.16
. 2 .
. 1 .
. . .

Reward: +0.00, Result: neutral
Button pressed: red by Agent 2

--- Step 5 ---
Agent 1 joint action: 24 → (PRESS, UP)
Agent 2 joint action: 24 → (PRESS, UP)
Executed: Agent 1: PRESS, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 4:1.00, 8:0.00, 7:0.00
    agent2_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 2:0.00, 7:0.00
    blue_button_pos: 4:1.00, 2:0.00, 6:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 4:1.00, 8:0.00, 7:0.00
    agent2_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 2:0.00, 7:0.00
    blue_button_pos: 4:1.00, 2:0.00, 6:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 1027:0.00; 1028:0.00; 1029:0.00; 1030:0.00; 1031:0.00
  Agent2 top policies: 1027:0.00; 1028:0.00; 1029:0.00; 1030:0.00; 1031:0.00
. 2 .
. 1 .
. . .

Reward: +1.00, Result: win
Button pressed: blue by Agent 1

Result: ✅ WIN - win (steps: 5, reward: +1.00)

================================================================================
EPISODE 87
================================================================================
Environment: Red at (1, 0), Blue at (1, 1)

Initial state:
1 r .
. b .
. . 2


--- Step 1 ---
Agent 1 joint action: 6 → (DOWN, UP)
Agent 2 joint action: 6 → (DOWN, UP)
Executed: Agent 1: DOWN, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 0:1.00, 8:0.00, 7:0.00
    agent2_pos: 8:1.00, 0:0.00, 7:0.00
    red_button_pos: 7:0.14, 3:0.14, 6:0.14
    blue_button_pos: 7:0.14, 3:0.14, 6:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 0:1.00, 8:0.00, 7:0.00
    agent2_pos: 8:1.00, 0:0.00, 7:0.00
    red_button_pos: 7:0.14, 3:0.14, 6:0.14
    blue_button_pos: 7:0.14, 3:0.14, 6:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 244:0.02; 676:0.02; 316:0.02; 748:0.02; 677:0.01
  Agent2 top policies: 244:0.02; 676:0.02; 316:0.02; 748:0.02; 677:0.01
. r .
1 b 2
. . .

Reward: +0.00, Result: neutral

--- Step 2 ---
Agent 1 joint action: 8 → (DOWN, LEFT)
Agent 2 joint action: 8 → (DOWN, LEFT)
Executed: Agent 1: DOWN, Agent 2: LEFT
  Agent1 beliefs:
    agent1_pos: 3:1.00, 8:0.00, 5:0.00
    agent2_pos: 5:1.00, 8:0.00, 3:0.00
    red_button_pos: 7:0.20, 1:0.20, 6:0.20
    blue_button_pos: 7:0.20, 1:0.20, 6:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 3:1.00, 8:0.00, 5:0.00
    agent2_pos: 5:1.00, 8:0.00, 3:0.00
    red_button_pos: 7:0.20, 1:0.20, 6:0.20
    blue_button_pos: 7:0.20, 1:0.20, 6:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 316:0.05; 676:0.05; 244:0.05; 313:0.02; 243:0.02
  Agent2 top policies: 316:0.05; 676:0.05; 244:0.05; 313:0.02; 243:0.02
. r .
. 2 .
1 . .

Reward: +0.00, Result: neutral

--- Step 3 ---
Agent 1 joint action: 18 → (RIGHT, UP)
Agent 2 joint action: 18 → (RIGHT, UP)
Executed: Agent 1: RIGHT, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 6:1.00, 8:0.00, 5:0.00
    agent2_pos: 4:1.00, 8:0.00, 7:0.00
    red_button_pos: 7:0.33, 1:0.33, 2:0.33
    blue_button_pos: 4:1.00, 1:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 6:1.00, 8:0.00, 5:0.00
    agent2_pos: 4:1.00, 8:0.00, 7:0.00
    red_button_pos: 7:0.33, 1:0.33, 2:0.33
    blue_button_pos: 4:1.00, 1:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 676:0.04; 672:0.03; 675:0.03; 677:0.03; 682:0.03
  Agent2 top policies: 676:0.04; 672:0.03; 675:0.03; 677:0.03; 682:0.03
. 2 .
. b .
. 1 .

Reward: +0.00, Result: neutral

--- Step 4 ---
Agent 1 joint action: 4 → (UP, PRESS)
Agent 2 joint action: 4 → (UP, PRESS)
Executed: Agent 1: UP, Agent 2: PRESS
  Agent1 beliefs:
    agent1_pos: 7:1.00, 8:0.00, 6:0.00
    agent2_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 2:0.00, 7:0.00
    blue_button_pos: 4:1.00, 2:0.00, 6:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 7:1.00, 8:0.00, 6:0.00
    agent2_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 2:0.00, 7:0.00
    blue_button_pos: 4:1.00, 2:0.00, 6:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 169:0.16; 168:0.16; 173:0.16; 172:0.16; 171:0.16
  Agent2 top policies: 169:0.16; 168:0.16; 173:0.16; 172:0.16; 171:0.16
. 2 .
. 1 .
. . .

Reward: +0.00, Result: neutral
Button pressed: red by Agent 2

--- Step 5 ---
Agent 1 joint action: 24 → (PRESS, UP)
Agent 2 joint action: 24 → (PRESS, UP)
Executed: Agent 1: PRESS, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 4:1.00, 8:0.00, 7:0.00
    agent2_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 2:0.00, 7:0.00
    blue_button_pos: 4:1.00, 2:0.00, 6:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 4:1.00, 8:0.00, 7:0.00
    agent2_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 2:0.00, 7:0.00
    blue_button_pos: 4:1.00, 2:0.00, 6:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 1027:0.00; 1028:0.00; 1029:0.00; 1030:0.00; 1031:0.00
  Agent2 top policies: 1027:0.00; 1028:0.00; 1029:0.00; 1030:0.00; 1031:0.00
. 2 .
. 1 .
. . .

Reward: +1.00, Result: win
Button pressed: blue by Agent 1

Result: ✅ WIN - win (steps: 5, reward: +1.00)

================================================================================
EPISODE 88
================================================================================
Environment: Red at (1, 0), Blue at (1, 1)

Initial state:
1 r .
. b .
. . 2


--- Step 1 ---
Agent 1 joint action: 6 → (DOWN, UP)
Agent 2 joint action: 6 → (DOWN, UP)
Executed: Agent 1: DOWN, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 0:1.00, 8:0.00, 7:0.00
    agent2_pos: 8:1.00, 0:0.00, 7:0.00
    red_button_pos: 7:0.14, 3:0.14, 6:0.14
    blue_button_pos: 7:0.14, 3:0.14, 6:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 0:1.00, 8:0.00, 7:0.00
    agent2_pos: 8:1.00, 0:0.00, 7:0.00
    red_button_pos: 7:0.14, 3:0.14, 6:0.14
    blue_button_pos: 7:0.14, 3:0.14, 6:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 244:0.02; 676:0.02; 316:0.02; 748:0.02; 677:0.01
  Agent2 top policies: 244:0.02; 676:0.02; 316:0.02; 748:0.02; 677:0.01
. r .
1 b 2
. . .

Reward: +0.00, Result: neutral

--- Step 2 ---
Agent 1 joint action: 8 → (DOWN, LEFT)
Agent 2 joint action: 8 → (DOWN, LEFT)
Executed: Agent 1: DOWN, Agent 2: LEFT
  Agent1 beliefs:
    agent1_pos: 3:1.00, 8:0.00, 5:0.00
    agent2_pos: 5:1.00, 8:0.00, 3:0.00
    red_button_pos: 7:0.20, 1:0.20, 6:0.20
    blue_button_pos: 7:0.20, 1:0.20, 6:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 3:1.00, 8:0.00, 5:0.00
    agent2_pos: 5:1.00, 8:0.00, 3:0.00
    red_button_pos: 7:0.20, 1:0.20, 6:0.20
    blue_button_pos: 7:0.20, 1:0.20, 6:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 316:0.05; 676:0.05; 244:0.05; 313:0.02; 243:0.02
  Agent2 top policies: 316:0.05; 676:0.05; 244:0.05; 313:0.02; 243:0.02
. r .
. 2 .
1 . .

Reward: +0.00, Result: neutral

--- Step 3 ---
Agent 1 joint action: 18 → (RIGHT, UP)
Agent 2 joint action: 18 → (RIGHT, UP)
Executed: Agent 1: RIGHT, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 6:1.00, 8:0.00, 5:0.00
    agent2_pos: 4:1.00, 8:0.00, 7:0.00
    red_button_pos: 7:0.33, 1:0.33, 2:0.33
    blue_button_pos: 4:1.00, 1:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 6:1.00, 8:0.00, 5:0.00
    agent2_pos: 4:1.00, 8:0.00, 7:0.00
    red_button_pos: 7:0.33, 1:0.33, 2:0.33
    blue_button_pos: 4:1.00, 1:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 676:0.04; 672:0.03; 675:0.03; 677:0.03; 682:0.03
  Agent2 top policies: 676:0.04; 672:0.03; 675:0.03; 677:0.03; 682:0.03
. 2 .
. b .
. 1 .

Reward: +0.00, Result: neutral

--- Step 4 ---
Agent 1 joint action: 4 → (UP, PRESS)
Agent 2 joint action: 4 → (UP, PRESS)
Executed: Agent 1: UP, Agent 2: PRESS
  Agent1 beliefs:
    agent1_pos: 7:1.00, 8:0.00, 6:0.00
    agent2_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 2:0.00, 7:0.00
    blue_button_pos: 4:1.00, 2:0.00, 6:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 7:1.00, 8:0.00, 6:0.00
    agent2_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 2:0.00, 7:0.00
    blue_button_pos: 4:1.00, 2:0.00, 6:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 169:0.16; 168:0.16; 173:0.16; 172:0.16; 171:0.16
  Agent2 top policies: 169:0.16; 168:0.16; 173:0.16; 172:0.16; 171:0.16
. 2 .
. 1 .
. . .

Reward: +0.00, Result: neutral
Button pressed: red by Agent 2

--- Step 5 ---
Agent 1 joint action: 24 → (PRESS, UP)
Agent 2 joint action: 24 → (PRESS, UP)
Executed: Agent 1: PRESS, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 4:1.00, 8:0.00, 7:0.00
    agent2_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 2:0.00, 7:0.00
    blue_button_pos: 4:1.00, 2:0.00, 6:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 4:1.00, 8:0.00, 7:0.00
    agent2_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 2:0.00, 7:0.00
    blue_button_pos: 4:1.00, 2:0.00, 6:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 1027:0.00; 1028:0.00; 1029:0.00; 1030:0.00; 1031:0.00
  Agent2 top policies: 1027:0.00; 1028:0.00; 1029:0.00; 1030:0.00; 1031:0.00
. 2 .
. 1 .
. . .

Reward: +1.00, Result: win
Button pressed: blue by Agent 1

Result: ✅ WIN - win (steps: 5, reward: +1.00)

================================================================================
EPISODE 89
================================================================================
Environment: Red at (1, 0), Blue at (1, 1)

Initial state:
1 r .
. b .
. . 2


--- Step 1 ---
Agent 1 joint action: 6 → (DOWN, UP)
Agent 2 joint action: 6 → (DOWN, UP)
Executed: Agent 1: DOWN, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 0:1.00, 8:0.00, 7:0.00
    agent2_pos: 8:1.00, 0:0.00, 7:0.00
    red_button_pos: 7:0.14, 3:0.14, 6:0.14
    blue_button_pos: 7:0.14, 3:0.14, 6:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 0:1.00, 8:0.00, 7:0.00
    agent2_pos: 8:1.00, 0:0.00, 7:0.00
    red_button_pos: 7:0.14, 3:0.14, 6:0.14
    blue_button_pos: 7:0.14, 3:0.14, 6:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 244:0.02; 676:0.02; 316:0.02; 748:0.02; 677:0.01
  Agent2 top policies: 244:0.02; 676:0.02; 316:0.02; 748:0.02; 677:0.01
. r .
1 b 2
. . .

Reward: +0.00, Result: neutral

--- Step 2 ---
Agent 1 joint action: 8 → (DOWN, LEFT)
Agent 2 joint action: 8 → (DOWN, LEFT)
Executed: Agent 1: DOWN, Agent 2: LEFT
  Agent1 beliefs:
    agent1_pos: 3:1.00, 8:0.00, 5:0.00
    agent2_pos: 5:1.00, 8:0.00, 3:0.00
    red_button_pos: 7:0.20, 1:0.20, 6:0.20
    blue_button_pos: 7:0.20, 1:0.20, 6:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 3:1.00, 8:0.00, 5:0.00
    agent2_pos: 5:1.00, 8:0.00, 3:0.00
    red_button_pos: 7:0.20, 1:0.20, 6:0.20
    blue_button_pos: 7:0.20, 1:0.20, 6:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 316:0.05; 676:0.05; 244:0.05; 313:0.02; 243:0.02
  Agent2 top policies: 316:0.05; 676:0.05; 244:0.05; 313:0.02; 243:0.02
. r .
. 2 .
1 . .

Reward: +0.00, Result: neutral

--- Step 3 ---
Agent 1 joint action: 18 → (RIGHT, UP)
Agent 2 joint action: 18 → (RIGHT, UP)
Executed: Agent 1: RIGHT, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 6:1.00, 8:0.00, 5:0.00
    agent2_pos: 4:1.00, 8:0.00, 7:0.00
    red_button_pos: 7:0.33, 1:0.33, 2:0.33
    blue_button_pos: 4:1.00, 1:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 6:1.00, 8:0.00, 5:0.00
    agent2_pos: 4:1.00, 8:0.00, 7:0.00
    red_button_pos: 7:0.33, 1:0.33, 2:0.33
    blue_button_pos: 4:1.00, 1:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 676:0.04; 672:0.03; 675:0.03; 677:0.03; 682:0.03
  Agent2 top policies: 676:0.04; 672:0.03; 675:0.03; 677:0.03; 682:0.03
. 2 .
. b .
. 1 .

Reward: +0.00, Result: neutral

--- Step 4 ---
Agent 1 joint action: 4 → (UP, PRESS)
Agent 2 joint action: 4 → (UP, PRESS)
Executed: Agent 1: UP, Agent 2: PRESS
  Agent1 beliefs:
    agent1_pos: 7:1.00, 8:0.00, 6:0.00
    agent2_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 2:0.00, 7:0.00
    blue_button_pos: 4:1.00, 2:0.00, 6:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 7:1.00, 8:0.00, 6:0.00
    agent2_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 2:0.00, 7:0.00
    blue_button_pos: 4:1.00, 2:0.00, 6:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 169:0.16; 168:0.16; 173:0.16; 172:0.16; 171:0.16
  Agent2 top policies: 169:0.16; 168:0.16; 173:0.16; 172:0.16; 171:0.16
. 2 .
. 1 .
. . .

Reward: +0.00, Result: neutral
Button pressed: red by Agent 2

--- Step 5 ---
Agent 1 joint action: 24 → (PRESS, UP)
Agent 2 joint action: 24 → (PRESS, UP)
Executed: Agent 1: PRESS, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 4:1.00, 8:0.00, 7:0.00
    agent2_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 2:0.00, 7:0.00
    blue_button_pos: 4:1.00, 2:0.00, 6:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 4:1.00, 8:0.00, 7:0.00
    agent2_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 2:0.00, 7:0.00
    blue_button_pos: 4:1.00, 2:0.00, 6:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 1027:0.00; 1028:0.00; 1029:0.00; 1030:0.00; 1031:0.00
  Agent2 top policies: 1027:0.00; 1028:0.00; 1029:0.00; 1030:0.00; 1031:0.00
. 2 .
. 1 .
. . .

Reward: +1.00, Result: win
Button pressed: blue by Agent 1

Result: ✅ WIN - win (steps: 5, reward: +1.00)

================================================================================
EPISODE 90
================================================================================
Environment: Red at (1, 0), Blue at (1, 1)

Initial state:
1 r .
. b .
. . 2


--- Step 1 ---
Agent 1 joint action: 6 → (DOWN, UP)
Agent 2 joint action: 6 → (DOWN, UP)
Executed: Agent 1: DOWN, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 0:1.00, 8:0.00, 7:0.00
    agent2_pos: 8:1.00, 0:0.00, 7:0.00
    red_button_pos: 7:0.14, 3:0.14, 6:0.14
    blue_button_pos: 7:0.14, 3:0.14, 6:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 0:1.00, 8:0.00, 7:0.00
    agent2_pos: 8:1.00, 0:0.00, 7:0.00
    red_button_pos: 7:0.14, 3:0.14, 6:0.14
    blue_button_pos: 7:0.14, 3:0.14, 6:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 244:0.02; 676:0.02; 316:0.02; 748:0.02; 677:0.01
  Agent2 top policies: 244:0.02; 676:0.02; 316:0.02; 748:0.02; 677:0.01
. r .
1 b 2
. . .

Reward: +0.00, Result: neutral

--- Step 2 ---
Agent 1 joint action: 8 → (DOWN, LEFT)
Agent 2 joint action: 8 → (DOWN, LEFT)
Executed: Agent 1: DOWN, Agent 2: LEFT
  Agent1 beliefs:
    agent1_pos: 3:1.00, 8:0.00, 5:0.00
    agent2_pos: 5:1.00, 8:0.00, 3:0.00
    red_button_pos: 7:0.20, 1:0.20, 6:0.20
    blue_button_pos: 7:0.20, 1:0.20, 6:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 3:1.00, 8:0.00, 5:0.00
    agent2_pos: 5:1.00, 8:0.00, 3:0.00
    red_button_pos: 7:0.20, 1:0.20, 6:0.20
    blue_button_pos: 7:0.20, 1:0.20, 6:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 316:0.05; 676:0.05; 244:0.05; 313:0.02; 243:0.02
  Agent2 top policies: 316:0.05; 676:0.05; 244:0.05; 313:0.02; 243:0.02
. r .
. 2 .
1 . .

Reward: +0.00, Result: neutral

--- Step 3 ---
Agent 1 joint action: 18 → (RIGHT, UP)
Agent 2 joint action: 18 → (RIGHT, UP)
Executed: Agent 1: RIGHT, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 6:1.00, 8:0.00, 5:0.00
    agent2_pos: 4:1.00, 8:0.00, 7:0.00
    red_button_pos: 7:0.33, 1:0.33, 2:0.33
    blue_button_pos: 4:1.00, 1:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 6:1.00, 8:0.00, 5:0.00
    agent2_pos: 4:1.00, 8:0.00, 7:0.00
    red_button_pos: 7:0.33, 1:0.33, 2:0.33
    blue_button_pos: 4:1.00, 1:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 676:0.04; 672:0.03; 675:0.03; 677:0.03; 682:0.03
  Agent2 top policies: 676:0.04; 672:0.03; 675:0.03; 677:0.03; 682:0.03
. 2 .
. b .
. 1 .

Reward: +0.00, Result: neutral

--- Step 4 ---
Agent 1 joint action: 4 → (UP, PRESS)
Agent 2 joint action: 4 → (UP, PRESS)
Executed: Agent 1: UP, Agent 2: PRESS
  Agent1 beliefs:
    agent1_pos: 7:1.00, 8:0.00, 6:0.00
    agent2_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 2:0.00, 7:0.00
    blue_button_pos: 4:1.00, 2:0.00, 6:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 7:1.00, 8:0.00, 6:0.00
    agent2_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 2:0.00, 7:0.00
    blue_button_pos: 4:1.00, 2:0.00, 6:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 169:0.16; 168:0.16; 173:0.16; 172:0.16; 171:0.16
  Agent2 top policies: 169:0.16; 168:0.16; 173:0.16; 172:0.16; 171:0.16
. 2 .
. 1 .
. . .

Reward: +0.00, Result: neutral
Button pressed: red by Agent 2

--- Step 5 ---
Agent 1 joint action: 24 → (PRESS, UP)
Agent 2 joint action: 24 → (PRESS, UP)
Executed: Agent 1: PRESS, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 4:1.00, 8:0.00, 7:0.00
    agent2_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 2:0.00, 7:0.00
    blue_button_pos: 4:1.00, 2:0.00, 6:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 4:1.00, 8:0.00, 7:0.00
    agent2_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 2:0.00, 7:0.00
    blue_button_pos: 4:1.00, 2:0.00, 6:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 1027:0.00; 1028:0.00; 1029:0.00; 1030:0.00; 1031:0.00
  Agent2 top policies: 1027:0.00; 1028:0.00; 1029:0.00; 1030:0.00; 1031:0.00
. 2 .
. 1 .
. . .

Reward: +1.00, Result: win
Button pressed: blue by Agent 1

Result: ✅ WIN - win (steps: 5, reward: +1.00)

================================================================================
EPISODE 91
================================================================================
Environment: Red at (1, 0), Blue at (1, 1)

Initial state:
1 r .
. b .
. . 2


--- Step 1 ---
Agent 1 joint action: 6 → (DOWN, UP)
Agent 2 joint action: 6 → (DOWN, UP)
Executed: Agent 1: DOWN, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 0:1.00, 8:0.00, 7:0.00
    agent2_pos: 8:1.00, 0:0.00, 7:0.00
    red_button_pos: 7:0.14, 3:0.14, 6:0.14
    blue_button_pos: 7:0.14, 3:0.14, 6:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 0:1.00, 8:0.00, 7:0.00
    agent2_pos: 8:1.00, 0:0.00, 7:0.00
    red_button_pos: 7:0.14, 3:0.14, 6:0.14
    blue_button_pos: 7:0.14, 3:0.14, 6:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 244:0.02; 676:0.02; 316:0.02; 748:0.02; 677:0.01
  Agent2 top policies: 244:0.02; 676:0.02; 316:0.02; 748:0.02; 677:0.01
. r .
1 b 2
. . .

Reward: +0.00, Result: neutral

--- Step 2 ---
Agent 1 joint action: 8 → (DOWN, LEFT)
Agent 2 joint action: 8 → (DOWN, LEFT)
Executed: Agent 1: DOWN, Agent 2: LEFT
  Agent1 beliefs:
    agent1_pos: 3:1.00, 8:0.00, 5:0.00
    agent2_pos: 5:1.00, 8:0.00, 3:0.00
    red_button_pos: 7:0.20, 1:0.20, 6:0.20
    blue_button_pos: 7:0.20, 1:0.20, 6:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 3:1.00, 8:0.00, 5:0.00
    agent2_pos: 5:1.00, 8:0.00, 3:0.00
    red_button_pos: 7:0.20, 1:0.20, 6:0.20
    blue_button_pos: 7:0.20, 1:0.20, 6:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 316:0.05; 676:0.05; 244:0.05; 313:0.02; 243:0.02
  Agent2 top policies: 316:0.05; 676:0.05; 244:0.05; 313:0.02; 243:0.02
. r .
. 2 .
1 . .

Reward: +0.00, Result: neutral

--- Step 3 ---
Agent 1 joint action: 18 → (RIGHT, UP)
Agent 2 joint action: 18 → (RIGHT, UP)
Executed: Agent 1: RIGHT, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 6:1.00, 8:0.00, 5:0.00
    agent2_pos: 4:1.00, 8:0.00, 7:0.00
    red_button_pos: 7:0.33, 1:0.33, 2:0.33
    blue_button_pos: 4:1.00, 1:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 6:1.00, 8:0.00, 5:0.00
    agent2_pos: 4:1.00, 8:0.00, 7:0.00
    red_button_pos: 7:0.33, 1:0.33, 2:0.33
    blue_button_pos: 4:1.00, 1:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 676:0.04; 672:0.03; 675:0.03; 677:0.03; 682:0.03
  Agent2 top policies: 676:0.04; 672:0.03; 675:0.03; 677:0.03; 682:0.03
. 2 .
. b .
. 1 .

Reward: +0.00, Result: neutral

--- Step 4 ---
Agent 1 joint action: 4 → (UP, PRESS)
Agent 2 joint action: 4 → (UP, PRESS)
Executed: Agent 1: UP, Agent 2: PRESS
  Agent1 beliefs:
    agent1_pos: 7:1.00, 8:0.00, 6:0.00
    agent2_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 2:0.00, 7:0.00
    blue_button_pos: 4:1.00, 2:0.00, 6:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 7:1.00, 8:0.00, 6:0.00
    agent2_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 2:0.00, 7:0.00
    blue_button_pos: 4:1.00, 2:0.00, 6:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 169:0.16; 168:0.16; 173:0.16; 172:0.16; 171:0.16
  Agent2 top policies: 169:0.16; 168:0.16; 173:0.16; 172:0.16; 171:0.16
. 2 .
. 1 .
. . .

Reward: +0.00, Result: neutral
Button pressed: red by Agent 2

--- Step 5 ---
Agent 1 joint action: 24 → (PRESS, UP)
Agent 2 joint action: 24 → (PRESS, UP)
Executed: Agent 1: PRESS, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 4:1.00, 8:0.00, 7:0.00
    agent2_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 2:0.00, 7:0.00
    blue_button_pos: 4:1.00, 2:0.00, 6:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 4:1.00, 8:0.00, 7:0.00
    agent2_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 2:0.00, 7:0.00
    blue_button_pos: 4:1.00, 2:0.00, 6:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 1027:0.00; 1028:0.00; 1029:0.00; 1030:0.00; 1031:0.00
  Agent2 top policies: 1027:0.00; 1028:0.00; 1029:0.00; 1030:0.00; 1031:0.00
. 2 .
. 1 .
. . .

Reward: +1.00, Result: win
Button pressed: blue by Agent 1

Result: ✅ WIN - win (steps: 5, reward: +1.00)

================================================================================
EPISODE 92
================================================================================
Environment: Red at (1, 0), Blue at (1, 1)

Initial state:
1 r .
. b .
. . 2


--- Step 1 ---
Agent 1 joint action: 6 → (DOWN, UP)
Agent 2 joint action: 6 → (DOWN, UP)
Executed: Agent 1: DOWN, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 0:1.00, 8:0.00, 7:0.00
    agent2_pos: 8:1.00, 0:0.00, 7:0.00
    red_button_pos: 7:0.14, 3:0.14, 6:0.14
    blue_button_pos: 7:0.14, 3:0.14, 6:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 0:1.00, 8:0.00, 7:0.00
    agent2_pos: 8:1.00, 0:0.00, 7:0.00
    red_button_pos: 7:0.14, 3:0.14, 6:0.14
    blue_button_pos: 7:0.14, 3:0.14, 6:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 244:0.02; 676:0.02; 316:0.02; 748:0.02; 677:0.01
  Agent2 top policies: 244:0.02; 676:0.02; 316:0.02; 748:0.02; 677:0.01
. r .
1 b 2
. . .

Reward: +0.00, Result: neutral

--- Step 2 ---
Agent 1 joint action: 8 → (DOWN, LEFT)
Agent 2 joint action: 8 → (DOWN, LEFT)
Executed: Agent 1: DOWN, Agent 2: LEFT
  Agent1 beliefs:
    agent1_pos: 3:1.00, 8:0.00, 5:0.00
    agent2_pos: 5:1.00, 8:0.00, 3:0.00
    red_button_pos: 7:0.20, 1:0.20, 6:0.20
    blue_button_pos: 7:0.20, 1:0.20, 6:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 3:1.00, 8:0.00, 5:0.00
    agent2_pos: 5:1.00, 8:0.00, 3:0.00
    red_button_pos: 7:0.20, 1:0.20, 6:0.20
    blue_button_pos: 7:0.20, 1:0.20, 6:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 316:0.05; 676:0.05; 244:0.05; 313:0.02; 243:0.02
  Agent2 top policies: 316:0.05; 676:0.05; 244:0.05; 313:0.02; 243:0.02
. r .
. 2 .
1 . .

Reward: +0.00, Result: neutral

--- Step 3 ---
Agent 1 joint action: 18 → (RIGHT, UP)
Agent 2 joint action: 18 → (RIGHT, UP)
Executed: Agent 1: RIGHT, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 6:1.00, 8:0.00, 5:0.00
    agent2_pos: 4:1.00, 8:0.00, 7:0.00
    red_button_pos: 7:0.33, 1:0.33, 2:0.33
    blue_button_pos: 4:1.00, 1:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 6:1.00, 8:0.00, 5:0.00
    agent2_pos: 4:1.00, 8:0.00, 7:0.00
    red_button_pos: 7:0.33, 1:0.33, 2:0.33
    blue_button_pos: 4:1.00, 1:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 676:0.04; 672:0.03; 675:0.03; 677:0.03; 682:0.03
  Agent2 top policies: 676:0.04; 672:0.03; 675:0.03; 677:0.03; 682:0.03
. 2 .
. b .
. 1 .

Reward: +0.00, Result: neutral

--- Step 4 ---
Agent 1 joint action: 4 → (UP, PRESS)
Agent 2 joint action: 4 → (UP, PRESS)
Executed: Agent 1: UP, Agent 2: PRESS
  Agent1 beliefs:
    agent1_pos: 7:1.00, 8:0.00, 6:0.00
    agent2_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 2:0.00, 7:0.00
    blue_button_pos: 4:1.00, 2:0.00, 6:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 7:1.00, 8:0.00, 6:0.00
    agent2_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 2:0.00, 7:0.00
    blue_button_pos: 4:1.00, 2:0.00, 6:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 169:0.16; 168:0.16; 173:0.16; 172:0.16; 171:0.16
  Agent2 top policies: 169:0.16; 168:0.16; 173:0.16; 172:0.16; 171:0.16
. 2 .
. 1 .
. . .

Reward: +0.00, Result: neutral
Button pressed: red by Agent 2

--- Step 5 ---
Agent 1 joint action: 24 → (PRESS, UP)
Agent 2 joint action: 24 → (PRESS, UP)
Executed: Agent 1: PRESS, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 4:1.00, 8:0.00, 7:0.00
    agent2_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 2:0.00, 7:0.00
    blue_button_pos: 4:1.00, 2:0.00, 6:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 4:1.00, 8:0.00, 7:0.00
    agent2_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 2:0.00, 7:0.00
    blue_button_pos: 4:1.00, 2:0.00, 6:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 1027:0.00; 1028:0.00; 1029:0.00; 1030:0.00; 1031:0.00
  Agent2 top policies: 1027:0.00; 1028:0.00; 1029:0.00; 1030:0.00; 1031:0.00
. 2 .
. 1 .
. . .

Reward: +1.00, Result: win
Button pressed: blue by Agent 1

Result: ✅ WIN - win (steps: 5, reward: +1.00)

================================================================================
EPISODE 93
================================================================================
Environment: Red at (1, 0), Blue at (1, 1)

Initial state:
1 r .
. b .
. . 2


--- Step 1 ---
Agent 1 joint action: 6 → (DOWN, UP)
Agent 2 joint action: 6 → (DOWN, UP)
Executed: Agent 1: DOWN, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 0:1.00, 8:0.00, 7:0.00
    agent2_pos: 8:1.00, 0:0.00, 7:0.00
    red_button_pos: 7:0.14, 3:0.14, 6:0.14
    blue_button_pos: 7:0.14, 3:0.14, 6:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 0:1.00, 8:0.00, 7:0.00
    agent2_pos: 8:1.00, 0:0.00, 7:0.00
    red_button_pos: 7:0.14, 3:0.14, 6:0.14
    blue_button_pos: 7:0.14, 3:0.14, 6:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 244:0.02; 676:0.02; 316:0.02; 748:0.02; 677:0.01
  Agent2 top policies: 244:0.02; 676:0.02; 316:0.02; 748:0.02; 677:0.01
. r .
1 b 2
. . .

Reward: +0.00, Result: neutral

--- Step 2 ---
Agent 1 joint action: 8 → (DOWN, LEFT)
Agent 2 joint action: 8 → (DOWN, LEFT)
Executed: Agent 1: DOWN, Agent 2: LEFT
  Agent1 beliefs:
    agent1_pos: 3:1.00, 8:0.00, 5:0.00
    agent2_pos: 5:1.00, 8:0.00, 3:0.00
    red_button_pos: 7:0.20, 1:0.20, 6:0.20
    blue_button_pos: 7:0.20, 1:0.20, 6:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 3:1.00, 8:0.00, 5:0.00
    agent2_pos: 5:1.00, 8:0.00, 3:0.00
    red_button_pos: 7:0.20, 1:0.20, 6:0.20
    blue_button_pos: 7:0.20, 1:0.20, 6:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 316:0.05; 676:0.05; 244:0.05; 313:0.02; 243:0.02
  Agent2 top policies: 316:0.05; 676:0.05; 244:0.05; 313:0.02; 243:0.02
. r .
. 2 .
1 . .

Reward: +0.00, Result: neutral

--- Step 3 ---
Agent 1 joint action: 18 → (RIGHT, UP)
Agent 2 joint action: 18 → (RIGHT, UP)
Executed: Agent 1: RIGHT, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 6:1.00, 8:0.00, 5:0.00
    agent2_pos: 4:1.00, 8:0.00, 7:0.00
    red_button_pos: 7:0.33, 1:0.33, 2:0.33
    blue_button_pos: 4:1.00, 1:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 6:1.00, 8:0.00, 5:0.00
    agent2_pos: 4:1.00, 8:0.00, 7:0.00
    red_button_pos: 7:0.33, 1:0.33, 2:0.33
    blue_button_pos: 4:1.00, 1:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 676:0.04; 672:0.03; 675:0.03; 677:0.03; 682:0.03
  Agent2 top policies: 676:0.04; 672:0.03; 675:0.03; 677:0.03; 682:0.03
. 2 .
. b .
. 1 .

Reward: +0.00, Result: neutral

--- Step 4 ---
Agent 1 joint action: 4 → (UP, PRESS)
Agent 2 joint action: 4 → (UP, PRESS)
Executed: Agent 1: UP, Agent 2: PRESS
  Agent1 beliefs:
    agent1_pos: 7:1.00, 8:0.00, 6:0.00
    agent2_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 2:0.00, 7:0.00
    blue_button_pos: 4:1.00, 2:0.00, 6:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 7:1.00, 8:0.00, 6:0.00
    agent2_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 2:0.00, 7:0.00
    blue_button_pos: 4:1.00, 2:0.00, 6:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 169:0.16; 168:0.16; 173:0.16; 172:0.16; 171:0.16
  Agent2 top policies: 169:0.16; 168:0.16; 173:0.16; 172:0.16; 171:0.16
. 2 .
. 1 .
. . .

Reward: +0.00, Result: neutral
Button pressed: red by Agent 2

--- Step 5 ---
Agent 1 joint action: 24 → (PRESS, UP)
Agent 2 joint action: 24 → (PRESS, UP)
Executed: Agent 1: PRESS, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 4:1.00, 8:0.00, 7:0.00
    agent2_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 2:0.00, 7:0.00
    blue_button_pos: 4:1.00, 2:0.00, 6:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 4:1.00, 8:0.00, 7:0.00
    agent2_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 2:0.00, 7:0.00
    blue_button_pos: 4:1.00, 2:0.00, 6:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 1027:0.00; 1028:0.00; 1029:0.00; 1030:0.00; 1031:0.00
  Agent2 top policies: 1027:0.00; 1028:0.00; 1029:0.00; 1030:0.00; 1031:0.00
. 2 .
. 1 .
. . .

Reward: +1.00, Result: win
Button pressed: blue by Agent 1

Result: ✅ WIN - win (steps: 5, reward: +1.00)

================================================================================
EPISODE 94
================================================================================
Environment: Red at (1, 0), Blue at (1, 1)

Initial state:
1 r .
. b .
. . 2


--- Step 1 ---
Agent 1 joint action: 6 → (DOWN, UP)
Agent 2 joint action: 6 → (DOWN, UP)
Executed: Agent 1: DOWN, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 0:1.00, 8:0.00, 7:0.00
    agent2_pos: 8:1.00, 0:0.00, 7:0.00
    red_button_pos: 7:0.14, 3:0.14, 6:0.14
    blue_button_pos: 7:0.14, 3:0.14, 6:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 0:1.00, 8:0.00, 7:0.00
    agent2_pos: 8:1.00, 0:0.00, 7:0.00
    red_button_pos: 7:0.14, 3:0.14, 6:0.14
    blue_button_pos: 7:0.14, 3:0.14, 6:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 244:0.02; 676:0.02; 316:0.02; 748:0.02; 677:0.01
  Agent2 top policies: 244:0.02; 676:0.02; 316:0.02; 748:0.02; 677:0.01
. r .
1 b 2
. . .

Reward: +0.00, Result: neutral

--- Step 2 ---
Agent 1 joint action: 8 → (DOWN, LEFT)
Agent 2 joint action: 8 → (DOWN, LEFT)
Executed: Agent 1: DOWN, Agent 2: LEFT
  Agent1 beliefs:
    agent1_pos: 3:1.00, 8:0.00, 5:0.00
    agent2_pos: 5:1.00, 8:0.00, 3:0.00
    red_button_pos: 7:0.20, 1:0.20, 6:0.20
    blue_button_pos: 7:0.20, 1:0.20, 6:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 3:1.00, 8:0.00, 5:0.00
    agent2_pos: 5:1.00, 8:0.00, 3:0.00
    red_button_pos: 7:0.20, 1:0.20, 6:0.20
    blue_button_pos: 7:0.20, 1:0.20, 6:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 316:0.05; 676:0.05; 244:0.05; 313:0.02; 243:0.02
  Agent2 top policies: 316:0.05; 676:0.05; 244:0.05; 313:0.02; 243:0.02
. r .
. 2 .
1 . .

Reward: +0.00, Result: neutral

--- Step 3 ---
Agent 1 joint action: 18 → (RIGHT, UP)
Agent 2 joint action: 18 → (RIGHT, UP)
Executed: Agent 1: RIGHT, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 6:1.00, 8:0.00, 5:0.00
    agent2_pos: 4:1.00, 8:0.00, 7:0.00
    red_button_pos: 7:0.33, 1:0.33, 2:0.33
    blue_button_pos: 4:1.00, 1:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 6:1.00, 8:0.00, 5:0.00
    agent2_pos: 4:1.00, 8:0.00, 7:0.00
    red_button_pos: 7:0.33, 1:0.33, 2:0.33
    blue_button_pos: 4:1.00, 1:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 676:0.04; 672:0.03; 675:0.03; 677:0.03; 682:0.03
  Agent2 top policies: 676:0.04; 672:0.03; 675:0.03; 677:0.03; 682:0.03
. 2 .
. b .
. 1 .

Reward: +0.00, Result: neutral

--- Step 4 ---
Agent 1 joint action: 4 → (UP, PRESS)
Agent 2 joint action: 4 → (UP, PRESS)
Executed: Agent 1: UP, Agent 2: PRESS
  Agent1 beliefs:
    agent1_pos: 7:1.00, 8:0.00, 6:0.00
    agent2_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 2:0.00, 7:0.00
    blue_button_pos: 4:1.00, 2:0.00, 6:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 7:1.00, 8:0.00, 6:0.00
    agent2_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 2:0.00, 7:0.00
    blue_button_pos: 4:1.00, 2:0.00, 6:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 169:0.16; 168:0.16; 173:0.16; 172:0.16; 171:0.16
  Agent2 top policies: 169:0.16; 168:0.16; 173:0.16; 172:0.16; 171:0.16
. 2 .
. 1 .
. . .

Reward: +0.00, Result: neutral
Button pressed: red by Agent 2

--- Step 5 ---
Agent 1 joint action: 24 → (PRESS, UP)
Agent 2 joint action: 24 → (PRESS, UP)
Executed: Agent 1: PRESS, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 4:1.00, 8:0.00, 7:0.00
    agent2_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 2:0.00, 7:0.00
    blue_button_pos: 4:1.00, 2:0.00, 6:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 4:1.00, 8:0.00, 7:0.00
    agent2_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 2:0.00, 7:0.00
    blue_button_pos: 4:1.00, 2:0.00, 6:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 1027:0.00; 1028:0.00; 1029:0.00; 1030:0.00; 1031:0.00
  Agent2 top policies: 1027:0.00; 1028:0.00; 1029:0.00; 1030:0.00; 1031:0.00
. 2 .
. 1 .
. . .

Reward: +1.00, Result: win
Button pressed: blue by Agent 1

Result: ✅ WIN - win (steps: 5, reward: +1.00)

================================================================================
EPISODE 95
================================================================================
Environment: Red at (1, 0), Blue at (1, 1)

Initial state:
1 r .
. b .
. . 2


--- Step 1 ---
Agent 1 joint action: 6 → (DOWN, UP)
Agent 2 joint action: 6 → (DOWN, UP)
Executed: Agent 1: DOWN, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 0:1.00, 8:0.00, 7:0.00
    agent2_pos: 8:1.00, 0:0.00, 7:0.00
    red_button_pos: 7:0.14, 3:0.14, 6:0.14
    blue_button_pos: 7:0.14, 3:0.14, 6:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 0:1.00, 8:0.00, 7:0.00
    agent2_pos: 8:1.00, 0:0.00, 7:0.00
    red_button_pos: 7:0.14, 3:0.14, 6:0.14
    blue_button_pos: 7:0.14, 3:0.14, 6:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 244:0.02; 676:0.02; 316:0.02; 748:0.02; 677:0.01
  Agent2 top policies: 244:0.02; 676:0.02; 316:0.02; 748:0.02; 677:0.01
. r .
1 b 2
. . .

Reward: +0.00, Result: neutral

--- Step 2 ---
Agent 1 joint action: 8 → (DOWN, LEFT)
Agent 2 joint action: 8 → (DOWN, LEFT)
Executed: Agent 1: DOWN, Agent 2: LEFT
  Agent1 beliefs:
    agent1_pos: 3:1.00, 8:0.00, 5:0.00
    agent2_pos: 5:1.00, 8:0.00, 3:0.00
    red_button_pos: 7:0.20, 1:0.20, 6:0.20
    blue_button_pos: 7:0.20, 1:0.20, 6:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 3:1.00, 8:0.00, 5:0.00
    agent2_pos: 5:1.00, 8:0.00, 3:0.00
    red_button_pos: 7:0.20, 1:0.20, 6:0.20
    blue_button_pos: 7:0.20, 1:0.20, 6:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 316:0.05; 676:0.05; 244:0.05; 313:0.02; 243:0.02
  Agent2 top policies: 316:0.05; 676:0.05; 244:0.05; 313:0.02; 243:0.02
. r .
. 2 .
1 . .

Reward: +0.00, Result: neutral

--- Step 3 ---
Agent 1 joint action: 18 → (RIGHT, UP)
Agent 2 joint action: 18 → (RIGHT, UP)
Executed: Agent 1: RIGHT, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 6:1.00, 8:0.00, 5:0.00
    agent2_pos: 4:1.00, 8:0.00, 7:0.00
    red_button_pos: 7:0.33, 1:0.33, 2:0.33
    blue_button_pos: 4:1.00, 1:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 6:1.00, 8:0.00, 5:0.00
    agent2_pos: 4:1.00, 8:0.00, 7:0.00
    red_button_pos: 7:0.33, 1:0.33, 2:0.33
    blue_button_pos: 4:1.00, 1:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 676:0.04; 672:0.03; 675:0.03; 677:0.03; 682:0.03
  Agent2 top policies: 676:0.04; 672:0.03; 675:0.03; 677:0.03; 682:0.03
. 2 .
. b .
. 1 .

Reward: +0.00, Result: neutral

--- Step 4 ---
Agent 1 joint action: 4 → (UP, PRESS)
Agent 2 joint action: 4 → (UP, PRESS)
Executed: Agent 1: UP, Agent 2: PRESS
  Agent1 beliefs:
    agent1_pos: 7:1.00, 8:0.00, 6:0.00
    agent2_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 2:0.00, 7:0.00
    blue_button_pos: 4:1.00, 2:0.00, 6:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 7:1.00, 8:0.00, 6:0.00
    agent2_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 2:0.00, 7:0.00
    blue_button_pos: 4:1.00, 2:0.00, 6:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 169:0.16; 168:0.16; 173:0.16; 172:0.16; 171:0.16
  Agent2 top policies: 169:0.16; 168:0.16; 173:0.16; 172:0.16; 171:0.16
. 2 .
. 1 .
. . .

Reward: +0.00, Result: neutral
Button pressed: red by Agent 2

--- Step 5 ---
Agent 1 joint action: 24 → (PRESS, UP)
Agent 2 joint action: 24 → (PRESS, UP)
Executed: Agent 1: PRESS, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 4:1.00, 8:0.00, 7:0.00
    agent2_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 2:0.00, 7:0.00
    blue_button_pos: 4:1.00, 2:0.00, 6:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 4:1.00, 8:0.00, 7:0.00
    agent2_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 2:0.00, 7:0.00
    blue_button_pos: 4:1.00, 2:0.00, 6:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 1027:0.00; 1028:0.00; 1029:0.00; 1030:0.00; 1031:0.00
  Agent2 top policies: 1027:0.00; 1028:0.00; 1029:0.00; 1030:0.00; 1031:0.00
. 2 .
. 1 .
. . .

Reward: +1.00, Result: win
Button pressed: blue by Agent 1

Result: ✅ WIN - win (steps: 5, reward: +1.00)

================================================================================
EPISODE 96
================================================================================
Environment: Red at (1, 0), Blue at (1, 1)

Initial state:
1 r .
. b .
. . 2


--- Step 1 ---
Agent 1 joint action: 6 → (DOWN, UP)
Agent 2 joint action: 6 → (DOWN, UP)
Executed: Agent 1: DOWN, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 0:1.00, 8:0.00, 7:0.00
    agent2_pos: 8:1.00, 0:0.00, 7:0.00
    red_button_pos: 7:0.14, 3:0.14, 6:0.14
    blue_button_pos: 7:0.14, 3:0.14, 6:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 0:1.00, 8:0.00, 7:0.00
    agent2_pos: 8:1.00, 0:0.00, 7:0.00
    red_button_pos: 7:0.14, 3:0.14, 6:0.14
    blue_button_pos: 7:0.14, 3:0.14, 6:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 244:0.02; 676:0.02; 316:0.02; 748:0.02; 677:0.01
  Agent2 top policies: 244:0.02; 676:0.02; 316:0.02; 748:0.02; 677:0.01
. r .
1 b 2
. . .

Reward: +0.00, Result: neutral

--- Step 2 ---
Agent 1 joint action: 8 → (DOWN, LEFT)
Agent 2 joint action: 8 → (DOWN, LEFT)
Executed: Agent 1: DOWN, Agent 2: LEFT
  Agent1 beliefs:
    agent1_pos: 3:1.00, 8:0.00, 5:0.00
    agent2_pos: 5:1.00, 8:0.00, 3:0.00
    red_button_pos: 7:0.20, 1:0.20, 6:0.20
    blue_button_pos: 7:0.20, 1:0.20, 6:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 3:1.00, 8:0.00, 5:0.00
    agent2_pos: 5:1.00, 8:0.00, 3:0.00
    red_button_pos: 7:0.20, 1:0.20, 6:0.20
    blue_button_pos: 7:0.20, 1:0.20, 6:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 316:0.05; 676:0.05; 244:0.05; 313:0.02; 243:0.02
  Agent2 top policies: 316:0.05; 676:0.05; 244:0.05; 313:0.02; 243:0.02
. r .
. 2 .
1 . .

Reward: +0.00, Result: neutral

--- Step 3 ---
Agent 1 joint action: 18 → (RIGHT, UP)
Agent 2 joint action: 18 → (RIGHT, UP)
Executed: Agent 1: RIGHT, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 6:1.00, 8:0.00, 5:0.00
    agent2_pos: 4:1.00, 8:0.00, 7:0.00
    red_button_pos: 7:0.33, 1:0.33, 2:0.33
    blue_button_pos: 4:1.00, 1:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 6:1.00, 8:0.00, 5:0.00
    agent2_pos: 4:1.00, 8:0.00, 7:0.00
    red_button_pos: 7:0.33, 1:0.33, 2:0.33
    blue_button_pos: 4:1.00, 1:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 676:0.04; 672:0.03; 675:0.03; 677:0.03; 682:0.03
  Agent2 top policies: 676:0.04; 672:0.03; 675:0.03; 677:0.03; 682:0.03
. 2 .
. b .
. 1 .

Reward: +0.00, Result: neutral

--- Step 4 ---
Agent 1 joint action: 4 → (UP, PRESS)
Agent 2 joint action: 4 → (UP, PRESS)
Executed: Agent 1: UP, Agent 2: PRESS
  Agent1 beliefs:
    agent1_pos: 7:1.00, 8:0.00, 6:0.00
    agent2_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 2:0.00, 7:0.00
    blue_button_pos: 4:1.00, 2:0.00, 6:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 7:1.00, 8:0.00, 6:0.00
    agent2_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 2:0.00, 7:0.00
    blue_button_pos: 4:1.00, 2:0.00, 6:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 169:0.16; 168:0.16; 173:0.16; 172:0.16; 171:0.16
  Agent2 top policies: 169:0.16; 168:0.16; 173:0.16; 172:0.16; 171:0.16
. 2 .
. 1 .
. . .

Reward: +0.00, Result: neutral
Button pressed: red by Agent 2

--- Step 5 ---
Agent 1 joint action: 24 → (PRESS, UP)
Agent 2 joint action: 24 → (PRESS, UP)
Executed: Agent 1: PRESS, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 4:1.00, 8:0.00, 7:0.00
    agent2_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 2:0.00, 7:0.00
    blue_button_pos: 4:1.00, 2:0.00, 6:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 4:1.00, 8:0.00, 7:0.00
    agent2_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 2:0.00, 7:0.00
    blue_button_pos: 4:1.00, 2:0.00, 6:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 1027:0.00; 1028:0.00; 1029:0.00; 1030:0.00; 1031:0.00
  Agent2 top policies: 1027:0.00; 1028:0.00; 1029:0.00; 1030:0.00; 1031:0.00
. 2 .
. 1 .
. . .

Reward: +1.00, Result: win
Button pressed: blue by Agent 1

Result: ✅ WIN - win (steps: 5, reward: +1.00)

================================================================================
EPISODE 97
================================================================================
Environment: Red at (1, 0), Blue at (1, 1)

Initial state:
1 r .
. b .
. . 2


--- Step 1 ---
Agent 1 joint action: 6 → (DOWN, UP)
Agent 2 joint action: 6 → (DOWN, UP)
Executed: Agent 1: DOWN, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 0:1.00, 8:0.00, 7:0.00
    agent2_pos: 8:1.00, 0:0.00, 7:0.00
    red_button_pos: 7:0.14, 3:0.14, 6:0.14
    blue_button_pos: 7:0.14, 3:0.14, 6:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 0:1.00, 8:0.00, 7:0.00
    agent2_pos: 8:1.00, 0:0.00, 7:0.00
    red_button_pos: 7:0.14, 3:0.14, 6:0.14
    blue_button_pos: 7:0.14, 3:0.14, 6:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 244:0.02; 676:0.02; 316:0.02; 748:0.02; 677:0.01
  Agent2 top policies: 244:0.02; 676:0.02; 316:0.02; 748:0.02; 677:0.01
. r .
1 b 2
. . .

Reward: +0.00, Result: neutral

--- Step 2 ---
Agent 1 joint action: 8 → (DOWN, LEFT)
Agent 2 joint action: 8 → (DOWN, LEFT)
Executed: Agent 1: DOWN, Agent 2: LEFT
  Agent1 beliefs:
    agent1_pos: 3:1.00, 8:0.00, 5:0.00
    agent2_pos: 5:1.00, 8:0.00, 3:0.00
    red_button_pos: 7:0.20, 1:0.20, 6:0.20
    blue_button_pos: 7:0.20, 1:0.20, 6:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 3:1.00, 8:0.00, 5:0.00
    agent2_pos: 5:1.00, 8:0.00, 3:0.00
    red_button_pos: 7:0.20, 1:0.20, 6:0.20
    blue_button_pos: 7:0.20, 1:0.20, 6:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 316:0.05; 676:0.05; 244:0.05; 313:0.02; 243:0.02
  Agent2 top policies: 316:0.05; 676:0.05; 244:0.05; 313:0.02; 243:0.02
. r .
. 2 .
1 . .

Reward: +0.00, Result: neutral

--- Step 3 ---
Agent 1 joint action: 18 → (RIGHT, UP)
Agent 2 joint action: 18 → (RIGHT, UP)
Executed: Agent 1: RIGHT, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 6:1.00, 8:0.00, 5:0.00
    agent2_pos: 4:1.00, 8:0.00, 7:0.00
    red_button_pos: 7:0.33, 1:0.33, 2:0.33
    blue_button_pos: 4:1.00, 1:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 6:1.00, 8:0.00, 5:0.00
    agent2_pos: 4:1.00, 8:0.00, 7:0.00
    red_button_pos: 7:0.33, 1:0.33, 2:0.33
    blue_button_pos: 4:1.00, 1:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 676:0.04; 672:0.03; 675:0.03; 677:0.03; 682:0.03
  Agent2 top policies: 676:0.04; 672:0.03; 675:0.03; 677:0.03; 682:0.03
. 2 .
. b .
. 1 .

Reward: +0.00, Result: neutral

--- Step 4 ---
Agent 1 joint action: 4 → (UP, PRESS)
Agent 2 joint action: 4 → (UP, PRESS)
Executed: Agent 1: UP, Agent 2: PRESS
  Agent1 beliefs:
    agent1_pos: 7:1.00, 8:0.00, 6:0.00
    agent2_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 2:0.00, 7:0.00
    blue_button_pos: 4:1.00, 2:0.00, 6:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 7:1.00, 8:0.00, 6:0.00
    agent2_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 2:0.00, 7:0.00
    blue_button_pos: 4:1.00, 2:0.00, 6:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 169:0.16; 168:0.16; 173:0.16; 172:0.16; 171:0.16
  Agent2 top policies: 169:0.16; 168:0.16; 173:0.16; 172:0.16; 171:0.16
. 2 .
. 1 .
. . .

Reward: +0.00, Result: neutral
Button pressed: red by Agent 2

--- Step 5 ---
Agent 1 joint action: 24 → (PRESS, UP)
Agent 2 joint action: 24 → (PRESS, UP)
Executed: Agent 1: PRESS, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 4:1.00, 8:0.00, 7:0.00
    agent2_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 2:0.00, 7:0.00
    blue_button_pos: 4:1.00, 2:0.00, 6:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 4:1.00, 8:0.00, 7:0.00
    agent2_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 2:0.00, 7:0.00
    blue_button_pos: 4:1.00, 2:0.00, 6:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 1027:0.00; 1028:0.00; 1029:0.00; 1030:0.00; 1031:0.00
  Agent2 top policies: 1027:0.00; 1028:0.00; 1029:0.00; 1030:0.00; 1031:0.00
. 2 .
. 1 .
. . .

Reward: +1.00, Result: win
Button pressed: blue by Agent 1

Result: ✅ WIN - win (steps: 5, reward: +1.00)

================================================================================
EPISODE 98
================================================================================
Environment: Red at (1, 0), Blue at (1, 1)

Initial state:
1 r .
. b .
. . 2


--- Step 1 ---
Agent 1 joint action: 6 → (DOWN, UP)
Agent 2 joint action: 6 → (DOWN, UP)
Executed: Agent 1: DOWN, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 0:1.00, 8:0.00, 7:0.00
    agent2_pos: 8:1.00, 0:0.00, 7:0.00
    red_button_pos: 7:0.14, 3:0.14, 6:0.14
    blue_button_pos: 7:0.14, 3:0.14, 6:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 0:1.00, 8:0.00, 7:0.00
    agent2_pos: 8:1.00, 0:0.00, 7:0.00
    red_button_pos: 7:0.14, 3:0.14, 6:0.14
    blue_button_pos: 7:0.14, 3:0.14, 6:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 244:0.02; 676:0.02; 316:0.02; 748:0.02; 677:0.01
  Agent2 top policies: 244:0.02; 676:0.02; 316:0.02; 748:0.02; 677:0.01
. r .
1 b 2
. . .

Reward: +0.00, Result: neutral

--- Step 2 ---
Agent 1 joint action: 8 → (DOWN, LEFT)
Agent 2 joint action: 8 → (DOWN, LEFT)
Executed: Agent 1: DOWN, Agent 2: LEFT
  Agent1 beliefs:
    agent1_pos: 3:1.00, 8:0.00, 5:0.00
    agent2_pos: 5:1.00, 8:0.00, 3:0.00
    red_button_pos: 7:0.20, 1:0.20, 6:0.20
    blue_button_pos: 7:0.20, 1:0.20, 6:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 3:1.00, 8:0.00, 5:0.00
    agent2_pos: 5:1.00, 8:0.00, 3:0.00
    red_button_pos: 7:0.20, 1:0.20, 6:0.20
    blue_button_pos: 7:0.20, 1:0.20, 6:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 316:0.05; 676:0.05; 244:0.05; 313:0.02; 243:0.02
  Agent2 top policies: 316:0.05; 676:0.05; 244:0.05; 313:0.02; 243:0.02
. r .
. 2 .
1 . .

Reward: +0.00, Result: neutral

--- Step 3 ---
Agent 1 joint action: 18 → (RIGHT, UP)
Agent 2 joint action: 18 → (RIGHT, UP)
Executed: Agent 1: RIGHT, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 6:1.00, 8:0.00, 5:0.00
    agent2_pos: 4:1.00, 8:0.00, 7:0.00
    red_button_pos: 7:0.33, 1:0.33, 2:0.33
    blue_button_pos: 4:1.00, 1:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 6:1.00, 8:0.00, 5:0.00
    agent2_pos: 4:1.00, 8:0.00, 7:0.00
    red_button_pos: 7:0.33, 1:0.33, 2:0.33
    blue_button_pos: 4:1.00, 1:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 676:0.04; 672:0.03; 675:0.03; 677:0.03; 682:0.03
  Agent2 top policies: 676:0.04; 672:0.03; 675:0.03; 677:0.03; 682:0.03
. 2 .
. b .
. 1 .

Reward: +0.00, Result: neutral

--- Step 4 ---
Agent 1 joint action: 4 → (UP, PRESS)
Agent 2 joint action: 4 → (UP, PRESS)
Executed: Agent 1: UP, Agent 2: PRESS
  Agent1 beliefs:
    agent1_pos: 7:1.00, 8:0.00, 6:0.00
    agent2_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 2:0.00, 7:0.00
    blue_button_pos: 4:1.00, 2:0.00, 6:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 7:1.00, 8:0.00, 6:0.00
    agent2_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 2:0.00, 7:0.00
    blue_button_pos: 4:1.00, 2:0.00, 6:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 169:0.16; 168:0.16; 173:0.16; 172:0.16; 171:0.16
  Agent2 top policies: 169:0.16; 168:0.16; 173:0.16; 172:0.16; 171:0.16
. 2 .
. 1 .
. . .

Reward: +0.00, Result: neutral
Button pressed: red by Agent 2

--- Step 5 ---
Agent 1 joint action: 24 → (PRESS, UP)
Agent 2 joint action: 24 → (PRESS, UP)
Executed: Agent 1: PRESS, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 4:1.00, 8:0.00, 7:0.00
    agent2_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 2:0.00, 7:0.00
    blue_button_pos: 4:1.00, 2:0.00, 6:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 4:1.00, 8:0.00, 7:0.00
    agent2_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 2:0.00, 7:0.00
    blue_button_pos: 4:1.00, 2:0.00, 6:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 1027:0.00; 1028:0.00; 1029:0.00; 1030:0.00; 1031:0.00
  Agent2 top policies: 1027:0.00; 1028:0.00; 1029:0.00; 1030:0.00; 1031:0.00
. 2 .
. 1 .
. . .

Reward: +1.00, Result: win
Button pressed: blue by Agent 1

Result: ✅ WIN - win (steps: 5, reward: +1.00)

================================================================================
EPISODE 99
================================================================================
Environment: Red at (1, 0), Blue at (1, 1)

Initial state:
1 r .
. b .
. . 2


--- Step 1 ---
Agent 1 joint action: 6 → (DOWN, UP)
Agent 2 joint action: 6 → (DOWN, UP)
Executed: Agent 1: DOWN, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 0:1.00, 8:0.00, 7:0.00
    agent2_pos: 8:1.00, 0:0.00, 7:0.00
    red_button_pos: 7:0.14, 3:0.14, 6:0.14
    blue_button_pos: 7:0.14, 3:0.14, 6:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 0:1.00, 8:0.00, 7:0.00
    agent2_pos: 8:1.00, 0:0.00, 7:0.00
    red_button_pos: 7:0.14, 3:0.14, 6:0.14
    blue_button_pos: 7:0.14, 3:0.14, 6:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 244:0.02; 676:0.02; 316:0.02; 748:0.02; 677:0.01
  Agent2 top policies: 244:0.02; 676:0.02; 316:0.02; 748:0.02; 677:0.01
. r .
1 b 2
. . .

Reward: +0.00, Result: neutral

--- Step 2 ---
Agent 1 joint action: 8 → (DOWN, LEFT)
Agent 2 joint action: 8 → (DOWN, LEFT)
Executed: Agent 1: DOWN, Agent 2: LEFT
  Agent1 beliefs:
    agent1_pos: 3:1.00, 8:0.00, 5:0.00
    agent2_pos: 5:1.00, 8:0.00, 3:0.00
    red_button_pos: 7:0.20, 1:0.20, 6:0.20
    blue_button_pos: 7:0.20, 1:0.20, 6:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 3:1.00, 8:0.00, 5:0.00
    agent2_pos: 5:1.00, 8:0.00, 3:0.00
    red_button_pos: 7:0.20, 1:0.20, 6:0.20
    blue_button_pos: 7:0.20, 1:0.20, 6:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 316:0.05; 676:0.05; 244:0.05; 313:0.02; 243:0.02
  Agent2 top policies: 316:0.05; 676:0.05; 244:0.05; 313:0.02; 243:0.02
. r .
. 2 .
1 . .

Reward: +0.00, Result: neutral

--- Step 3 ---
Agent 1 joint action: 18 → (RIGHT, UP)
Agent 2 joint action: 18 → (RIGHT, UP)
Executed: Agent 1: RIGHT, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 6:1.00, 8:0.00, 5:0.00
    agent2_pos: 4:1.00, 8:0.00, 7:0.00
    red_button_pos: 7:0.33, 1:0.33, 2:0.33
    blue_button_pos: 4:1.00, 1:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 6:1.00, 8:0.00, 5:0.00
    agent2_pos: 4:1.00, 8:0.00, 7:0.00
    red_button_pos: 7:0.33, 1:0.33, 2:0.33
    blue_button_pos: 4:1.00, 1:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 676:0.04; 672:0.03; 675:0.03; 677:0.03; 682:0.03
  Agent2 top policies: 676:0.04; 672:0.03; 675:0.03; 677:0.03; 682:0.03
. 2 .
. b .
. 1 .

Reward: +0.00, Result: neutral

--- Step 4 ---
Agent 1 joint action: 4 → (UP, PRESS)
Agent 2 joint action: 4 → (UP, PRESS)
Executed: Agent 1: UP, Agent 2: PRESS
  Agent1 beliefs:
    agent1_pos: 7:1.00, 8:0.00, 6:0.00
    agent2_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 2:0.00, 7:0.00
    blue_button_pos: 4:1.00, 2:0.00, 6:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 7:1.00, 8:0.00, 6:0.00
    agent2_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 2:0.00, 7:0.00
    blue_button_pos: 4:1.00, 2:0.00, 6:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 169:0.16; 168:0.16; 173:0.16; 172:0.16; 171:0.16
  Agent2 top policies: 169:0.16; 168:0.16; 173:0.16; 172:0.16; 171:0.16
. 2 .
. 1 .
. . .

Reward: +0.00, Result: neutral
Button pressed: red by Agent 2

--- Step 5 ---
Agent 1 joint action: 24 → (PRESS, UP)
Agent 2 joint action: 24 → (PRESS, UP)
Executed: Agent 1: PRESS, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 4:1.00, 8:0.00, 7:0.00
    agent2_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 2:0.00, 7:0.00
    blue_button_pos: 4:1.00, 2:0.00, 6:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 4:1.00, 8:0.00, 7:0.00
    agent2_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 2:0.00, 7:0.00
    blue_button_pos: 4:1.00, 2:0.00, 6:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 1027:0.00; 1028:0.00; 1029:0.00; 1030:0.00; 1031:0.00
  Agent2 top policies: 1027:0.00; 1028:0.00; 1029:0.00; 1030:0.00; 1031:0.00
. 2 .
. 1 .
. . .

Reward: +1.00, Result: win
Button pressed: blue by Agent 1

Result: ✅ WIN - win (steps: 5, reward: +1.00)

================================================================================
EPISODE 100
================================================================================
Environment: Red at (1, 0), Blue at (1, 1)

Initial state:
1 r .
. b .
. . 2


--- Step 1 ---
Agent 1 joint action: 6 → (DOWN, UP)
Agent 2 joint action: 6 → (DOWN, UP)
Executed: Agent 1: DOWN, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 0:1.00, 8:0.00, 7:0.00
    agent2_pos: 8:1.00, 0:0.00, 7:0.00
    red_button_pos: 7:0.14, 3:0.14, 6:0.14
    blue_button_pos: 7:0.14, 3:0.14, 6:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 0:1.00, 8:0.00, 7:0.00
    agent2_pos: 8:1.00, 0:0.00, 7:0.00
    red_button_pos: 7:0.14, 3:0.14, 6:0.14
    blue_button_pos: 7:0.14, 3:0.14, 6:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 244:0.02; 676:0.02; 316:0.02; 748:0.02; 677:0.01
  Agent2 top policies: 244:0.02; 676:0.02; 316:0.02; 748:0.02; 677:0.01
. r .
1 b 2
. . .

Reward: +0.00, Result: neutral

--- Step 2 ---
Agent 1 joint action: 8 → (DOWN, LEFT)
Agent 2 joint action: 8 → (DOWN, LEFT)
Executed: Agent 1: DOWN, Agent 2: LEFT
  Agent1 beliefs:
    agent1_pos: 3:1.00, 8:0.00, 5:0.00
    agent2_pos: 5:1.00, 8:0.00, 3:0.00
    red_button_pos: 7:0.20, 1:0.20, 6:0.20
    blue_button_pos: 7:0.20, 1:0.20, 6:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 3:1.00, 8:0.00, 5:0.00
    agent2_pos: 5:1.00, 8:0.00, 3:0.00
    red_button_pos: 7:0.20, 1:0.20, 6:0.20
    blue_button_pos: 7:0.20, 1:0.20, 6:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 316:0.05; 676:0.05; 244:0.05; 313:0.02; 243:0.02
  Agent2 top policies: 316:0.05; 676:0.05; 244:0.05; 313:0.02; 243:0.02
. r .
. 2 .
1 . .

Reward: +0.00, Result: neutral

--- Step 3 ---
Agent 1 joint action: 18 → (RIGHT, UP)
Agent 2 joint action: 18 → (RIGHT, UP)
Executed: Agent 1: RIGHT, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 6:1.00, 8:0.00, 5:0.00
    agent2_pos: 4:1.00, 8:0.00, 7:0.00
    red_button_pos: 7:0.33, 1:0.33, 2:0.33
    blue_button_pos: 4:1.00, 1:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 6:1.00, 8:0.00, 5:0.00
    agent2_pos: 4:1.00, 8:0.00, 7:0.00
    red_button_pos: 7:0.33, 1:0.33, 2:0.33
    blue_button_pos: 4:1.00, 1:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 676:0.04; 672:0.03; 675:0.03; 677:0.03; 682:0.03
  Agent2 top policies: 676:0.04; 672:0.03; 675:0.03; 677:0.03; 682:0.03
. 2 .
. b .
. 1 .

Reward: +0.00, Result: neutral

--- Step 4 ---
Agent 1 joint action: 4 → (UP, PRESS)
Agent 2 joint action: 4 → (UP, PRESS)
Executed: Agent 1: UP, Agent 2: PRESS
  Agent1 beliefs:
    agent1_pos: 7:1.00, 8:0.00, 6:0.00
    agent2_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 2:0.00, 7:0.00
    blue_button_pos: 4:1.00, 2:0.00, 6:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 7:1.00, 8:0.00, 6:0.00
    agent2_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 2:0.00, 7:0.00
    blue_button_pos: 4:1.00, 2:0.00, 6:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 169:0.16; 168:0.16; 173:0.16; 172:0.16; 171:0.16
  Agent2 top policies: 169:0.16; 168:0.16; 173:0.16; 172:0.16; 171:0.16
. 2 .
. 1 .
. . .

Reward: +0.00, Result: neutral
Button pressed: red by Agent 2

--- Step 5 ---
Agent 1 joint action: 24 → (PRESS, UP)
Agent 2 joint action: 24 → (PRESS, UP)
Executed: Agent 1: PRESS, Agent 2: UP
  Agent1 beliefs:
    agent1_pos: 4:1.00, 8:0.00, 7:0.00
    agent2_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 2:0.00, 7:0.00
    blue_button_pos: 4:1.00, 2:0.00, 6:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent1_pos: 4:1.00, 8:0.00, 7:0.00
    agent2_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 2:0.00, 7:0.00
    blue_button_pos: 4:1.00, 2:0.00, 6:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 1027:0.00; 1028:0.00; 1029:0.00; 1030:0.00; 1031:0.00
  Agent2 top policies: 1027:0.00; 1028:0.00; 1029:0.00; 1030:0.00; 1031:0.00
. 2 .
. 1 .
. . .

Reward: +1.00, Result: win
Button pressed: blue by Agent 1

Result: ✅ WIN - win (steps: 5, reward: +1.00)
  Seed 0, Episode 100/100: Last 100 win rate: 100.0% (100/100)

Seed 0 Summary:
  Success rate: 100/100 (100.0%)
  Average reward: +1.00
  Average steps: 5.6
  Learning: First half 50/50, Second half 50/50

✓ Log saved to: /localscratch/toulabin.15760724.0/project/Fn_ActiveInference/logs/two_aif_agents_individually_collective_seeds1_ep100_20251216_034908.csv

================================================================================
OVERALL RESULTS SUMMARY
================================================================================

Total episodes: 100
Total successes: 100 (100.0%)
Overall average reward: +1.00
Overall average steps: 5.6

Seed   Success Rate       Avg Reward   1st Half   2nd Half  
-----------------------------------------------------------------
0       100/100  (100.0%)    +1.00      50/50       50/50   

Learning Progress:
  First half: 50/50 (100.0%)
  Second half: 50/50 (100.0%)

(plots disabled; pass --plots to generate figures)

================================================================================
EXPERIMENT COMPLETE
================================================================================
Copying logs...
Copy done
---- IndividuallyCollective paradigm seed index 2 complete ----
