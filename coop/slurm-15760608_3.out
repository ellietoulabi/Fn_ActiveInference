The following modules were not unloaded:
  (Use "module --force purge" to unload all):

  1) CCconfig        6)  ucx/1.14.1         11) flexiblas/3.3.1
  2) gentoo/2023     7)  libfabric/1.18.0   12) aocl-blas/5.1
  3) gcccore/.12.3   8)  pmix/4.2.4         13) aocl-lapack/5.1
  4) gcc/12.3        9)  ucc/1.2.0          14) StdEnv/2023
  5) hwloc/2.9.1     10) openmpi/4.1.5
Working in SLURM_TMPDIR: /localscratch/toulabin.15760721.0
Cloning repository...
Repository cloned.
Creating virtual environment...
Activated virtualenv.
Installing dependencies...
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/gentoo2023/x86-64-v4, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/gentoo2023/x86-64-v3, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/gentoo2023/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Requirement already satisfied: numpy>=1.20.0 in /cvmfs/soft.computecanada.ca/easybuild/software/2023/x86-64-v4/Compiler/gcccore/scipy-stack/2025a/lib/python3.11/site-packages (from -r requirements.txt (line 3)) (2.2.2+computecanada)
Collecting jax>=0.4.0 (from -r requirements.txt (line 4))
  Obtaining dependency information for jax>=0.4.0 from https://files.pythonhosted.org/packages/f9/e7/19b8cfc8963b2e10a01a4db7bb27ec5fa39ecd024bc62f8e2d1de5625a9d/jax-0.8.1-py3-none-any.whl.metadata
  Using cached jax-0.8.1-py3-none-any.whl.metadata (13 kB)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/gentoo2023/x86-64-v3/jaxlib-0.7.2+computecanada-cp311-cp311-linux_x86_64.whl (from -r requirements.txt (line 5))
Collecting gymnasium>=0.29.0 (from -r requirements.txt (line 8))
  Obtaining dependency information for gymnasium>=0.29.0 from https://files.pythonhosted.org/packages/c7/53/39cd8c2f85e213fce1f32367c4bdbd3402d3bcde7d0826a1172a0f2c5cc0/gymnasium-1.2.2-py3-none-any.whl.metadata
  Using cached gymnasium-1.2.2-py3-none-any.whl.metadata (10 kB)
Requirement already satisfied: pandas>=1.3.0 in /cvmfs/soft.computecanada.ca/easybuild/software/2023/x86-64-v4/Compiler/gcccore/scipy-stack/2025a/lib/python3.11/site-packages (from -r requirements.txt (line 11)) (2.2.3+computecanada)
Requirement already satisfied: scipy>=1.7.0 in /cvmfs/soft.computecanada.ca/easybuild/software/2023/x86-64-v4/Compiler/gcccore/scipy-stack/2025a/lib/python3.11/site-packages (from -r requirements.txt (line 14)) (1.15.1+computecanada)
Requirement already satisfied: matplotlib>=3.4.0 in /cvmfs/soft.computecanada.ca/easybuild/software/2023/x86-64-v4/Compiler/gcccore/scipy-stack/2025a/lib/python3.11/site-packages (from -r requirements.txt (line 17)) (3.10.0+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tqdm-4.67.1+computecanada-py3-none-any.whl (from -r requirements.txt (line 20))
INFO: pip is looking at multiple versions of jax to determine which version is compatible with other requirements. This could take a while.
Collecting jax>=0.4.0 (from -r requirements.txt (line 4))
  Obtaining dependency information for jax>=0.4.0 from https://files.pythonhosted.org/packages/b3/77/4e6c9a54247810eff8ac8a1af7dc1be0779b52df0d82f3fc8586061914f3/jax-0.8.0-py3-none-any.whl.metadata
  Using cached jax-0.8.0-py3-none-any.whl.metadata (13 kB)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/jax-0.7.2+computecanada-py3-none-any.whl (from -r requirements.txt (line 4))
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/gentoo2023/generic/ml_dtypes-0.5.1+computecanada-cp311-cp311-linux_x86_64.whl (from jax>=0.4.0->-r requirements.txt (line 4))
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/opt_einsum-3.4.0+computecanada-py3-none-any.whl (from jax>=0.4.0->-r requirements.txt (line 4))
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/cloudpickle-3.1.2+computecanada-py3-none-any.whl (from gymnasium>=0.29.0->-r requirements.txt (line 8))
Requirement already satisfied: typing-extensions>=4.3.0 in /cvmfs/soft.computecanada.ca/easybuild/software/2023/x86-64-v4/Compiler/gcccore/ipykernel/2025a/lib/python3.11/site-packages (from gymnasium>=0.29.0->-r requirements.txt (line 8)) (4.12.2+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/Farama_Notifications-0.0.4+computecanada-py3-none-any.whl (from gymnasium>=0.29.0->-r requirements.txt (line 8))
Requirement already satisfied: python-dateutil>=2.8.2 in /cvmfs/soft.computecanada.ca/easybuild/software/2023/x86-64-v4/Compiler/gcccore/scipy-stack/2025a/lib/python3.11/site-packages (from pandas>=1.3.0->-r requirements.txt (line 11)) (2.9.0.post0+computecanada)
Requirement already satisfied: pytz>=2020.1 in /cvmfs/soft.computecanada.ca/easybuild/software/2023/x86-64-v4/Compiler/gcccore/scipy-stack/2025a/lib/python3.11/site-packages (from pandas>=1.3.0->-r requirements.txt (line 11)) (2025.1+computecanada)
Requirement already satisfied: tzdata>=2022.7 in /cvmfs/soft.computecanada.ca/easybuild/software/2023/x86-64-v4/Compiler/gcccore/scipy-stack/2025a/lib/python3.11/site-packages (from pandas>=1.3.0->-r requirements.txt (line 11)) (2025.1+computecanada)
Requirement already satisfied: contourpy>=1.0.1 in /cvmfs/soft.computecanada.ca/easybuild/software/2023/x86-64-v4/Compiler/gcccore/scipy-stack/2025a/lib/python3.11/site-packages (from matplotlib>=3.4.0->-r requirements.txt (line 17)) (1.3.1+computecanada)
Requirement already satisfied: cycler>=0.10 in /cvmfs/soft.computecanada.ca/easybuild/software/2023/x86-64-v4/Compiler/gcccore/scipy-stack/2025a/lib/python3.11/site-packages (from matplotlib>=3.4.0->-r requirements.txt (line 17)) (0.12.1+computecanada)
Requirement already satisfied: fonttools>=4.22.0 in /cvmfs/soft.computecanada.ca/easybuild/software/2023/x86-64-v4/Compiler/gcccore/scipy-stack/2025a/lib/python3.11/site-packages (from matplotlib>=3.4.0->-r requirements.txt (line 17)) (4.55.8+computecanada)
Requirement already satisfied: kiwisolver>=1.3.1 in /cvmfs/soft.computecanada.ca/easybuild/software/2023/x86-64-v4/Compiler/gcccore/scipy-stack/2025a/lib/python3.11/site-packages (from matplotlib>=3.4.0->-r requirements.txt (line 17)) (1.4.8+computecanada)
Requirement already satisfied: packaging>=20.0 in /cvmfs/soft.computecanada.ca/easybuild/software/2023/x86-64-v4/Compiler/gcccore/scipy-stack/2025a/lib/python3.11/site-packages (from matplotlib>=3.4.0->-r requirements.txt (line 17)) (24.2+computecanada)
Requirement already satisfied: pillow>=8 in /cvmfs/soft.computecanada.ca/easybuild/software/2023/x86-64-v4/Compiler/gcccore/scipy-stack/2025a/lib/python3.11/site-packages (from matplotlib>=3.4.0->-r requirements.txt (line 17)) (11.1.0+computecanada)
Requirement already satisfied: pyparsing>=2.3.1 in /cvmfs/soft.computecanada.ca/easybuild/software/2023/x86-64-v4/Compiler/gcccore/scipy-stack/2025a/lib/python3.11/site-packages (from matplotlib>=3.4.0->-r requirements.txt (line 17)) (3.2.1+computecanada)
Requirement already satisfied: six>=1.5 in /cvmfs/soft.computecanada.ca/easybuild/software/2023/x86-64-v4/Compiler/gcccore/scipy-stack/2025a/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas>=1.3.0->-r requirements.txt (line 11)) (1.17.0+computecanada)
Using cached gymnasium-1.2.2-py3-none-any.whl (952 kB)
Installing collected packages: farama-notifications, tqdm, opt_einsum, ml_dtypes, cloudpickle, jaxlib, gymnasium, jax
Successfully installed cloudpickle-3.1.2+computecanada farama-notifications-0.0.4+computecanada gymnasium-1.2.2 jax-0.7.2+computecanada jaxlib-0.7.2+computecanada ml_dtypes-0.5.1+computecanada opt_einsum-3.4.0+computecanada tqdm-4.67.1+computecanada
Dependencies installed.
---- Starting seed index 3 ----
================================================================================
TWO ACTIVE INFERENCE AGENTS - FULLY COLLECTIVE PARADIGM
================================================================================

Experiment Parameters:
  Number of seeds: 1
  Episodes per seed: 100
  Episodes per config: 20
  Max steps per episode: 30
  Logging to: /localscratch/toulabin.15760721.0/project/Fn_ActiveInference/logs/two_aif_agents_fully_collective_seeds1_ep100_20251216_034908.csv

================================================================================
SEED 0 (1/1)
================================================================================

================================================================================
SEED 0 - CONFIG 1
Red at (1, 0), Blue at (1, 2)
Episodes 1-20
================================================================================

================================================================================
EPISODE 1
================================================================================
Environment: Red at (1, 0), Blue at (1, 2)

Initial state:
1 r .
. . .
. b 2


--- Step 1 ---
Joint action: 6 → Agent 1: DOWN, Agent 2: UP
  Beliefs:
    agent1_pos: 0:1.00, 8:0.00, 7:0.00
    agent2_pos: 8:1.00, 0:0.00, 7:0.00
    red_button_pos: 7:0.14, 3:0.14, 6:0.14
    blue_button_pos: 7:0.14, 3:0.14, 6:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Top policies: 8812:0.01; 24364:0.01; 11404:0.01; 26956:0.01; 8810:0.00
. r .
1 . 2
. b .

Reward: +0.00, Result: neutral

--- Step 2 ---
Joint action: 6 → Agent 1: DOWN, Agent 2: UP
  Beliefs:
    agent1_pos: 3:1.00, 8:0.00, 5:0.00
    agent2_pos: 5:1.00, 8:0.00, 3:0.00
    red_button_pos: 7:0.20, 1:0.20, 6:0.20
    blue_button_pos: 7:0.20, 1:0.20, 6:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Top policies: 8812:0.02; 11404:0.02; 24364:0.02; 11400:0.01; 8800:0.01
. r 2
. . .
1 b .

Reward: +0.00, Result: neutral

--- Step 3 ---
Joint action: 20 → Agent 1: RIGHT, Agent 2: LEFT
  Beliefs:
    agent1_pos: 6:1.00, 8:0.00, 5:0.00
    agent2_pos: 2:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:0.33, 1:0.33, 4:0.33
    blue_button_pos: 7:0.33, 1:0.33, 4:0.33
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Top policies: 26956:0.23; 26932:0.05; 26953:0.05; 26952:0.05; 26957:0.05
. 2 .
. . .
. 1 .

Reward: +0.00, Result: neutral

--- Step 4 ---
Joint action: 10 → Agent 1: DOWN, Agent 2: PRESS
  Beliefs:
    agent1_pos: 7:1.00, 8:0.00, 6:0.00
    agent2_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 4:0.00, 7:0.00
    blue_button_pos: 7:1.00, 1:0.00, 4:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Top policies: 13862:0.00; 13909:0.00; 13908:0.00; 13907:0.00; 13906:0.00
. 2 .
. . .
. 1 .

Reward: +0.00, Result: neutral
Button pressed: red by Agent 2

--- Step 5 ---
Joint action: 24 → Agent 1: PRESS, Agent 2: UP
  Beliefs:
    agent1_pos: 7:1.00, 8:0.00, 6:0.00
    agent2_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 4:0.00, 7:0.00
    blue_button_pos: 7:1.00, 1:0.00, 4:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Top policies: 37020:0.00; 37019:0.00; 37018:0.00; 37017:0.00; 37016:0.00
. 2 .
. . .
. 1 .

Reward: +1.00, Result: win
Button pressed: blue by Agent 1

Result: ✅ WIN - win (steps: 5, reward: +1.00)

================================================================================
EPISODE 2
================================================================================
Environment: Red at (1, 0), Blue at (1, 2)

Initial state:
1 r .
. . .
. b 2


--- Step 1 ---
Joint action: 6 → Agent 1: DOWN, Agent 2: UP
  Beliefs:
    agent1_pos: 0:1.00, 8:0.00, 7:0.00
    agent2_pos: 8:1.00, 0:0.00, 7:0.00
    red_button_pos: 7:0.14, 3:0.14, 6:0.14
    blue_button_pos: 7:0.14, 3:0.14, 6:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Top policies: 8812:0.01; 24364:0.01; 11404:0.01; 26956:0.01; 8810:0.00
. r .
1 . 2
. b .

Reward: +0.00, Result: neutral

--- Step 2 ---
Joint action: 6 → Agent 1: DOWN, Agent 2: UP
  Beliefs:
    agent1_pos: 3:1.00, 8:0.00, 5:0.00
    agent2_pos: 5:1.00, 8:0.00, 3:0.00
    red_button_pos: 7:0.20, 1:0.20, 6:0.20
    blue_button_pos: 7:0.20, 1:0.20, 6:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Top policies: 8812:0.02; 11404:0.02; 24364:0.02; 11400:0.01; 8800:0.01
. r 2
. . .
1 b .

Reward: +0.00, Result: neutral

--- Step 3 ---
Joint action: 20 → Agent 1: RIGHT, Agent 2: LEFT
  Beliefs:
    agent1_pos: 6:1.00, 8:0.00, 5:0.00
    agent2_pos: 2:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:0.33, 1:0.33, 4:0.33
    blue_button_pos: 7:0.33, 1:0.33, 4:0.33
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Top policies: 26956:0.23; 26932:0.05; 26953:0.05; 26952:0.05; 26957:0.05
. 2 .
. . .
. 1 .

Reward: +0.00, Result: neutral

--- Step 4 ---
Joint action: 10 → Agent 1: DOWN, Agent 2: PRESS
  Beliefs:
    agent1_pos: 7:1.00, 8:0.00, 6:0.00
    agent2_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 4:0.00, 7:0.00
    blue_button_pos: 7:1.00, 1:0.00, 4:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Top policies: 13862:0.00; 13909:0.00; 13908:0.00; 13907:0.00; 13906:0.00
. 2 .
. . .
. 1 .

Reward: +0.00, Result: neutral
Button pressed: red by Agent 2

--- Step 5 ---
Joint action: 24 → Agent 1: PRESS, Agent 2: UP
  Beliefs:
    agent1_pos: 7:1.00, 8:0.00, 6:0.00
    agent2_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 4:0.00, 7:0.00
    blue_button_pos: 7:1.00, 1:0.00, 4:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Top policies: 37020:0.00; 37019:0.00; 37018:0.00; 37017:0.00; 37016:0.00
. 2 .
. . .
. 1 .

Reward: +1.00, Result: win
Button pressed: blue by Agent 1

Result: ✅ WIN - win (steps: 5, reward: +1.00)

================================================================================
EPISODE 3
================================================================================
Environment: Red at (1, 0), Blue at (1, 2)

Initial state:
1 r .
. . .
. b 2


--- Step 1 ---
Joint action: 6 → Agent 1: DOWN, Agent 2: UP
  Beliefs:
    agent1_pos: 0:1.00, 8:0.00, 7:0.00
    agent2_pos: 8:1.00, 0:0.00, 7:0.00
    red_button_pos: 7:0.14, 3:0.14, 6:0.14
    blue_button_pos: 7:0.14, 3:0.14, 6:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Top policies: 8812:0.01; 24364:0.01; 11404:0.01; 26956:0.01; 8810:0.00
. r .
1 . 2
. b .

Reward: +0.00, Result: neutral

--- Step 2 ---
Joint action: 6 → Agent 1: DOWN, Agent 2: UP
  Beliefs:
    agent1_pos: 3:1.00, 8:0.00, 5:0.00
    agent2_pos: 5:1.00, 8:0.00, 3:0.00
    red_button_pos: 7:0.20, 1:0.20, 6:0.20
    blue_button_pos: 7:0.20, 1:0.20, 6:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Top policies: 8812:0.02; 11404:0.02; 24364:0.02; 11400:0.01; 8800:0.01
. r 2
. . .
1 b .

Reward: +0.00, Result: neutral

--- Step 3 ---
Joint action: 20 → Agent 1: RIGHT, Agent 2: LEFT
  Beliefs:
    agent1_pos: 6:1.00, 8:0.00, 5:0.00
    agent2_pos: 2:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:0.33, 1:0.33, 4:0.33
    blue_button_pos: 7:0.33, 1:0.33, 4:0.33
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Top policies: 26956:0.23; 26932:0.05; 26953:0.05; 26952:0.05; 26957:0.05
. 2 .
. . .
. 1 .

Reward: +0.00, Result: neutral

--- Step 4 ---
Joint action: 10 → Agent 1: DOWN, Agent 2: PRESS
  Beliefs:
    agent1_pos: 7:1.00, 8:0.00, 6:0.00
    agent2_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 4:0.00, 7:0.00
    blue_button_pos: 7:1.00, 1:0.00, 4:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Top policies: 13862:0.00; 13909:0.00; 13908:0.00; 13907:0.00; 13906:0.00
. 2 .
. . .
. 1 .

Reward: +0.00, Result: neutral
Button pressed: red by Agent 2

--- Step 5 ---
Joint action: 24 → Agent 1: PRESS, Agent 2: UP
  Beliefs:
    agent1_pos: 7:1.00, 8:0.00, 6:0.00
    agent2_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 4:0.00, 7:0.00
    blue_button_pos: 7:1.00, 1:0.00, 4:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Top policies: 37020:0.00; 37019:0.00; 37018:0.00; 37017:0.00; 37016:0.00
. 2 .
. . .
. 1 .

Reward: +1.00, Result: win
Button pressed: blue by Agent 1

Result: ✅ WIN - win (steps: 5, reward: +1.00)

================================================================================
EPISODE 4
================================================================================
Environment: Red at (1, 0), Blue at (1, 2)

Initial state:
1 r .
. . .
. b 2


--- Step 1 ---
Joint action: 6 → Agent 1: DOWN, Agent 2: UP
  Beliefs:
    agent1_pos: 0:1.00, 8:0.00, 7:0.00
    agent2_pos: 8:1.00, 0:0.00, 7:0.00
    red_button_pos: 7:0.14, 3:0.14, 6:0.14
    blue_button_pos: 7:0.14, 3:0.14, 6:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Top policies: 8812:0.01; 24364:0.01; 11404:0.01; 26956:0.01; 8810:0.00
. r .
1 . 2
. b .

Reward: +0.00, Result: neutral

--- Step 2 ---
Joint action: 6 → Agent 1: DOWN, Agent 2: UP
  Beliefs:
    agent1_pos: 3:1.00, 8:0.00, 5:0.00
    agent2_pos: 5:1.00, 8:0.00, 3:0.00
    red_button_pos: 7:0.20, 1:0.20, 6:0.20
    blue_button_pos: 7:0.20, 1:0.20, 6:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Top policies: 8812:0.02; 11404:0.02; 24364:0.02; 11400:0.01; 8800:0.01
. r 2
. . .
1 b .

Reward: +0.00, Result: neutral

--- Step 3 ---
Joint action: 20 → Agent 1: RIGHT, Agent 2: LEFT
  Beliefs:
    agent1_pos: 6:1.00, 8:0.00, 5:0.00
    agent2_pos: 2:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:0.33, 1:0.33, 4:0.33
    blue_button_pos: 7:0.33, 1:0.33, 4:0.33
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Top policies: 26956:0.23; 26932:0.05; 26953:0.05; 26952:0.05; 26957:0.05
. 2 .
. . .
. 1 .

Reward: +0.00, Result: neutral

--- Step 4 ---
Joint action: 10 → Agent 1: DOWN, Agent 2: PRESS
  Beliefs:
    agent1_pos: 7:1.00, 8:0.00, 6:0.00
    agent2_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 4:0.00, 7:0.00
    blue_button_pos: 7:1.00, 1:0.00, 4:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Top policies: 13862:0.00; 13909:0.00; 13908:0.00; 13907:0.00; 13906:0.00
. 2 .
. . .
. 1 .

Reward: +0.00, Result: neutral
Button pressed: red by Agent 2

--- Step 5 ---
Joint action: 24 → Agent 1: PRESS, Agent 2: UP
  Beliefs:
    agent1_pos: 7:1.00, 8:0.00, 6:0.00
    agent2_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 4:0.00, 7:0.00
    blue_button_pos: 7:1.00, 1:0.00, 4:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Top policies: 37020:0.00; 37019:0.00; 37018:0.00; 37017:0.00; 37016:0.00
. 2 .
. . .
. 1 .

Reward: +1.00, Result: win
Button pressed: blue by Agent 1

Result: ✅ WIN - win (steps: 5, reward: +1.00)

================================================================================
EPISODE 5
================================================================================
Environment: Red at (1, 0), Blue at (1, 2)

Initial state:
1 r .
. . .
. b 2


--- Step 1 ---
Joint action: 6 → Agent 1: DOWN, Agent 2: UP
  Beliefs:
    agent1_pos: 0:1.00, 8:0.00, 7:0.00
    agent2_pos: 8:1.00, 0:0.00, 7:0.00
    red_button_pos: 7:0.14, 3:0.14, 6:0.14
    blue_button_pos: 7:0.14, 3:0.14, 6:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Top policies: 8812:0.01; 24364:0.01; 11404:0.01; 26956:0.01; 8810:0.00
. r .
1 . 2
. b .

Reward: +0.00, Result: neutral

--- Step 2 ---
Joint action: 6 → Agent 1: DOWN, Agent 2: UP
  Beliefs:
    agent1_pos: 3:1.00, 8:0.00, 5:0.00
    agent2_pos: 5:1.00, 8:0.00, 3:0.00
    red_button_pos: 7:0.20, 1:0.20, 6:0.20
    blue_button_pos: 7:0.20, 1:0.20, 6:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Top policies: 8812:0.02; 11404:0.02; 24364:0.02; 11400:0.01; 8800:0.01
. r 2
. . .
1 b .

Reward: +0.00, Result: neutral

--- Step 3 ---
Joint action: 20 → Agent 1: RIGHT, Agent 2: LEFT
  Beliefs:
    agent1_pos: 6:1.00, 8:0.00, 5:0.00
    agent2_pos: 2:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:0.33, 1:0.33, 4:0.33
    blue_button_pos: 7:0.33, 1:0.33, 4:0.33
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Top policies: 26956:0.23; 26932:0.05; 26953:0.05; 26952:0.05; 26957:0.05
. 2 .
. . .
. 1 .

Reward: +0.00, Result: neutral

--- Step 4 ---
Joint action: 10 → Agent 1: DOWN, Agent 2: PRESS
  Beliefs:
    agent1_pos: 7:1.00, 8:0.00, 6:0.00
    agent2_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 4:0.00, 7:0.00
    blue_button_pos: 7:1.00, 1:0.00, 4:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Top policies: 13862:0.00; 13909:0.00; 13908:0.00; 13907:0.00; 13906:0.00
. 2 .
. . .
. 1 .

Reward: +0.00, Result: neutral
Button pressed: red by Agent 2

--- Step 5 ---
Joint action: 24 → Agent 1: PRESS, Agent 2: UP
  Beliefs:
    agent1_pos: 7:1.00, 8:0.00, 6:0.00
    agent2_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 4:0.00, 7:0.00
    blue_button_pos: 7:1.00, 1:0.00, 4:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Top policies: 37020:0.00; 37019:0.00; 37018:0.00; 37017:0.00; 37016:0.00
. 2 .
. . .
. 1 .

Reward: +1.00, Result: win
Button pressed: blue by Agent 1

Result: ✅ WIN - win (steps: 5, reward: +1.00)

================================================================================
EPISODE 6
================================================================================
Environment: Red at (1, 0), Blue at (1, 2)

Initial state:
1 r .
. . .
. b 2


--- Step 1 ---
Joint action: 6 → Agent 1: DOWN, Agent 2: UP
  Beliefs:
    agent1_pos: 0:1.00, 8:0.00, 7:0.00
    agent2_pos: 8:1.00, 0:0.00, 7:0.00
    red_button_pos: 7:0.14, 3:0.14, 6:0.14
    blue_button_pos: 7:0.14, 3:0.14, 6:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Top policies: 8812:0.01; 24364:0.01; 11404:0.01; 26956:0.01; 8810:0.00
. r .
1 . 2
. b .

Reward: +0.00, Result: neutral

--- Step 2 ---
Joint action: 6 → Agent 1: DOWN, Agent 2: UP
  Beliefs:
    agent1_pos: 3:1.00, 8:0.00, 5:0.00
    agent2_pos: 5:1.00, 8:0.00, 3:0.00
    red_button_pos: 7:0.20, 1:0.20, 6:0.20
    blue_button_pos: 7:0.20, 1:0.20, 6:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Top policies: 8812:0.02; 11404:0.02; 24364:0.02; 11400:0.01; 8800:0.01
. r 2
. . .
1 b .

Reward: +0.00, Result: neutral
