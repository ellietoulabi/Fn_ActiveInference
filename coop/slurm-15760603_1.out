The following modules were not unloaded:
  (Use "module --force purge" to unload all):

  1) CCconfig        6)  ucx/1.14.1         11) flexiblas/3.3.1
  2) gentoo/2023     7)  libfabric/1.18.0   12) aocl-blas/5.1
  3) gcccore/.12.3   8)  pmix/4.2.4         13) aocl-lapack/5.1
  4) gcc/12.3        9)  ucc/1.2.0          14) StdEnv/2023
  5) hwloc/2.9.1     10) openmpi/4.1.5
Working in SLURM_TMPDIR: /localscratch/toulabin.15760715.0
Cloning repository...
Repository cloned.
Creating virtual environment...
Activated virtualenv.
Installing dependencies...
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/gentoo2023/x86-64-v4, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/gentoo2023/x86-64-v3, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/gentoo2023/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Requirement already satisfied: numpy>=1.20.0 in /cvmfs/soft.computecanada.ca/easybuild/software/2023/x86-64-v4/Compiler/gcccore/scipy-stack/2025a/lib/python3.11/site-packages (from -r requirements.txt (line 3)) (2.2.2+computecanada)
Collecting jax>=0.4.0 (from -r requirements.txt (line 4))
  Obtaining dependency information for jax>=0.4.0 from https://files.pythonhosted.org/packages/f9/e7/19b8cfc8963b2e10a01a4db7bb27ec5fa39ecd024bc62f8e2d1de5625a9d/jax-0.8.1-py3-none-any.whl.metadata
  Using cached jax-0.8.1-py3-none-any.whl.metadata (13 kB)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/gentoo2023/x86-64-v3/jaxlib-0.7.2+computecanada-cp311-cp311-linux_x86_64.whl (from -r requirements.txt (line 5))
Collecting gymnasium>=0.29.0 (from -r requirements.txt (line 8))
  Obtaining dependency information for gymnasium>=0.29.0 from https://files.pythonhosted.org/packages/c7/53/39cd8c2f85e213fce1f32367c4bdbd3402d3bcde7d0826a1172a0f2c5cc0/gymnasium-1.2.2-py3-none-any.whl.metadata
  Using cached gymnasium-1.2.2-py3-none-any.whl.metadata (10 kB)
Requirement already satisfied: pandas>=1.3.0 in /cvmfs/soft.computecanada.ca/easybuild/software/2023/x86-64-v4/Compiler/gcccore/scipy-stack/2025a/lib/python3.11/site-packages (from -r requirements.txt (line 11)) (2.2.3+computecanada)
Requirement already satisfied: scipy>=1.7.0 in /cvmfs/soft.computecanada.ca/easybuild/software/2023/x86-64-v4/Compiler/gcccore/scipy-stack/2025a/lib/python3.11/site-packages (from -r requirements.txt (line 14)) (1.15.1+computecanada)
Requirement already satisfied: matplotlib>=3.4.0 in /cvmfs/soft.computecanada.ca/easybuild/software/2023/x86-64-v4/Compiler/gcccore/scipy-stack/2025a/lib/python3.11/site-packages (from -r requirements.txt (line 17)) (3.10.0+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tqdm-4.67.1+computecanada-py3-none-any.whl (from -r requirements.txt (line 20))
INFO: pip is looking at multiple versions of jax to determine which version is compatible with other requirements. This could take a while.
Collecting jax>=0.4.0 (from -r requirements.txt (line 4))
  Obtaining dependency information for jax>=0.4.0 from https://files.pythonhosted.org/packages/b3/77/4e6c9a54247810eff8ac8a1af7dc1be0779b52df0d82f3fc8586061914f3/jax-0.8.0-py3-none-any.whl.metadata
  Using cached jax-0.8.0-py3-none-any.whl.metadata (13 kB)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/jax-0.7.2+computecanada-py3-none-any.whl (from -r requirements.txt (line 4))
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/gentoo2023/generic/ml_dtypes-0.5.1+computecanada-cp311-cp311-linux_x86_64.whl (from jax>=0.4.0->-r requirements.txt (line 4))
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/opt_einsum-3.4.0+computecanada-py3-none-any.whl (from jax>=0.4.0->-r requirements.txt (line 4))
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/cloudpickle-3.1.2+computecanada-py3-none-any.whl (from gymnasium>=0.29.0->-r requirements.txt (line 8))
Requirement already satisfied: typing-extensions>=4.3.0 in /cvmfs/soft.computecanada.ca/easybuild/software/2023/x86-64-v4/Compiler/gcccore/ipykernel/2025a/lib/python3.11/site-packages (from gymnasium>=0.29.0->-r requirements.txt (line 8)) (4.12.2+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/Farama_Notifications-0.0.4+computecanada-py3-none-any.whl (from gymnasium>=0.29.0->-r requirements.txt (line 8))
Requirement already satisfied: python-dateutil>=2.8.2 in /cvmfs/soft.computecanada.ca/easybuild/software/2023/x86-64-v4/Compiler/gcccore/scipy-stack/2025a/lib/python3.11/site-packages (from pandas>=1.3.0->-r requirements.txt (line 11)) (2.9.0.post0+computecanada)
Requirement already satisfied: pytz>=2020.1 in /cvmfs/soft.computecanada.ca/easybuild/software/2023/x86-64-v4/Compiler/gcccore/scipy-stack/2025a/lib/python3.11/site-packages (from pandas>=1.3.0->-r requirements.txt (line 11)) (2025.1+computecanada)
Requirement already satisfied: tzdata>=2022.7 in /cvmfs/soft.computecanada.ca/easybuild/software/2023/x86-64-v4/Compiler/gcccore/scipy-stack/2025a/lib/python3.11/site-packages (from pandas>=1.3.0->-r requirements.txt (line 11)) (2025.1+computecanada)
Requirement already satisfied: contourpy>=1.0.1 in /cvmfs/soft.computecanada.ca/easybuild/software/2023/x86-64-v4/Compiler/gcccore/scipy-stack/2025a/lib/python3.11/site-packages (from matplotlib>=3.4.0->-r requirements.txt (line 17)) (1.3.1+computecanada)
Requirement already satisfied: cycler>=0.10 in /cvmfs/soft.computecanada.ca/easybuild/software/2023/x86-64-v4/Compiler/gcccore/scipy-stack/2025a/lib/python3.11/site-packages (from matplotlib>=3.4.0->-r requirements.txt (line 17)) (0.12.1+computecanada)
Requirement already satisfied: fonttools>=4.22.0 in /cvmfs/soft.computecanada.ca/easybuild/software/2023/x86-64-v4/Compiler/gcccore/scipy-stack/2025a/lib/python3.11/site-packages (from matplotlib>=3.4.0->-r requirements.txt (line 17)) (4.55.8+computecanada)
Requirement already satisfied: kiwisolver>=1.3.1 in /cvmfs/soft.computecanada.ca/easybuild/software/2023/x86-64-v4/Compiler/gcccore/scipy-stack/2025a/lib/python3.11/site-packages (from matplotlib>=3.4.0->-r requirements.txt (line 17)) (1.4.8+computecanada)
Requirement already satisfied: packaging>=20.0 in /cvmfs/soft.computecanada.ca/easybuild/software/2023/x86-64-v4/Compiler/gcccore/scipy-stack/2025a/lib/python3.11/site-packages (from matplotlib>=3.4.0->-r requirements.txt (line 17)) (24.2+computecanada)
Requirement already satisfied: pillow>=8 in /cvmfs/soft.computecanada.ca/easybuild/software/2023/x86-64-v4/Compiler/gcccore/scipy-stack/2025a/lib/python3.11/site-packages (from matplotlib>=3.4.0->-r requirements.txt (line 17)) (11.1.0+computecanada)
Requirement already satisfied: pyparsing>=2.3.1 in /cvmfs/soft.computecanada.ca/easybuild/software/2023/x86-64-v4/Compiler/gcccore/scipy-stack/2025a/lib/python3.11/site-packages (from matplotlib>=3.4.0->-r requirements.txt (line 17)) (3.2.1+computecanada)
Requirement already satisfied: six>=1.5 in /cvmfs/soft.computecanada.ca/easybuild/software/2023/x86-64-v4/Compiler/gcccore/scipy-stack/2025a/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas>=1.3.0->-r requirements.txt (line 11)) (1.17.0+computecanada)
Using cached gymnasium-1.2.2-py3-none-any.whl (952 kB)
Installing collected packages: farama-notifications, tqdm, opt_einsum, ml_dtypes, cloudpickle, jaxlib, gymnasium, jax
Successfully installed cloudpickle-3.1.2+computecanada farama-notifications-0.0.4+computecanada gymnasium-1.2.2 jax-0.7.2+computecanada jaxlib-0.7.2+computecanada ml_dtypes-0.5.1+computecanada opt_einsum-3.4.0+computecanada tqdm-4.67.1+computecanada
Dependencies installed.
---- Starting seed index 1 ----
================================================================================
TWO ACTIVE INFERENCE AGENTS - RED BLUE BUTTON ENVIRONMENT
================================================================================

Experiment Parameters:
  Number of seeds: 1
  Episodes per seed: 100
  Episodes per config: 20
  Max steps per episode: 30
  Logging to: /localscratch/toulabin.15760715.0/project/Fn_ActiveInference/logs/two_aif_agents_seeds1_ep100_20251216_034907.csv

================================================================================
SEED 0 (1/1)
================================================================================

================================================================================
SEED 0 - CONFIG 1
Red at (1, 0), Blue at (1, 2)
Episodes 1-20
================================================================================

================================================================================
EPISODE 1
================================================================================
Environment: Red at (1, 0), Blue at (1, 2)

Initial state:
1 r .
. . .
. b 2


--- Step 1 ---
Agent 1: DOWN, Agent 2: LEFT
  Agent1 beliefs:
    agent_pos: 0:1.00, 8:0.00, 7:0.00
    red_button_pos: 8:0.12, 7:0.12, 6:0.12
    blue_button_pos: 8:0.12, 7:0.12, 6:0.12
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 8:1.00, 7:0.00, 6:0.00
    red_button_pos: 7:0.12, 3:0.12, 6:0.12
    blue_button_pos: 7:0.12, 3:0.12, 6:0.12
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 10:0.21; 22:0.21; 9:0.06; 19:0.06; 21:0.05
  Agent2 top policies: 16:0.21; 4:0.21; 12:0.06; 2:0.06; 0:0.05
. r .
1 . .
. 2 .

Reward: +0.00, Result: neutral

--- Step 2 ---
Agent 1: RIGHT, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 3:1.00, 0:0.00, 8:0.00
    red_button_pos: 8:0.14, 7:0.14, 6:0.14
    blue_button_pos: 8:0.14, 7:0.14, 6:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 7:1.00, 8:0.00, 6:0.00
    red_button_pos: 6:0.14, 1:0.14, 5:0.14
    blue_button_pos: 7:1.00, 3:0.00, 6:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 22:0.23; 10:0.23; 9:0.06; 21:0.05; 19:0.05
  Agent2 top policies: 4:0.13; 16:0.13; 12:0.06; 0:0.06; 2:0.06
. r .
. 1 .
. 2 .

Reward: +0.00, Result: neutral

--- Step 3 ---
Agent 1: RIGHT, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 4:1.00, 3:0.00, 0:0.00
    red_button_pos: 8:0.17, 7:0.17, 6:0.17
    blue_button_pos: 8:0.17, 7:0.17, 6:0.17
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 7:1.00, 4:0.00, 8:0.00
    red_button_pos: 6:0.14, 1:0.14, 5:0.14
    blue_button_pos: 7:1.00, 3:0.00, 6:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 22:0.18; 10:0.18; 4:0.18; 21:0.04; 9:0.04
  Agent2 top policies: 4:0.13; 16:0.13; 12:0.06; 0:0.06; 2:0.06
. r .
. 2 1
. b .

Reward: +0.00, Result: neutral

--- Step 4 ---
Agent 1: DOWN, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 5:1.00, 4:0.00, 3:0.00
    red_button_pos: 8:0.20, 7:0.20, 6:0.20
    blue_button_pos: 8:0.20, 7:0.20, 6:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 4:1.00, 8:0.00, 1:0.00
    red_button_pos: 6:0.17, 1:0.17, 5:0.17
    blue_button_pos: 7:0.99, 8:0.00, 6:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 10:0.27; 4:0.27; 8:0.05; 2:0.05; 7:0.05
  Agent2 top policies: 4:0.10; 16:0.10; 22:0.10; 0:0.04; 12:0.04
. 2 .
. . .
. b 1

Reward: +0.00, Result: neutral

--- Step 5 ---
Agent 1: LEFT, Agent 2: PRESS
  Agent1 beliefs:
    agent_pos: 8:1.00, 5:0.00, 4:0.00
    red_button_pos: 7:0.25, 1:0.25, 6:0.25
    blue_button_pos: 7:0.25, 1:0.25, 6:0.25
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 1:1.00, 0:0.00, 2:0.00
    red_button_pos: 1:1.00, 2:0.00, 6:0.00
    blue_button_pos: 7:0.98, 8:0.00, 6:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 16:0.63; 14:0.09; 13:0.09; 17:0.07; 12:0.01
  Agent2 top policies: 24:0.06; 4:0.06; 25:0.06; 26:0.05; 27:0.05
. 2 .
. . .
. 1 .

Reward: +0.00, Result: neutral
Button pressed: red by Agent 2

--- Step 6 ---
Agent 1: LEFT, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 7:1.00, 3:0.00, 0:0.00
    red_button_pos: 1:0.32, 2:0.32, 6:0.32
    blue_button_pos: 7:1.00, 1:0.00, 6:0.00
    red_button_state: 0:0.50, 1:0.50
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 2:0.00, 6:0.00
    blue_button_pos: 7:0.98, 8:0.00, 6:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 14:0.10; 13:0.10; 16:0.10; 17:0.08; 26:0.07
  Agent2 top policies: 4:0.04; 28:0.04; 7:0.04; 24:0.04; 0:0.04
. 2 .
. . .
1 b .

Reward: +0.00, Result: neutral

--- Step 7 ---
Agent 1: RIGHT, Agent 2: DOWN
  Agent1 beliefs:
    agent_pos: 6:1.00, 8:0.00, 5:0.00
    red_button_pos: 1:0.47, 2:0.47, 0:0.02
    blue_button_pos: 7:0.99, 1:0.00, 2:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 8:0.00, 7:0.00
    blue_button_pos: 7:0.97, 8:0.00, 6:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 22:0.36; 19:0.03; 18:0.03; 4:0.02; 0:0.02
  Agent2 top policies: 7:0.04; 28:0.04; 4:0.04; 24:0.03; 0:0.03
. R .
. 2 .
. 1 .

Reward: +0.00, Result: neutral

--- Step 8 ---
Agent 1: PRESS, Agent 2: DOWN
  Agent1 beliefs:
    agent_pos: 7:1.00, 5:0.00, 2:0.00
    red_button_pos: 1:0.47, 2:0.47, 0:0.02
    blue_button_pos: 7:1.00, 1:0.00, 2:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 4:1.00, 8:0.00, 6:0.00
    red_button_pos: 1:0.99, 8:0.00, 7:0.00
    blue_button_pos: 7:0.96, 8:0.01, 6:0.01
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 25:0.17; 24:0.17; 27:0.16; 26:0.15; 28:0.14
  Agent2 top policies: 10:0.42; 7:0.03; 11:0.02; 4:0.02; 0:0.02
. R .
. 2 .
. 1 .

Reward: +1.00, Result: win
Button pressed: blue by Agent 1

Result: ✅ WIN - win (steps: 8, reward: +1.00)

================================================================================
EPISODE 2
================================================================================
Environment: Red at (1, 0), Blue at (1, 2)

Initial state:
1 r .
. . .
. b 2


--- Step 1 ---
Agent 1: DOWN, Agent 2: LEFT
  Agent1 beliefs:
    agent_pos: 0:1.00, 8:0.00, 7:0.00
    red_button_pos: 8:0.12, 7:0.12, 6:0.12
    blue_button_pos: 8:0.12, 7:0.12, 6:0.12
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 8:1.00, 7:0.00, 6:0.00
    red_button_pos: 7:0.12, 3:0.12, 6:0.12
    blue_button_pos: 7:0.12, 3:0.12, 6:0.12
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 10:0.21; 22:0.21; 9:0.06; 19:0.06; 21:0.05
  Agent2 top policies: 16:0.21; 4:0.21; 12:0.06; 2:0.06; 0:0.05
. r .
1 . .
. 2 .

Reward: +0.00, Result: neutral

--- Step 2 ---
Agent 1: RIGHT, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 3:1.00, 0:0.00, 8:0.00
    red_button_pos: 8:0.14, 7:0.14, 6:0.14
    blue_button_pos: 8:0.14, 7:0.14, 6:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 7:1.00, 8:0.00, 6:0.00
    red_button_pos: 6:0.14, 1:0.14, 5:0.14
    blue_button_pos: 7:1.00, 3:0.00, 6:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 22:0.23; 10:0.23; 9:0.06; 21:0.05; 19:0.05
  Agent2 top policies: 4:0.13; 16:0.13; 12:0.06; 0:0.06; 2:0.06
. r .
. 1 .
. 2 .

Reward: +0.00, Result: neutral

--- Step 3 ---
Agent 1: RIGHT, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 4:1.00, 3:0.00, 0:0.00
    red_button_pos: 8:0.17, 7:0.17, 6:0.17
    blue_button_pos: 8:0.17, 7:0.17, 6:0.17
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 7:1.00, 4:0.00, 8:0.00
    red_button_pos: 6:0.14, 1:0.14, 5:0.14
    blue_button_pos: 7:1.00, 3:0.00, 6:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 22:0.18; 10:0.18; 4:0.18; 21:0.04; 9:0.04
  Agent2 top policies: 4:0.13; 16:0.13; 12:0.06; 0:0.06; 2:0.06
. r .
. 2 1
. b .

Reward: +0.00, Result: neutral

--- Step 4 ---
Agent 1: DOWN, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 5:1.00, 4:0.00, 3:0.00
    red_button_pos: 8:0.20, 7:0.20, 6:0.20
    blue_button_pos: 8:0.20, 7:0.20, 6:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 4:1.00, 8:0.00, 1:0.00
    red_button_pos: 6:0.17, 1:0.17, 5:0.17
    blue_button_pos: 7:0.99, 8:0.00, 6:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 10:0.27; 4:0.27; 8:0.05; 2:0.05; 7:0.05
  Agent2 top policies: 4:0.10; 16:0.10; 22:0.10; 0:0.04; 12:0.04
. 2 .
. . .
. b 1

Reward: +0.00, Result: neutral

--- Step 5 ---
Agent 1: LEFT, Agent 2: PRESS
  Agent1 beliefs:
    agent_pos: 8:1.00, 5:0.00, 4:0.00
    red_button_pos: 7:0.25, 1:0.25, 6:0.25
    blue_button_pos: 7:0.25, 1:0.25, 6:0.25
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 1:1.00, 0:0.00, 2:0.00
    red_button_pos: 1:1.00, 2:0.00, 6:0.00
    blue_button_pos: 7:0.98, 8:0.00, 6:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 16:0.63; 14:0.09; 13:0.09; 17:0.07; 12:0.01
  Agent2 top policies: 24:0.06; 4:0.06; 25:0.06; 26:0.05; 27:0.05
. 2 .
. . .
. 1 .

Reward: +0.00, Result: neutral
Button pressed: red by Agent 2

--- Step 6 ---
Agent 1: LEFT, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 7:1.00, 3:0.00, 0:0.00
    red_button_pos: 1:0.32, 2:0.32, 6:0.32
    blue_button_pos: 7:1.00, 1:0.00, 6:0.00
    red_button_state: 0:0.50, 1:0.50
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 2:0.00, 6:0.00
    blue_button_pos: 7:0.98, 8:0.00, 6:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 14:0.10; 13:0.10; 16:0.10; 17:0.08; 26:0.07
  Agent2 top policies: 4:0.04; 28:0.04; 7:0.04; 24:0.04; 0:0.04
. 2 .
. . .
1 b .

Reward: +0.00, Result: neutral

--- Step 7 ---
Agent 1: RIGHT, Agent 2: DOWN
  Agent1 beliefs:
    agent_pos: 6:1.00, 8:0.00, 5:0.00
    red_button_pos: 1:0.47, 2:0.47, 0:0.02
    blue_button_pos: 7:0.99, 1:0.00, 2:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 8:0.00, 7:0.00
    blue_button_pos: 7:0.97, 8:0.00, 6:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 22:0.36; 19:0.03; 18:0.03; 4:0.02; 0:0.02
  Agent2 top policies: 7:0.04; 28:0.04; 4:0.04; 24:0.03; 0:0.03
. R .
. 2 .
. 1 .

Reward: +0.00, Result: neutral

--- Step 8 ---
Agent 1: PRESS, Agent 2: DOWN
  Agent1 beliefs:
    agent_pos: 7:1.00, 5:0.00, 2:0.00
    red_button_pos: 1:0.47, 2:0.47, 0:0.02
    blue_button_pos: 7:1.00, 1:0.00, 2:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 4:1.00, 8:0.00, 6:0.00
    red_button_pos: 1:0.99, 8:0.00, 7:0.00
    blue_button_pos: 7:0.96, 8:0.01, 6:0.01
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 25:0.17; 24:0.17; 27:0.16; 26:0.15; 28:0.14
  Agent2 top policies: 10:0.42; 7:0.03; 11:0.02; 4:0.02; 0:0.02
. R .
. 2 .
. 1 .

Reward: +1.00, Result: win
Button pressed: blue by Agent 1

Result: ✅ WIN - win (steps: 8, reward: +1.00)

================================================================================
EPISODE 3
================================================================================
Environment: Red at (1, 0), Blue at (1, 2)

Initial state:
1 r .
. . .
. b 2


--- Step 1 ---
Agent 1: DOWN, Agent 2: LEFT
  Agent1 beliefs:
    agent_pos: 0:1.00, 8:0.00, 7:0.00
    red_button_pos: 8:0.12, 7:0.12, 6:0.12
    blue_button_pos: 8:0.12, 7:0.12, 6:0.12
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 8:1.00, 7:0.00, 6:0.00
    red_button_pos: 7:0.12, 3:0.12, 6:0.12
    blue_button_pos: 7:0.12, 3:0.12, 6:0.12
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 10:0.21; 22:0.21; 9:0.06; 19:0.06; 21:0.05
  Agent2 top policies: 16:0.21; 4:0.21; 12:0.06; 2:0.06; 0:0.05
. r .
1 . .
. 2 .

Reward: +0.00, Result: neutral

--- Step 2 ---
Agent 1: RIGHT, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 3:1.00, 0:0.00, 8:0.00
    red_button_pos: 8:0.14, 7:0.14, 6:0.14
    blue_button_pos: 8:0.14, 7:0.14, 6:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 7:1.00, 8:0.00, 6:0.00
    red_button_pos: 6:0.14, 1:0.14, 5:0.14
    blue_button_pos: 7:1.00, 3:0.00, 6:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 22:0.23; 10:0.23; 9:0.06; 21:0.05; 19:0.05
  Agent2 top policies: 4:0.13; 16:0.13; 12:0.06; 0:0.06; 2:0.06
. r .
. 1 .
. 2 .

Reward: +0.00, Result: neutral

--- Step 3 ---
Agent 1: RIGHT, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 4:1.00, 3:0.00, 0:0.00
    red_button_pos: 8:0.17, 7:0.17, 6:0.17
    blue_button_pos: 8:0.17, 7:0.17, 6:0.17
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 7:1.00, 4:0.00, 8:0.00
    red_button_pos: 6:0.14, 1:0.14, 5:0.14
    blue_button_pos: 7:1.00, 3:0.00, 6:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 22:0.18; 10:0.18; 4:0.18; 21:0.04; 9:0.04
  Agent2 top policies: 4:0.13; 16:0.13; 12:0.06; 0:0.06; 2:0.06
. r .
. 2 1
. b .

Reward: +0.00, Result: neutral

--- Step 4 ---
Agent 1: DOWN, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 5:1.00, 4:0.00, 3:0.00
    red_button_pos: 8:0.20, 7:0.20, 6:0.20
    blue_button_pos: 8:0.20, 7:0.20, 6:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 4:1.00, 8:0.00, 1:0.00
    red_button_pos: 6:0.17, 1:0.17, 5:0.17
    blue_button_pos: 7:0.99, 8:0.00, 6:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 10:0.27; 4:0.27; 8:0.05; 2:0.05; 7:0.05
  Agent2 top policies: 4:0.10; 16:0.10; 22:0.10; 0:0.04; 12:0.04
. 2 .
. . .
. b 1

Reward: +0.00, Result: neutral

--- Step 5 ---
Agent 1: LEFT, Agent 2: PRESS
  Agent1 beliefs:
    agent_pos: 8:1.00, 5:0.00, 4:0.00
    red_button_pos: 7:0.25, 1:0.25, 6:0.25
    blue_button_pos: 7:0.25, 1:0.25, 6:0.25
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 1:1.00, 0:0.00, 2:0.00
    red_button_pos: 1:1.00, 2:0.00, 6:0.00
    blue_button_pos: 7:0.98, 8:0.00, 6:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 16:0.63; 14:0.09; 13:0.09; 17:0.07; 12:0.01
  Agent2 top policies: 24:0.06; 4:0.06; 25:0.06; 26:0.05; 27:0.05
. 2 .
. . .
. 1 .

Reward: +0.00, Result: neutral
Button pressed: red by Agent 2

--- Step 6 ---
Agent 1: LEFT, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 7:1.00, 3:0.00, 0:0.00
    red_button_pos: 1:0.32, 2:0.32, 6:0.32
    blue_button_pos: 7:1.00, 1:0.00, 6:0.00
    red_button_state: 0:0.50, 1:0.50
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 2:0.00, 6:0.00
    blue_button_pos: 7:0.98, 8:0.00, 6:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 14:0.10; 13:0.10; 16:0.10; 17:0.08; 26:0.07
  Agent2 top policies: 4:0.04; 28:0.04; 7:0.04; 24:0.04; 0:0.04
. 2 .
. . .
1 b .

Reward: +0.00, Result: neutral

--- Step 7 ---
Agent 1: RIGHT, Agent 2: DOWN
  Agent1 beliefs:
    agent_pos: 6:1.00, 8:0.00, 5:0.00
    red_button_pos: 1:0.47, 2:0.47, 0:0.02
    blue_button_pos: 7:0.99, 1:0.00, 2:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 8:0.00, 7:0.00
    blue_button_pos: 7:0.97, 8:0.00, 6:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 22:0.36; 19:0.03; 18:0.03; 4:0.02; 0:0.02
  Agent2 top policies: 7:0.04; 28:0.04; 4:0.04; 24:0.03; 0:0.03
. R .
. 2 .
. 1 .

Reward: +0.00, Result: neutral

--- Step 8 ---
Agent 1: PRESS, Agent 2: DOWN
  Agent1 beliefs:
    agent_pos: 7:1.00, 5:0.00, 2:0.00
    red_button_pos: 1:0.47, 2:0.47, 0:0.02
    blue_button_pos: 7:1.00, 1:0.00, 2:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 4:1.00, 8:0.00, 6:0.00
    red_button_pos: 1:0.99, 8:0.00, 7:0.00
    blue_button_pos: 7:0.96, 8:0.01, 6:0.01
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 25:0.17; 24:0.17; 27:0.16; 26:0.15; 28:0.14
  Agent2 top policies: 10:0.42; 7:0.03; 11:0.02; 4:0.02; 0:0.02
. R .
. 2 .
. 1 .

Reward: +1.00, Result: win
Button pressed: blue by Agent 1

Result: ✅ WIN - win (steps: 8, reward: +1.00)

================================================================================
EPISODE 4
================================================================================
Environment: Red at (1, 0), Blue at (1, 2)

Initial state:
1 r .
. . .
. b 2


--- Step 1 ---
Agent 1: DOWN, Agent 2: LEFT
  Agent1 beliefs:
    agent_pos: 0:1.00, 8:0.00, 7:0.00
    red_button_pos: 8:0.12, 7:0.12, 6:0.12
    blue_button_pos: 8:0.12, 7:0.12, 6:0.12
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 8:1.00, 7:0.00, 6:0.00
    red_button_pos: 7:0.12, 3:0.12, 6:0.12
    blue_button_pos: 7:0.12, 3:0.12, 6:0.12
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 10:0.21; 22:0.21; 9:0.06; 19:0.06; 21:0.05
  Agent2 top policies: 16:0.21; 4:0.21; 12:0.06; 2:0.06; 0:0.05
. r .
1 . .
. 2 .

Reward: +0.00, Result: neutral

--- Step 2 ---
Agent 1: RIGHT, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 3:1.00, 0:0.00, 8:0.00
    red_button_pos: 8:0.14, 7:0.14, 6:0.14
    blue_button_pos: 8:0.14, 7:0.14, 6:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 7:1.00, 8:0.00, 6:0.00
    red_button_pos: 6:0.14, 1:0.14, 5:0.14
    blue_button_pos: 7:1.00, 3:0.00, 6:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 22:0.23; 10:0.23; 9:0.06; 21:0.05; 19:0.05
  Agent2 top policies: 4:0.13; 16:0.13; 12:0.06; 0:0.06; 2:0.06
. r .
. 1 .
. 2 .

Reward: +0.00, Result: neutral

--- Step 3 ---
Agent 1: RIGHT, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 4:1.00, 3:0.00, 0:0.00
    red_button_pos: 8:0.17, 7:0.17, 6:0.17
    blue_button_pos: 8:0.17, 7:0.17, 6:0.17
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 7:1.00, 4:0.00, 8:0.00
    red_button_pos: 6:0.14, 1:0.14, 5:0.14
    blue_button_pos: 7:1.00, 3:0.00, 6:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 22:0.18; 10:0.18; 4:0.18; 21:0.04; 9:0.04
  Agent2 top policies: 4:0.13; 16:0.13; 12:0.06; 0:0.06; 2:0.06
. r .
. 2 1
. b .

Reward: +0.00, Result: neutral

--- Step 4 ---
Agent 1: DOWN, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 5:1.00, 4:0.00, 3:0.00
    red_button_pos: 8:0.20, 7:0.20, 6:0.20
    blue_button_pos: 8:0.20, 7:0.20, 6:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 4:1.00, 8:0.00, 1:0.00
    red_button_pos: 6:0.17, 1:0.17, 5:0.17
    blue_button_pos: 7:0.99, 8:0.00, 6:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 10:0.27; 4:0.27; 8:0.05; 2:0.05; 7:0.05
  Agent2 top policies: 4:0.10; 16:0.10; 22:0.10; 0:0.04; 12:0.04
. 2 .
. . .
. b 1

Reward: +0.00, Result: neutral

--- Step 5 ---
Agent 1: LEFT, Agent 2: PRESS
  Agent1 beliefs:
    agent_pos: 8:1.00, 5:0.00, 4:0.00
    red_button_pos: 7:0.25, 1:0.25, 6:0.25
    blue_button_pos: 7:0.25, 1:0.25, 6:0.25
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 1:1.00, 0:0.00, 2:0.00
    red_button_pos: 1:1.00, 2:0.00, 6:0.00
    blue_button_pos: 7:0.98, 8:0.00, 6:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 16:0.63; 14:0.09; 13:0.09; 17:0.07; 12:0.01
  Agent2 top policies: 24:0.06; 4:0.06; 25:0.06; 26:0.05; 27:0.05
. 2 .
. . .
. 1 .

Reward: +0.00, Result: neutral
Button pressed: red by Agent 2

--- Step 6 ---
Agent 1: LEFT, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 7:1.00, 3:0.00, 0:0.00
    red_button_pos: 1:0.32, 2:0.32, 6:0.32
    blue_button_pos: 7:1.00, 1:0.00, 6:0.00
    red_button_state: 0:0.50, 1:0.50
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 2:0.00, 6:0.00
    blue_button_pos: 7:0.98, 8:0.00, 6:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 14:0.10; 13:0.10; 16:0.10; 17:0.08; 26:0.07
  Agent2 top policies: 4:0.04; 28:0.04; 7:0.04; 24:0.04; 0:0.04
. 2 .
. . .
1 b .

Reward: +0.00, Result: neutral

--- Step 7 ---
Agent 1: RIGHT, Agent 2: DOWN
  Agent1 beliefs:
    agent_pos: 6:1.00, 8:0.00, 5:0.00
    red_button_pos: 1:0.47, 2:0.47, 0:0.02
    blue_button_pos: 7:0.99, 1:0.00, 2:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 8:0.00, 7:0.00
    blue_button_pos: 7:0.97, 8:0.00, 6:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 22:0.36; 19:0.03; 18:0.03; 4:0.02; 0:0.02
  Agent2 top policies: 7:0.04; 28:0.04; 4:0.04; 24:0.03; 0:0.03
. R .
. 2 .
. 1 .

Reward: +0.00, Result: neutral

--- Step 8 ---
Agent 1: PRESS, Agent 2: DOWN
  Agent1 beliefs:
    agent_pos: 7:1.00, 5:0.00, 2:0.00
    red_button_pos: 1:0.47, 2:0.47, 0:0.02
    blue_button_pos: 7:1.00, 1:0.00, 2:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 4:1.00, 8:0.00, 6:0.00
    red_button_pos: 1:0.99, 8:0.00, 7:0.00
    blue_button_pos: 7:0.96, 8:0.01, 6:0.01
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 25:0.17; 24:0.17; 27:0.16; 26:0.15; 28:0.14
  Agent2 top policies: 10:0.42; 7:0.03; 11:0.02; 4:0.02; 0:0.02
. R .
. 2 .
. 1 .

Reward: +1.00, Result: win
Button pressed: blue by Agent 1

Result: ✅ WIN - win (steps: 8, reward: +1.00)

================================================================================
EPISODE 5
================================================================================
Environment: Red at (1, 0), Blue at (1, 2)

Initial state:
1 r .
. . .
. b 2


--- Step 1 ---
Agent 1: DOWN, Agent 2: LEFT
  Agent1 beliefs:
    agent_pos: 0:1.00, 8:0.00, 7:0.00
    red_button_pos: 8:0.12, 7:0.12, 6:0.12
    blue_button_pos: 8:0.12, 7:0.12, 6:0.12
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 8:1.00, 7:0.00, 6:0.00
    red_button_pos: 7:0.12, 3:0.12, 6:0.12
    blue_button_pos: 7:0.12, 3:0.12, 6:0.12
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 10:0.21; 22:0.21; 9:0.06; 19:0.06; 21:0.05
  Agent2 top policies: 16:0.21; 4:0.21; 12:0.06; 2:0.06; 0:0.05
. r .
1 . .
. 2 .

Reward: +0.00, Result: neutral

--- Step 2 ---
Agent 1: RIGHT, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 3:1.00, 0:0.00, 8:0.00
    red_button_pos: 8:0.14, 7:0.14, 6:0.14
    blue_button_pos: 8:0.14, 7:0.14, 6:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 7:1.00, 8:0.00, 6:0.00
    red_button_pos: 6:0.14, 1:0.14, 5:0.14
    blue_button_pos: 7:1.00, 3:0.00, 6:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 22:0.23; 10:0.23; 9:0.06; 21:0.05; 19:0.05
  Agent2 top policies: 4:0.13; 16:0.13; 12:0.06; 0:0.06; 2:0.06
. r .
. 1 .
. 2 .

Reward: +0.00, Result: neutral

--- Step 3 ---
Agent 1: RIGHT, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 4:1.00, 3:0.00, 0:0.00
    red_button_pos: 8:0.17, 7:0.17, 6:0.17
    blue_button_pos: 8:0.17, 7:0.17, 6:0.17
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 7:1.00, 4:0.00, 8:0.00
    red_button_pos: 6:0.14, 1:0.14, 5:0.14
    blue_button_pos: 7:1.00, 3:0.00, 6:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 22:0.18; 10:0.18; 4:0.18; 21:0.04; 9:0.04
  Agent2 top policies: 4:0.13; 16:0.13; 12:0.06; 0:0.06; 2:0.06
. r .
. 2 1
. b .

Reward: +0.00, Result: neutral

--- Step 4 ---
Agent 1: DOWN, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 5:1.00, 4:0.00, 3:0.00
    red_button_pos: 8:0.20, 7:0.20, 6:0.20
    blue_button_pos: 8:0.20, 7:0.20, 6:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 4:1.00, 8:0.00, 1:0.00
    red_button_pos: 6:0.17, 1:0.17, 5:0.17
    blue_button_pos: 7:0.99, 8:0.00, 6:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 10:0.27; 4:0.27; 8:0.05; 2:0.05; 7:0.05
  Agent2 top policies: 4:0.10; 16:0.10; 22:0.10; 0:0.04; 12:0.04
. 2 .
. . .
. b 1

Reward: +0.00, Result: neutral

--- Step 5 ---
Agent 1: LEFT, Agent 2: PRESS
  Agent1 beliefs:
    agent_pos: 8:1.00, 5:0.00, 4:0.00
    red_button_pos: 7:0.25, 1:0.25, 6:0.25
    blue_button_pos: 7:0.25, 1:0.25, 6:0.25
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 1:1.00, 0:0.00, 2:0.00
    red_button_pos: 1:1.00, 2:0.00, 6:0.00
    blue_button_pos: 7:0.98, 8:0.00, 6:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 16:0.63; 14:0.09; 13:0.09; 17:0.07; 12:0.01
  Agent2 top policies: 24:0.06; 4:0.06; 25:0.06; 26:0.05; 27:0.05
. 2 .
. . .
. 1 .

Reward: +0.00, Result: neutral
Button pressed: red by Agent 2

--- Step 6 ---
Agent 1: LEFT, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 7:1.00, 3:0.00, 0:0.00
    red_button_pos: 1:0.32, 2:0.32, 6:0.32
    blue_button_pos: 7:1.00, 1:0.00, 6:0.00
    red_button_state: 0:0.50, 1:0.50
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 2:0.00, 6:0.00
    blue_button_pos: 7:0.98, 8:0.00, 6:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 14:0.10; 13:0.10; 16:0.10; 17:0.08; 26:0.07
  Agent2 top policies: 4:0.04; 28:0.04; 7:0.04; 24:0.04; 0:0.04
. 2 .
. . .
1 b .

Reward: +0.00, Result: neutral

--- Step 7 ---
Agent 1: RIGHT, Agent 2: DOWN
  Agent1 beliefs:
    agent_pos: 6:1.00, 8:0.00, 5:0.00
    red_button_pos: 1:0.47, 2:0.47, 0:0.02
    blue_button_pos: 7:0.99, 1:0.00, 2:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 8:0.00, 7:0.00
    blue_button_pos: 7:0.97, 8:0.00, 6:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 22:0.36; 19:0.03; 18:0.03; 4:0.02; 0:0.02
  Agent2 top policies: 7:0.04; 28:0.04; 4:0.04; 24:0.03; 0:0.03
. R .
. 2 .
. 1 .

Reward: +0.00, Result: neutral

--- Step 8 ---
Agent 1: PRESS, Agent 2: DOWN
  Agent1 beliefs:
    agent_pos: 7:1.00, 5:0.00, 2:0.00
    red_button_pos: 1:0.47, 2:0.47, 0:0.02
    blue_button_pos: 7:1.00, 1:0.00, 2:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 4:1.00, 8:0.00, 6:0.00
    red_button_pos: 1:0.99, 8:0.00, 7:0.00
    blue_button_pos: 7:0.96, 8:0.01, 6:0.01
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 25:0.17; 24:0.17; 27:0.16; 26:0.15; 28:0.14
  Agent2 top policies: 10:0.42; 7:0.03; 11:0.02; 4:0.02; 0:0.02
. R .
. 2 .
. 1 .

Reward: +1.00, Result: win
Button pressed: blue by Agent 1

Result: ✅ WIN - win (steps: 8, reward: +1.00)

================================================================================
EPISODE 6
================================================================================
Environment: Red at (1, 0), Blue at (1, 2)

Initial state:
1 r .
. . .
. b 2


--- Step 1 ---
Agent 1: DOWN, Agent 2: LEFT
  Agent1 beliefs:
    agent_pos: 0:1.00, 8:0.00, 7:0.00
    red_button_pos: 8:0.12, 7:0.12, 6:0.12
    blue_button_pos: 8:0.12, 7:0.12, 6:0.12
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 8:1.00, 7:0.00, 6:0.00
    red_button_pos: 7:0.12, 3:0.12, 6:0.12
    blue_button_pos: 7:0.12, 3:0.12, 6:0.12
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 10:0.21; 22:0.21; 9:0.06; 19:0.06; 21:0.05
  Agent2 top policies: 16:0.21; 4:0.21; 12:0.06; 2:0.06; 0:0.05
. r .
1 . .
. 2 .

Reward: +0.00, Result: neutral

--- Step 2 ---
Agent 1: RIGHT, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 3:1.00, 0:0.00, 8:0.00
    red_button_pos: 8:0.14, 7:0.14, 6:0.14
    blue_button_pos: 8:0.14, 7:0.14, 6:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 7:1.00, 8:0.00, 6:0.00
    red_button_pos: 6:0.14, 1:0.14, 5:0.14
    blue_button_pos: 7:1.00, 3:0.00, 6:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 22:0.23; 10:0.23; 9:0.06; 21:0.05; 19:0.05
  Agent2 top policies: 4:0.13; 16:0.13; 12:0.06; 0:0.06; 2:0.06
. r .
. 1 .
. 2 .

Reward: +0.00, Result: neutral

--- Step 3 ---
Agent 1: RIGHT, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 4:1.00, 3:0.00, 0:0.00
    red_button_pos: 8:0.17, 7:0.17, 6:0.17
    blue_button_pos: 8:0.17, 7:0.17, 6:0.17
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 7:1.00, 4:0.00, 8:0.00
    red_button_pos: 6:0.14, 1:0.14, 5:0.14
    blue_button_pos: 7:1.00, 3:0.00, 6:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 22:0.18; 10:0.18; 4:0.18; 21:0.04; 9:0.04
  Agent2 top policies: 4:0.13; 16:0.13; 12:0.06; 0:0.06; 2:0.06
. r .
. 2 1
. b .

Reward: +0.00, Result: neutral

--- Step 4 ---
Agent 1: DOWN, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 5:1.00, 4:0.00, 3:0.00
    red_button_pos: 8:0.20, 7:0.20, 6:0.20
    blue_button_pos: 8:0.20, 7:0.20, 6:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 4:1.00, 8:0.00, 1:0.00
    red_button_pos: 6:0.17, 1:0.17, 5:0.17
    blue_button_pos: 7:0.99, 8:0.00, 6:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 10:0.27; 4:0.27; 8:0.05; 2:0.05; 7:0.05
  Agent2 top policies: 4:0.10; 16:0.10; 22:0.10; 0:0.04; 12:0.04
. 2 .
. . .
. b 1

Reward: +0.00, Result: neutral

--- Step 5 ---
Agent 1: LEFT, Agent 2: PRESS
  Agent1 beliefs:
    agent_pos: 8:1.00, 5:0.00, 4:0.00
    red_button_pos: 7:0.25, 1:0.25, 6:0.25
    blue_button_pos: 7:0.25, 1:0.25, 6:0.25
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 1:1.00, 0:0.00, 2:0.00
    red_button_pos: 1:1.00, 2:0.00, 6:0.00
    blue_button_pos: 7:0.98, 8:0.00, 6:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 16:0.63; 14:0.09; 13:0.09; 17:0.07; 12:0.01
  Agent2 top policies: 24:0.06; 4:0.06; 25:0.06; 26:0.05; 27:0.05
. 2 .
. . .
. 1 .

Reward: +0.00, Result: neutral
Button pressed: red by Agent 2

--- Step 6 ---
Agent 1: LEFT, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 7:1.00, 3:0.00, 0:0.00
    red_button_pos: 1:0.32, 2:0.32, 6:0.32
    blue_button_pos: 7:1.00, 1:0.00, 6:0.00
    red_button_state: 0:0.50, 1:0.50
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 2:0.00, 6:0.00
    blue_button_pos: 7:0.98, 8:0.00, 6:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 14:0.10; 13:0.10; 16:0.10; 17:0.08; 26:0.07
  Agent2 top policies: 4:0.04; 28:0.04; 7:0.04; 24:0.04; 0:0.04
. 2 .
. . .
1 b .

Reward: +0.00, Result: neutral

--- Step 7 ---
Agent 1: RIGHT, Agent 2: DOWN
  Agent1 beliefs:
    agent_pos: 6:1.00, 8:0.00, 5:0.00
    red_button_pos: 1:0.47, 2:0.47, 0:0.02
    blue_button_pos: 7:0.99, 1:0.00, 2:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 8:0.00, 7:0.00
    blue_button_pos: 7:0.97, 8:0.00, 6:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 22:0.36; 19:0.03; 18:0.03; 4:0.02; 0:0.02
  Agent2 top policies: 7:0.04; 28:0.04; 4:0.04; 24:0.03; 0:0.03
. R .
. 2 .
. 1 .

Reward: +0.00, Result: neutral

--- Step 8 ---
Agent 1: PRESS, Agent 2: DOWN
  Agent1 beliefs:
    agent_pos: 7:1.00, 5:0.00, 2:0.00
    red_button_pos: 1:0.47, 2:0.47, 0:0.02
    blue_button_pos: 7:1.00, 1:0.00, 2:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 4:1.00, 8:0.00, 6:0.00
    red_button_pos: 1:0.99, 8:0.00, 7:0.00
    blue_button_pos: 7:0.96, 8:0.01, 6:0.01
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 25:0.17; 24:0.17; 27:0.16; 26:0.15; 28:0.14
  Agent2 top policies: 10:0.42; 7:0.03; 11:0.02; 4:0.02; 0:0.02
. R .
. 2 .
. 1 .

Reward: +1.00, Result: win
Button pressed: blue by Agent 1

Result: ✅ WIN - win (steps: 8, reward: +1.00)

================================================================================
EPISODE 7
================================================================================
Environment: Red at (1, 0), Blue at (1, 2)

Initial state:
1 r .
. . .
. b 2


--- Step 1 ---
Agent 1: DOWN, Agent 2: LEFT
  Agent1 beliefs:
    agent_pos: 0:1.00, 8:0.00, 7:0.00
    red_button_pos: 8:0.12, 7:0.12, 6:0.12
    blue_button_pos: 8:0.12, 7:0.12, 6:0.12
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 8:1.00, 7:0.00, 6:0.00
    red_button_pos: 7:0.12, 3:0.12, 6:0.12
    blue_button_pos: 7:0.12, 3:0.12, 6:0.12
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 10:0.21; 22:0.21; 9:0.06; 19:0.06; 21:0.05
  Agent2 top policies: 16:0.21; 4:0.21; 12:0.06; 2:0.06; 0:0.05
. r .
1 . .
. 2 .

Reward: +0.00, Result: neutral

--- Step 2 ---
Agent 1: RIGHT, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 3:1.00, 0:0.00, 8:0.00
    red_button_pos: 8:0.14, 7:0.14, 6:0.14
    blue_button_pos: 8:0.14, 7:0.14, 6:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 7:1.00, 8:0.00, 6:0.00
    red_button_pos: 6:0.14, 1:0.14, 5:0.14
    blue_button_pos: 7:1.00, 3:0.00, 6:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 22:0.23; 10:0.23; 9:0.06; 21:0.05; 19:0.05
  Agent2 top policies: 4:0.13; 16:0.13; 12:0.06; 0:0.06; 2:0.06
. r .
. 1 .
. 2 .

Reward: +0.00, Result: neutral

--- Step 3 ---
Agent 1: RIGHT, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 4:1.00, 3:0.00, 0:0.00
    red_button_pos: 8:0.17, 7:0.17, 6:0.17
    blue_button_pos: 8:0.17, 7:0.17, 6:0.17
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 7:1.00, 4:0.00, 8:0.00
    red_button_pos: 6:0.14, 1:0.14, 5:0.14
    blue_button_pos: 7:1.00, 3:0.00, 6:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 22:0.18; 10:0.18; 4:0.18; 21:0.04; 9:0.04
  Agent2 top policies: 4:0.13; 16:0.13; 12:0.06; 0:0.06; 2:0.06
. r .
. 2 1
. b .

Reward: +0.00, Result: neutral

--- Step 4 ---
Agent 1: DOWN, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 5:1.00, 4:0.00, 3:0.00
    red_button_pos: 8:0.20, 7:0.20, 6:0.20
    blue_button_pos: 8:0.20, 7:0.20, 6:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 4:1.00, 8:0.00, 1:0.00
    red_button_pos: 6:0.17, 1:0.17, 5:0.17
    blue_button_pos: 7:0.99, 8:0.00, 6:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 10:0.27; 4:0.27; 8:0.05; 2:0.05; 7:0.05
  Agent2 top policies: 4:0.10; 16:0.10; 22:0.10; 0:0.04; 12:0.04
. 2 .
. . .
. b 1

Reward: +0.00, Result: neutral

--- Step 5 ---
Agent 1: LEFT, Agent 2: PRESS
  Agent1 beliefs:
    agent_pos: 8:1.00, 5:0.00, 4:0.00
    red_button_pos: 7:0.25, 1:0.25, 6:0.25
    blue_button_pos: 7:0.25, 1:0.25, 6:0.25
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 1:1.00, 0:0.00, 2:0.00
    red_button_pos: 1:1.00, 2:0.00, 6:0.00
    blue_button_pos: 7:0.98, 8:0.00, 6:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 16:0.63; 14:0.09; 13:0.09; 17:0.07; 12:0.01
  Agent2 top policies: 24:0.06; 4:0.06; 25:0.06; 26:0.05; 27:0.05
. 2 .
. . .
. 1 .

Reward: +0.00, Result: neutral
Button pressed: red by Agent 2

--- Step 6 ---
Agent 1: LEFT, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 7:1.00, 3:0.00, 0:0.00
    red_button_pos: 1:0.32, 2:0.32, 6:0.32
    blue_button_pos: 7:1.00, 1:0.00, 6:0.00
    red_button_state: 0:0.50, 1:0.50
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 2:0.00, 6:0.00
    blue_button_pos: 7:0.98, 8:0.00, 6:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 14:0.10; 13:0.10; 16:0.10; 17:0.08; 26:0.07
  Agent2 top policies: 4:0.04; 28:0.04; 7:0.04; 24:0.04; 0:0.04
. 2 .
. . .
1 b .

Reward: +0.00, Result: neutral

--- Step 7 ---
Agent 1: RIGHT, Agent 2: DOWN
  Agent1 beliefs:
    agent_pos: 6:1.00, 8:0.00, 5:0.00
    red_button_pos: 1:0.47, 2:0.47, 0:0.02
    blue_button_pos: 7:0.99, 1:0.00, 2:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 8:0.00, 7:0.00
    blue_button_pos: 7:0.97, 8:0.00, 6:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 22:0.36; 19:0.03; 18:0.03; 4:0.02; 0:0.02
  Agent2 top policies: 7:0.04; 28:0.04; 4:0.04; 24:0.03; 0:0.03
. R .
. 2 .
. 1 .

Reward: +0.00, Result: neutral

--- Step 8 ---
Agent 1: PRESS, Agent 2: DOWN
  Agent1 beliefs:
    agent_pos: 7:1.00, 5:0.00, 2:0.00
    red_button_pos: 1:0.47, 2:0.47, 0:0.02
    blue_button_pos: 7:1.00, 1:0.00, 2:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 4:1.00, 8:0.00, 6:0.00
    red_button_pos: 1:0.99, 8:0.00, 7:0.00
    blue_button_pos: 7:0.96, 8:0.01, 6:0.01
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 25:0.17; 24:0.17; 27:0.16; 26:0.15; 28:0.14
  Agent2 top policies: 10:0.42; 7:0.03; 11:0.02; 4:0.02; 0:0.02
. R .
. 2 .
. 1 .

Reward: +1.00, Result: win
Button pressed: blue by Agent 1

Result: ✅ WIN - win (steps: 8, reward: +1.00)

================================================================================
EPISODE 8
================================================================================
Environment: Red at (1, 0), Blue at (1, 2)

Initial state:
1 r .
. . .
. b 2


--- Step 1 ---
Agent 1: DOWN, Agent 2: LEFT
  Agent1 beliefs:
    agent_pos: 0:1.00, 8:0.00, 7:0.00
    red_button_pos: 8:0.12, 7:0.12, 6:0.12
    blue_button_pos: 8:0.12, 7:0.12, 6:0.12
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 8:1.00, 7:0.00, 6:0.00
    red_button_pos: 7:0.12, 3:0.12, 6:0.12
    blue_button_pos: 7:0.12, 3:0.12, 6:0.12
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 10:0.21; 22:0.21; 9:0.06; 19:0.06; 21:0.05
  Agent2 top policies: 16:0.21; 4:0.21; 12:0.06; 2:0.06; 0:0.05
. r .
1 . .
. 2 .

Reward: +0.00, Result: neutral

--- Step 2 ---
Agent 1: RIGHT, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 3:1.00, 0:0.00, 8:0.00
    red_button_pos: 8:0.14, 7:0.14, 6:0.14
    blue_button_pos: 8:0.14, 7:0.14, 6:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 7:1.00, 8:0.00, 6:0.00
    red_button_pos: 6:0.14, 1:0.14, 5:0.14
    blue_button_pos: 7:1.00, 3:0.00, 6:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 22:0.23; 10:0.23; 9:0.06; 21:0.05; 19:0.05
  Agent2 top policies: 4:0.13; 16:0.13; 12:0.06; 0:0.06; 2:0.06
. r .
. 1 .
. 2 .

Reward: +0.00, Result: neutral

--- Step 3 ---
Agent 1: RIGHT, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 4:1.00, 3:0.00, 0:0.00
    red_button_pos: 8:0.17, 7:0.17, 6:0.17
    blue_button_pos: 8:0.17, 7:0.17, 6:0.17
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 7:1.00, 4:0.00, 8:0.00
    red_button_pos: 6:0.14, 1:0.14, 5:0.14
    blue_button_pos: 7:1.00, 3:0.00, 6:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 22:0.18; 10:0.18; 4:0.18; 21:0.04; 9:0.04
  Agent2 top policies: 4:0.13; 16:0.13; 12:0.06; 0:0.06; 2:0.06
. r .
. 2 1
. b .

Reward: +0.00, Result: neutral

--- Step 4 ---
Agent 1: DOWN, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 5:1.00, 4:0.00, 3:0.00
    red_button_pos: 8:0.20, 7:0.20, 6:0.20
    blue_button_pos: 8:0.20, 7:0.20, 6:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 4:1.00, 8:0.00, 1:0.00
    red_button_pos: 6:0.17, 1:0.17, 5:0.17
    blue_button_pos: 7:0.99, 8:0.00, 6:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 10:0.27; 4:0.27; 8:0.05; 2:0.05; 7:0.05
  Agent2 top policies: 4:0.10; 16:0.10; 22:0.10; 0:0.04; 12:0.04
. 2 .
. . .
. b 1

Reward: +0.00, Result: neutral

--- Step 5 ---
Agent 1: LEFT, Agent 2: PRESS
  Agent1 beliefs:
    agent_pos: 8:1.00, 5:0.00, 4:0.00
    red_button_pos: 7:0.25, 1:0.25, 6:0.25
    blue_button_pos: 7:0.25, 1:0.25, 6:0.25
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 1:1.00, 0:0.00, 2:0.00
    red_button_pos: 1:1.00, 2:0.00, 6:0.00
    blue_button_pos: 7:0.98, 8:0.00, 6:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 16:0.63; 14:0.09; 13:0.09; 17:0.07; 12:0.01
  Agent2 top policies: 24:0.06; 4:0.06; 25:0.06; 26:0.05; 27:0.05
. 2 .
. . .
. 1 .

Reward: +0.00, Result: neutral
Button pressed: red by Agent 2

--- Step 6 ---
Agent 1: LEFT, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 7:1.00, 3:0.00, 0:0.00
    red_button_pos: 1:0.32, 2:0.32, 6:0.32
    blue_button_pos: 7:1.00, 1:0.00, 6:0.00
    red_button_state: 0:0.50, 1:0.50
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 2:0.00, 6:0.00
    blue_button_pos: 7:0.98, 8:0.00, 6:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 14:0.10; 13:0.10; 16:0.10; 17:0.08; 26:0.07
  Agent2 top policies: 4:0.04; 28:0.04; 7:0.04; 24:0.04; 0:0.04
. 2 .
. . .
1 b .

Reward: +0.00, Result: neutral

--- Step 7 ---
Agent 1: RIGHT, Agent 2: DOWN
  Agent1 beliefs:
    agent_pos: 6:1.00, 8:0.00, 5:0.00
    red_button_pos: 1:0.47, 2:0.47, 0:0.02
    blue_button_pos: 7:0.99, 1:0.00, 2:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 8:0.00, 7:0.00
    blue_button_pos: 7:0.97, 8:0.00, 6:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 22:0.36; 19:0.03; 18:0.03; 4:0.02; 0:0.02
  Agent2 top policies: 7:0.04; 28:0.04; 4:0.04; 24:0.03; 0:0.03
. R .
. 2 .
. 1 .

Reward: +0.00, Result: neutral

--- Step 8 ---
Agent 1: PRESS, Agent 2: DOWN
  Agent1 beliefs:
    agent_pos: 7:1.00, 5:0.00, 2:0.00
    red_button_pos: 1:0.47, 2:0.47, 0:0.02
    blue_button_pos: 7:1.00, 1:0.00, 2:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 4:1.00, 8:0.00, 6:0.00
    red_button_pos: 1:0.99, 8:0.00, 7:0.00
    blue_button_pos: 7:0.96, 8:0.01, 6:0.01
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 25:0.17; 24:0.17; 27:0.16; 26:0.15; 28:0.14
  Agent2 top policies: 10:0.42; 7:0.03; 11:0.02; 4:0.02; 0:0.02
. R .
. 2 .
. 1 .

Reward: +1.00, Result: win
Button pressed: blue by Agent 1

Result: ✅ WIN - win (steps: 8, reward: +1.00)

================================================================================
EPISODE 9
================================================================================
Environment: Red at (1, 0), Blue at (1, 2)

Initial state:
1 r .
. . .
. b 2


--- Step 1 ---
Agent 1: DOWN, Agent 2: LEFT
  Agent1 beliefs:
    agent_pos: 0:1.00, 8:0.00, 7:0.00
    red_button_pos: 8:0.12, 7:0.12, 6:0.12
    blue_button_pos: 8:0.12, 7:0.12, 6:0.12
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 8:1.00, 7:0.00, 6:0.00
    red_button_pos: 7:0.12, 3:0.12, 6:0.12
    blue_button_pos: 7:0.12, 3:0.12, 6:0.12
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 10:0.21; 22:0.21; 9:0.06; 19:0.06; 21:0.05
  Agent2 top policies: 16:0.21; 4:0.21; 12:0.06; 2:0.06; 0:0.05
. r .
1 . .
. 2 .

Reward: +0.00, Result: neutral

--- Step 2 ---
Agent 1: RIGHT, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 3:1.00, 0:0.00, 8:0.00
    red_button_pos: 8:0.14, 7:0.14, 6:0.14
    blue_button_pos: 8:0.14, 7:0.14, 6:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 7:1.00, 8:0.00, 6:0.00
    red_button_pos: 6:0.14, 1:0.14, 5:0.14
    blue_button_pos: 7:1.00, 3:0.00, 6:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 22:0.23; 10:0.23; 9:0.06; 21:0.05; 19:0.05
  Agent2 top policies: 4:0.13; 16:0.13; 12:0.06; 0:0.06; 2:0.06
. r .
. 1 .
. 2 .

Reward: +0.00, Result: neutral

--- Step 3 ---
Agent 1: RIGHT, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 4:1.00, 3:0.00, 0:0.00
    red_button_pos: 8:0.17, 7:0.17, 6:0.17
    blue_button_pos: 8:0.17, 7:0.17, 6:0.17
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 7:1.00, 4:0.00, 8:0.00
    red_button_pos: 6:0.14, 1:0.14, 5:0.14
    blue_button_pos: 7:1.00, 3:0.00, 6:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 22:0.18; 10:0.18; 4:0.18; 21:0.04; 9:0.04
  Agent2 top policies: 4:0.13; 16:0.13; 12:0.06; 0:0.06; 2:0.06
. r .
. 2 1
. b .

Reward: +0.00, Result: neutral

--- Step 4 ---
Agent 1: DOWN, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 5:1.00, 4:0.00, 3:0.00
    red_button_pos: 8:0.20, 7:0.20, 6:0.20
    blue_button_pos: 8:0.20, 7:0.20, 6:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 4:1.00, 8:0.00, 1:0.00
    red_button_pos: 6:0.17, 1:0.17, 5:0.17
    blue_button_pos: 7:0.99, 8:0.00, 6:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 10:0.27; 4:0.27; 8:0.05; 2:0.05; 7:0.05
  Agent2 top policies: 4:0.10; 16:0.10; 22:0.10; 0:0.04; 12:0.04
. 2 .
. . .
. b 1

Reward: +0.00, Result: neutral

--- Step 5 ---
Agent 1: LEFT, Agent 2: PRESS
  Agent1 beliefs:
    agent_pos: 8:1.00, 5:0.00, 4:0.00
    red_button_pos: 7:0.25, 1:0.25, 6:0.25
    blue_button_pos: 7:0.25, 1:0.25, 6:0.25
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 1:1.00, 0:0.00, 2:0.00
    red_button_pos: 1:1.00, 2:0.00, 6:0.00
    blue_button_pos: 7:0.98, 8:0.00, 6:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 16:0.63; 14:0.09; 13:0.09; 17:0.07; 12:0.01
  Agent2 top policies: 24:0.06; 4:0.06; 25:0.06; 26:0.05; 27:0.05
. 2 .
. . .
. 1 .

Reward: +0.00, Result: neutral
Button pressed: red by Agent 2

--- Step 6 ---
Agent 1: LEFT, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 7:1.00, 3:0.00, 0:0.00
    red_button_pos: 1:0.32, 2:0.32, 6:0.32
    blue_button_pos: 7:1.00, 1:0.00, 6:0.00
    red_button_state: 0:0.50, 1:0.50
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 2:0.00, 6:0.00
    blue_button_pos: 7:0.98, 8:0.00, 6:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 14:0.10; 13:0.10; 16:0.10; 17:0.08; 26:0.07
  Agent2 top policies: 4:0.04; 28:0.04; 7:0.04; 24:0.04; 0:0.04
. 2 .
. . .
1 b .

Reward: +0.00, Result: neutral

--- Step 7 ---
Agent 1: RIGHT, Agent 2: DOWN
  Agent1 beliefs:
    agent_pos: 6:1.00, 8:0.00, 5:0.00
    red_button_pos: 1:0.47, 2:0.47, 0:0.02
    blue_button_pos: 7:0.99, 1:0.00, 2:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 8:0.00, 7:0.00
    blue_button_pos: 7:0.97, 8:0.00, 6:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 22:0.36; 19:0.03; 18:0.03; 4:0.02; 0:0.02
  Agent2 top policies: 7:0.04; 28:0.04; 4:0.04; 24:0.03; 0:0.03
. R .
. 2 .
. 1 .

Reward: +0.00, Result: neutral

--- Step 8 ---
Agent 1: PRESS, Agent 2: DOWN
  Agent1 beliefs:
    agent_pos: 7:1.00, 5:0.00, 2:0.00
    red_button_pos: 1:0.47, 2:0.47, 0:0.02
    blue_button_pos: 7:1.00, 1:0.00, 2:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 4:1.00, 8:0.00, 6:0.00
    red_button_pos: 1:0.99, 8:0.00, 7:0.00
    blue_button_pos: 7:0.96, 8:0.01, 6:0.01
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 25:0.17; 24:0.17; 27:0.16; 26:0.15; 28:0.14
  Agent2 top policies: 10:0.42; 7:0.03; 11:0.02; 4:0.02; 0:0.02
. R .
. 2 .
. 1 .

Reward: +1.00, Result: win
Button pressed: blue by Agent 1

Result: ✅ WIN - win (steps: 8, reward: +1.00)

================================================================================
EPISODE 10
================================================================================
Environment: Red at (1, 0), Blue at (1, 2)

Initial state:
1 r .
. . .
. b 2


--- Step 1 ---
Agent 1: DOWN, Agent 2: LEFT
  Agent1 beliefs:
    agent_pos: 0:1.00, 8:0.00, 7:0.00
    red_button_pos: 8:0.12, 7:0.12, 6:0.12
    blue_button_pos: 8:0.12, 7:0.12, 6:0.12
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 8:1.00, 7:0.00, 6:0.00
    red_button_pos: 7:0.12, 3:0.12, 6:0.12
    blue_button_pos: 7:0.12, 3:0.12, 6:0.12
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 10:0.21; 22:0.21; 9:0.06; 19:0.06; 21:0.05
  Agent2 top policies: 16:0.21; 4:0.21; 12:0.06; 2:0.06; 0:0.05
. r .
1 . .
. 2 .

Reward: +0.00, Result: neutral

--- Step 2 ---
Agent 1: RIGHT, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 3:1.00, 0:0.00, 8:0.00
    red_button_pos: 8:0.14, 7:0.14, 6:0.14
    blue_button_pos: 8:0.14, 7:0.14, 6:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 7:1.00, 8:0.00, 6:0.00
    red_button_pos: 6:0.14, 1:0.14, 5:0.14
    blue_button_pos: 7:1.00, 3:0.00, 6:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 22:0.23; 10:0.23; 9:0.06; 21:0.05; 19:0.05
  Agent2 top policies: 4:0.13; 16:0.13; 12:0.06; 0:0.06; 2:0.06
. r .
. 1 .
. 2 .

Reward: +0.00, Result: neutral

--- Step 3 ---
Agent 1: RIGHT, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 4:1.00, 3:0.00, 0:0.00
    red_button_pos: 8:0.17, 7:0.17, 6:0.17
    blue_button_pos: 8:0.17, 7:0.17, 6:0.17
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 7:1.00, 4:0.00, 8:0.00
    red_button_pos: 6:0.14, 1:0.14, 5:0.14
    blue_button_pos: 7:1.00, 3:0.00, 6:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 22:0.18; 10:0.18; 4:0.18; 21:0.04; 9:0.04
  Agent2 top policies: 4:0.13; 16:0.13; 12:0.06; 0:0.06; 2:0.06
. r .
. 2 1
. b .

Reward: +0.00, Result: neutral

--- Step 4 ---
Agent 1: DOWN, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 5:1.00, 4:0.00, 3:0.00
    red_button_pos: 8:0.20, 7:0.20, 6:0.20
    blue_button_pos: 8:0.20, 7:0.20, 6:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 4:1.00, 8:0.00, 1:0.00
    red_button_pos: 6:0.17, 1:0.17, 5:0.17
    blue_button_pos: 7:0.99, 8:0.00, 6:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 10:0.27; 4:0.27; 8:0.05; 2:0.05; 7:0.05
  Agent2 top policies: 4:0.10; 16:0.10; 22:0.10; 0:0.04; 12:0.04
. 2 .
. . .
. b 1

Reward: +0.00, Result: neutral

--- Step 5 ---
Agent 1: LEFT, Agent 2: PRESS
  Agent1 beliefs:
    agent_pos: 8:1.00, 5:0.00, 4:0.00
    red_button_pos: 7:0.25, 1:0.25, 6:0.25
    blue_button_pos: 7:0.25, 1:0.25, 6:0.25
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 1:1.00, 0:0.00, 2:0.00
    red_button_pos: 1:1.00, 2:0.00, 6:0.00
    blue_button_pos: 7:0.98, 8:0.00, 6:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 16:0.63; 14:0.09; 13:0.09; 17:0.07; 12:0.01
  Agent2 top policies: 24:0.06; 4:0.06; 25:0.06; 26:0.05; 27:0.05
. 2 .
. . .
. 1 .

Reward: +0.00, Result: neutral
Button pressed: red by Agent 2

--- Step 6 ---
Agent 1: LEFT, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 7:1.00, 3:0.00, 0:0.00
    red_button_pos: 1:0.32, 2:0.32, 6:0.32
    blue_button_pos: 7:1.00, 1:0.00, 6:0.00
    red_button_state: 0:0.50, 1:0.50
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 2:0.00, 6:0.00
    blue_button_pos: 7:0.98, 8:0.00, 6:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 14:0.10; 13:0.10; 16:0.10; 17:0.08; 26:0.07
  Agent2 top policies: 4:0.04; 28:0.04; 7:0.04; 24:0.04; 0:0.04
. 2 .
. . .
1 b .

Reward: +0.00, Result: neutral

--- Step 7 ---
Agent 1: RIGHT, Agent 2: DOWN
  Agent1 beliefs:
    agent_pos: 6:1.00, 8:0.00, 5:0.00
    red_button_pos: 1:0.47, 2:0.47, 0:0.02
    blue_button_pos: 7:0.99, 1:0.00, 2:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 8:0.00, 7:0.00
    blue_button_pos: 7:0.97, 8:0.00, 6:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 22:0.36; 19:0.03; 18:0.03; 4:0.02; 0:0.02
  Agent2 top policies: 7:0.04; 28:0.04; 4:0.04; 24:0.03; 0:0.03
. R .
. 2 .
. 1 .

Reward: +0.00, Result: neutral

--- Step 8 ---
Agent 1: PRESS, Agent 2: DOWN
  Agent1 beliefs:
    agent_pos: 7:1.00, 5:0.00, 2:0.00
    red_button_pos: 1:0.47, 2:0.47, 0:0.02
    blue_button_pos: 7:1.00, 1:0.00, 2:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 4:1.00, 8:0.00, 6:0.00
    red_button_pos: 1:0.99, 8:0.00, 7:0.00
    blue_button_pos: 7:0.96, 8:0.01, 6:0.01
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 25:0.17; 24:0.17; 27:0.16; 26:0.15; 28:0.14
  Agent2 top policies: 10:0.42; 7:0.03; 11:0.02; 4:0.02; 0:0.02
. R .
. 2 .
. 1 .

Reward: +1.00, Result: win
Button pressed: blue by Agent 1

Result: ✅ WIN - win (steps: 8, reward: +1.00)

================================================================================
EPISODE 11
================================================================================
Environment: Red at (1, 0), Blue at (1, 2)

Initial state:
1 r .
. . .
. b 2


--- Step 1 ---
Agent 1: DOWN, Agent 2: LEFT
  Agent1 beliefs:
    agent_pos: 0:1.00, 8:0.00, 7:0.00
    red_button_pos: 8:0.12, 7:0.12, 6:0.12
    blue_button_pos: 8:0.12, 7:0.12, 6:0.12
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 8:1.00, 7:0.00, 6:0.00
    red_button_pos: 7:0.12, 3:0.12, 6:0.12
    blue_button_pos: 7:0.12, 3:0.12, 6:0.12
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 10:0.21; 22:0.21; 9:0.06; 19:0.06; 21:0.05
  Agent2 top policies: 16:0.21; 4:0.21; 12:0.06; 2:0.06; 0:0.05
. r .
1 . .
. 2 .

Reward: +0.00, Result: neutral

--- Step 2 ---
Agent 1: RIGHT, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 3:1.00, 0:0.00, 8:0.00
    red_button_pos: 8:0.14, 7:0.14, 6:0.14
    blue_button_pos: 8:0.14, 7:0.14, 6:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 7:1.00, 8:0.00, 6:0.00
    red_button_pos: 6:0.14, 1:0.14, 5:0.14
    blue_button_pos: 7:1.00, 3:0.00, 6:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 22:0.23; 10:0.23; 9:0.06; 21:0.05; 19:0.05
  Agent2 top policies: 4:0.13; 16:0.13; 12:0.06; 0:0.06; 2:0.06
. r .
. 1 .
. 2 .

Reward: +0.00, Result: neutral

--- Step 3 ---
Agent 1: RIGHT, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 4:1.00, 3:0.00, 0:0.00
    red_button_pos: 8:0.17, 7:0.17, 6:0.17
    blue_button_pos: 8:0.17, 7:0.17, 6:0.17
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 7:1.00, 4:0.00, 8:0.00
    red_button_pos: 6:0.14, 1:0.14, 5:0.14
    blue_button_pos: 7:1.00, 3:0.00, 6:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 22:0.18; 10:0.18; 4:0.18; 21:0.04; 9:0.04
  Agent2 top policies: 4:0.13; 16:0.13; 12:0.06; 0:0.06; 2:0.06
. r .
. 2 1
. b .

Reward: +0.00, Result: neutral

--- Step 4 ---
Agent 1: DOWN, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 5:1.00, 4:0.00, 3:0.00
    red_button_pos: 8:0.20, 7:0.20, 6:0.20
    blue_button_pos: 8:0.20, 7:0.20, 6:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 4:1.00, 8:0.00, 1:0.00
    red_button_pos: 6:0.17, 1:0.17, 5:0.17
    blue_button_pos: 7:0.99, 8:0.00, 6:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 10:0.27; 4:0.27; 8:0.05; 2:0.05; 7:0.05
  Agent2 top policies: 4:0.10; 16:0.10; 22:0.10; 0:0.04; 12:0.04
. 2 .
. . .
. b 1

Reward: +0.00, Result: neutral

--- Step 5 ---
Agent 1: LEFT, Agent 2: PRESS
  Agent1 beliefs:
    agent_pos: 8:1.00, 5:0.00, 4:0.00
    red_button_pos: 7:0.25, 1:0.25, 6:0.25
    blue_button_pos: 7:0.25, 1:0.25, 6:0.25
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 1:1.00, 0:0.00, 2:0.00
    red_button_pos: 1:1.00, 2:0.00, 6:0.00
    blue_button_pos: 7:0.98, 8:0.00, 6:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 16:0.63; 14:0.09; 13:0.09; 17:0.07; 12:0.01
  Agent2 top policies: 24:0.06; 4:0.06; 25:0.06; 26:0.05; 27:0.05
. 2 .
. . .
. 1 .

Reward: +0.00, Result: neutral
Button pressed: red by Agent 2

--- Step 6 ---
Agent 1: LEFT, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 7:1.00, 3:0.00, 0:0.00
    red_button_pos: 1:0.32, 2:0.32, 6:0.32
    blue_button_pos: 7:1.00, 1:0.00, 6:0.00
    red_button_state: 0:0.50, 1:0.50
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 2:0.00, 6:0.00
    blue_button_pos: 7:0.98, 8:0.00, 6:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 14:0.10; 13:0.10; 16:0.10; 17:0.08; 26:0.07
  Agent2 top policies: 4:0.04; 28:0.04; 7:0.04; 24:0.04; 0:0.04
. 2 .
. . .
1 b .

Reward: +0.00, Result: neutral

--- Step 7 ---
Agent 1: RIGHT, Agent 2: DOWN
  Agent1 beliefs:
    agent_pos: 6:1.00, 8:0.00, 5:0.00
    red_button_pos: 1:0.47, 2:0.47, 0:0.02
    blue_button_pos: 7:0.99, 1:0.00, 2:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 8:0.00, 7:0.00
    blue_button_pos: 7:0.97, 8:0.00, 6:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 22:0.36; 19:0.03; 18:0.03; 4:0.02; 0:0.02
  Agent2 top policies: 7:0.04; 28:0.04; 4:0.04; 24:0.03; 0:0.03
. R .
. 2 .
. 1 .

Reward: +0.00, Result: neutral

--- Step 8 ---
Agent 1: PRESS, Agent 2: DOWN
  Agent1 beliefs:
    agent_pos: 7:1.00, 5:0.00, 2:0.00
    red_button_pos: 1:0.47, 2:0.47, 0:0.02
    blue_button_pos: 7:1.00, 1:0.00, 2:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 4:1.00, 8:0.00, 6:0.00
    red_button_pos: 1:0.99, 8:0.00, 7:0.00
    blue_button_pos: 7:0.96, 8:0.01, 6:0.01
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 25:0.17; 24:0.17; 27:0.16; 26:0.15; 28:0.14
  Agent2 top policies: 10:0.42; 7:0.03; 11:0.02; 4:0.02; 0:0.02
. R .
. 2 .
. 1 .

Reward: +1.00, Result: win
Button pressed: blue by Agent 1

Result: ✅ WIN - win (steps: 8, reward: +1.00)

================================================================================
EPISODE 12
================================================================================
Environment: Red at (1, 0), Blue at (1, 2)

Initial state:
1 r .
. . .
. b 2


--- Step 1 ---
Agent 1: DOWN, Agent 2: LEFT
  Agent1 beliefs:
    agent_pos: 0:1.00, 8:0.00, 7:0.00
    red_button_pos: 8:0.12, 7:0.12, 6:0.12
    blue_button_pos: 8:0.12, 7:0.12, 6:0.12
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 8:1.00, 7:0.00, 6:0.00
    red_button_pos: 7:0.12, 3:0.12, 6:0.12
    blue_button_pos: 7:0.12, 3:0.12, 6:0.12
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 10:0.21; 22:0.21; 9:0.06; 19:0.06; 21:0.05
  Agent2 top policies: 16:0.21; 4:0.21; 12:0.06; 2:0.06; 0:0.05
. r .
1 . .
. 2 .

Reward: +0.00, Result: neutral

--- Step 2 ---
Agent 1: RIGHT, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 3:1.00, 0:0.00, 8:0.00
    red_button_pos: 8:0.14, 7:0.14, 6:0.14
    blue_button_pos: 8:0.14, 7:0.14, 6:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 7:1.00, 8:0.00, 6:0.00
    red_button_pos: 6:0.14, 1:0.14, 5:0.14
    blue_button_pos: 7:1.00, 3:0.00, 6:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 22:0.23; 10:0.23; 9:0.06; 21:0.05; 19:0.05
  Agent2 top policies: 4:0.13; 16:0.13; 12:0.06; 0:0.06; 2:0.06
. r .
. 1 .
. 2 .

Reward: +0.00, Result: neutral

--- Step 3 ---
Agent 1: RIGHT, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 4:1.00, 3:0.00, 0:0.00
    red_button_pos: 8:0.17, 7:0.17, 6:0.17
    blue_button_pos: 8:0.17, 7:0.17, 6:0.17
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 7:1.00, 4:0.00, 8:0.00
    red_button_pos: 6:0.14, 1:0.14, 5:0.14
    blue_button_pos: 7:1.00, 3:0.00, 6:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 22:0.18; 10:0.18; 4:0.18; 21:0.04; 9:0.04
  Agent2 top policies: 4:0.13; 16:0.13; 12:0.06; 0:0.06; 2:0.06
. r .
. 2 1
. b .

Reward: +0.00, Result: neutral

--- Step 4 ---
Agent 1: DOWN, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 5:1.00, 4:0.00, 3:0.00
    red_button_pos: 8:0.20, 7:0.20, 6:0.20
    blue_button_pos: 8:0.20, 7:0.20, 6:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 4:1.00, 8:0.00, 1:0.00
    red_button_pos: 6:0.17, 1:0.17, 5:0.17
    blue_button_pos: 7:0.99, 8:0.00, 6:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 10:0.27; 4:0.27; 8:0.05; 2:0.05; 7:0.05
  Agent2 top policies: 4:0.10; 16:0.10; 22:0.10; 0:0.04; 12:0.04
. 2 .
. . .
. b 1

Reward: +0.00, Result: neutral

--- Step 5 ---
Agent 1: LEFT, Agent 2: PRESS
  Agent1 beliefs:
    agent_pos: 8:1.00, 5:0.00, 4:0.00
    red_button_pos: 7:0.25, 1:0.25, 6:0.25
    blue_button_pos: 7:0.25, 1:0.25, 6:0.25
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 1:1.00, 0:0.00, 2:0.00
    red_button_pos: 1:1.00, 2:0.00, 6:0.00
    blue_button_pos: 7:0.98, 8:0.00, 6:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 16:0.63; 14:0.09; 13:0.09; 17:0.07; 12:0.01
  Agent2 top policies: 24:0.06; 4:0.06; 25:0.06; 26:0.05; 27:0.05
. 2 .
. . .
. 1 .

Reward: +0.00, Result: neutral
Button pressed: red by Agent 2

--- Step 6 ---
Agent 1: LEFT, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 7:1.00, 3:0.00, 0:0.00
    red_button_pos: 1:0.32, 2:0.32, 6:0.32
    blue_button_pos: 7:1.00, 1:0.00, 6:0.00
    red_button_state: 0:0.50, 1:0.50
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 2:0.00, 6:0.00
    blue_button_pos: 7:0.98, 8:0.00, 6:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 14:0.10; 13:0.10; 16:0.10; 17:0.08; 26:0.07
  Agent2 top policies: 4:0.04; 28:0.04; 7:0.04; 24:0.04; 0:0.04
. 2 .
. . .
1 b .

Reward: +0.00, Result: neutral

--- Step 7 ---
Agent 1: RIGHT, Agent 2: DOWN
  Agent1 beliefs:
    agent_pos: 6:1.00, 8:0.00, 5:0.00
    red_button_pos: 1:0.47, 2:0.47, 0:0.02
    blue_button_pos: 7:0.99, 1:0.00, 2:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 8:0.00, 7:0.00
    blue_button_pos: 7:0.97, 8:0.00, 6:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 22:0.36; 19:0.03; 18:0.03; 4:0.02; 0:0.02
  Agent2 top policies: 7:0.04; 28:0.04; 4:0.04; 24:0.03; 0:0.03
. R .
. 2 .
. 1 .

Reward: +0.00, Result: neutral

--- Step 8 ---
Agent 1: PRESS, Agent 2: DOWN
  Agent1 beliefs:
    agent_pos: 7:1.00, 5:0.00, 2:0.00
    red_button_pos: 1:0.47, 2:0.47, 0:0.02
    blue_button_pos: 7:1.00, 1:0.00, 2:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 4:1.00, 8:0.00, 6:0.00
    red_button_pos: 1:0.99, 8:0.00, 7:0.00
    blue_button_pos: 7:0.96, 8:0.01, 6:0.01
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 25:0.17; 24:0.17; 27:0.16; 26:0.15; 28:0.14
  Agent2 top policies: 10:0.42; 7:0.03; 11:0.02; 4:0.02; 0:0.02
. R .
. 2 .
. 1 .

Reward: +1.00, Result: win
Button pressed: blue by Agent 1

Result: ✅ WIN - win (steps: 8, reward: +1.00)

================================================================================
EPISODE 13
================================================================================
Environment: Red at (1, 0), Blue at (1, 2)

Initial state:
1 r .
. . .
. b 2


--- Step 1 ---
Agent 1: DOWN, Agent 2: LEFT
  Agent1 beliefs:
    agent_pos: 0:1.00, 8:0.00, 7:0.00
    red_button_pos: 8:0.12, 7:0.12, 6:0.12
    blue_button_pos: 8:0.12, 7:0.12, 6:0.12
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 8:1.00, 7:0.00, 6:0.00
    red_button_pos: 7:0.12, 3:0.12, 6:0.12
    blue_button_pos: 7:0.12, 3:0.12, 6:0.12
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 10:0.21; 22:0.21; 9:0.06; 19:0.06; 21:0.05
  Agent2 top policies: 16:0.21; 4:0.21; 12:0.06; 2:0.06; 0:0.05
. r .
1 . .
. 2 .

Reward: +0.00, Result: neutral

--- Step 2 ---
Agent 1: RIGHT, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 3:1.00, 0:0.00, 8:0.00
    red_button_pos: 8:0.14, 7:0.14, 6:0.14
    blue_button_pos: 8:0.14, 7:0.14, 6:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 7:1.00, 8:0.00, 6:0.00
    red_button_pos: 6:0.14, 1:0.14, 5:0.14
    blue_button_pos: 7:1.00, 3:0.00, 6:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 22:0.23; 10:0.23; 9:0.06; 21:0.05; 19:0.05
  Agent2 top policies: 4:0.13; 16:0.13; 12:0.06; 0:0.06; 2:0.06
. r .
. 1 .
. 2 .

Reward: +0.00, Result: neutral

--- Step 3 ---
Agent 1: RIGHT, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 4:1.00, 3:0.00, 0:0.00
    red_button_pos: 8:0.17, 7:0.17, 6:0.17
    blue_button_pos: 8:0.17, 7:0.17, 6:0.17
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 7:1.00, 4:0.00, 8:0.00
    red_button_pos: 6:0.14, 1:0.14, 5:0.14
    blue_button_pos: 7:1.00, 3:0.00, 6:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 22:0.18; 10:0.18; 4:0.18; 21:0.04; 9:0.04
  Agent2 top policies: 4:0.13; 16:0.13; 12:0.06; 0:0.06; 2:0.06
. r .
. 2 1
. b .

Reward: +0.00, Result: neutral

--- Step 4 ---
Agent 1: DOWN, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 5:1.00, 4:0.00, 3:0.00
    red_button_pos: 8:0.20, 7:0.20, 6:0.20
    blue_button_pos: 8:0.20, 7:0.20, 6:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 4:1.00, 8:0.00, 1:0.00
    red_button_pos: 6:0.17, 1:0.17, 5:0.17
    blue_button_pos: 7:0.99, 8:0.00, 6:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 10:0.27; 4:0.27; 8:0.05; 2:0.05; 7:0.05
  Agent2 top policies: 4:0.10; 16:0.10; 22:0.10; 0:0.04; 12:0.04
. 2 .
. . .
. b 1

Reward: +0.00, Result: neutral

--- Step 5 ---
Agent 1: LEFT, Agent 2: PRESS
  Agent1 beliefs:
    agent_pos: 8:1.00, 5:0.00, 4:0.00
    red_button_pos: 7:0.25, 1:0.25, 6:0.25
    blue_button_pos: 7:0.25, 1:0.25, 6:0.25
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 1:1.00, 0:0.00, 2:0.00
    red_button_pos: 1:1.00, 2:0.00, 6:0.00
    blue_button_pos: 7:0.98, 8:0.00, 6:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 16:0.63; 14:0.09; 13:0.09; 17:0.07; 12:0.01
  Agent2 top policies: 24:0.06; 4:0.06; 25:0.06; 26:0.05; 27:0.05
. 2 .
. . .
. 1 .

Reward: +0.00, Result: neutral
Button pressed: red by Agent 2

--- Step 6 ---
Agent 1: LEFT, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 7:1.00, 3:0.00, 0:0.00
    red_button_pos: 1:0.32, 2:0.32, 6:0.32
    blue_button_pos: 7:1.00, 1:0.00, 6:0.00
    red_button_state: 0:0.50, 1:0.50
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 2:0.00, 6:0.00
    blue_button_pos: 7:0.98, 8:0.00, 6:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 14:0.10; 13:0.10; 16:0.10; 17:0.08; 26:0.07
  Agent2 top policies: 4:0.04; 28:0.04; 7:0.04; 24:0.04; 0:0.04
. 2 .
. . .
1 b .

Reward: +0.00, Result: neutral

--- Step 7 ---
Agent 1: RIGHT, Agent 2: DOWN
  Agent1 beliefs:
    agent_pos: 6:1.00, 8:0.00, 5:0.00
    red_button_pos: 1:0.47, 2:0.47, 0:0.02
    blue_button_pos: 7:0.99, 1:0.00, 2:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 8:0.00, 7:0.00
    blue_button_pos: 7:0.97, 8:0.00, 6:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 22:0.36; 19:0.03; 18:0.03; 4:0.02; 0:0.02
  Agent2 top policies: 7:0.04; 28:0.04; 4:0.04; 24:0.03; 0:0.03
. R .
. 2 .
. 1 .

Reward: +0.00, Result: neutral

--- Step 8 ---
Agent 1: PRESS, Agent 2: DOWN
  Agent1 beliefs:
    agent_pos: 7:1.00, 5:0.00, 2:0.00
    red_button_pos: 1:0.47, 2:0.47, 0:0.02
    blue_button_pos: 7:1.00, 1:0.00, 2:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 4:1.00, 8:0.00, 6:0.00
    red_button_pos: 1:0.99, 8:0.00, 7:0.00
    blue_button_pos: 7:0.96, 8:0.01, 6:0.01
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 25:0.17; 24:0.17; 27:0.16; 26:0.15; 28:0.14
  Agent2 top policies: 10:0.42; 7:0.03; 11:0.02; 4:0.02; 0:0.02
. R .
. 2 .
. 1 .

Reward: +1.00, Result: win
Button pressed: blue by Agent 1

Result: ✅ WIN - win (steps: 8, reward: +1.00)

================================================================================
EPISODE 14
================================================================================
Environment: Red at (1, 0), Blue at (1, 2)

Initial state:
1 r .
. . .
. b 2


--- Step 1 ---
Agent 1: DOWN, Agent 2: LEFT
  Agent1 beliefs:
    agent_pos: 0:1.00, 8:0.00, 7:0.00
    red_button_pos: 8:0.12, 7:0.12, 6:0.12
    blue_button_pos: 8:0.12, 7:0.12, 6:0.12
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 8:1.00, 7:0.00, 6:0.00
    red_button_pos: 7:0.12, 3:0.12, 6:0.12
    blue_button_pos: 7:0.12, 3:0.12, 6:0.12
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 10:0.21; 22:0.21; 9:0.06; 19:0.06; 21:0.05
  Agent2 top policies: 16:0.21; 4:0.21; 12:0.06; 2:0.06; 0:0.05
. r .
1 . .
. 2 .

Reward: +0.00, Result: neutral

--- Step 2 ---
Agent 1: RIGHT, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 3:1.00, 0:0.00, 8:0.00
    red_button_pos: 8:0.14, 7:0.14, 6:0.14
    blue_button_pos: 8:0.14, 7:0.14, 6:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 7:1.00, 8:0.00, 6:0.00
    red_button_pos: 6:0.14, 1:0.14, 5:0.14
    blue_button_pos: 7:1.00, 3:0.00, 6:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 22:0.23; 10:0.23; 9:0.06; 21:0.05; 19:0.05
  Agent2 top policies: 4:0.13; 16:0.13; 12:0.06; 0:0.06; 2:0.06
. r .
. 1 .
. 2 .

Reward: +0.00, Result: neutral

--- Step 3 ---
Agent 1: RIGHT, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 4:1.00, 3:0.00, 0:0.00
    red_button_pos: 8:0.17, 7:0.17, 6:0.17
    blue_button_pos: 8:0.17, 7:0.17, 6:0.17
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 7:1.00, 4:0.00, 8:0.00
    red_button_pos: 6:0.14, 1:0.14, 5:0.14
    blue_button_pos: 7:1.00, 3:0.00, 6:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 22:0.18; 10:0.18; 4:0.18; 21:0.04; 9:0.04
  Agent2 top policies: 4:0.13; 16:0.13; 12:0.06; 0:0.06; 2:0.06
. r .
. 2 1
. b .

Reward: +0.00, Result: neutral

--- Step 4 ---
Agent 1: DOWN, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 5:1.00, 4:0.00, 3:0.00
    red_button_pos: 8:0.20, 7:0.20, 6:0.20
    blue_button_pos: 8:0.20, 7:0.20, 6:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 4:1.00, 8:0.00, 1:0.00
    red_button_pos: 6:0.17, 1:0.17, 5:0.17
    blue_button_pos: 7:0.99, 8:0.00, 6:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 10:0.27; 4:0.27; 8:0.05; 2:0.05; 7:0.05
  Agent2 top policies: 4:0.10; 16:0.10; 22:0.10; 0:0.04; 12:0.04
. 2 .
. . .
. b 1

Reward: +0.00, Result: neutral

--- Step 5 ---
Agent 1: LEFT, Agent 2: PRESS
  Agent1 beliefs:
    agent_pos: 8:1.00, 5:0.00, 4:0.00
    red_button_pos: 7:0.25, 1:0.25, 6:0.25
    blue_button_pos: 7:0.25, 1:0.25, 6:0.25
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 1:1.00, 0:0.00, 2:0.00
    red_button_pos: 1:1.00, 2:0.00, 6:0.00
    blue_button_pos: 7:0.98, 8:0.00, 6:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 16:0.63; 14:0.09; 13:0.09; 17:0.07; 12:0.01
  Agent2 top policies: 24:0.06; 4:0.06; 25:0.06; 26:0.05; 27:0.05
. 2 .
. . .
. 1 .

Reward: +0.00, Result: neutral
Button pressed: red by Agent 2

--- Step 6 ---
Agent 1: LEFT, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 7:1.00, 3:0.00, 0:0.00
    red_button_pos: 1:0.32, 2:0.32, 6:0.32
    blue_button_pos: 7:1.00, 1:0.00, 6:0.00
    red_button_state: 0:0.50, 1:0.50
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 2:0.00, 6:0.00
    blue_button_pos: 7:0.98, 8:0.00, 6:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 14:0.10; 13:0.10; 16:0.10; 17:0.08; 26:0.07
  Agent2 top policies: 4:0.04; 28:0.04; 7:0.04; 24:0.04; 0:0.04
. 2 .
. . .
1 b .

Reward: +0.00, Result: neutral

--- Step 7 ---
Agent 1: RIGHT, Agent 2: DOWN
  Agent1 beliefs:
    agent_pos: 6:1.00, 8:0.00, 5:0.00
    red_button_pos: 1:0.47, 2:0.47, 0:0.02
    blue_button_pos: 7:0.99, 1:0.00, 2:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 8:0.00, 7:0.00
    blue_button_pos: 7:0.97, 8:0.00, 6:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 22:0.36; 19:0.03; 18:0.03; 4:0.02; 0:0.02
  Agent2 top policies: 7:0.04; 28:0.04; 4:0.04; 24:0.03; 0:0.03
. R .
. 2 .
. 1 .

Reward: +0.00, Result: neutral

--- Step 8 ---
Agent 1: PRESS, Agent 2: DOWN
  Agent1 beliefs:
    agent_pos: 7:1.00, 5:0.00, 2:0.00
    red_button_pos: 1:0.47, 2:0.47, 0:0.02
    blue_button_pos: 7:1.00, 1:0.00, 2:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 4:1.00, 8:0.00, 6:0.00
    red_button_pos: 1:0.99, 8:0.00, 7:0.00
    blue_button_pos: 7:0.96, 8:0.01, 6:0.01
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 25:0.17; 24:0.17; 27:0.16; 26:0.15; 28:0.14
  Agent2 top policies: 10:0.42; 7:0.03; 11:0.02; 4:0.02; 0:0.02
. R .
. 2 .
. 1 .

Reward: +1.00, Result: win
Button pressed: blue by Agent 1

Result: ✅ WIN - win (steps: 8, reward: +1.00)

================================================================================
EPISODE 15
================================================================================
Environment: Red at (1, 0), Blue at (1, 2)

Initial state:
1 r .
. . .
. b 2


--- Step 1 ---
Agent 1: DOWN, Agent 2: LEFT
  Agent1 beliefs:
    agent_pos: 0:1.00, 8:0.00, 7:0.00
    red_button_pos: 8:0.12, 7:0.12, 6:0.12
    blue_button_pos: 8:0.12, 7:0.12, 6:0.12
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 8:1.00, 7:0.00, 6:0.00
    red_button_pos: 7:0.12, 3:0.12, 6:0.12
    blue_button_pos: 7:0.12, 3:0.12, 6:0.12
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 10:0.21; 22:0.21; 9:0.06; 19:0.06; 21:0.05
  Agent2 top policies: 16:0.21; 4:0.21; 12:0.06; 2:0.06; 0:0.05
. r .
1 . .
. 2 .

Reward: +0.00, Result: neutral

--- Step 2 ---
Agent 1: RIGHT, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 3:1.00, 0:0.00, 8:0.00
    red_button_pos: 8:0.14, 7:0.14, 6:0.14
    blue_button_pos: 8:0.14, 7:0.14, 6:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 7:1.00, 8:0.00, 6:0.00
    red_button_pos: 6:0.14, 1:0.14, 5:0.14
    blue_button_pos: 7:1.00, 3:0.00, 6:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 22:0.23; 10:0.23; 9:0.06; 21:0.05; 19:0.05
  Agent2 top policies: 4:0.13; 16:0.13; 12:0.06; 0:0.06; 2:0.06
. r .
. 1 .
. 2 .

Reward: +0.00, Result: neutral

--- Step 3 ---
Agent 1: RIGHT, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 4:1.00, 3:0.00, 0:0.00
    red_button_pos: 8:0.17, 7:0.17, 6:0.17
    blue_button_pos: 8:0.17, 7:0.17, 6:0.17
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 7:1.00, 4:0.00, 8:0.00
    red_button_pos: 6:0.14, 1:0.14, 5:0.14
    blue_button_pos: 7:1.00, 3:0.00, 6:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 22:0.18; 10:0.18; 4:0.18; 21:0.04; 9:0.04
  Agent2 top policies: 4:0.13; 16:0.13; 12:0.06; 0:0.06; 2:0.06
. r .
. 2 1
. b .

Reward: +0.00, Result: neutral

--- Step 4 ---
Agent 1: DOWN, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 5:1.00, 4:0.00, 3:0.00
    red_button_pos: 8:0.20, 7:0.20, 6:0.20
    blue_button_pos: 8:0.20, 7:0.20, 6:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 4:1.00, 8:0.00, 1:0.00
    red_button_pos: 6:0.17, 1:0.17, 5:0.17
    blue_button_pos: 7:0.99, 8:0.00, 6:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 10:0.27; 4:0.27; 8:0.05; 2:0.05; 7:0.05
  Agent2 top policies: 4:0.10; 16:0.10; 22:0.10; 0:0.04; 12:0.04
. 2 .
. . .
. b 1

Reward: +0.00, Result: neutral

--- Step 5 ---
Agent 1: LEFT, Agent 2: PRESS
  Agent1 beliefs:
    agent_pos: 8:1.00, 5:0.00, 4:0.00
    red_button_pos: 7:0.25, 1:0.25, 6:0.25
    blue_button_pos: 7:0.25, 1:0.25, 6:0.25
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 1:1.00, 0:0.00, 2:0.00
    red_button_pos: 1:1.00, 2:0.00, 6:0.00
    blue_button_pos: 7:0.98, 8:0.00, 6:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 16:0.63; 14:0.09; 13:0.09; 17:0.07; 12:0.01
  Agent2 top policies: 24:0.06; 4:0.06; 25:0.06; 26:0.05; 27:0.05
. 2 .
. . .
. 1 .

Reward: +0.00, Result: neutral
Button pressed: red by Agent 2

--- Step 6 ---
Agent 1: LEFT, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 7:1.00, 3:0.00, 0:0.00
    red_button_pos: 1:0.32, 2:0.32, 6:0.32
    blue_button_pos: 7:1.00, 1:0.00, 6:0.00
    red_button_state: 0:0.50, 1:0.50
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 2:0.00, 6:0.00
    blue_button_pos: 7:0.98, 8:0.00, 6:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 14:0.10; 13:0.10; 16:0.10; 17:0.08; 26:0.07
  Agent2 top policies: 4:0.04; 28:0.04; 7:0.04; 24:0.04; 0:0.04
. 2 .
. . .
1 b .

Reward: +0.00, Result: neutral

--- Step 7 ---
Agent 1: RIGHT, Agent 2: DOWN
  Agent1 beliefs:
    agent_pos: 6:1.00, 8:0.00, 5:0.00
    red_button_pos: 1:0.47, 2:0.47, 0:0.02
    blue_button_pos: 7:0.99, 1:0.00, 2:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 8:0.00, 7:0.00
    blue_button_pos: 7:0.97, 8:0.00, 6:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 22:0.36; 19:0.03; 18:0.03; 4:0.02; 0:0.02
  Agent2 top policies: 7:0.04; 28:0.04; 4:0.04; 24:0.03; 0:0.03
. R .
. 2 .
. 1 .

Reward: +0.00, Result: neutral

--- Step 8 ---
Agent 1: PRESS, Agent 2: DOWN
  Agent1 beliefs:
    agent_pos: 7:1.00, 5:0.00, 2:0.00
    red_button_pos: 1:0.47, 2:0.47, 0:0.02
    blue_button_pos: 7:1.00, 1:0.00, 2:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 4:1.00, 8:0.00, 6:0.00
    red_button_pos: 1:0.99, 8:0.00, 7:0.00
    blue_button_pos: 7:0.96, 8:0.01, 6:0.01
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 25:0.17; 24:0.17; 27:0.16; 26:0.15; 28:0.14
  Agent2 top policies: 10:0.42; 7:0.03; 11:0.02; 4:0.02; 0:0.02
. R .
. 2 .
. 1 .

Reward: +1.00, Result: win
Button pressed: blue by Agent 1

Result: ✅ WIN - win (steps: 8, reward: +1.00)

================================================================================
EPISODE 16
================================================================================
Environment: Red at (1, 0), Blue at (1, 2)

Initial state:
1 r .
. . .
. b 2


--- Step 1 ---
Agent 1: DOWN, Agent 2: LEFT
  Agent1 beliefs:
    agent_pos: 0:1.00, 8:0.00, 7:0.00
    red_button_pos: 8:0.12, 7:0.12, 6:0.12
    blue_button_pos: 8:0.12, 7:0.12, 6:0.12
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 8:1.00, 7:0.00, 6:0.00
    red_button_pos: 7:0.12, 3:0.12, 6:0.12
    blue_button_pos: 7:0.12, 3:0.12, 6:0.12
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 10:0.21; 22:0.21; 9:0.06; 19:0.06; 21:0.05
  Agent2 top policies: 16:0.21; 4:0.21; 12:0.06; 2:0.06; 0:0.05
. r .
1 . .
. 2 .

Reward: +0.00, Result: neutral

--- Step 2 ---
Agent 1: RIGHT, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 3:1.00, 0:0.00, 8:0.00
    red_button_pos: 8:0.14, 7:0.14, 6:0.14
    blue_button_pos: 8:0.14, 7:0.14, 6:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 7:1.00, 8:0.00, 6:0.00
    red_button_pos: 6:0.14, 1:0.14, 5:0.14
    blue_button_pos: 7:1.00, 3:0.00, 6:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 22:0.23; 10:0.23; 9:0.06; 21:0.05; 19:0.05
  Agent2 top policies: 4:0.13; 16:0.13; 12:0.06; 0:0.06; 2:0.06
. r .
. 1 .
. 2 .

Reward: +0.00, Result: neutral

--- Step 3 ---
Agent 1: RIGHT, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 4:1.00, 3:0.00, 0:0.00
    red_button_pos: 8:0.17, 7:0.17, 6:0.17
    blue_button_pos: 8:0.17, 7:0.17, 6:0.17
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 7:1.00, 4:0.00, 8:0.00
    red_button_pos: 6:0.14, 1:0.14, 5:0.14
    blue_button_pos: 7:1.00, 3:0.00, 6:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 22:0.18; 10:0.18; 4:0.18; 21:0.04; 9:0.04
  Agent2 top policies: 4:0.13; 16:0.13; 12:0.06; 0:0.06; 2:0.06
. r .
. 2 1
. b .

Reward: +0.00, Result: neutral

--- Step 4 ---
Agent 1: DOWN, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 5:1.00, 4:0.00, 3:0.00
    red_button_pos: 8:0.20, 7:0.20, 6:0.20
    blue_button_pos: 8:0.20, 7:0.20, 6:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 4:1.00, 8:0.00, 1:0.00
    red_button_pos: 6:0.17, 1:0.17, 5:0.17
    blue_button_pos: 7:0.99, 8:0.00, 6:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 10:0.27; 4:0.27; 8:0.05; 2:0.05; 7:0.05
  Agent2 top policies: 4:0.10; 16:0.10; 22:0.10; 0:0.04; 12:0.04
. 2 .
. . .
. b 1

Reward: +0.00, Result: neutral

--- Step 5 ---
Agent 1: LEFT, Agent 2: PRESS
  Agent1 beliefs:
    agent_pos: 8:1.00, 5:0.00, 4:0.00
    red_button_pos: 7:0.25, 1:0.25, 6:0.25
    blue_button_pos: 7:0.25, 1:0.25, 6:0.25
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 1:1.00, 0:0.00, 2:0.00
    red_button_pos: 1:1.00, 2:0.00, 6:0.00
    blue_button_pos: 7:0.98, 8:0.00, 6:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 16:0.63; 14:0.09; 13:0.09; 17:0.07; 12:0.01
  Agent2 top policies: 24:0.06; 4:0.06; 25:0.06; 26:0.05; 27:0.05
. 2 .
. . .
. 1 .

Reward: +0.00, Result: neutral
Button pressed: red by Agent 2

--- Step 6 ---
Agent 1: LEFT, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 7:1.00, 3:0.00, 0:0.00
    red_button_pos: 1:0.32, 2:0.32, 6:0.32
    blue_button_pos: 7:1.00, 1:0.00, 6:0.00
    red_button_state: 0:0.50, 1:0.50
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 2:0.00, 6:0.00
    blue_button_pos: 7:0.98, 8:0.00, 6:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 14:0.10; 13:0.10; 16:0.10; 17:0.08; 26:0.07
  Agent2 top policies: 4:0.04; 28:0.04; 7:0.04; 24:0.04; 0:0.04
. 2 .
. . .
1 b .

Reward: +0.00, Result: neutral

--- Step 7 ---
Agent 1: RIGHT, Agent 2: DOWN
  Agent1 beliefs:
    agent_pos: 6:1.00, 8:0.00, 5:0.00
    red_button_pos: 1:0.47, 2:0.47, 0:0.02
    blue_button_pos: 7:0.99, 1:0.00, 2:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 8:0.00, 7:0.00
    blue_button_pos: 7:0.97, 8:0.00, 6:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 22:0.36; 19:0.03; 18:0.03; 4:0.02; 0:0.02
  Agent2 top policies: 7:0.04; 28:0.04; 4:0.04; 24:0.03; 0:0.03
. R .
. 2 .
. 1 .

Reward: +0.00, Result: neutral

--- Step 8 ---
Agent 1: PRESS, Agent 2: DOWN
  Agent1 beliefs:
    agent_pos: 7:1.00, 5:0.00, 2:0.00
    red_button_pos: 1:0.47, 2:0.47, 0:0.02
    blue_button_pos: 7:1.00, 1:0.00, 2:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 4:1.00, 8:0.00, 6:0.00
    red_button_pos: 1:0.99, 8:0.00, 7:0.00
    blue_button_pos: 7:0.96, 8:0.01, 6:0.01
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 25:0.17; 24:0.17; 27:0.16; 26:0.15; 28:0.14
  Agent2 top policies: 10:0.42; 7:0.03; 11:0.02; 4:0.02; 0:0.02
. R .
. 2 .
. 1 .

Reward: +1.00, Result: win
Button pressed: blue by Agent 1

Result: ✅ WIN - win (steps: 8, reward: +1.00)

================================================================================
EPISODE 17
================================================================================
Environment: Red at (1, 0), Blue at (1, 2)

Initial state:
1 r .
. . .
. b 2


--- Step 1 ---
Agent 1: DOWN, Agent 2: LEFT
  Agent1 beliefs:
    agent_pos: 0:1.00, 8:0.00, 7:0.00
    red_button_pos: 8:0.12, 7:0.12, 6:0.12
    blue_button_pos: 8:0.12, 7:0.12, 6:0.12
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 8:1.00, 7:0.00, 6:0.00
    red_button_pos: 7:0.12, 3:0.12, 6:0.12
    blue_button_pos: 7:0.12, 3:0.12, 6:0.12
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 10:0.21; 22:0.21; 9:0.06; 19:0.06; 21:0.05
  Agent2 top policies: 16:0.21; 4:0.21; 12:0.06; 2:0.06; 0:0.05
. r .
1 . .
. 2 .

Reward: +0.00, Result: neutral

--- Step 2 ---
Agent 1: RIGHT, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 3:1.00, 0:0.00, 8:0.00
    red_button_pos: 8:0.14, 7:0.14, 6:0.14
    blue_button_pos: 8:0.14, 7:0.14, 6:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 7:1.00, 8:0.00, 6:0.00
    red_button_pos: 6:0.14, 1:0.14, 5:0.14
    blue_button_pos: 7:1.00, 3:0.00, 6:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 22:0.23; 10:0.23; 9:0.06; 21:0.05; 19:0.05
  Agent2 top policies: 4:0.13; 16:0.13; 12:0.06; 0:0.06; 2:0.06
. r .
. 1 .
. 2 .

Reward: +0.00, Result: neutral

--- Step 3 ---
Agent 1: RIGHT, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 4:1.00, 3:0.00, 0:0.00
    red_button_pos: 8:0.17, 7:0.17, 6:0.17
    blue_button_pos: 8:0.17, 7:0.17, 6:0.17
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 7:1.00, 4:0.00, 8:0.00
    red_button_pos: 6:0.14, 1:0.14, 5:0.14
    blue_button_pos: 7:1.00, 3:0.00, 6:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 22:0.18; 10:0.18; 4:0.18; 21:0.04; 9:0.04
  Agent2 top policies: 4:0.13; 16:0.13; 12:0.06; 0:0.06; 2:0.06
. r .
. 2 1
. b .

Reward: +0.00, Result: neutral

--- Step 4 ---
Agent 1: DOWN, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 5:1.00, 4:0.00, 3:0.00
    red_button_pos: 8:0.20, 7:0.20, 6:0.20
    blue_button_pos: 8:0.20, 7:0.20, 6:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 4:1.00, 8:0.00, 1:0.00
    red_button_pos: 6:0.17, 1:0.17, 5:0.17
    blue_button_pos: 7:0.99, 8:0.00, 6:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 10:0.27; 4:0.27; 8:0.05; 2:0.05; 7:0.05
  Agent2 top policies: 4:0.10; 16:0.10; 22:0.10; 0:0.04; 12:0.04
. 2 .
. . .
. b 1

Reward: +0.00, Result: neutral

--- Step 5 ---
Agent 1: LEFT, Agent 2: PRESS
  Agent1 beliefs:
    agent_pos: 8:1.00, 5:0.00, 4:0.00
    red_button_pos: 7:0.25, 1:0.25, 6:0.25
    blue_button_pos: 7:0.25, 1:0.25, 6:0.25
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 1:1.00, 0:0.00, 2:0.00
    red_button_pos: 1:1.00, 2:0.00, 6:0.00
    blue_button_pos: 7:0.98, 8:0.00, 6:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 16:0.63; 14:0.09; 13:0.09; 17:0.07; 12:0.01
  Agent2 top policies: 24:0.06; 4:0.06; 25:0.06; 26:0.05; 27:0.05
. 2 .
. . .
. 1 .

Reward: +0.00, Result: neutral
Button pressed: red by Agent 2

--- Step 6 ---
Agent 1: LEFT, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 7:1.00, 3:0.00, 0:0.00
    red_button_pos: 1:0.32, 2:0.32, 6:0.32
    blue_button_pos: 7:1.00, 1:0.00, 6:0.00
    red_button_state: 0:0.50, 1:0.50
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 2:0.00, 6:0.00
    blue_button_pos: 7:0.98, 8:0.00, 6:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 14:0.10; 13:0.10; 16:0.10; 17:0.08; 26:0.07
  Agent2 top policies: 4:0.04; 28:0.04; 7:0.04; 24:0.04; 0:0.04
. 2 .
. . .
1 b .

Reward: +0.00, Result: neutral

--- Step 7 ---
Agent 1: RIGHT, Agent 2: DOWN
  Agent1 beliefs:
    agent_pos: 6:1.00, 8:0.00, 5:0.00
    red_button_pos: 1:0.47, 2:0.47, 0:0.02
    blue_button_pos: 7:0.99, 1:0.00, 2:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 8:0.00, 7:0.00
    blue_button_pos: 7:0.97, 8:0.00, 6:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 22:0.36; 19:0.03; 18:0.03; 4:0.02; 0:0.02
  Agent2 top policies: 7:0.04; 28:0.04; 4:0.04; 24:0.03; 0:0.03
. R .
. 2 .
. 1 .

Reward: +0.00, Result: neutral

--- Step 8 ---
Agent 1: PRESS, Agent 2: DOWN
  Agent1 beliefs:
    agent_pos: 7:1.00, 5:0.00, 2:0.00
    red_button_pos: 1:0.47, 2:0.47, 0:0.02
    blue_button_pos: 7:1.00, 1:0.00, 2:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 4:1.00, 8:0.00, 6:0.00
    red_button_pos: 1:0.99, 8:0.00, 7:0.00
    blue_button_pos: 7:0.96, 8:0.01, 6:0.01
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 25:0.17; 24:0.17; 27:0.16; 26:0.15; 28:0.14
  Agent2 top policies: 10:0.42; 7:0.03; 11:0.02; 4:0.02; 0:0.02
. R .
. 2 .
. 1 .

Reward: +1.00, Result: win
Button pressed: blue by Agent 1

Result: ✅ WIN - win (steps: 8, reward: +1.00)

================================================================================
EPISODE 18
================================================================================
Environment: Red at (1, 0), Blue at (1, 2)

Initial state:
1 r .
. . .
. b 2


--- Step 1 ---
Agent 1: DOWN, Agent 2: LEFT
  Agent1 beliefs:
    agent_pos: 0:1.00, 8:0.00, 7:0.00
    red_button_pos: 8:0.12, 7:0.12, 6:0.12
    blue_button_pos: 8:0.12, 7:0.12, 6:0.12
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 8:1.00, 7:0.00, 6:0.00
    red_button_pos: 7:0.12, 3:0.12, 6:0.12
    blue_button_pos: 7:0.12, 3:0.12, 6:0.12
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 10:0.21; 22:0.21; 9:0.06; 19:0.06; 21:0.05
  Agent2 top policies: 16:0.21; 4:0.21; 12:0.06; 2:0.06; 0:0.05
. r .
1 . .
. 2 .

Reward: +0.00, Result: neutral

--- Step 2 ---
Agent 1: RIGHT, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 3:1.00, 0:0.00, 8:0.00
    red_button_pos: 8:0.14, 7:0.14, 6:0.14
    blue_button_pos: 8:0.14, 7:0.14, 6:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 7:1.00, 8:0.00, 6:0.00
    red_button_pos: 6:0.14, 1:0.14, 5:0.14
    blue_button_pos: 7:1.00, 3:0.00, 6:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 22:0.23; 10:0.23; 9:0.06; 21:0.05; 19:0.05
  Agent2 top policies: 4:0.13; 16:0.13; 12:0.06; 0:0.06; 2:0.06
. r .
. 1 .
. 2 .

Reward: +0.00, Result: neutral

--- Step 3 ---
Agent 1: RIGHT, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 4:1.00, 3:0.00, 0:0.00
    red_button_pos: 8:0.17, 7:0.17, 6:0.17
    blue_button_pos: 8:0.17, 7:0.17, 6:0.17
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 7:1.00, 4:0.00, 8:0.00
    red_button_pos: 6:0.14, 1:0.14, 5:0.14
    blue_button_pos: 7:1.00, 3:0.00, 6:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 22:0.18; 10:0.18; 4:0.18; 21:0.04; 9:0.04
  Agent2 top policies: 4:0.13; 16:0.13; 12:0.06; 0:0.06; 2:0.06
. r .
. 2 1
. b .

Reward: +0.00, Result: neutral

--- Step 4 ---
Agent 1: DOWN, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 5:1.00, 4:0.00, 3:0.00
    red_button_pos: 8:0.20, 7:0.20, 6:0.20
    blue_button_pos: 8:0.20, 7:0.20, 6:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 4:1.00, 8:0.00, 1:0.00
    red_button_pos: 6:0.17, 1:0.17, 5:0.17
    blue_button_pos: 7:0.99, 8:0.00, 6:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 10:0.27; 4:0.27; 8:0.05; 2:0.05; 7:0.05
  Agent2 top policies: 4:0.10; 16:0.10; 22:0.10; 0:0.04; 12:0.04
. 2 .
. . .
. b 1

Reward: +0.00, Result: neutral

--- Step 5 ---
Agent 1: LEFT, Agent 2: PRESS
  Agent1 beliefs:
    agent_pos: 8:1.00, 5:0.00, 4:0.00
    red_button_pos: 7:0.25, 1:0.25, 6:0.25
    blue_button_pos: 7:0.25, 1:0.25, 6:0.25
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 1:1.00, 0:0.00, 2:0.00
    red_button_pos: 1:1.00, 2:0.00, 6:0.00
    blue_button_pos: 7:0.98, 8:0.00, 6:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 16:0.63; 14:0.09; 13:0.09; 17:0.07; 12:0.01
  Agent2 top policies: 24:0.06; 4:0.06; 25:0.06; 26:0.05; 27:0.05
. 2 .
. . .
. 1 .

Reward: +0.00, Result: neutral
Button pressed: red by Agent 2

--- Step 6 ---
Agent 1: LEFT, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 7:1.00, 3:0.00, 0:0.00
    red_button_pos: 1:0.32, 2:0.32, 6:0.32
    blue_button_pos: 7:1.00, 1:0.00, 6:0.00
    red_button_state: 0:0.50, 1:0.50
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 2:0.00, 6:0.00
    blue_button_pos: 7:0.98, 8:0.00, 6:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 14:0.10; 13:0.10; 16:0.10; 17:0.08; 26:0.07
  Agent2 top policies: 4:0.04; 28:0.04; 7:0.04; 24:0.04; 0:0.04
. 2 .
. . .
1 b .

Reward: +0.00, Result: neutral

--- Step 7 ---
Agent 1: RIGHT, Agent 2: DOWN
  Agent1 beliefs:
    agent_pos: 6:1.00, 8:0.00, 5:0.00
    red_button_pos: 1:0.47, 2:0.47, 0:0.02
    blue_button_pos: 7:0.99, 1:0.00, 2:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 8:0.00, 7:0.00
    blue_button_pos: 7:0.97, 8:0.00, 6:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 22:0.36; 19:0.03; 18:0.03; 4:0.02; 0:0.02
  Agent2 top policies: 7:0.04; 28:0.04; 4:0.04; 24:0.03; 0:0.03
. R .
. 2 .
. 1 .

Reward: +0.00, Result: neutral

--- Step 8 ---
Agent 1: PRESS, Agent 2: DOWN
  Agent1 beliefs:
    agent_pos: 7:1.00, 5:0.00, 2:0.00
    red_button_pos: 1:0.47, 2:0.47, 0:0.02
    blue_button_pos: 7:1.00, 1:0.00, 2:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 4:1.00, 8:0.00, 6:0.00
    red_button_pos: 1:0.99, 8:0.00, 7:0.00
    blue_button_pos: 7:0.96, 8:0.01, 6:0.01
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 25:0.17; 24:0.17; 27:0.16; 26:0.15; 28:0.14
  Agent2 top policies: 10:0.42; 7:0.03; 11:0.02; 4:0.02; 0:0.02
. R .
. 2 .
. 1 .

Reward: +1.00, Result: win
Button pressed: blue by Agent 1

Result: ✅ WIN - win (steps: 8, reward: +1.00)

================================================================================
EPISODE 19
================================================================================
Environment: Red at (1, 0), Blue at (1, 2)

Initial state:
1 r .
. . .
. b 2


--- Step 1 ---
Agent 1: DOWN, Agent 2: LEFT
  Agent1 beliefs:
    agent_pos: 0:1.00, 8:0.00, 7:0.00
    red_button_pos: 8:0.12, 7:0.12, 6:0.12
    blue_button_pos: 8:0.12, 7:0.12, 6:0.12
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 8:1.00, 7:0.00, 6:0.00
    red_button_pos: 7:0.12, 3:0.12, 6:0.12
    blue_button_pos: 7:0.12, 3:0.12, 6:0.12
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 10:0.21; 22:0.21; 9:0.06; 19:0.06; 21:0.05
  Agent2 top policies: 16:0.21; 4:0.21; 12:0.06; 2:0.06; 0:0.05
. r .
1 . .
. 2 .

Reward: +0.00, Result: neutral

--- Step 2 ---
Agent 1: RIGHT, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 3:1.00, 0:0.00, 8:0.00
    red_button_pos: 8:0.14, 7:0.14, 6:0.14
    blue_button_pos: 8:0.14, 7:0.14, 6:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 7:1.00, 8:0.00, 6:0.00
    red_button_pos: 6:0.14, 1:0.14, 5:0.14
    blue_button_pos: 7:1.00, 3:0.00, 6:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 22:0.23; 10:0.23; 9:0.06; 21:0.05; 19:0.05
  Agent2 top policies: 4:0.13; 16:0.13; 12:0.06; 0:0.06; 2:0.06
. r .
. 1 .
. 2 .

Reward: +0.00, Result: neutral

--- Step 3 ---
Agent 1: RIGHT, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 4:1.00, 3:0.00, 0:0.00
    red_button_pos: 8:0.17, 7:0.17, 6:0.17
    blue_button_pos: 8:0.17, 7:0.17, 6:0.17
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 7:1.00, 4:0.00, 8:0.00
    red_button_pos: 6:0.14, 1:0.14, 5:0.14
    blue_button_pos: 7:1.00, 3:0.00, 6:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 22:0.18; 10:0.18; 4:0.18; 21:0.04; 9:0.04
  Agent2 top policies: 4:0.13; 16:0.13; 12:0.06; 0:0.06; 2:0.06
. r .
. 2 1
. b .

Reward: +0.00, Result: neutral

--- Step 4 ---
Agent 1: DOWN, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 5:1.00, 4:0.00, 3:0.00
    red_button_pos: 8:0.20, 7:0.20, 6:0.20
    blue_button_pos: 8:0.20, 7:0.20, 6:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 4:1.00, 8:0.00, 1:0.00
    red_button_pos: 6:0.17, 1:0.17, 5:0.17
    blue_button_pos: 7:0.99, 8:0.00, 6:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 10:0.27; 4:0.27; 8:0.05; 2:0.05; 7:0.05
  Agent2 top policies: 4:0.10; 16:0.10; 22:0.10; 0:0.04; 12:0.04
. 2 .
. . .
. b 1

Reward: +0.00, Result: neutral

--- Step 5 ---
Agent 1: LEFT, Agent 2: PRESS
  Agent1 beliefs:
    agent_pos: 8:1.00, 5:0.00, 4:0.00
    red_button_pos: 7:0.25, 1:0.25, 6:0.25
    blue_button_pos: 7:0.25, 1:0.25, 6:0.25
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 1:1.00, 0:0.00, 2:0.00
    red_button_pos: 1:1.00, 2:0.00, 6:0.00
    blue_button_pos: 7:0.98, 8:0.00, 6:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 16:0.63; 14:0.09; 13:0.09; 17:0.07; 12:0.01
  Agent2 top policies: 24:0.06; 4:0.06; 25:0.06; 26:0.05; 27:0.05
. 2 .
. . .
. 1 .

Reward: +0.00, Result: neutral
Button pressed: red by Agent 2

--- Step 6 ---
Agent 1: LEFT, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 7:1.00, 3:0.00, 0:0.00
    red_button_pos: 1:0.32, 2:0.32, 6:0.32
    blue_button_pos: 7:1.00, 1:0.00, 6:0.00
    red_button_state: 0:0.50, 1:0.50
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 2:0.00, 6:0.00
    blue_button_pos: 7:0.98, 8:0.00, 6:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 14:0.10; 13:0.10; 16:0.10; 17:0.08; 26:0.07
  Agent2 top policies: 4:0.04; 28:0.04; 7:0.04; 24:0.04; 0:0.04
. 2 .
. . .
1 b .

Reward: +0.00, Result: neutral

--- Step 7 ---
Agent 1: RIGHT, Agent 2: DOWN
  Agent1 beliefs:
    agent_pos: 6:1.00, 8:0.00, 5:0.00
    red_button_pos: 1:0.47, 2:0.47, 0:0.02
    blue_button_pos: 7:0.99, 1:0.00, 2:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 8:0.00, 7:0.00
    blue_button_pos: 7:0.97, 8:0.00, 6:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 22:0.36; 19:0.03; 18:0.03; 4:0.02; 0:0.02
  Agent2 top policies: 7:0.04; 28:0.04; 4:0.04; 24:0.03; 0:0.03
. R .
. 2 .
. 1 .

Reward: +0.00, Result: neutral

--- Step 8 ---
Agent 1: PRESS, Agent 2: DOWN
  Agent1 beliefs:
    agent_pos: 7:1.00, 5:0.00, 2:0.00
    red_button_pos: 1:0.47, 2:0.47, 0:0.02
    blue_button_pos: 7:1.00, 1:0.00, 2:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 4:1.00, 8:0.00, 6:0.00
    red_button_pos: 1:0.99, 8:0.00, 7:0.00
    blue_button_pos: 7:0.96, 8:0.01, 6:0.01
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 25:0.17; 24:0.17; 27:0.16; 26:0.15; 28:0.14
  Agent2 top policies: 10:0.42; 7:0.03; 11:0.02; 4:0.02; 0:0.02
. R .
. 2 .
. 1 .

Reward: +1.00, Result: win
Button pressed: blue by Agent 1

Result: ✅ WIN - win (steps: 8, reward: +1.00)

================================================================================
EPISODE 20
================================================================================
Environment: Red at (1, 0), Blue at (1, 2)

Initial state:
1 r .
. . .
. b 2


--- Step 1 ---
Agent 1: DOWN, Agent 2: LEFT
  Agent1 beliefs:
    agent_pos: 0:1.00, 8:0.00, 7:0.00
    red_button_pos: 8:0.12, 7:0.12, 6:0.12
    blue_button_pos: 8:0.12, 7:0.12, 6:0.12
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 8:1.00, 7:0.00, 6:0.00
    red_button_pos: 7:0.12, 3:0.12, 6:0.12
    blue_button_pos: 7:0.12, 3:0.12, 6:0.12
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 10:0.21; 22:0.21; 9:0.06; 19:0.06; 21:0.05
  Agent2 top policies: 16:0.21; 4:0.21; 12:0.06; 2:0.06; 0:0.05
. r .
1 . .
. 2 .

Reward: +0.00, Result: neutral

--- Step 2 ---
Agent 1: RIGHT, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 3:1.00, 0:0.00, 8:0.00
    red_button_pos: 8:0.14, 7:0.14, 6:0.14
    blue_button_pos: 8:0.14, 7:0.14, 6:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 7:1.00, 8:0.00, 6:0.00
    red_button_pos: 6:0.14, 1:0.14, 5:0.14
    blue_button_pos: 7:1.00, 3:0.00, 6:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 22:0.23; 10:0.23; 9:0.06; 21:0.05; 19:0.05
  Agent2 top policies: 4:0.13; 16:0.13; 12:0.06; 0:0.06; 2:0.06
. r .
. 1 .
. 2 .

Reward: +0.00, Result: neutral

--- Step 3 ---
Agent 1: RIGHT, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 4:1.00, 3:0.00, 0:0.00
    red_button_pos: 8:0.17, 7:0.17, 6:0.17
    blue_button_pos: 8:0.17, 7:0.17, 6:0.17
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 7:1.00, 4:0.00, 8:0.00
    red_button_pos: 6:0.14, 1:0.14, 5:0.14
    blue_button_pos: 7:1.00, 3:0.00, 6:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 22:0.18; 10:0.18; 4:0.18; 21:0.04; 9:0.04
  Agent2 top policies: 4:0.13; 16:0.13; 12:0.06; 0:0.06; 2:0.06
. r .
. 2 1
. b .

Reward: +0.00, Result: neutral

--- Step 4 ---
Agent 1: DOWN, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 5:1.00, 4:0.00, 3:0.00
    red_button_pos: 8:0.20, 7:0.20, 6:0.20
    blue_button_pos: 8:0.20, 7:0.20, 6:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 4:1.00, 8:0.00, 1:0.00
    red_button_pos: 6:0.17, 1:0.17, 5:0.17
    blue_button_pos: 7:0.99, 8:0.00, 6:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 10:0.27; 4:0.27; 8:0.05; 2:0.05; 7:0.05
  Agent2 top policies: 4:0.10; 16:0.10; 22:0.10; 0:0.04; 12:0.04
. 2 .
. . .
. b 1

Reward: +0.00, Result: neutral

--- Step 5 ---
Agent 1: LEFT, Agent 2: PRESS
  Agent1 beliefs:
    agent_pos: 8:1.00, 5:0.00, 4:0.00
    red_button_pos: 7:0.25, 1:0.25, 6:0.25
    blue_button_pos: 7:0.25, 1:0.25, 6:0.25
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 1:1.00, 0:0.00, 2:0.00
    red_button_pos: 1:1.00, 2:0.00, 6:0.00
    blue_button_pos: 7:0.98, 8:0.00, 6:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 16:0.63; 14:0.09; 13:0.09; 17:0.07; 12:0.01
  Agent2 top policies: 24:0.06; 4:0.06; 25:0.06; 26:0.05; 27:0.05
. 2 .
. . .
. 1 .

Reward: +0.00, Result: neutral
Button pressed: red by Agent 2

--- Step 6 ---
Agent 1: LEFT, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 7:1.00, 3:0.00, 0:0.00
    red_button_pos: 1:0.32, 2:0.32, 6:0.32
    blue_button_pos: 7:1.00, 1:0.00, 6:0.00
    red_button_state: 0:0.50, 1:0.50
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 2:0.00, 6:0.00
    blue_button_pos: 7:0.98, 8:0.00, 6:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 14:0.10; 13:0.10; 16:0.10; 17:0.08; 26:0.07
  Agent2 top policies: 4:0.04; 28:0.04; 7:0.04; 24:0.04; 0:0.04
. 2 .
. . .
1 b .

Reward: +0.00, Result: neutral

--- Step 7 ---
Agent 1: RIGHT, Agent 2: DOWN
  Agent1 beliefs:
    agent_pos: 6:1.00, 8:0.00, 5:0.00
    red_button_pos: 1:0.47, 2:0.47, 0:0.02
    blue_button_pos: 7:0.99, 1:0.00, 2:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 8:0.00, 7:0.00
    blue_button_pos: 7:0.97, 8:0.00, 6:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 22:0.36; 19:0.03; 18:0.03; 4:0.02; 0:0.02
  Agent2 top policies: 7:0.04; 28:0.04; 4:0.04; 24:0.03; 0:0.03
. R .
. 2 .
. 1 .

Reward: +0.00, Result: neutral

--- Step 8 ---
Agent 1: PRESS, Agent 2: DOWN
  Agent1 beliefs:
    agent_pos: 7:1.00, 5:0.00, 2:0.00
    red_button_pos: 1:0.47, 2:0.47, 0:0.02
    blue_button_pos: 7:1.00, 1:0.00, 2:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 4:1.00, 8:0.00, 6:0.00
    red_button_pos: 1:0.99, 8:0.00, 7:0.00
    blue_button_pos: 7:0.96, 8:0.01, 6:0.01
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 25:0.17; 24:0.17; 27:0.16; 26:0.15; 28:0.14
  Agent2 top policies: 10:0.42; 7:0.03; 11:0.02; 4:0.02; 0:0.02
. R .
. 2 .
. 1 .

Reward: +1.00, Result: win
Button pressed: blue by Agent 1

Result: ✅ WIN - win (steps: 8, reward: +1.00)

================================================================================
SEED 0 - CONFIG 2
Red at (2, 0), Blue at (1, 0)
Episodes 21-40
================================================================================

================================================================================
EPISODE 21
================================================================================
Environment: Red at (2, 0), Blue at (1, 0)

Initial state:
1 b r
. . .
. . 2


--- Step 1 ---
Agent 1: DOWN, Agent 2: LEFT
  Agent1 beliefs:
    agent_pos: 0:1.00, 8:0.00, 7:0.00
    red_button_pos: 8:0.12, 7:0.12, 6:0.12
    blue_button_pos: 8:0.12, 7:0.12, 6:0.12
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 8:1.00, 7:0.00, 6:0.00
    red_button_pos: 7:0.12, 3:0.12, 6:0.12
    blue_button_pos: 7:0.12, 3:0.12, 6:0.12
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 10:0.21; 22:0.21; 9:0.06; 19:0.06; 21:0.05
  Agent2 top policies: 16:0.21; 4:0.21; 12:0.06; 2:0.06; 0:0.05
. b r
1 . .
. 2 .

Reward: +0.00, Result: neutral

--- Step 2 ---
Agent 1: RIGHT, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 3:1.00, 0:0.00, 8:0.00
    red_button_pos: 8:0.14, 7:0.14, 6:0.14
    blue_button_pos: 8:0.14, 7:0.14, 6:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 7:1.00, 8:0.00, 6:0.00
    red_button_pos: 6:0.14, 1:0.14, 5:0.14
    blue_button_pos: 6:0.14, 1:0.14, 5:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 22:0.23; 10:0.23; 9:0.06; 21:0.05; 19:0.05
  Agent2 top policies: 4:0.23; 16:0.23; 12:0.06; 0:0.05; 2:0.05
. b r
. 1 .
. 2 .

Reward: +0.00, Result: neutral

--- Step 3 ---
Agent 1: RIGHT, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 4:1.00, 3:0.00, 0:0.00
    red_button_pos: 8:0.17, 7:0.17, 6:0.17
    blue_button_pos: 8:0.17, 7:0.17, 6:0.17
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 7:0.87, 4:0.12, 8:0.00
    red_button_pos: 6:0.14, 1:0.14, 5:0.14
    blue_button_pos: 6:0.14, 1:0.14, 5:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 22:0.18; 10:0.18; 4:0.18; 21:0.04; 9:0.04
  Agent2 top policies: 4:0.24; 16:0.23; 12:0.06; 2:0.05; 14:0.05
. b r
. 2 1
. . .

Reward: +0.00, Result: neutral

--- Step 4 ---
Agent 1: DOWN, Agent 2: LEFT
  Agent1 beliefs:
    agent_pos: 5:1.00, 4:0.00, 3:0.00
    red_button_pos: 8:0.20, 7:0.20, 6:0.20
    blue_button_pos: 8:0.20, 7:0.20, 6:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 4:1.00, 1:0.00, 7:0.00
    red_button_pos: 6:0.17, 1:0.17, 5:0.17
    blue_button_pos: 6:0.17, 1:0.17, 5:0.17
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 10:0.27; 4:0.27; 8:0.05; 2:0.05; 7:0.05
  Agent2 top policies: 16:0.18; 22:0.18; 4:0.18; 12:0.04; 18:0.04
. b r
2 . .
. . 1

Reward: +0.00, Result: neutral

--- Step 5 ---
Agent 1: LEFT, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 8:1.00, 5:0.00, 4:0.00
    red_button_pos: 7:0.25, 1:0.25, 6:0.25
    blue_button_pos: 7:0.25, 1:0.25, 6:0.25
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 3:1.00, 4:0.00, 7:0.00
    red_button_pos: 6:0.20, 5:0.20, 0:0.20
    blue_button_pos: 6:0.20, 5:0.20, 0:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 16:0.63; 14:0.09; 13:0.09; 17:0.07; 12:0.01
  Agent2 top policies: 4:0.28; 10:0.28; 3:0.05; 0:0.05; 2:0.05
2 b r
. . .
. 1 .

Reward: +0.00, Result: neutral

--- Step 6 ---
Agent 1: LEFT, Agent 2: RIGHT
  Agent1 beliefs:
    agent_pos: 7:1.00, 8:0.00, 5:0.00
    red_button_pos: 1:0.32, 2:0.32, 6:0.32
    blue_button_pos: 1:0.32, 2:0.32, 6:0.32
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 0:1.00, 3:0.00, 4:0.00
    red_button_pos: 6:0.24, 1:0.24, 5:0.24
    blue_button_pos: 6:0.24, 1:0.24, 5:0.24
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 16:0.72; 14:0.08; 13:0.08; 17:0.06; 12:0.01
  Agent2 top policies: 22:0.63; 21:0.09; 18:0.09; 23:0.07; 19:0.01
. 2 r
. . .
1 . .

Reward: +0.00, Result: neutral

--- Step 7 ---
Agent 1: UP, Agent 2: RIGHT
  Agent1 beliefs:
    agent_pos: 6:1.00, 7:0.00, 8:0.00
    red_button_pos: 1:0.47, 2:0.47, 0:0.02
    blue_button_pos: 1:0.47, 2:0.47, 0:0.02
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 1:1.00, 8:0.00, 5:0.00
    red_button_pos: 6:0.32, 2:0.32, 5:0.32
    blue_button_pos: 1:1.00, 2:0.00, 6:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 0:0.05; 4:0.05; 3:0.05; 2:0.04; 24:0.04
  Agent2 top policies: 22:0.34; 19:0.10; 21:0.09; 18:0.09; 23:0.07
. b 2
1 . .
. . .

Reward: +0.00, Result: neutral

--- Step 8 ---
Agent 1: UP, Agent 2: PRESS
  Agent1 beliefs:
    agent_pos: 3:1.00, 6:0.00, 7:0.00
    red_button_pos: 1:0.47, 2:0.47, 0:0.02
    blue_button_pos: 1:0.47, 2:0.47, 0:0.02
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 2:1.00, 8:0.00, 7:0.00
    red_button_pos: 2:1.00, 5:0.00, 6:0.00
    blue_button_pos: 1:0.99, 5:0.00, 6:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 3:0.24; 18:0.21; 4:0.05; 0:0.03; 2:0.03
  Agent2 top policies: 26:0.06; 24:0.06; 27:0.06; 22:0.05; 4:0.05
1 b 2
. . .
. . .

Reward: +0.00, Result: neutral
Button pressed: red by Agent 2

--- Step 9 ---
Agent 1: RIGHT, Agent 2: LEFT
  Agent1 beliefs:
    agent_pos: 0:1.00, 3:0.00, 6:0.00
    red_button_pos: 1:0.48, 2:0.48, 4:0.01
    blue_button_pos: 1:0.48, 2:0.48, 4:0.01
    red_button_state: 0:0.50, 1:0.50
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 2:1.00, 8:0.00, 7:0.00
    red_button_pos: 2:1.00, 5:0.00, 6:0.00
    blue_button_pos: 1:0.98, 5:0.00, 6:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 22:0.59; 18:0.12; 21:0.12; 23:0.10; 19:0.01
  Agent2 top policies: 16:0.35; 12:0.03; 26:0.02; 20:0.02; 2:0.02
. 1 2
. . .
. . .

Reward: +0.00, Result: neutral

--- Step 10 ---
Agent 1: PRESS, Agent 2: LEFT
  Agent1 beliefs:
    agent_pos: 1:1.00, 8:0.00, 5:0.00
    red_button_pos: 2:0.91, 4:0.03, 5:0.02
    blue_button_pos: 1:1.00, 2:0.00, 4:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 2:1.00, 1:0.00, 8:0.00
    red_button_pos: 2:1.00, 8:0.00, 7:0.00
    blue_button_pos: 1:0.97, 5:0.00, 6:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 27:0.24; 25:0.16; 24:0.15; 26:0.13; 28:0.12
  Agent2 top policies: 16:0.37; 12:0.03; 26:0.02; 2:0.02; 20:0.02
. 1 2
. . .
. . .

Reward: +1.00, Result: win
Button pressed: blue by Agent 1

Result: ✅ WIN - win (steps: 10, reward: +1.00)

================================================================================
EPISODE 22
================================================================================
Environment: Red at (2, 0), Blue at (1, 0)

Initial state:
1 b r
. . .
. . 2


--- Step 1 ---
Agent 1: DOWN, Agent 2: LEFT
  Agent1 beliefs:
    agent_pos: 0:1.00, 8:0.00, 7:0.00
    red_button_pos: 8:0.12, 7:0.12, 6:0.12
    blue_button_pos: 8:0.12, 7:0.12, 6:0.12
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 8:1.00, 7:0.00, 6:0.00
    red_button_pos: 7:0.12, 3:0.12, 6:0.12
    blue_button_pos: 7:0.12, 3:0.12, 6:0.12
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 10:0.21; 22:0.21; 9:0.06; 19:0.06; 21:0.05
  Agent2 top policies: 16:0.21; 4:0.21; 12:0.06; 2:0.06; 0:0.05
. b r
1 . .
. 2 .

Reward: +0.00, Result: neutral

--- Step 2 ---
Agent 1: RIGHT, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 3:1.00, 0:0.00, 8:0.00
    red_button_pos: 8:0.14, 7:0.14, 6:0.14
    blue_button_pos: 8:0.14, 7:0.14, 6:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 7:1.00, 8:0.00, 6:0.00
    red_button_pos: 6:0.14, 1:0.14, 5:0.14
    blue_button_pos: 6:0.14, 1:0.14, 5:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 22:0.23; 10:0.23; 9:0.06; 21:0.05; 19:0.05
  Agent2 top policies: 4:0.23; 16:0.23; 12:0.06; 0:0.05; 2:0.05
. b r
. 1 .
. 2 .

Reward: +0.00, Result: neutral

--- Step 3 ---
Agent 1: RIGHT, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 4:1.00, 3:0.00, 0:0.00
    red_button_pos: 8:0.17, 7:0.17, 6:0.17
    blue_button_pos: 8:0.17, 7:0.17, 6:0.17
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 7:0.87, 4:0.12, 8:0.00
    red_button_pos: 6:0.14, 1:0.14, 5:0.14
    blue_button_pos: 6:0.14, 1:0.14, 5:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 22:0.18; 10:0.18; 4:0.18; 21:0.04; 9:0.04
  Agent2 top policies: 4:0.24; 16:0.23; 12:0.06; 2:0.05; 14:0.05
. b r
. 2 1
. . .

Reward: +0.00, Result: neutral

--- Step 4 ---
Agent 1: DOWN, Agent 2: LEFT
  Agent1 beliefs:
    agent_pos: 5:1.00, 4:0.00, 3:0.00
    red_button_pos: 8:0.20, 7:0.20, 6:0.20
    blue_button_pos: 8:0.20, 7:0.20, 6:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 4:1.00, 1:0.00, 7:0.00
    red_button_pos: 6:0.17, 1:0.17, 5:0.17
    blue_button_pos: 6:0.17, 1:0.17, 5:0.17
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 10:0.27; 4:0.27; 8:0.05; 2:0.05; 7:0.05
  Agent2 top policies: 16:0.18; 22:0.18; 4:0.18; 12:0.04; 18:0.04
. b r
2 . .
. . 1

Reward: +0.00, Result: neutral

--- Step 5 ---
Agent 1: LEFT, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 8:1.00, 5:0.00, 4:0.00
    red_button_pos: 7:0.25, 1:0.25, 6:0.25
    blue_button_pos: 7:0.25, 1:0.25, 6:0.25
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 3:1.00, 4:0.00, 7:0.00
    red_button_pos: 6:0.20, 5:0.20, 0:0.20
    blue_button_pos: 6:0.20, 5:0.20, 0:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 16:0.63; 14:0.09; 13:0.09; 17:0.07; 12:0.01
  Agent2 top policies: 4:0.28; 10:0.28; 3:0.05; 0:0.05; 2:0.05
2 b r
. . .
. 1 .

Reward: +0.00, Result: neutral

--- Step 6 ---
Agent 1: LEFT, Agent 2: RIGHT
  Agent1 beliefs:
    agent_pos: 7:1.00, 8:0.00, 5:0.00
    red_button_pos: 1:0.32, 2:0.32, 6:0.32
    blue_button_pos: 1:0.32, 2:0.32, 6:0.32
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 0:1.00, 3:0.00, 4:0.00
    red_button_pos: 6:0.24, 1:0.24, 5:0.24
    blue_button_pos: 6:0.24, 1:0.24, 5:0.24
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 16:0.72; 14:0.08; 13:0.08; 17:0.06; 12:0.01
  Agent2 top policies: 22:0.63; 21:0.09; 18:0.09; 23:0.07; 19:0.01
. 2 r
. . .
1 . .

Reward: +0.00, Result: neutral

--- Step 7 ---
Agent 1: UP, Agent 2: RIGHT
  Agent1 beliefs:
    agent_pos: 6:1.00, 7:0.00, 8:0.00
    red_button_pos: 1:0.47, 2:0.47, 0:0.02
    blue_button_pos: 1:0.47, 2:0.47, 0:0.02
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 1:1.00, 8:0.00, 5:0.00
    red_button_pos: 6:0.32, 2:0.32, 5:0.32
    blue_button_pos: 1:1.00, 2:0.00, 6:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 0:0.05; 4:0.05; 3:0.05; 2:0.04; 24:0.04
  Agent2 top policies: 22:0.34; 19:0.10; 21:0.09; 18:0.09; 23:0.07
. b 2
1 . .
. . .

Reward: +0.00, Result: neutral

--- Step 8 ---
Agent 1: UP, Agent 2: PRESS
  Agent1 beliefs:
    agent_pos: 3:1.00, 6:0.00, 7:0.00
    red_button_pos: 1:0.47, 2:0.47, 0:0.02
    blue_button_pos: 1:0.47, 2:0.47, 0:0.02
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 2:1.00, 8:0.00, 7:0.00
    red_button_pos: 2:1.00, 5:0.00, 6:0.00
    blue_button_pos: 1:0.99, 5:0.00, 6:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 3:0.24; 18:0.21; 4:0.05; 0:0.03; 2:0.03
  Agent2 top policies: 26:0.06; 24:0.06; 27:0.06; 22:0.05; 4:0.05
1 b 2
. . .
. . .

Reward: +0.00, Result: neutral
Button pressed: red by Agent 2

--- Step 9 ---
Agent 1: RIGHT, Agent 2: LEFT
  Agent1 beliefs:
    agent_pos: 0:1.00, 3:0.00, 6:0.00
    red_button_pos: 1:0.48, 2:0.48, 4:0.01
    blue_button_pos: 1:0.48, 2:0.48, 4:0.01
    red_button_state: 0:0.50, 1:0.50
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 2:1.00, 8:0.00, 7:0.00
    red_button_pos: 2:1.00, 5:0.00, 6:0.00
    blue_button_pos: 1:0.98, 5:0.00, 6:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 22:0.59; 18:0.12; 21:0.12; 23:0.10; 19:0.01
  Agent2 top policies: 16:0.35; 12:0.03; 26:0.02; 20:0.02; 2:0.02
. 1 2
. . .
. . .

Reward: +0.00, Result: neutral

--- Step 10 ---
Agent 1: PRESS, Agent 2: LEFT
  Agent1 beliefs:
    agent_pos: 1:1.00, 8:0.00, 5:0.00
    red_button_pos: 2:0.91, 4:0.03, 5:0.02
    blue_button_pos: 1:1.00, 2:0.00, 4:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 2:1.00, 1:0.00, 8:0.00
    red_button_pos: 2:1.00, 8:0.00, 7:0.00
    blue_button_pos: 1:0.97, 5:0.00, 6:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 27:0.24; 25:0.16; 24:0.15; 26:0.13; 28:0.12
  Agent2 top policies: 16:0.37; 12:0.03; 26:0.02; 2:0.02; 20:0.02
. 1 2
. . .
. . .

Reward: +1.00, Result: win
Button pressed: blue by Agent 1

Result: ✅ WIN - win (steps: 10, reward: +1.00)

================================================================================
EPISODE 23
================================================================================
Environment: Red at (2, 0), Blue at (1, 0)

Initial state:
1 b r
. . .
. . 2


--- Step 1 ---
Agent 1: DOWN, Agent 2: LEFT
  Agent1 beliefs:
    agent_pos: 0:1.00, 8:0.00, 7:0.00
    red_button_pos: 8:0.12, 7:0.12, 6:0.12
    blue_button_pos: 8:0.12, 7:0.12, 6:0.12
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 8:1.00, 7:0.00, 6:0.00
    red_button_pos: 7:0.12, 3:0.12, 6:0.12
    blue_button_pos: 7:0.12, 3:0.12, 6:0.12
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 10:0.21; 22:0.21; 9:0.06; 19:0.06; 21:0.05
  Agent2 top policies: 16:0.21; 4:0.21; 12:0.06; 2:0.06; 0:0.05
. b r
1 . .
. 2 .

Reward: +0.00, Result: neutral

--- Step 2 ---
Agent 1: RIGHT, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 3:1.00, 0:0.00, 8:0.00
    red_button_pos: 8:0.14, 7:0.14, 6:0.14
    blue_button_pos: 8:0.14, 7:0.14, 6:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 7:1.00, 8:0.00, 6:0.00
    red_button_pos: 6:0.14, 1:0.14, 5:0.14
    blue_button_pos: 6:0.14, 1:0.14, 5:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 22:0.23; 10:0.23; 9:0.06; 21:0.05; 19:0.05
  Agent2 top policies: 4:0.23; 16:0.23; 12:0.06; 0:0.05; 2:0.05
. b r
. 1 .
. 2 .

Reward: +0.00, Result: neutral

--- Step 3 ---
Agent 1: RIGHT, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 4:1.00, 3:0.00, 0:0.00
    red_button_pos: 8:0.17, 7:0.17, 6:0.17
    blue_button_pos: 8:0.17, 7:0.17, 6:0.17
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 7:0.87, 4:0.12, 8:0.00
    red_button_pos: 6:0.14, 1:0.14, 5:0.14
    blue_button_pos: 6:0.14, 1:0.14, 5:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 22:0.18; 10:0.18; 4:0.18; 21:0.04; 9:0.04
  Agent2 top policies: 4:0.24; 16:0.23; 12:0.06; 2:0.05; 14:0.05
. b r
. 2 1
. . .

Reward: +0.00, Result: neutral

--- Step 4 ---
Agent 1: DOWN, Agent 2: LEFT
  Agent1 beliefs:
    agent_pos: 5:1.00, 4:0.00, 3:0.00
    red_button_pos: 8:0.20, 7:0.20, 6:0.20
    blue_button_pos: 8:0.20, 7:0.20, 6:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 4:1.00, 1:0.00, 7:0.00
    red_button_pos: 6:0.17, 1:0.17, 5:0.17
    blue_button_pos: 6:0.17, 1:0.17, 5:0.17
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 10:0.27; 4:0.27; 8:0.05; 2:0.05; 7:0.05
  Agent2 top policies: 16:0.18; 22:0.18; 4:0.18; 12:0.04; 18:0.04
. b r
2 . .
. . 1

Reward: +0.00, Result: neutral

--- Step 5 ---
Agent 1: LEFT, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 8:1.00, 5:0.00, 4:0.00
    red_button_pos: 7:0.25, 1:0.25, 6:0.25
    blue_button_pos: 7:0.25, 1:0.25, 6:0.25
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 3:1.00, 4:0.00, 7:0.00
    red_button_pos: 6:0.20, 5:0.20, 0:0.20
    blue_button_pos: 6:0.20, 5:0.20, 0:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 16:0.63; 14:0.09; 13:0.09; 17:0.07; 12:0.01
  Agent2 top policies: 4:0.28; 10:0.28; 3:0.05; 0:0.05; 2:0.05
2 b r
. . .
. 1 .

Reward: +0.00, Result: neutral

--- Step 6 ---
Agent 1: LEFT, Agent 2: RIGHT
  Agent1 beliefs:
    agent_pos: 7:1.00, 8:0.00, 5:0.00
    red_button_pos: 1:0.32, 2:0.32, 6:0.32
    blue_button_pos: 1:0.32, 2:0.32, 6:0.32
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 0:1.00, 3:0.00, 4:0.00
    red_button_pos: 6:0.24, 1:0.24, 5:0.24
    blue_button_pos: 6:0.24, 1:0.24, 5:0.24
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 16:0.72; 14:0.08; 13:0.08; 17:0.06; 12:0.01
  Agent2 top policies: 22:0.63; 21:0.09; 18:0.09; 23:0.07; 19:0.01
. 2 r
. . .
1 . .

Reward: +0.00, Result: neutral

--- Step 7 ---
Agent 1: UP, Agent 2: RIGHT
  Agent1 beliefs:
    agent_pos: 6:1.00, 7:0.00, 8:0.00
    red_button_pos: 1:0.47, 2:0.47, 0:0.02
    blue_button_pos: 1:0.47, 2:0.47, 0:0.02
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 1:1.00, 8:0.00, 5:0.00
    red_button_pos: 6:0.32, 2:0.32, 5:0.32
    blue_button_pos: 1:1.00, 2:0.00, 6:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 0:0.05; 4:0.05; 3:0.05; 2:0.04; 24:0.04
  Agent2 top policies: 22:0.34; 19:0.10; 21:0.09; 18:0.09; 23:0.07
. b 2
1 . .
. . .

Reward: +0.00, Result: neutral

--- Step 8 ---
Agent 1: UP, Agent 2: PRESS
  Agent1 beliefs:
    agent_pos: 3:1.00, 6:0.00, 7:0.00
    red_button_pos: 1:0.47, 2:0.47, 0:0.02
    blue_button_pos: 1:0.47, 2:0.47, 0:0.02
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 2:1.00, 8:0.00, 7:0.00
    red_button_pos: 2:1.00, 5:0.00, 6:0.00
    blue_button_pos: 1:0.99, 5:0.00, 6:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 3:0.24; 18:0.21; 4:0.05; 0:0.03; 2:0.03
  Agent2 top policies: 26:0.06; 24:0.06; 27:0.06; 22:0.05; 4:0.05
1 b 2
. . .
. . .

Reward: +0.00, Result: neutral
Button pressed: red by Agent 2

--- Step 9 ---
Agent 1: RIGHT, Agent 2: LEFT
  Agent1 beliefs:
    agent_pos: 0:1.00, 3:0.00, 6:0.00
    red_button_pos: 1:0.48, 2:0.48, 4:0.01
    blue_button_pos: 1:0.48, 2:0.48, 4:0.01
    red_button_state: 0:0.50, 1:0.50
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 2:1.00, 8:0.00, 7:0.00
    red_button_pos: 2:1.00, 5:0.00, 6:0.00
    blue_button_pos: 1:0.98, 5:0.00, 6:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 22:0.59; 18:0.12; 21:0.12; 23:0.10; 19:0.01
  Agent2 top policies: 16:0.35; 12:0.03; 26:0.02; 20:0.02; 2:0.02
. 1 2
. . .
. . .

Reward: +0.00, Result: neutral

--- Step 10 ---
Agent 1: PRESS, Agent 2: LEFT
  Agent1 beliefs:
    agent_pos: 1:1.00, 8:0.00, 5:0.00
    red_button_pos: 2:0.91, 4:0.03, 5:0.02
    blue_button_pos: 1:1.00, 2:0.00, 4:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 2:1.00, 1:0.00, 8:0.00
    red_button_pos: 2:1.00, 8:0.00, 7:0.00
    blue_button_pos: 1:0.97, 5:0.00, 6:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 27:0.24; 25:0.16; 24:0.15; 26:0.13; 28:0.12
  Agent2 top policies: 16:0.37; 12:0.03; 26:0.02; 2:0.02; 20:0.02
. 1 2
. . .
. . .

Reward: +1.00, Result: win
Button pressed: blue by Agent 1

Result: ✅ WIN - win (steps: 10, reward: +1.00)

================================================================================
EPISODE 24
================================================================================
Environment: Red at (2, 0), Blue at (1, 0)

Initial state:
1 b r
. . .
. . 2


--- Step 1 ---
Agent 1: DOWN, Agent 2: LEFT
  Agent1 beliefs:
    agent_pos: 0:1.00, 8:0.00, 7:0.00
    red_button_pos: 8:0.12, 7:0.12, 6:0.12
    blue_button_pos: 8:0.12, 7:0.12, 6:0.12
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 8:1.00, 7:0.00, 6:0.00
    red_button_pos: 7:0.12, 3:0.12, 6:0.12
    blue_button_pos: 7:0.12, 3:0.12, 6:0.12
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 10:0.21; 22:0.21; 9:0.06; 19:0.06; 21:0.05
  Agent2 top policies: 16:0.21; 4:0.21; 12:0.06; 2:0.06; 0:0.05
. b r
1 . .
. 2 .

Reward: +0.00, Result: neutral

--- Step 2 ---
Agent 1: RIGHT, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 3:1.00, 0:0.00, 8:0.00
    red_button_pos: 8:0.14, 7:0.14, 6:0.14
    blue_button_pos: 8:0.14, 7:0.14, 6:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 7:1.00, 8:0.00, 6:0.00
    red_button_pos: 6:0.14, 1:0.14, 5:0.14
    blue_button_pos: 6:0.14, 1:0.14, 5:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 22:0.23; 10:0.23; 9:0.06; 21:0.05; 19:0.05
  Agent2 top policies: 4:0.23; 16:0.23; 12:0.06; 0:0.05; 2:0.05
. b r
. 1 .
. 2 .

Reward: +0.00, Result: neutral

--- Step 3 ---
Agent 1: RIGHT, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 4:1.00, 3:0.00, 0:0.00
    red_button_pos: 8:0.17, 7:0.17, 6:0.17
    blue_button_pos: 8:0.17, 7:0.17, 6:0.17
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 7:0.87, 4:0.12, 8:0.00
    red_button_pos: 6:0.14, 1:0.14, 5:0.14
    blue_button_pos: 6:0.14, 1:0.14, 5:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 22:0.18; 10:0.18; 4:0.18; 21:0.04; 9:0.04
  Agent2 top policies: 4:0.24; 16:0.23; 12:0.06; 2:0.05; 14:0.05
. b r
. 2 1
. . .

Reward: +0.00, Result: neutral

--- Step 4 ---
Agent 1: DOWN, Agent 2: LEFT
  Agent1 beliefs:
    agent_pos: 5:1.00, 4:0.00, 3:0.00
    red_button_pos: 8:0.20, 7:0.20, 6:0.20
    blue_button_pos: 8:0.20, 7:0.20, 6:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 4:1.00, 1:0.00, 7:0.00
    red_button_pos: 6:0.17, 1:0.17, 5:0.17
    blue_button_pos: 6:0.17, 1:0.17, 5:0.17
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 10:0.27; 4:0.27; 8:0.05; 2:0.05; 7:0.05
  Agent2 top policies: 16:0.18; 22:0.18; 4:0.18; 12:0.04; 18:0.04
. b r
2 . .
. . 1

Reward: +0.00, Result: neutral

--- Step 5 ---
Agent 1: LEFT, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 8:1.00, 5:0.00, 4:0.00
    red_button_pos: 7:0.25, 1:0.25, 6:0.25
    blue_button_pos: 7:0.25, 1:0.25, 6:0.25
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 3:1.00, 4:0.00, 7:0.00
    red_button_pos: 6:0.20, 5:0.20, 0:0.20
    blue_button_pos: 6:0.20, 5:0.20, 0:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 16:0.63; 14:0.09; 13:0.09; 17:0.07; 12:0.01
  Agent2 top policies: 4:0.28; 10:0.28; 3:0.05; 0:0.05; 2:0.05
2 b r
. . .
. 1 .

Reward: +0.00, Result: neutral

--- Step 6 ---
Agent 1: LEFT, Agent 2: RIGHT
  Agent1 beliefs:
    agent_pos: 7:1.00, 8:0.00, 5:0.00
    red_button_pos: 1:0.32, 2:0.32, 6:0.32
    blue_button_pos: 1:0.32, 2:0.32, 6:0.32
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 0:1.00, 3:0.00, 4:0.00
    red_button_pos: 6:0.24, 1:0.24, 5:0.24
    blue_button_pos: 6:0.24, 1:0.24, 5:0.24
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 16:0.72; 14:0.08; 13:0.08; 17:0.06; 12:0.01
  Agent2 top policies: 22:0.63; 21:0.09; 18:0.09; 23:0.07; 19:0.01
. 2 r
. . .
1 . .

Reward: +0.00, Result: neutral

--- Step 7 ---
Agent 1: UP, Agent 2: RIGHT
  Agent1 beliefs:
    agent_pos: 6:1.00, 7:0.00, 8:0.00
    red_button_pos: 1:0.47, 2:0.47, 0:0.02
    blue_button_pos: 1:0.47, 2:0.47, 0:0.02
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 1:1.00, 8:0.00, 5:0.00
    red_button_pos: 6:0.32, 2:0.32, 5:0.32
    blue_button_pos: 1:1.00, 2:0.00, 6:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 0:0.05; 4:0.05; 3:0.05; 2:0.04; 24:0.04
  Agent2 top policies: 22:0.34; 19:0.10; 21:0.09; 18:0.09; 23:0.07
. b 2
1 . .
. . .

Reward: +0.00, Result: neutral

--- Step 8 ---
Agent 1: UP, Agent 2: PRESS
  Agent1 beliefs:
    agent_pos: 3:1.00, 6:0.00, 7:0.00
    red_button_pos: 1:0.47, 2:0.47, 0:0.02
    blue_button_pos: 1:0.47, 2:0.47, 0:0.02
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 2:1.00, 8:0.00, 7:0.00
    red_button_pos: 2:1.00, 5:0.00, 6:0.00
    blue_button_pos: 1:0.99, 5:0.00, 6:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 3:0.24; 18:0.21; 4:0.05; 0:0.03; 2:0.03
  Agent2 top policies: 26:0.06; 24:0.06; 27:0.06; 22:0.05; 4:0.05
1 b 2
. . .
. . .

Reward: +0.00, Result: neutral
Button pressed: red by Agent 2

--- Step 9 ---
Agent 1: RIGHT, Agent 2: LEFT
  Agent1 beliefs:
    agent_pos: 0:1.00, 3:0.00, 6:0.00
    red_button_pos: 1:0.48, 2:0.48, 4:0.01
    blue_button_pos: 1:0.48, 2:0.48, 4:0.01
    red_button_state: 0:0.50, 1:0.50
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 2:1.00, 8:0.00, 7:0.00
    red_button_pos: 2:1.00, 5:0.00, 6:0.00
    blue_button_pos: 1:0.98, 5:0.00, 6:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 22:0.59; 18:0.12; 21:0.12; 23:0.10; 19:0.01
  Agent2 top policies: 16:0.35; 12:0.03; 26:0.02; 20:0.02; 2:0.02
. 1 2
. . .
. . .

Reward: +0.00, Result: neutral

--- Step 10 ---
Agent 1: PRESS, Agent 2: LEFT
  Agent1 beliefs:
    agent_pos: 1:1.00, 8:0.00, 5:0.00
    red_button_pos: 2:0.91, 4:0.03, 5:0.02
    blue_button_pos: 1:1.00, 2:0.00, 4:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 2:1.00, 1:0.00, 8:0.00
    red_button_pos: 2:1.00, 8:0.00, 7:0.00
    blue_button_pos: 1:0.97, 5:0.00, 6:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 27:0.24; 25:0.16; 24:0.15; 26:0.13; 28:0.12
  Agent2 top policies: 16:0.37; 12:0.03; 26:0.02; 2:0.02; 20:0.02
. 1 2
. . .
. . .

Reward: +1.00, Result: win
Button pressed: blue by Agent 1

Result: ✅ WIN - win (steps: 10, reward: +1.00)

================================================================================
EPISODE 25
================================================================================
Environment: Red at (2, 0), Blue at (1, 0)

Initial state:
1 b r
. . .
. . 2


--- Step 1 ---
Agent 1: DOWN, Agent 2: LEFT
  Agent1 beliefs:
    agent_pos: 0:1.00, 8:0.00, 7:0.00
    red_button_pos: 8:0.12, 7:0.12, 6:0.12
    blue_button_pos: 8:0.12, 7:0.12, 6:0.12
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 8:1.00, 7:0.00, 6:0.00
    red_button_pos: 7:0.12, 3:0.12, 6:0.12
    blue_button_pos: 7:0.12, 3:0.12, 6:0.12
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 10:0.21; 22:0.21; 9:0.06; 19:0.06; 21:0.05
  Agent2 top policies: 16:0.21; 4:0.21; 12:0.06; 2:0.06; 0:0.05
. b r
1 . .
. 2 .

Reward: +0.00, Result: neutral

--- Step 2 ---
Agent 1: RIGHT, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 3:1.00, 0:0.00, 8:0.00
    red_button_pos: 8:0.14, 7:0.14, 6:0.14
    blue_button_pos: 8:0.14, 7:0.14, 6:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 7:1.00, 8:0.00, 6:0.00
    red_button_pos: 6:0.14, 1:0.14, 5:0.14
    blue_button_pos: 6:0.14, 1:0.14, 5:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 22:0.23; 10:0.23; 9:0.06; 21:0.05; 19:0.05
  Agent2 top policies: 4:0.23; 16:0.23; 12:0.06; 0:0.05; 2:0.05
. b r
. 1 .
. 2 .

Reward: +0.00, Result: neutral

--- Step 3 ---
Agent 1: RIGHT, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 4:1.00, 3:0.00, 0:0.00
    red_button_pos: 8:0.17, 7:0.17, 6:0.17
    blue_button_pos: 8:0.17, 7:0.17, 6:0.17
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 7:0.87, 4:0.12, 8:0.00
    red_button_pos: 6:0.14, 1:0.14, 5:0.14
    blue_button_pos: 6:0.14, 1:0.14, 5:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 22:0.18; 10:0.18; 4:0.18; 21:0.04; 9:0.04
  Agent2 top policies: 4:0.24; 16:0.23; 12:0.06; 2:0.05; 14:0.05
. b r
. 2 1
. . .

Reward: +0.00, Result: neutral

--- Step 4 ---
Agent 1: DOWN, Agent 2: LEFT
  Agent1 beliefs:
    agent_pos: 5:1.00, 4:0.00, 3:0.00
    red_button_pos: 8:0.20, 7:0.20, 6:0.20
    blue_button_pos: 8:0.20, 7:0.20, 6:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 4:1.00, 1:0.00, 7:0.00
    red_button_pos: 6:0.17, 1:0.17, 5:0.17
    blue_button_pos: 6:0.17, 1:0.17, 5:0.17
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 10:0.27; 4:0.27; 8:0.05; 2:0.05; 7:0.05
  Agent2 top policies: 16:0.18; 22:0.18; 4:0.18; 12:0.04; 18:0.04
. b r
2 . .
. . 1

Reward: +0.00, Result: neutral

--- Step 5 ---
Agent 1: LEFT, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 8:1.00, 5:0.00, 4:0.00
    red_button_pos: 7:0.25, 1:0.25, 6:0.25
    blue_button_pos: 7:0.25, 1:0.25, 6:0.25
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 3:1.00, 4:0.00, 7:0.00
    red_button_pos: 6:0.20, 5:0.20, 0:0.20
    blue_button_pos: 6:0.20, 5:0.20, 0:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 16:0.63; 14:0.09; 13:0.09; 17:0.07; 12:0.01
  Agent2 top policies: 4:0.28; 10:0.28; 3:0.05; 0:0.05; 2:0.05
2 b r
. . .
. 1 .

Reward: +0.00, Result: neutral

--- Step 6 ---
Agent 1: LEFT, Agent 2: RIGHT
  Agent1 beliefs:
    agent_pos: 7:1.00, 8:0.00, 5:0.00
    red_button_pos: 1:0.32, 2:0.32, 6:0.32
    blue_button_pos: 1:0.32, 2:0.32, 6:0.32
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 0:1.00, 3:0.00, 4:0.00
    red_button_pos: 6:0.24, 1:0.24, 5:0.24
    blue_button_pos: 6:0.24, 1:0.24, 5:0.24
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 16:0.72; 14:0.08; 13:0.08; 17:0.06; 12:0.01
  Agent2 top policies: 22:0.63; 21:0.09; 18:0.09; 23:0.07; 19:0.01
. 2 r
. . .
1 . .

Reward: +0.00, Result: neutral

--- Step 7 ---
Agent 1: UP, Agent 2: RIGHT
  Agent1 beliefs:
    agent_pos: 6:1.00, 7:0.00, 8:0.00
    red_button_pos: 1:0.47, 2:0.47, 0:0.02
    blue_button_pos: 1:0.47, 2:0.47, 0:0.02
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 1:1.00, 8:0.00, 5:0.00
    red_button_pos: 6:0.32, 2:0.32, 5:0.32
    blue_button_pos: 1:1.00, 2:0.00, 6:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 0:0.05; 4:0.05; 3:0.05; 2:0.04; 24:0.04
  Agent2 top policies: 22:0.34; 19:0.10; 21:0.09; 18:0.09; 23:0.07
. b 2
1 . .
. . .

Reward: +0.00, Result: neutral

--- Step 8 ---
Agent 1: UP, Agent 2: PRESS
  Agent1 beliefs:
    agent_pos: 3:1.00, 6:0.00, 7:0.00
    red_button_pos: 1:0.47, 2:0.47, 0:0.02
    blue_button_pos: 1:0.47, 2:0.47, 0:0.02
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 2:1.00, 8:0.00, 7:0.00
    red_button_pos: 2:1.00, 5:0.00, 6:0.00
    blue_button_pos: 1:0.99, 5:0.00, 6:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 3:0.24; 18:0.21; 4:0.05; 0:0.03; 2:0.03
  Agent2 top policies: 26:0.06; 24:0.06; 27:0.06; 22:0.05; 4:0.05
1 b 2
. . .
. . .

Reward: +0.00, Result: neutral
Button pressed: red by Agent 2

--- Step 9 ---
Agent 1: RIGHT, Agent 2: LEFT
  Agent1 beliefs:
    agent_pos: 0:1.00, 3:0.00, 6:0.00
    red_button_pos: 1:0.48, 2:0.48, 4:0.01
    blue_button_pos: 1:0.48, 2:0.48, 4:0.01
    red_button_state: 0:0.50, 1:0.50
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 2:1.00, 8:0.00, 7:0.00
    red_button_pos: 2:1.00, 5:0.00, 6:0.00
    blue_button_pos: 1:0.98, 5:0.00, 6:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 22:0.59; 18:0.12; 21:0.12; 23:0.10; 19:0.01
  Agent2 top policies: 16:0.35; 12:0.03; 26:0.02; 20:0.02; 2:0.02
. 1 2
. . .
. . .

Reward: +0.00, Result: neutral

--- Step 10 ---
Agent 1: PRESS, Agent 2: LEFT
  Agent1 beliefs:
    agent_pos: 1:1.00, 8:0.00, 5:0.00
    red_button_pos: 2:0.91, 4:0.03, 5:0.02
    blue_button_pos: 1:1.00, 2:0.00, 4:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 2:1.00, 1:0.00, 8:0.00
    red_button_pos: 2:1.00, 8:0.00, 7:0.00
    blue_button_pos: 1:0.97, 5:0.00, 6:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 27:0.24; 25:0.16; 24:0.15; 26:0.13; 28:0.12
  Agent2 top policies: 16:0.37; 12:0.03; 26:0.02; 2:0.02; 20:0.02
. 1 2
. . .
. . .

Reward: +1.00, Result: win
Button pressed: blue by Agent 1

Result: ✅ WIN - win (steps: 10, reward: +1.00)

================================================================================
EPISODE 26
================================================================================
Environment: Red at (2, 0), Blue at (1, 0)

Initial state:
1 b r
. . .
. . 2


--- Step 1 ---
Agent 1: DOWN, Agent 2: LEFT
  Agent1 beliefs:
    agent_pos: 0:1.00, 8:0.00, 7:0.00
    red_button_pos: 8:0.12, 7:0.12, 6:0.12
    blue_button_pos: 8:0.12, 7:0.12, 6:0.12
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 8:1.00, 7:0.00, 6:0.00
    red_button_pos: 7:0.12, 3:0.12, 6:0.12
    blue_button_pos: 7:0.12, 3:0.12, 6:0.12
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 10:0.21; 22:0.21; 9:0.06; 19:0.06; 21:0.05
  Agent2 top policies: 16:0.21; 4:0.21; 12:0.06; 2:0.06; 0:0.05
. b r
1 . .
. 2 .

Reward: +0.00, Result: neutral

--- Step 2 ---
Agent 1: RIGHT, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 3:1.00, 0:0.00, 8:0.00
    red_button_pos: 8:0.14, 7:0.14, 6:0.14
    blue_button_pos: 8:0.14, 7:0.14, 6:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 7:1.00, 8:0.00, 6:0.00
    red_button_pos: 6:0.14, 1:0.14, 5:0.14
    blue_button_pos: 6:0.14, 1:0.14, 5:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 22:0.23; 10:0.23; 9:0.06; 21:0.05; 19:0.05
  Agent2 top policies: 4:0.23; 16:0.23; 12:0.06; 0:0.05; 2:0.05
. b r
. 1 .
. 2 .

Reward: +0.00, Result: neutral

--- Step 3 ---
Agent 1: RIGHT, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 4:1.00, 3:0.00, 0:0.00
    red_button_pos: 8:0.17, 7:0.17, 6:0.17
    blue_button_pos: 8:0.17, 7:0.17, 6:0.17
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 7:0.87, 4:0.12, 8:0.00
    red_button_pos: 6:0.14, 1:0.14, 5:0.14
    blue_button_pos: 6:0.14, 1:0.14, 5:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 22:0.18; 10:0.18; 4:0.18; 21:0.04; 9:0.04
  Agent2 top policies: 4:0.24; 16:0.23; 12:0.06; 2:0.05; 14:0.05
. b r
. 2 1
. . .

Reward: +0.00, Result: neutral

--- Step 4 ---
Agent 1: DOWN, Agent 2: LEFT
  Agent1 beliefs:
    agent_pos: 5:1.00, 4:0.00, 3:0.00
    red_button_pos: 8:0.20, 7:0.20, 6:0.20
    blue_button_pos: 8:0.20, 7:0.20, 6:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 4:1.00, 1:0.00, 7:0.00
    red_button_pos: 6:0.17, 1:0.17, 5:0.17
    blue_button_pos: 6:0.17, 1:0.17, 5:0.17
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 10:0.27; 4:0.27; 8:0.05; 2:0.05; 7:0.05
  Agent2 top policies: 16:0.18; 22:0.18; 4:0.18; 12:0.04; 18:0.04
. b r
2 . .
. . 1

Reward: +0.00, Result: neutral

--- Step 5 ---
Agent 1: LEFT, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 8:1.00, 5:0.00, 4:0.00
    red_button_pos: 7:0.25, 1:0.25, 6:0.25
    blue_button_pos: 7:0.25, 1:0.25, 6:0.25
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 3:1.00, 4:0.00, 7:0.00
    red_button_pos: 6:0.20, 5:0.20, 0:0.20
    blue_button_pos: 6:0.20, 5:0.20, 0:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 16:0.63; 14:0.09; 13:0.09; 17:0.07; 12:0.01
  Agent2 top policies: 4:0.28; 10:0.28; 3:0.05; 0:0.05; 2:0.05
2 b r
. . .
. 1 .

Reward: +0.00, Result: neutral

--- Step 6 ---
Agent 1: LEFT, Agent 2: RIGHT
  Agent1 beliefs:
    agent_pos: 7:1.00, 8:0.00, 5:0.00
    red_button_pos: 1:0.32, 2:0.32, 6:0.32
    blue_button_pos: 1:0.32, 2:0.32, 6:0.32
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 0:1.00, 3:0.00, 4:0.00
    red_button_pos: 6:0.24, 1:0.24, 5:0.24
    blue_button_pos: 6:0.24, 1:0.24, 5:0.24
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 16:0.72; 14:0.08; 13:0.08; 17:0.06; 12:0.01
  Agent2 top policies: 22:0.63; 21:0.09; 18:0.09; 23:0.07; 19:0.01
. 2 r
. . .
1 . .

Reward: +0.00, Result: neutral

--- Step 7 ---
Agent 1: UP, Agent 2: RIGHT
  Agent1 beliefs:
    agent_pos: 6:1.00, 7:0.00, 8:0.00
    red_button_pos: 1:0.47, 2:0.47, 0:0.02
    blue_button_pos: 1:0.47, 2:0.47, 0:0.02
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 1:1.00, 8:0.00, 5:0.00
    red_button_pos: 6:0.32, 2:0.32, 5:0.32
    blue_button_pos: 1:1.00, 2:0.00, 6:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 0:0.05; 4:0.05; 3:0.05; 2:0.04; 24:0.04
  Agent2 top policies: 22:0.34; 19:0.10; 21:0.09; 18:0.09; 23:0.07
. b 2
1 . .
. . .

Reward: +0.00, Result: neutral

--- Step 8 ---
Agent 1: UP, Agent 2: PRESS
  Agent1 beliefs:
    agent_pos: 3:1.00, 6:0.00, 7:0.00
    red_button_pos: 1:0.47, 2:0.47, 0:0.02
    blue_button_pos: 1:0.47, 2:0.47, 0:0.02
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 2:1.00, 8:0.00, 7:0.00
    red_button_pos: 2:1.00, 5:0.00, 6:0.00
    blue_button_pos: 1:0.99, 5:0.00, 6:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 3:0.24; 18:0.21; 4:0.05; 0:0.03; 2:0.03
  Agent2 top policies: 26:0.06; 24:0.06; 27:0.06; 22:0.05; 4:0.05
1 b 2
. . .
. . .

Reward: +0.00, Result: neutral
Button pressed: red by Agent 2

--- Step 9 ---
Agent 1: RIGHT, Agent 2: LEFT
  Agent1 beliefs:
    agent_pos: 0:1.00, 3:0.00, 6:0.00
    red_button_pos: 1:0.48, 2:0.48, 4:0.01
    blue_button_pos: 1:0.48, 2:0.48, 4:0.01
    red_button_state: 0:0.50, 1:0.50
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 2:1.00, 8:0.00, 7:0.00
    red_button_pos: 2:1.00, 5:0.00, 6:0.00
    blue_button_pos: 1:0.98, 5:0.00, 6:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 22:0.59; 18:0.12; 21:0.12; 23:0.10; 19:0.01
  Agent2 top policies: 16:0.35; 12:0.03; 26:0.02; 20:0.02; 2:0.02
. 1 2
. . .
. . .

Reward: +0.00, Result: neutral

--- Step 10 ---
Agent 1: PRESS, Agent 2: LEFT
  Agent1 beliefs:
    agent_pos: 1:1.00, 8:0.00, 5:0.00
    red_button_pos: 2:0.91, 4:0.03, 5:0.02
    blue_button_pos: 1:1.00, 2:0.00, 4:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 2:1.00, 1:0.00, 8:0.00
    red_button_pos: 2:1.00, 8:0.00, 7:0.00
    blue_button_pos: 1:0.97, 5:0.00, 6:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 27:0.24; 25:0.16; 24:0.15; 26:0.13; 28:0.12
  Agent2 top policies: 16:0.37; 12:0.03; 26:0.02; 2:0.02; 20:0.02
. 1 2
. . .
. . .

Reward: +1.00, Result: win
Button pressed: blue by Agent 1

Result: ✅ WIN - win (steps: 10, reward: +1.00)

================================================================================
EPISODE 27
================================================================================
Environment: Red at (2, 0), Blue at (1, 0)

Initial state:
1 b r
. . .
. . 2


--- Step 1 ---
Agent 1: DOWN, Agent 2: LEFT
  Agent1 beliefs:
    agent_pos: 0:1.00, 8:0.00, 7:0.00
    red_button_pos: 8:0.12, 7:0.12, 6:0.12
    blue_button_pos: 8:0.12, 7:0.12, 6:0.12
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 8:1.00, 7:0.00, 6:0.00
    red_button_pos: 7:0.12, 3:0.12, 6:0.12
    blue_button_pos: 7:0.12, 3:0.12, 6:0.12
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 10:0.21; 22:0.21; 9:0.06; 19:0.06; 21:0.05
  Agent2 top policies: 16:0.21; 4:0.21; 12:0.06; 2:0.06; 0:0.05
. b r
1 . .
. 2 .

Reward: +0.00, Result: neutral

--- Step 2 ---
Agent 1: RIGHT, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 3:1.00, 0:0.00, 8:0.00
    red_button_pos: 8:0.14, 7:0.14, 6:0.14
    blue_button_pos: 8:0.14, 7:0.14, 6:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 7:1.00, 8:0.00, 6:0.00
    red_button_pos: 6:0.14, 1:0.14, 5:0.14
    blue_button_pos: 6:0.14, 1:0.14, 5:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 22:0.23; 10:0.23; 9:0.06; 21:0.05; 19:0.05
  Agent2 top policies: 4:0.23; 16:0.23; 12:0.06; 0:0.05; 2:0.05
. b r
. 1 .
. 2 .

Reward: +0.00, Result: neutral

--- Step 3 ---
Agent 1: RIGHT, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 4:1.00, 3:0.00, 0:0.00
    red_button_pos: 8:0.17, 7:0.17, 6:0.17
    blue_button_pos: 8:0.17, 7:0.17, 6:0.17
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 7:0.87, 4:0.12, 8:0.00
    red_button_pos: 6:0.14, 1:0.14, 5:0.14
    blue_button_pos: 6:0.14, 1:0.14, 5:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 22:0.18; 10:0.18; 4:0.18; 21:0.04; 9:0.04
  Agent2 top policies: 4:0.24; 16:0.23; 12:0.06; 2:0.05; 14:0.05
. b r
. 2 1
. . .

Reward: +0.00, Result: neutral

--- Step 4 ---
Agent 1: DOWN, Agent 2: LEFT
  Agent1 beliefs:
    agent_pos: 5:1.00, 4:0.00, 3:0.00
    red_button_pos: 8:0.20, 7:0.20, 6:0.20
    blue_button_pos: 8:0.20, 7:0.20, 6:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 4:1.00, 1:0.00, 7:0.00
    red_button_pos: 6:0.17, 1:0.17, 5:0.17
    blue_button_pos: 6:0.17, 1:0.17, 5:0.17
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 10:0.27; 4:0.27; 8:0.05; 2:0.05; 7:0.05
  Agent2 top policies: 16:0.18; 22:0.18; 4:0.18; 12:0.04; 18:0.04
. b r
2 . .
. . 1

Reward: +0.00, Result: neutral

--- Step 5 ---
Agent 1: LEFT, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 8:1.00, 5:0.00, 4:0.00
    red_button_pos: 7:0.25, 1:0.25, 6:0.25
    blue_button_pos: 7:0.25, 1:0.25, 6:0.25
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 3:1.00, 4:0.00, 7:0.00
    red_button_pos: 6:0.20, 5:0.20, 0:0.20
    blue_button_pos: 6:0.20, 5:0.20, 0:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 16:0.63; 14:0.09; 13:0.09; 17:0.07; 12:0.01
  Agent2 top policies: 4:0.28; 10:0.28; 3:0.05; 0:0.05; 2:0.05
2 b r
. . .
. 1 .

Reward: +0.00, Result: neutral

--- Step 6 ---
Agent 1: LEFT, Agent 2: RIGHT
  Agent1 beliefs:
    agent_pos: 7:1.00, 8:0.00, 5:0.00
    red_button_pos: 1:0.32, 2:0.32, 6:0.32
    blue_button_pos: 1:0.32, 2:0.32, 6:0.32
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 0:1.00, 3:0.00, 4:0.00
    red_button_pos: 6:0.24, 1:0.24, 5:0.24
    blue_button_pos: 6:0.24, 1:0.24, 5:0.24
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 16:0.72; 14:0.08; 13:0.08; 17:0.06; 12:0.01
  Agent2 top policies: 22:0.63; 21:0.09; 18:0.09; 23:0.07; 19:0.01
. 2 r
. . .
1 . .

Reward: +0.00, Result: neutral

--- Step 7 ---
Agent 1: UP, Agent 2: RIGHT
  Agent1 beliefs:
    agent_pos: 6:1.00, 7:0.00, 8:0.00
    red_button_pos: 1:0.47, 2:0.47, 0:0.02
    blue_button_pos: 1:0.47, 2:0.47, 0:0.02
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 1:1.00, 8:0.00, 5:0.00
    red_button_pos: 6:0.32, 2:0.32, 5:0.32
    blue_button_pos: 1:1.00, 2:0.00, 6:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 0:0.05; 4:0.05; 3:0.05; 2:0.04; 24:0.04
  Agent2 top policies: 22:0.34; 19:0.10; 21:0.09; 18:0.09; 23:0.07
. b 2
1 . .
. . .

Reward: +0.00, Result: neutral

--- Step 8 ---
Agent 1: UP, Agent 2: PRESS
  Agent1 beliefs:
    agent_pos: 3:1.00, 6:0.00, 7:0.00
    red_button_pos: 1:0.47, 2:0.47, 0:0.02
    blue_button_pos: 1:0.47, 2:0.47, 0:0.02
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 2:1.00, 8:0.00, 7:0.00
    red_button_pos: 2:1.00, 5:0.00, 6:0.00
    blue_button_pos: 1:0.99, 5:0.00, 6:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 3:0.24; 18:0.21; 4:0.05; 0:0.03; 2:0.03
  Agent2 top policies: 26:0.06; 24:0.06; 27:0.06; 22:0.05; 4:0.05
1 b 2
. . .
. . .

Reward: +0.00, Result: neutral
Button pressed: red by Agent 2

--- Step 9 ---
Agent 1: RIGHT, Agent 2: LEFT
  Agent1 beliefs:
    agent_pos: 0:1.00, 3:0.00, 6:0.00
    red_button_pos: 1:0.48, 2:0.48, 4:0.01
    blue_button_pos: 1:0.48, 2:0.48, 4:0.01
    red_button_state: 0:0.50, 1:0.50
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 2:1.00, 8:0.00, 7:0.00
    red_button_pos: 2:1.00, 5:0.00, 6:0.00
    blue_button_pos: 1:0.98, 5:0.00, 6:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 22:0.59; 18:0.12; 21:0.12; 23:0.10; 19:0.01
  Agent2 top policies: 16:0.35; 12:0.03; 26:0.02; 20:0.02; 2:0.02
. 1 2
. . .
. . .

Reward: +0.00, Result: neutral

--- Step 10 ---
Agent 1: PRESS, Agent 2: LEFT
  Agent1 beliefs:
    agent_pos: 1:1.00, 8:0.00, 5:0.00
    red_button_pos: 2:0.91, 4:0.03, 5:0.02
    blue_button_pos: 1:1.00, 2:0.00, 4:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 2:1.00, 1:0.00, 8:0.00
    red_button_pos: 2:1.00, 8:0.00, 7:0.00
    blue_button_pos: 1:0.97, 5:0.00, 6:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 27:0.24; 25:0.16; 24:0.15; 26:0.13; 28:0.12
  Agent2 top policies: 16:0.37; 12:0.03; 26:0.02; 2:0.02; 20:0.02
. 1 2
. . .
. . .

Reward: +1.00, Result: win
Button pressed: blue by Agent 1

Result: ✅ WIN - win (steps: 10, reward: +1.00)

================================================================================
EPISODE 28
================================================================================
Environment: Red at (2, 0), Blue at (1, 0)

Initial state:
1 b r
. . .
. . 2


--- Step 1 ---
Agent 1: DOWN, Agent 2: LEFT
  Agent1 beliefs:
    agent_pos: 0:1.00, 8:0.00, 7:0.00
    red_button_pos: 8:0.12, 7:0.12, 6:0.12
    blue_button_pos: 8:0.12, 7:0.12, 6:0.12
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 8:1.00, 7:0.00, 6:0.00
    red_button_pos: 7:0.12, 3:0.12, 6:0.12
    blue_button_pos: 7:0.12, 3:0.12, 6:0.12
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 10:0.21; 22:0.21; 9:0.06; 19:0.06; 21:0.05
  Agent2 top policies: 16:0.21; 4:0.21; 12:0.06; 2:0.06; 0:0.05
. b r
1 . .
. 2 .

Reward: +0.00, Result: neutral

--- Step 2 ---
Agent 1: RIGHT, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 3:1.00, 0:0.00, 8:0.00
    red_button_pos: 8:0.14, 7:0.14, 6:0.14
    blue_button_pos: 8:0.14, 7:0.14, 6:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 7:1.00, 8:0.00, 6:0.00
    red_button_pos: 6:0.14, 1:0.14, 5:0.14
    blue_button_pos: 6:0.14, 1:0.14, 5:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 22:0.23; 10:0.23; 9:0.06; 21:0.05; 19:0.05
  Agent2 top policies: 4:0.23; 16:0.23; 12:0.06; 0:0.05; 2:0.05
. b r
. 1 .
. 2 .

Reward: +0.00, Result: neutral

--- Step 3 ---
Agent 1: RIGHT, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 4:1.00, 3:0.00, 0:0.00
    red_button_pos: 8:0.17, 7:0.17, 6:0.17
    blue_button_pos: 8:0.17, 7:0.17, 6:0.17
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 7:0.87, 4:0.12, 8:0.00
    red_button_pos: 6:0.14, 1:0.14, 5:0.14
    blue_button_pos: 6:0.14, 1:0.14, 5:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 22:0.18; 10:0.18; 4:0.18; 21:0.04; 9:0.04
  Agent2 top policies: 4:0.24; 16:0.23; 12:0.06; 2:0.05; 14:0.05
. b r
. 2 1
. . .

Reward: +0.00, Result: neutral

--- Step 4 ---
Agent 1: DOWN, Agent 2: LEFT
  Agent1 beliefs:
    agent_pos: 5:1.00, 4:0.00, 3:0.00
    red_button_pos: 8:0.20, 7:0.20, 6:0.20
    blue_button_pos: 8:0.20, 7:0.20, 6:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 4:1.00, 1:0.00, 7:0.00
    red_button_pos: 6:0.17, 1:0.17, 5:0.17
    blue_button_pos: 6:0.17, 1:0.17, 5:0.17
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 10:0.27; 4:0.27; 8:0.05; 2:0.05; 7:0.05
  Agent2 top policies: 16:0.18; 22:0.18; 4:0.18; 12:0.04; 18:0.04
. b r
2 . .
. . 1

Reward: +0.00, Result: neutral

--- Step 5 ---
Agent 1: LEFT, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 8:1.00, 5:0.00, 4:0.00
    red_button_pos: 7:0.25, 1:0.25, 6:0.25
    blue_button_pos: 7:0.25, 1:0.25, 6:0.25
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 3:1.00, 4:0.00, 7:0.00
    red_button_pos: 6:0.20, 5:0.20, 0:0.20
    blue_button_pos: 6:0.20, 5:0.20, 0:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 16:0.63; 14:0.09; 13:0.09; 17:0.07; 12:0.01
  Agent2 top policies: 4:0.28; 10:0.28; 3:0.05; 0:0.05; 2:0.05
2 b r
. . .
. 1 .

Reward: +0.00, Result: neutral

--- Step 6 ---
Agent 1: LEFT, Agent 2: RIGHT
  Agent1 beliefs:
    agent_pos: 7:1.00, 8:0.00, 5:0.00
    red_button_pos: 1:0.32, 2:0.32, 6:0.32
    blue_button_pos: 1:0.32, 2:0.32, 6:0.32
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 0:1.00, 3:0.00, 4:0.00
    red_button_pos: 6:0.24, 1:0.24, 5:0.24
    blue_button_pos: 6:0.24, 1:0.24, 5:0.24
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 16:0.72; 14:0.08; 13:0.08; 17:0.06; 12:0.01
  Agent2 top policies: 22:0.63; 21:0.09; 18:0.09; 23:0.07; 19:0.01
. 2 r
. . .
1 . .

Reward: +0.00, Result: neutral

--- Step 7 ---
Agent 1: UP, Agent 2: RIGHT
  Agent1 beliefs:
    agent_pos: 6:1.00, 7:0.00, 8:0.00
    red_button_pos: 1:0.47, 2:0.47, 0:0.02
    blue_button_pos: 1:0.47, 2:0.47, 0:0.02
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 1:1.00, 8:0.00, 5:0.00
    red_button_pos: 6:0.32, 2:0.32, 5:0.32
    blue_button_pos: 1:1.00, 2:0.00, 6:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 0:0.05; 4:0.05; 3:0.05; 2:0.04; 24:0.04
  Agent2 top policies: 22:0.34; 19:0.10; 21:0.09; 18:0.09; 23:0.07
. b 2
1 . .
. . .

Reward: +0.00, Result: neutral

--- Step 8 ---
Agent 1: UP, Agent 2: PRESS
  Agent1 beliefs:
    agent_pos: 3:1.00, 6:0.00, 7:0.00
    red_button_pos: 1:0.47, 2:0.47, 0:0.02
    blue_button_pos: 1:0.47, 2:0.47, 0:0.02
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 2:1.00, 8:0.00, 7:0.00
    red_button_pos: 2:1.00, 5:0.00, 6:0.00
    blue_button_pos: 1:0.99, 5:0.00, 6:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 3:0.24; 18:0.21; 4:0.05; 0:0.03; 2:0.03
  Agent2 top policies: 26:0.06; 24:0.06; 27:0.06; 22:0.05; 4:0.05
1 b 2
. . .
. . .

Reward: +0.00, Result: neutral
Button pressed: red by Agent 2

--- Step 9 ---
Agent 1: RIGHT, Agent 2: LEFT
  Agent1 beliefs:
    agent_pos: 0:1.00, 3:0.00, 6:0.00
    red_button_pos: 1:0.48, 2:0.48, 4:0.01
    blue_button_pos: 1:0.48, 2:0.48, 4:0.01
    red_button_state: 0:0.50, 1:0.50
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 2:1.00, 8:0.00, 7:0.00
    red_button_pos: 2:1.00, 5:0.00, 6:0.00
    blue_button_pos: 1:0.98, 5:0.00, 6:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 22:0.59; 18:0.12; 21:0.12; 23:0.10; 19:0.01
  Agent2 top policies: 16:0.35; 12:0.03; 26:0.02; 20:0.02; 2:0.02
. 1 2
. . .
. . .

Reward: +0.00, Result: neutral

--- Step 10 ---
Agent 1: PRESS, Agent 2: LEFT
  Agent1 beliefs:
    agent_pos: 1:1.00, 8:0.00, 5:0.00
    red_button_pos: 2:0.91, 4:0.03, 5:0.02
    blue_button_pos: 1:1.00, 2:0.00, 4:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 2:1.00, 1:0.00, 8:0.00
    red_button_pos: 2:1.00, 8:0.00, 7:0.00
    blue_button_pos: 1:0.97, 5:0.00, 6:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 27:0.24; 25:0.16; 24:0.15; 26:0.13; 28:0.12
  Agent2 top policies: 16:0.37; 12:0.03; 26:0.02; 2:0.02; 20:0.02
. 1 2
. . .
. . .

Reward: +1.00, Result: win
Button pressed: blue by Agent 1

Result: ✅ WIN - win (steps: 10, reward: +1.00)

================================================================================
EPISODE 29
================================================================================
Environment: Red at (2, 0), Blue at (1, 0)

Initial state:
1 b r
. . .
. . 2


--- Step 1 ---
Agent 1: DOWN, Agent 2: LEFT
  Agent1 beliefs:
    agent_pos: 0:1.00, 8:0.00, 7:0.00
    red_button_pos: 8:0.12, 7:0.12, 6:0.12
    blue_button_pos: 8:0.12, 7:0.12, 6:0.12
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 8:1.00, 7:0.00, 6:0.00
    red_button_pos: 7:0.12, 3:0.12, 6:0.12
    blue_button_pos: 7:0.12, 3:0.12, 6:0.12
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 10:0.21; 22:0.21; 9:0.06; 19:0.06; 21:0.05
  Agent2 top policies: 16:0.21; 4:0.21; 12:0.06; 2:0.06; 0:0.05
. b r
1 . .
. 2 .

Reward: +0.00, Result: neutral

--- Step 2 ---
Agent 1: RIGHT, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 3:1.00, 0:0.00, 8:0.00
    red_button_pos: 8:0.14, 7:0.14, 6:0.14
    blue_button_pos: 8:0.14, 7:0.14, 6:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 7:1.00, 8:0.00, 6:0.00
    red_button_pos: 6:0.14, 1:0.14, 5:0.14
    blue_button_pos: 6:0.14, 1:0.14, 5:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 22:0.23; 10:0.23; 9:0.06; 21:0.05; 19:0.05
  Agent2 top policies: 4:0.23; 16:0.23; 12:0.06; 0:0.05; 2:0.05
. b r
. 1 .
. 2 .

Reward: +0.00, Result: neutral

--- Step 3 ---
Agent 1: RIGHT, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 4:1.00, 3:0.00, 0:0.00
    red_button_pos: 8:0.17, 7:0.17, 6:0.17
    blue_button_pos: 8:0.17, 7:0.17, 6:0.17
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 7:0.87, 4:0.12, 8:0.00
    red_button_pos: 6:0.14, 1:0.14, 5:0.14
    blue_button_pos: 6:0.14, 1:0.14, 5:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 22:0.18; 10:0.18; 4:0.18; 21:0.04; 9:0.04
  Agent2 top policies: 4:0.24; 16:0.23; 12:0.06; 2:0.05; 14:0.05
. b r
. 2 1
. . .

Reward: +0.00, Result: neutral

--- Step 4 ---
Agent 1: DOWN, Agent 2: LEFT
  Agent1 beliefs:
    agent_pos: 5:1.00, 4:0.00, 3:0.00
    red_button_pos: 8:0.20, 7:0.20, 6:0.20
    blue_button_pos: 8:0.20, 7:0.20, 6:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 4:1.00, 1:0.00, 7:0.00
    red_button_pos: 6:0.17, 1:0.17, 5:0.17
    blue_button_pos: 6:0.17, 1:0.17, 5:0.17
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 10:0.27; 4:0.27; 8:0.05; 2:0.05; 7:0.05
  Agent2 top policies: 16:0.18; 22:0.18; 4:0.18; 12:0.04; 18:0.04
. b r
2 . .
. . 1

Reward: +0.00, Result: neutral

--- Step 5 ---
Agent 1: LEFT, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 8:1.00, 5:0.00, 4:0.00
    red_button_pos: 7:0.25, 1:0.25, 6:0.25
    blue_button_pos: 7:0.25, 1:0.25, 6:0.25
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 3:1.00, 4:0.00, 7:0.00
    red_button_pos: 6:0.20, 5:0.20, 0:0.20
    blue_button_pos: 6:0.20, 5:0.20, 0:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 16:0.63; 14:0.09; 13:0.09; 17:0.07; 12:0.01
  Agent2 top policies: 4:0.28; 10:0.28; 3:0.05; 0:0.05; 2:0.05
2 b r
. . .
. 1 .

Reward: +0.00, Result: neutral

--- Step 6 ---
Agent 1: LEFT, Agent 2: RIGHT
  Agent1 beliefs:
    agent_pos: 7:1.00, 8:0.00, 5:0.00
    red_button_pos: 1:0.32, 2:0.32, 6:0.32
    blue_button_pos: 1:0.32, 2:0.32, 6:0.32
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 0:1.00, 3:0.00, 4:0.00
    red_button_pos: 6:0.24, 1:0.24, 5:0.24
    blue_button_pos: 6:0.24, 1:0.24, 5:0.24
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 16:0.72; 14:0.08; 13:0.08; 17:0.06; 12:0.01
  Agent2 top policies: 22:0.63; 21:0.09; 18:0.09; 23:0.07; 19:0.01
. 2 r
. . .
1 . .

Reward: +0.00, Result: neutral

--- Step 7 ---
Agent 1: UP, Agent 2: RIGHT
  Agent1 beliefs:
    agent_pos: 6:1.00, 7:0.00, 8:0.00
    red_button_pos: 1:0.47, 2:0.47, 0:0.02
    blue_button_pos: 1:0.47, 2:0.47, 0:0.02
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 1:1.00, 8:0.00, 5:0.00
    red_button_pos: 6:0.32, 2:0.32, 5:0.32
    blue_button_pos: 1:1.00, 2:0.00, 6:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 0:0.05; 4:0.05; 3:0.05; 2:0.04; 24:0.04
  Agent2 top policies: 22:0.34; 19:0.10; 21:0.09; 18:0.09; 23:0.07
. b 2
1 . .
. . .

Reward: +0.00, Result: neutral

--- Step 8 ---
Agent 1: UP, Agent 2: PRESS
  Agent1 beliefs:
    agent_pos: 3:1.00, 6:0.00, 7:0.00
    red_button_pos: 1:0.47, 2:0.47, 0:0.02
    blue_button_pos: 1:0.47, 2:0.47, 0:0.02
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 2:1.00, 8:0.00, 7:0.00
    red_button_pos: 2:1.00, 5:0.00, 6:0.00
    blue_button_pos: 1:0.99, 5:0.00, 6:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 3:0.24; 18:0.21; 4:0.05; 0:0.03; 2:0.03
  Agent2 top policies: 26:0.06; 24:0.06; 27:0.06; 22:0.05; 4:0.05
1 b 2
. . .
. . .

Reward: +0.00, Result: neutral
Button pressed: red by Agent 2

--- Step 9 ---
Agent 1: RIGHT, Agent 2: LEFT
  Agent1 beliefs:
    agent_pos: 0:1.00, 3:0.00, 6:0.00
    red_button_pos: 1:0.48, 2:0.48, 4:0.01
    blue_button_pos: 1:0.48, 2:0.48, 4:0.01
    red_button_state: 0:0.50, 1:0.50
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 2:1.00, 8:0.00, 7:0.00
    red_button_pos: 2:1.00, 5:0.00, 6:0.00
    blue_button_pos: 1:0.98, 5:0.00, 6:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 22:0.59; 18:0.12; 21:0.12; 23:0.10; 19:0.01
  Agent2 top policies: 16:0.35; 12:0.03; 26:0.02; 20:0.02; 2:0.02
. 1 2
. . .
. . .

Reward: +0.00, Result: neutral

--- Step 10 ---
Agent 1: PRESS, Agent 2: LEFT
  Agent1 beliefs:
    agent_pos: 1:1.00, 8:0.00, 5:0.00
    red_button_pos: 2:0.91, 4:0.03, 5:0.02
    blue_button_pos: 1:1.00, 2:0.00, 4:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 2:1.00, 1:0.00, 8:0.00
    red_button_pos: 2:1.00, 8:0.00, 7:0.00
    blue_button_pos: 1:0.97, 5:0.00, 6:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 27:0.24; 25:0.16; 24:0.15; 26:0.13; 28:0.12
  Agent2 top policies: 16:0.37; 12:0.03; 26:0.02; 2:0.02; 20:0.02
. 1 2
. . .
. . .

Reward: +1.00, Result: win
Button pressed: blue by Agent 1

Result: ✅ WIN - win (steps: 10, reward: +1.00)

================================================================================
EPISODE 30
================================================================================
Environment: Red at (2, 0), Blue at (1, 0)

Initial state:
1 b r
. . .
. . 2


--- Step 1 ---
Agent 1: DOWN, Agent 2: LEFT
  Agent1 beliefs:
    agent_pos: 0:1.00, 8:0.00, 7:0.00
    red_button_pos: 8:0.12, 7:0.12, 6:0.12
    blue_button_pos: 8:0.12, 7:0.12, 6:0.12
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 8:1.00, 7:0.00, 6:0.00
    red_button_pos: 7:0.12, 3:0.12, 6:0.12
    blue_button_pos: 7:0.12, 3:0.12, 6:0.12
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 10:0.21; 22:0.21; 9:0.06; 19:0.06; 21:0.05
  Agent2 top policies: 16:0.21; 4:0.21; 12:0.06; 2:0.06; 0:0.05
. b r
1 . .
. 2 .

Reward: +0.00, Result: neutral

--- Step 2 ---
Agent 1: RIGHT, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 3:1.00, 0:0.00, 8:0.00
    red_button_pos: 8:0.14, 7:0.14, 6:0.14
    blue_button_pos: 8:0.14, 7:0.14, 6:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 7:1.00, 8:0.00, 6:0.00
    red_button_pos: 6:0.14, 1:0.14, 5:0.14
    blue_button_pos: 6:0.14, 1:0.14, 5:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 22:0.23; 10:0.23; 9:0.06; 21:0.05; 19:0.05
  Agent2 top policies: 4:0.23; 16:0.23; 12:0.06; 0:0.05; 2:0.05
. b r
. 1 .
. 2 .

Reward: +0.00, Result: neutral

--- Step 3 ---
Agent 1: RIGHT, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 4:1.00, 3:0.00, 0:0.00
    red_button_pos: 8:0.17, 7:0.17, 6:0.17
    blue_button_pos: 8:0.17, 7:0.17, 6:0.17
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 7:0.87, 4:0.12, 8:0.00
    red_button_pos: 6:0.14, 1:0.14, 5:0.14
    blue_button_pos: 6:0.14, 1:0.14, 5:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 22:0.18; 10:0.18; 4:0.18; 21:0.04; 9:0.04
  Agent2 top policies: 4:0.24; 16:0.23; 12:0.06; 2:0.05; 14:0.05
. b r
. 2 1
. . .

Reward: +0.00, Result: neutral

--- Step 4 ---
Agent 1: DOWN, Agent 2: LEFT
  Agent1 beliefs:
    agent_pos: 5:1.00, 4:0.00, 3:0.00
    red_button_pos: 8:0.20, 7:0.20, 6:0.20
    blue_button_pos: 8:0.20, 7:0.20, 6:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 4:1.00, 1:0.00, 7:0.00
    red_button_pos: 6:0.17, 1:0.17, 5:0.17
    blue_button_pos: 6:0.17, 1:0.17, 5:0.17
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 10:0.27; 4:0.27; 8:0.05; 2:0.05; 7:0.05
  Agent2 top policies: 16:0.18; 22:0.18; 4:0.18; 12:0.04; 18:0.04
. b r
2 . .
. . 1

Reward: +0.00, Result: neutral

--- Step 5 ---
Agent 1: LEFT, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 8:1.00, 5:0.00, 4:0.00
    red_button_pos: 7:0.25, 1:0.25, 6:0.25
    blue_button_pos: 7:0.25, 1:0.25, 6:0.25
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 3:1.00, 4:0.00, 7:0.00
    red_button_pos: 6:0.20, 5:0.20, 0:0.20
    blue_button_pos: 6:0.20, 5:0.20, 0:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 16:0.63; 14:0.09; 13:0.09; 17:0.07; 12:0.01
  Agent2 top policies: 4:0.28; 10:0.28; 3:0.05; 0:0.05; 2:0.05
2 b r
. . .
. 1 .

Reward: +0.00, Result: neutral

--- Step 6 ---
Agent 1: LEFT, Agent 2: RIGHT
  Agent1 beliefs:
    agent_pos: 7:1.00, 8:0.00, 5:0.00
    red_button_pos: 1:0.32, 2:0.32, 6:0.32
    blue_button_pos: 1:0.32, 2:0.32, 6:0.32
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 0:1.00, 3:0.00, 4:0.00
    red_button_pos: 6:0.24, 1:0.24, 5:0.24
    blue_button_pos: 6:0.24, 1:0.24, 5:0.24
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 16:0.72; 14:0.08; 13:0.08; 17:0.06; 12:0.01
  Agent2 top policies: 22:0.63; 21:0.09; 18:0.09; 23:0.07; 19:0.01
. 2 r
. . .
1 . .

Reward: +0.00, Result: neutral

--- Step 7 ---
Agent 1: UP, Agent 2: RIGHT
  Agent1 beliefs:
    agent_pos: 6:1.00, 7:0.00, 8:0.00
    red_button_pos: 1:0.47, 2:0.47, 0:0.02
    blue_button_pos: 1:0.47, 2:0.47, 0:0.02
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 1:1.00, 8:0.00, 5:0.00
    red_button_pos: 6:0.32, 2:0.32, 5:0.32
    blue_button_pos: 1:1.00, 2:0.00, 6:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 0:0.05; 4:0.05; 3:0.05; 2:0.04; 24:0.04
  Agent2 top policies: 22:0.34; 19:0.10; 21:0.09; 18:0.09; 23:0.07
. b 2
1 . .
. . .

Reward: +0.00, Result: neutral

--- Step 8 ---
Agent 1: UP, Agent 2: PRESS
  Agent1 beliefs:
    agent_pos: 3:1.00, 6:0.00, 7:0.00
    red_button_pos: 1:0.47, 2:0.47, 0:0.02
    blue_button_pos: 1:0.47, 2:0.47, 0:0.02
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 2:1.00, 8:0.00, 7:0.00
    red_button_pos: 2:1.00, 5:0.00, 6:0.00
    blue_button_pos: 1:0.99, 5:0.00, 6:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 3:0.24; 18:0.21; 4:0.05; 0:0.03; 2:0.03
  Agent2 top policies: 26:0.06; 24:0.06; 27:0.06; 22:0.05; 4:0.05
1 b 2
. . .
. . .

Reward: +0.00, Result: neutral
Button pressed: red by Agent 2

--- Step 9 ---
Agent 1: RIGHT, Agent 2: LEFT
  Agent1 beliefs:
    agent_pos: 0:1.00, 3:0.00, 6:0.00
    red_button_pos: 1:0.48, 2:0.48, 4:0.01
    blue_button_pos: 1:0.48, 2:0.48, 4:0.01
    red_button_state: 0:0.50, 1:0.50
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 2:1.00, 8:0.00, 7:0.00
    red_button_pos: 2:1.00, 5:0.00, 6:0.00
    blue_button_pos: 1:0.98, 5:0.00, 6:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 22:0.59; 18:0.12; 21:0.12; 23:0.10; 19:0.01
  Agent2 top policies: 16:0.35; 12:0.03; 26:0.02; 20:0.02; 2:0.02
. 1 2
. . .
. . .

Reward: +0.00, Result: neutral

--- Step 10 ---
Agent 1: PRESS, Agent 2: LEFT
  Agent1 beliefs:
    agent_pos: 1:1.00, 8:0.00, 5:0.00
    red_button_pos: 2:0.91, 4:0.03, 5:0.02
    blue_button_pos: 1:1.00, 2:0.00, 4:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 2:1.00, 1:0.00, 8:0.00
    red_button_pos: 2:1.00, 8:0.00, 7:0.00
    blue_button_pos: 1:0.97, 5:0.00, 6:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 27:0.24; 25:0.16; 24:0.15; 26:0.13; 28:0.12
  Agent2 top policies: 16:0.37; 12:0.03; 26:0.02; 2:0.02; 20:0.02
. 1 2
. . .
. . .

Reward: +1.00, Result: win
Button pressed: blue by Agent 1

Result: ✅ WIN - win (steps: 10, reward: +1.00)

================================================================================
EPISODE 31
================================================================================
Environment: Red at (2, 0), Blue at (1, 0)

Initial state:
1 b r
. . .
. . 2


--- Step 1 ---
Agent 1: DOWN, Agent 2: LEFT
  Agent1 beliefs:
    agent_pos: 0:1.00, 8:0.00, 7:0.00
    red_button_pos: 8:0.12, 7:0.12, 6:0.12
    blue_button_pos: 8:0.12, 7:0.12, 6:0.12
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 8:1.00, 7:0.00, 6:0.00
    red_button_pos: 7:0.12, 3:0.12, 6:0.12
    blue_button_pos: 7:0.12, 3:0.12, 6:0.12
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 10:0.21; 22:0.21; 9:0.06; 19:0.06; 21:0.05
  Agent2 top policies: 16:0.21; 4:0.21; 12:0.06; 2:0.06; 0:0.05
. b r
1 . .
. 2 .

Reward: +0.00, Result: neutral

--- Step 2 ---
Agent 1: RIGHT, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 3:1.00, 0:0.00, 8:0.00
    red_button_pos: 8:0.14, 7:0.14, 6:0.14
    blue_button_pos: 8:0.14, 7:0.14, 6:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 7:1.00, 8:0.00, 6:0.00
    red_button_pos: 6:0.14, 1:0.14, 5:0.14
    blue_button_pos: 6:0.14, 1:0.14, 5:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 22:0.23; 10:0.23; 9:0.06; 21:0.05; 19:0.05
  Agent2 top policies: 4:0.23; 16:0.23; 12:0.06; 0:0.05; 2:0.05
. b r
. 1 .
. 2 .

Reward: +0.00, Result: neutral

--- Step 3 ---
Agent 1: RIGHT, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 4:1.00, 3:0.00, 0:0.00
    red_button_pos: 8:0.17, 7:0.17, 6:0.17
    blue_button_pos: 8:0.17, 7:0.17, 6:0.17
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 7:0.87, 4:0.12, 8:0.00
    red_button_pos: 6:0.14, 1:0.14, 5:0.14
    blue_button_pos: 6:0.14, 1:0.14, 5:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 22:0.18; 10:0.18; 4:0.18; 21:0.04; 9:0.04
  Agent2 top policies: 4:0.24; 16:0.23; 12:0.06; 2:0.05; 14:0.05
. b r
. 2 1
. . .

Reward: +0.00, Result: neutral

--- Step 4 ---
Agent 1: DOWN, Agent 2: LEFT
  Agent1 beliefs:
    agent_pos: 5:1.00, 4:0.00, 3:0.00
    red_button_pos: 8:0.20, 7:0.20, 6:0.20
    blue_button_pos: 8:0.20, 7:0.20, 6:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 4:1.00, 1:0.00, 7:0.00
    red_button_pos: 6:0.17, 1:0.17, 5:0.17
    blue_button_pos: 6:0.17, 1:0.17, 5:0.17
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 10:0.27; 4:0.27; 8:0.05; 2:0.05; 7:0.05
  Agent2 top policies: 16:0.18; 22:0.18; 4:0.18; 12:0.04; 18:0.04
. b r
2 . .
. . 1

Reward: +0.00, Result: neutral

--- Step 5 ---
Agent 1: LEFT, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 8:1.00, 5:0.00, 4:0.00
    red_button_pos: 7:0.25, 1:0.25, 6:0.25
    blue_button_pos: 7:0.25, 1:0.25, 6:0.25
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 3:1.00, 4:0.00, 7:0.00
    red_button_pos: 6:0.20, 5:0.20, 0:0.20
    blue_button_pos: 6:0.20, 5:0.20, 0:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 16:0.63; 14:0.09; 13:0.09; 17:0.07; 12:0.01
  Agent2 top policies: 4:0.28; 10:0.28; 3:0.05; 0:0.05; 2:0.05
2 b r
. . .
. 1 .

Reward: +0.00, Result: neutral

--- Step 6 ---
Agent 1: LEFT, Agent 2: RIGHT
  Agent1 beliefs:
    agent_pos: 7:1.00, 8:0.00, 5:0.00
    red_button_pos: 1:0.32, 2:0.32, 6:0.32
    blue_button_pos: 1:0.32, 2:0.32, 6:0.32
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 0:1.00, 3:0.00, 4:0.00
    red_button_pos: 6:0.24, 1:0.24, 5:0.24
    blue_button_pos: 6:0.24, 1:0.24, 5:0.24
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 16:0.72; 14:0.08; 13:0.08; 17:0.06; 12:0.01
  Agent2 top policies: 22:0.63; 21:0.09; 18:0.09; 23:0.07; 19:0.01
. 2 r
. . .
1 . .

Reward: +0.00, Result: neutral

--- Step 7 ---
Agent 1: UP, Agent 2: RIGHT
  Agent1 beliefs:
    agent_pos: 6:1.00, 7:0.00, 8:0.00
    red_button_pos: 1:0.47, 2:0.47, 0:0.02
    blue_button_pos: 1:0.47, 2:0.47, 0:0.02
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 1:1.00, 8:0.00, 5:0.00
    red_button_pos: 6:0.32, 2:0.32, 5:0.32
    blue_button_pos: 1:1.00, 2:0.00, 6:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 0:0.05; 4:0.05; 3:0.05; 2:0.04; 24:0.04
  Agent2 top policies: 22:0.34; 19:0.10; 21:0.09; 18:0.09; 23:0.07
. b 2
1 . .
. . .

Reward: +0.00, Result: neutral

--- Step 8 ---
Agent 1: UP, Agent 2: PRESS
  Agent1 beliefs:
    agent_pos: 3:1.00, 6:0.00, 7:0.00
    red_button_pos: 1:0.47, 2:0.47, 0:0.02
    blue_button_pos: 1:0.47, 2:0.47, 0:0.02
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 2:1.00, 8:0.00, 7:0.00
    red_button_pos: 2:1.00, 5:0.00, 6:0.00
    blue_button_pos: 1:0.99, 5:0.00, 6:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 3:0.24; 18:0.21; 4:0.05; 0:0.03; 2:0.03
  Agent2 top policies: 26:0.06; 24:0.06; 27:0.06; 22:0.05; 4:0.05
1 b 2
. . .
. . .

Reward: +0.00, Result: neutral
Button pressed: red by Agent 2

--- Step 9 ---
Agent 1: RIGHT, Agent 2: LEFT
  Agent1 beliefs:
    agent_pos: 0:1.00, 3:0.00, 6:0.00
    red_button_pos: 1:0.48, 2:0.48, 4:0.01
    blue_button_pos: 1:0.48, 2:0.48, 4:0.01
    red_button_state: 0:0.50, 1:0.50
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 2:1.00, 8:0.00, 7:0.00
    red_button_pos: 2:1.00, 5:0.00, 6:0.00
    blue_button_pos: 1:0.98, 5:0.00, 6:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 22:0.59; 18:0.12; 21:0.12; 23:0.10; 19:0.01
  Agent2 top policies: 16:0.35; 12:0.03; 26:0.02; 20:0.02; 2:0.02
. 1 2
. . .
. . .

Reward: +0.00, Result: neutral

--- Step 10 ---
Agent 1: PRESS, Agent 2: LEFT
  Agent1 beliefs:
    agent_pos: 1:1.00, 8:0.00, 5:0.00
    red_button_pos: 2:0.91, 4:0.03, 5:0.02
    blue_button_pos: 1:1.00, 2:0.00, 4:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 2:1.00, 1:0.00, 8:0.00
    red_button_pos: 2:1.00, 8:0.00, 7:0.00
    blue_button_pos: 1:0.97, 5:0.00, 6:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 27:0.24; 25:0.16; 24:0.15; 26:0.13; 28:0.12
  Agent2 top policies: 16:0.37; 12:0.03; 26:0.02; 2:0.02; 20:0.02
. 1 2
. . .
. . .

Reward: +1.00, Result: win
Button pressed: blue by Agent 1

Result: ✅ WIN - win (steps: 10, reward: +1.00)

================================================================================
EPISODE 32
================================================================================
Environment: Red at (2, 0), Blue at (1, 0)

Initial state:
1 b r
. . .
. . 2


--- Step 1 ---
Agent 1: DOWN, Agent 2: LEFT
  Agent1 beliefs:
    agent_pos: 0:1.00, 8:0.00, 7:0.00
    red_button_pos: 8:0.12, 7:0.12, 6:0.12
    blue_button_pos: 8:0.12, 7:0.12, 6:0.12
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 8:1.00, 7:0.00, 6:0.00
    red_button_pos: 7:0.12, 3:0.12, 6:0.12
    blue_button_pos: 7:0.12, 3:0.12, 6:0.12
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 10:0.21; 22:0.21; 9:0.06; 19:0.06; 21:0.05
  Agent2 top policies: 16:0.21; 4:0.21; 12:0.06; 2:0.06; 0:0.05
. b r
1 . .
. 2 .

Reward: +0.00, Result: neutral

--- Step 2 ---
Agent 1: RIGHT, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 3:1.00, 0:0.00, 8:0.00
    red_button_pos: 8:0.14, 7:0.14, 6:0.14
    blue_button_pos: 8:0.14, 7:0.14, 6:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 7:1.00, 8:0.00, 6:0.00
    red_button_pos: 6:0.14, 1:0.14, 5:0.14
    blue_button_pos: 6:0.14, 1:0.14, 5:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 22:0.23; 10:0.23; 9:0.06; 21:0.05; 19:0.05
  Agent2 top policies: 4:0.23; 16:0.23; 12:0.06; 0:0.05; 2:0.05
. b r
. 1 .
. 2 .

Reward: +0.00, Result: neutral

--- Step 3 ---
Agent 1: RIGHT, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 4:1.00, 3:0.00, 0:0.00
    red_button_pos: 8:0.17, 7:0.17, 6:0.17
    blue_button_pos: 8:0.17, 7:0.17, 6:0.17
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 7:0.87, 4:0.12, 8:0.00
    red_button_pos: 6:0.14, 1:0.14, 5:0.14
    blue_button_pos: 6:0.14, 1:0.14, 5:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 22:0.18; 10:0.18; 4:0.18; 21:0.04; 9:0.04
  Agent2 top policies: 4:0.24; 16:0.23; 12:0.06; 2:0.05; 14:0.05
. b r
. 2 1
. . .

Reward: +0.00, Result: neutral

--- Step 4 ---
Agent 1: DOWN, Agent 2: LEFT
  Agent1 beliefs:
    agent_pos: 5:1.00, 4:0.00, 3:0.00
    red_button_pos: 8:0.20, 7:0.20, 6:0.20
    blue_button_pos: 8:0.20, 7:0.20, 6:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 4:1.00, 1:0.00, 7:0.00
    red_button_pos: 6:0.17, 1:0.17, 5:0.17
    blue_button_pos: 6:0.17, 1:0.17, 5:0.17
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 10:0.27; 4:0.27; 8:0.05; 2:0.05; 7:0.05
  Agent2 top policies: 16:0.18; 22:0.18; 4:0.18; 12:0.04; 18:0.04
. b r
2 . .
. . 1

Reward: +0.00, Result: neutral

--- Step 5 ---
Agent 1: LEFT, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 8:1.00, 5:0.00, 4:0.00
    red_button_pos: 7:0.25, 1:0.25, 6:0.25
    blue_button_pos: 7:0.25, 1:0.25, 6:0.25
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 3:1.00, 4:0.00, 7:0.00
    red_button_pos: 6:0.20, 5:0.20, 0:0.20
    blue_button_pos: 6:0.20, 5:0.20, 0:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 16:0.63; 14:0.09; 13:0.09; 17:0.07; 12:0.01
  Agent2 top policies: 4:0.28; 10:0.28; 3:0.05; 0:0.05; 2:0.05
2 b r
. . .
. 1 .

Reward: +0.00, Result: neutral

--- Step 6 ---
Agent 1: LEFT, Agent 2: RIGHT
  Agent1 beliefs:
    agent_pos: 7:1.00, 8:0.00, 5:0.00
    red_button_pos: 1:0.32, 2:0.32, 6:0.32
    blue_button_pos: 1:0.32, 2:0.32, 6:0.32
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 0:1.00, 3:0.00, 4:0.00
    red_button_pos: 6:0.24, 1:0.24, 5:0.24
    blue_button_pos: 6:0.24, 1:0.24, 5:0.24
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 16:0.72; 14:0.08; 13:0.08; 17:0.06; 12:0.01
  Agent2 top policies: 22:0.63; 21:0.09; 18:0.09; 23:0.07; 19:0.01
. 2 r
. . .
1 . .

Reward: +0.00, Result: neutral

--- Step 7 ---
Agent 1: UP, Agent 2: RIGHT
  Agent1 beliefs:
    agent_pos: 6:1.00, 7:0.00, 8:0.00
    red_button_pos: 1:0.47, 2:0.47, 0:0.02
    blue_button_pos: 1:0.47, 2:0.47, 0:0.02
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 1:1.00, 8:0.00, 5:0.00
    red_button_pos: 6:0.32, 2:0.32, 5:0.32
    blue_button_pos: 1:1.00, 2:0.00, 6:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 0:0.05; 4:0.05; 3:0.05; 2:0.04; 24:0.04
  Agent2 top policies: 22:0.34; 19:0.10; 21:0.09; 18:0.09; 23:0.07
. b 2
1 . .
. . .

Reward: +0.00, Result: neutral

--- Step 8 ---
Agent 1: UP, Agent 2: PRESS
  Agent1 beliefs:
    agent_pos: 3:1.00, 6:0.00, 7:0.00
    red_button_pos: 1:0.47, 2:0.47, 0:0.02
    blue_button_pos: 1:0.47, 2:0.47, 0:0.02
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 2:1.00, 8:0.00, 7:0.00
    red_button_pos: 2:1.00, 5:0.00, 6:0.00
    blue_button_pos: 1:0.99, 5:0.00, 6:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 3:0.24; 18:0.21; 4:0.05; 0:0.03; 2:0.03
  Agent2 top policies: 26:0.06; 24:0.06; 27:0.06; 22:0.05; 4:0.05
1 b 2
. . .
. . .

Reward: +0.00, Result: neutral
Button pressed: red by Agent 2

--- Step 9 ---
Agent 1: RIGHT, Agent 2: LEFT
  Agent1 beliefs:
    agent_pos: 0:1.00, 3:0.00, 6:0.00
    red_button_pos: 1:0.48, 2:0.48, 4:0.01
    blue_button_pos: 1:0.48, 2:0.48, 4:0.01
    red_button_state: 0:0.50, 1:0.50
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 2:1.00, 8:0.00, 7:0.00
    red_button_pos: 2:1.00, 5:0.00, 6:0.00
    blue_button_pos: 1:0.98, 5:0.00, 6:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 22:0.59; 18:0.12; 21:0.12; 23:0.10; 19:0.01
  Agent2 top policies: 16:0.35; 12:0.03; 26:0.02; 20:0.02; 2:0.02
. 1 2
. . .
. . .

Reward: +0.00, Result: neutral

--- Step 10 ---
Agent 1: PRESS, Agent 2: LEFT
  Agent1 beliefs:
    agent_pos: 1:1.00, 8:0.00, 5:0.00
    red_button_pos: 2:0.91, 4:0.03, 5:0.02
    blue_button_pos: 1:1.00, 2:0.00, 4:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 2:1.00, 1:0.00, 8:0.00
    red_button_pos: 2:1.00, 8:0.00, 7:0.00
    blue_button_pos: 1:0.97, 5:0.00, 6:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 27:0.24; 25:0.16; 24:0.15; 26:0.13; 28:0.12
  Agent2 top policies: 16:0.37; 12:0.03; 26:0.02; 2:0.02; 20:0.02
. 1 2
. . .
. . .

Reward: +1.00, Result: win
Button pressed: blue by Agent 1

Result: ✅ WIN - win (steps: 10, reward: +1.00)

================================================================================
EPISODE 33
================================================================================
Environment: Red at (2, 0), Blue at (1, 0)

Initial state:
1 b r
. . .
. . 2


--- Step 1 ---
Agent 1: DOWN, Agent 2: LEFT
  Agent1 beliefs:
    agent_pos: 0:1.00, 8:0.00, 7:0.00
    red_button_pos: 8:0.12, 7:0.12, 6:0.12
    blue_button_pos: 8:0.12, 7:0.12, 6:0.12
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 8:1.00, 7:0.00, 6:0.00
    red_button_pos: 7:0.12, 3:0.12, 6:0.12
    blue_button_pos: 7:0.12, 3:0.12, 6:0.12
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 10:0.21; 22:0.21; 9:0.06; 19:0.06; 21:0.05
  Agent2 top policies: 16:0.21; 4:0.21; 12:0.06; 2:0.06; 0:0.05
. b r
1 . .
. 2 .

Reward: +0.00, Result: neutral

--- Step 2 ---
Agent 1: RIGHT, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 3:1.00, 0:0.00, 8:0.00
    red_button_pos: 8:0.14, 7:0.14, 6:0.14
    blue_button_pos: 8:0.14, 7:0.14, 6:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 7:1.00, 8:0.00, 6:0.00
    red_button_pos: 6:0.14, 1:0.14, 5:0.14
    blue_button_pos: 6:0.14, 1:0.14, 5:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 22:0.23; 10:0.23; 9:0.06; 21:0.05; 19:0.05
  Agent2 top policies: 4:0.23; 16:0.23; 12:0.06; 0:0.05; 2:0.05
. b r
. 1 .
. 2 .

Reward: +0.00, Result: neutral

--- Step 3 ---
Agent 1: RIGHT, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 4:1.00, 3:0.00, 0:0.00
    red_button_pos: 8:0.17, 7:0.17, 6:0.17
    blue_button_pos: 8:0.17, 7:0.17, 6:0.17
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 7:0.87, 4:0.12, 8:0.00
    red_button_pos: 6:0.14, 1:0.14, 5:0.14
    blue_button_pos: 6:0.14, 1:0.14, 5:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 22:0.18; 10:0.18; 4:0.18; 21:0.04; 9:0.04
  Agent2 top policies: 4:0.24; 16:0.23; 12:0.06; 2:0.05; 14:0.05
. b r
. 2 1
. . .

Reward: +0.00, Result: neutral

--- Step 4 ---
Agent 1: DOWN, Agent 2: LEFT
  Agent1 beliefs:
    agent_pos: 5:1.00, 4:0.00, 3:0.00
    red_button_pos: 8:0.20, 7:0.20, 6:0.20
    blue_button_pos: 8:0.20, 7:0.20, 6:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 4:1.00, 1:0.00, 7:0.00
    red_button_pos: 6:0.17, 1:0.17, 5:0.17
    blue_button_pos: 6:0.17, 1:0.17, 5:0.17
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 10:0.27; 4:0.27; 8:0.05; 2:0.05; 7:0.05
  Agent2 top policies: 16:0.18; 22:0.18; 4:0.18; 12:0.04; 18:0.04
. b r
2 . .
. . 1

Reward: +0.00, Result: neutral

--- Step 5 ---
Agent 1: LEFT, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 8:1.00, 5:0.00, 4:0.00
    red_button_pos: 7:0.25, 1:0.25, 6:0.25
    blue_button_pos: 7:0.25, 1:0.25, 6:0.25
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 3:1.00, 4:0.00, 7:0.00
    red_button_pos: 6:0.20, 5:0.20, 0:0.20
    blue_button_pos: 6:0.20, 5:0.20, 0:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 16:0.63; 14:0.09; 13:0.09; 17:0.07; 12:0.01
  Agent2 top policies: 4:0.28; 10:0.28; 3:0.05; 0:0.05; 2:0.05
2 b r
. . .
. 1 .

Reward: +0.00, Result: neutral

--- Step 6 ---
Agent 1: LEFT, Agent 2: RIGHT
  Agent1 beliefs:
    agent_pos: 7:1.00, 8:0.00, 5:0.00
    red_button_pos: 1:0.32, 2:0.32, 6:0.32
    blue_button_pos: 1:0.32, 2:0.32, 6:0.32
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 0:1.00, 3:0.00, 4:0.00
    red_button_pos: 6:0.24, 1:0.24, 5:0.24
    blue_button_pos: 6:0.24, 1:0.24, 5:0.24
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 16:0.72; 14:0.08; 13:0.08; 17:0.06; 12:0.01
  Agent2 top policies: 22:0.63; 21:0.09; 18:0.09; 23:0.07; 19:0.01
. 2 r
. . .
1 . .

Reward: +0.00, Result: neutral

--- Step 7 ---
Agent 1: UP, Agent 2: RIGHT
  Agent1 beliefs:
    agent_pos: 6:1.00, 7:0.00, 8:0.00
    red_button_pos: 1:0.47, 2:0.47, 0:0.02
    blue_button_pos: 1:0.47, 2:0.47, 0:0.02
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 1:1.00, 8:0.00, 5:0.00
    red_button_pos: 6:0.32, 2:0.32, 5:0.32
    blue_button_pos: 1:1.00, 2:0.00, 6:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 0:0.05; 4:0.05; 3:0.05; 2:0.04; 24:0.04
  Agent2 top policies: 22:0.34; 19:0.10; 21:0.09; 18:0.09; 23:0.07
. b 2
1 . .
. . .

Reward: +0.00, Result: neutral

--- Step 8 ---
Agent 1: UP, Agent 2: PRESS
  Agent1 beliefs:
    agent_pos: 3:1.00, 6:0.00, 7:0.00
    red_button_pos: 1:0.47, 2:0.47, 0:0.02
    blue_button_pos: 1:0.47, 2:0.47, 0:0.02
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 2:1.00, 8:0.00, 7:0.00
    red_button_pos: 2:1.00, 5:0.00, 6:0.00
    blue_button_pos: 1:0.99, 5:0.00, 6:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 3:0.24; 18:0.21; 4:0.05; 0:0.03; 2:0.03
  Agent2 top policies: 26:0.06; 24:0.06; 27:0.06; 22:0.05; 4:0.05
1 b 2
. . .
. . .

Reward: +0.00, Result: neutral
Button pressed: red by Agent 2

--- Step 9 ---
Agent 1: RIGHT, Agent 2: LEFT
  Agent1 beliefs:
    agent_pos: 0:1.00, 3:0.00, 6:0.00
    red_button_pos: 1:0.48, 2:0.48, 4:0.01
    blue_button_pos: 1:0.48, 2:0.48, 4:0.01
    red_button_state: 0:0.50, 1:0.50
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 2:1.00, 8:0.00, 7:0.00
    red_button_pos: 2:1.00, 5:0.00, 6:0.00
    blue_button_pos: 1:0.98, 5:0.00, 6:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 22:0.59; 18:0.12; 21:0.12; 23:0.10; 19:0.01
  Agent2 top policies: 16:0.35; 12:0.03; 26:0.02; 20:0.02; 2:0.02
. 1 2
. . .
. . .

Reward: +0.00, Result: neutral

--- Step 10 ---
Agent 1: PRESS, Agent 2: LEFT
  Agent1 beliefs:
    agent_pos: 1:1.00, 8:0.00, 5:0.00
    red_button_pos: 2:0.91, 4:0.03, 5:0.02
    blue_button_pos: 1:1.00, 2:0.00, 4:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 2:1.00, 1:0.00, 8:0.00
    red_button_pos: 2:1.00, 8:0.00, 7:0.00
    blue_button_pos: 1:0.97, 5:0.00, 6:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 27:0.24; 25:0.16; 24:0.15; 26:0.13; 28:0.12
  Agent2 top policies: 16:0.37; 12:0.03; 26:0.02; 2:0.02; 20:0.02
. 1 2
. . .
. . .

Reward: +1.00, Result: win
Button pressed: blue by Agent 1

Result: ✅ WIN - win (steps: 10, reward: +1.00)

================================================================================
EPISODE 34
================================================================================
Environment: Red at (2, 0), Blue at (1, 0)

Initial state:
1 b r
. . .
. . 2


--- Step 1 ---
Agent 1: DOWN, Agent 2: LEFT
  Agent1 beliefs:
    agent_pos: 0:1.00, 8:0.00, 7:0.00
    red_button_pos: 8:0.12, 7:0.12, 6:0.12
    blue_button_pos: 8:0.12, 7:0.12, 6:0.12
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 8:1.00, 7:0.00, 6:0.00
    red_button_pos: 7:0.12, 3:0.12, 6:0.12
    blue_button_pos: 7:0.12, 3:0.12, 6:0.12
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 10:0.21; 22:0.21; 9:0.06; 19:0.06; 21:0.05
  Agent2 top policies: 16:0.21; 4:0.21; 12:0.06; 2:0.06; 0:0.05
. b r
1 . .
. 2 .

Reward: +0.00, Result: neutral

--- Step 2 ---
Agent 1: RIGHT, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 3:1.00, 0:0.00, 8:0.00
    red_button_pos: 8:0.14, 7:0.14, 6:0.14
    blue_button_pos: 8:0.14, 7:0.14, 6:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 7:1.00, 8:0.00, 6:0.00
    red_button_pos: 6:0.14, 1:0.14, 5:0.14
    blue_button_pos: 6:0.14, 1:0.14, 5:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 22:0.23; 10:0.23; 9:0.06; 21:0.05; 19:0.05
  Agent2 top policies: 4:0.23; 16:0.23; 12:0.06; 0:0.05; 2:0.05
. b r
. 1 .
. 2 .

Reward: +0.00, Result: neutral

--- Step 3 ---
Agent 1: RIGHT, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 4:1.00, 3:0.00, 0:0.00
    red_button_pos: 8:0.17, 7:0.17, 6:0.17
    blue_button_pos: 8:0.17, 7:0.17, 6:0.17
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 7:0.87, 4:0.12, 8:0.00
    red_button_pos: 6:0.14, 1:0.14, 5:0.14
    blue_button_pos: 6:0.14, 1:0.14, 5:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 22:0.18; 10:0.18; 4:0.18; 21:0.04; 9:0.04
  Agent2 top policies: 4:0.24; 16:0.23; 12:0.06; 2:0.05; 14:0.05
. b r
. 2 1
. . .

Reward: +0.00, Result: neutral

--- Step 4 ---
Agent 1: DOWN, Agent 2: LEFT
  Agent1 beliefs:
    agent_pos: 5:1.00, 4:0.00, 3:0.00
    red_button_pos: 8:0.20, 7:0.20, 6:0.20
    blue_button_pos: 8:0.20, 7:0.20, 6:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 4:1.00, 1:0.00, 7:0.00
    red_button_pos: 6:0.17, 1:0.17, 5:0.17
    blue_button_pos: 6:0.17, 1:0.17, 5:0.17
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 10:0.27; 4:0.27; 8:0.05; 2:0.05; 7:0.05
  Agent2 top policies: 16:0.18; 22:0.18; 4:0.18; 12:0.04; 18:0.04
. b r
2 . .
. . 1

Reward: +0.00, Result: neutral

--- Step 5 ---
Agent 1: LEFT, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 8:1.00, 5:0.00, 4:0.00
    red_button_pos: 7:0.25, 1:0.25, 6:0.25
    blue_button_pos: 7:0.25, 1:0.25, 6:0.25
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 3:1.00, 4:0.00, 7:0.00
    red_button_pos: 6:0.20, 5:0.20, 0:0.20
    blue_button_pos: 6:0.20, 5:0.20, 0:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 16:0.63; 14:0.09; 13:0.09; 17:0.07; 12:0.01
  Agent2 top policies: 4:0.28; 10:0.28; 3:0.05; 0:0.05; 2:0.05
2 b r
. . .
. 1 .

Reward: +0.00, Result: neutral

--- Step 6 ---
Agent 1: LEFT, Agent 2: RIGHT
  Agent1 beliefs:
    agent_pos: 7:1.00, 8:0.00, 5:0.00
    red_button_pos: 1:0.32, 2:0.32, 6:0.32
    blue_button_pos: 1:0.32, 2:0.32, 6:0.32
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 0:1.00, 3:0.00, 4:0.00
    red_button_pos: 6:0.24, 1:0.24, 5:0.24
    blue_button_pos: 6:0.24, 1:0.24, 5:0.24
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 16:0.72; 14:0.08; 13:0.08; 17:0.06; 12:0.01
  Agent2 top policies: 22:0.63; 21:0.09; 18:0.09; 23:0.07; 19:0.01
. 2 r
. . .
1 . .

Reward: +0.00, Result: neutral

--- Step 7 ---
Agent 1: UP, Agent 2: RIGHT
  Agent1 beliefs:
    agent_pos: 6:1.00, 7:0.00, 8:0.00
    red_button_pos: 1:0.47, 2:0.47, 0:0.02
    blue_button_pos: 1:0.47, 2:0.47, 0:0.02
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 1:1.00, 8:0.00, 5:0.00
    red_button_pos: 6:0.32, 2:0.32, 5:0.32
    blue_button_pos: 1:1.00, 2:0.00, 6:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 0:0.05; 4:0.05; 3:0.05; 2:0.04; 24:0.04
  Agent2 top policies: 22:0.34; 19:0.10; 21:0.09; 18:0.09; 23:0.07
. b 2
1 . .
. . .

Reward: +0.00, Result: neutral

--- Step 8 ---
Agent 1: UP, Agent 2: PRESS
  Agent1 beliefs:
    agent_pos: 3:1.00, 6:0.00, 7:0.00
    red_button_pos: 1:0.47, 2:0.47, 0:0.02
    blue_button_pos: 1:0.47, 2:0.47, 0:0.02
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 2:1.00, 8:0.00, 7:0.00
    red_button_pos: 2:1.00, 5:0.00, 6:0.00
    blue_button_pos: 1:0.99, 5:0.00, 6:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 3:0.24; 18:0.21; 4:0.05; 0:0.03; 2:0.03
  Agent2 top policies: 26:0.06; 24:0.06; 27:0.06; 22:0.05; 4:0.05
1 b 2
. . .
. . .

Reward: +0.00, Result: neutral
Button pressed: red by Agent 2

--- Step 9 ---
Agent 1: RIGHT, Agent 2: LEFT
  Agent1 beliefs:
    agent_pos: 0:1.00, 3:0.00, 6:0.00
    red_button_pos: 1:0.48, 2:0.48, 4:0.01
    blue_button_pos: 1:0.48, 2:0.48, 4:0.01
    red_button_state: 0:0.50, 1:0.50
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 2:1.00, 8:0.00, 7:0.00
    red_button_pos: 2:1.00, 5:0.00, 6:0.00
    blue_button_pos: 1:0.98, 5:0.00, 6:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 22:0.59; 18:0.12; 21:0.12; 23:0.10; 19:0.01
  Agent2 top policies: 16:0.35; 12:0.03; 26:0.02; 20:0.02; 2:0.02
. 1 2
. . .
. . .

Reward: +0.00, Result: neutral

--- Step 10 ---
Agent 1: PRESS, Agent 2: LEFT
  Agent1 beliefs:
    agent_pos: 1:1.00, 8:0.00, 5:0.00
    red_button_pos: 2:0.91, 4:0.03, 5:0.02
    blue_button_pos: 1:1.00, 2:0.00, 4:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 2:1.00, 1:0.00, 8:0.00
    red_button_pos: 2:1.00, 8:0.00, 7:0.00
    blue_button_pos: 1:0.97, 5:0.00, 6:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 27:0.24; 25:0.16; 24:0.15; 26:0.13; 28:0.12
  Agent2 top policies: 16:0.37; 12:0.03; 26:0.02; 2:0.02; 20:0.02
. 1 2
. . .
. . .

Reward: +1.00, Result: win
Button pressed: blue by Agent 1

Result: ✅ WIN - win (steps: 10, reward: +1.00)

================================================================================
EPISODE 35
================================================================================
Environment: Red at (2, 0), Blue at (1, 0)

Initial state:
1 b r
. . .
. . 2


--- Step 1 ---
Agent 1: DOWN, Agent 2: LEFT
  Agent1 beliefs:
    agent_pos: 0:1.00, 8:0.00, 7:0.00
    red_button_pos: 8:0.12, 7:0.12, 6:0.12
    blue_button_pos: 8:0.12, 7:0.12, 6:0.12
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 8:1.00, 7:0.00, 6:0.00
    red_button_pos: 7:0.12, 3:0.12, 6:0.12
    blue_button_pos: 7:0.12, 3:0.12, 6:0.12
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 10:0.21; 22:0.21; 9:0.06; 19:0.06; 21:0.05
  Agent2 top policies: 16:0.21; 4:0.21; 12:0.06; 2:0.06; 0:0.05
. b r
1 . .
. 2 .

Reward: +0.00, Result: neutral

--- Step 2 ---
Agent 1: RIGHT, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 3:1.00, 0:0.00, 8:0.00
    red_button_pos: 8:0.14, 7:0.14, 6:0.14
    blue_button_pos: 8:0.14, 7:0.14, 6:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 7:1.00, 8:0.00, 6:0.00
    red_button_pos: 6:0.14, 1:0.14, 5:0.14
    blue_button_pos: 6:0.14, 1:0.14, 5:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 22:0.23; 10:0.23; 9:0.06; 21:0.05; 19:0.05
  Agent2 top policies: 4:0.23; 16:0.23; 12:0.06; 0:0.05; 2:0.05
. b r
. 1 .
. 2 .

Reward: +0.00, Result: neutral

--- Step 3 ---
Agent 1: RIGHT, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 4:1.00, 3:0.00, 0:0.00
    red_button_pos: 8:0.17, 7:0.17, 6:0.17
    blue_button_pos: 8:0.17, 7:0.17, 6:0.17
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 7:0.87, 4:0.12, 8:0.00
    red_button_pos: 6:0.14, 1:0.14, 5:0.14
    blue_button_pos: 6:0.14, 1:0.14, 5:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 22:0.18; 10:0.18; 4:0.18; 21:0.04; 9:0.04
  Agent2 top policies: 4:0.24; 16:0.23; 12:0.06; 2:0.05; 14:0.05
. b r
. 2 1
. . .

Reward: +0.00, Result: neutral

--- Step 4 ---
Agent 1: DOWN, Agent 2: LEFT
  Agent1 beliefs:
    agent_pos: 5:1.00, 4:0.00, 3:0.00
    red_button_pos: 8:0.20, 7:0.20, 6:0.20
    blue_button_pos: 8:0.20, 7:0.20, 6:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 4:1.00, 1:0.00, 7:0.00
    red_button_pos: 6:0.17, 1:0.17, 5:0.17
    blue_button_pos: 6:0.17, 1:0.17, 5:0.17
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 10:0.27; 4:0.27; 8:0.05; 2:0.05; 7:0.05
  Agent2 top policies: 16:0.18; 22:0.18; 4:0.18; 12:0.04; 18:0.04
. b r
2 . .
. . 1

Reward: +0.00, Result: neutral

--- Step 5 ---
Agent 1: LEFT, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 8:1.00, 5:0.00, 4:0.00
    red_button_pos: 7:0.25, 1:0.25, 6:0.25
    blue_button_pos: 7:0.25, 1:0.25, 6:0.25
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 3:1.00, 4:0.00, 7:0.00
    red_button_pos: 6:0.20, 5:0.20, 0:0.20
    blue_button_pos: 6:0.20, 5:0.20, 0:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 16:0.63; 14:0.09; 13:0.09; 17:0.07; 12:0.01
  Agent2 top policies: 4:0.28; 10:0.28; 3:0.05; 0:0.05; 2:0.05
2 b r
. . .
. 1 .

Reward: +0.00, Result: neutral

--- Step 6 ---
Agent 1: LEFT, Agent 2: RIGHT
  Agent1 beliefs:
    agent_pos: 7:1.00, 8:0.00, 5:0.00
    red_button_pos: 1:0.32, 2:0.32, 6:0.32
    blue_button_pos: 1:0.32, 2:0.32, 6:0.32
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 0:1.00, 3:0.00, 4:0.00
    red_button_pos: 6:0.24, 1:0.24, 5:0.24
    blue_button_pos: 6:0.24, 1:0.24, 5:0.24
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 16:0.72; 14:0.08; 13:0.08; 17:0.06; 12:0.01
  Agent2 top policies: 22:0.63; 21:0.09; 18:0.09; 23:0.07; 19:0.01
. 2 r
. . .
1 . .

Reward: +0.00, Result: neutral

--- Step 7 ---
Agent 1: UP, Agent 2: RIGHT
  Agent1 beliefs:
    agent_pos: 6:1.00, 7:0.00, 8:0.00
    red_button_pos: 1:0.47, 2:0.47, 0:0.02
    blue_button_pos: 1:0.47, 2:0.47, 0:0.02
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 1:1.00, 8:0.00, 5:0.00
    red_button_pos: 6:0.32, 2:0.32, 5:0.32
    blue_button_pos: 1:1.00, 2:0.00, 6:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 0:0.05; 4:0.05; 3:0.05; 2:0.04; 24:0.04
  Agent2 top policies: 22:0.34; 19:0.10; 21:0.09; 18:0.09; 23:0.07
. b 2
1 . .
. . .

Reward: +0.00, Result: neutral

--- Step 8 ---
Agent 1: UP, Agent 2: PRESS
  Agent1 beliefs:
    agent_pos: 3:1.00, 6:0.00, 7:0.00
    red_button_pos: 1:0.47, 2:0.47, 0:0.02
    blue_button_pos: 1:0.47, 2:0.47, 0:0.02
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 2:1.00, 8:0.00, 7:0.00
    red_button_pos: 2:1.00, 5:0.00, 6:0.00
    blue_button_pos: 1:0.99, 5:0.00, 6:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 3:0.24; 18:0.21; 4:0.05; 0:0.03; 2:0.03
  Agent2 top policies: 26:0.06; 24:0.06; 27:0.06; 22:0.05; 4:0.05
1 b 2
. . .
. . .

Reward: +0.00, Result: neutral
Button pressed: red by Agent 2

--- Step 9 ---
Agent 1: RIGHT, Agent 2: LEFT
  Agent1 beliefs:
    agent_pos: 0:1.00, 3:0.00, 6:0.00
    red_button_pos: 1:0.48, 2:0.48, 4:0.01
    blue_button_pos: 1:0.48, 2:0.48, 4:0.01
    red_button_state: 0:0.50, 1:0.50
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 2:1.00, 8:0.00, 7:0.00
    red_button_pos: 2:1.00, 5:0.00, 6:0.00
    blue_button_pos: 1:0.98, 5:0.00, 6:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 22:0.59; 18:0.12; 21:0.12; 23:0.10; 19:0.01
  Agent2 top policies: 16:0.35; 12:0.03; 26:0.02; 20:0.02; 2:0.02
. 1 2
. . .
. . .

Reward: +0.00, Result: neutral

--- Step 10 ---
Agent 1: PRESS, Agent 2: LEFT
  Agent1 beliefs:
    agent_pos: 1:1.00, 8:0.00, 5:0.00
    red_button_pos: 2:0.91, 4:0.03, 5:0.02
    blue_button_pos: 1:1.00, 2:0.00, 4:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 2:1.00, 1:0.00, 8:0.00
    red_button_pos: 2:1.00, 8:0.00, 7:0.00
    blue_button_pos: 1:0.97, 5:0.00, 6:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 27:0.24; 25:0.16; 24:0.15; 26:0.13; 28:0.12
  Agent2 top policies: 16:0.37; 12:0.03; 26:0.02; 2:0.02; 20:0.02
. 1 2
. . .
. . .

Reward: +1.00, Result: win
Button pressed: blue by Agent 1

Result: ✅ WIN - win (steps: 10, reward: +1.00)

================================================================================
EPISODE 36
================================================================================
Environment: Red at (2, 0), Blue at (1, 0)

Initial state:
1 b r
. . .
. . 2


--- Step 1 ---
Agent 1: DOWN, Agent 2: LEFT
  Agent1 beliefs:
    agent_pos: 0:1.00, 8:0.00, 7:0.00
    red_button_pos: 8:0.12, 7:0.12, 6:0.12
    blue_button_pos: 8:0.12, 7:0.12, 6:0.12
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 8:1.00, 7:0.00, 6:0.00
    red_button_pos: 7:0.12, 3:0.12, 6:0.12
    blue_button_pos: 7:0.12, 3:0.12, 6:0.12
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 10:0.21; 22:0.21; 9:0.06; 19:0.06; 21:0.05
  Agent2 top policies: 16:0.21; 4:0.21; 12:0.06; 2:0.06; 0:0.05
. b r
1 . .
. 2 .

Reward: +0.00, Result: neutral

--- Step 2 ---
Agent 1: RIGHT, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 3:1.00, 0:0.00, 8:0.00
    red_button_pos: 8:0.14, 7:0.14, 6:0.14
    blue_button_pos: 8:0.14, 7:0.14, 6:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 7:1.00, 8:0.00, 6:0.00
    red_button_pos: 6:0.14, 1:0.14, 5:0.14
    blue_button_pos: 6:0.14, 1:0.14, 5:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 22:0.23; 10:0.23; 9:0.06; 21:0.05; 19:0.05
  Agent2 top policies: 4:0.23; 16:0.23; 12:0.06; 0:0.05; 2:0.05
. b r
. 1 .
. 2 .

Reward: +0.00, Result: neutral

--- Step 3 ---
Agent 1: RIGHT, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 4:1.00, 3:0.00, 0:0.00
    red_button_pos: 8:0.17, 7:0.17, 6:0.17
    blue_button_pos: 8:0.17, 7:0.17, 6:0.17
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 7:0.87, 4:0.12, 8:0.00
    red_button_pos: 6:0.14, 1:0.14, 5:0.14
    blue_button_pos: 6:0.14, 1:0.14, 5:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 22:0.18; 10:0.18; 4:0.18; 21:0.04; 9:0.04
  Agent2 top policies: 4:0.24; 16:0.23; 12:0.06; 2:0.05; 14:0.05
. b r
. 2 1
. . .

Reward: +0.00, Result: neutral

--- Step 4 ---
Agent 1: DOWN, Agent 2: LEFT
  Agent1 beliefs:
    agent_pos: 5:1.00, 4:0.00, 3:0.00
    red_button_pos: 8:0.20, 7:0.20, 6:0.20
    blue_button_pos: 8:0.20, 7:0.20, 6:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 4:1.00, 1:0.00, 7:0.00
    red_button_pos: 6:0.17, 1:0.17, 5:0.17
    blue_button_pos: 6:0.17, 1:0.17, 5:0.17
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 10:0.27; 4:0.27; 8:0.05; 2:0.05; 7:0.05
  Agent2 top policies: 16:0.18; 22:0.18; 4:0.18; 12:0.04; 18:0.04
. b r
2 . .
. . 1

Reward: +0.00, Result: neutral

--- Step 5 ---
Agent 1: LEFT, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 8:1.00, 5:0.00, 4:0.00
    red_button_pos: 7:0.25, 1:0.25, 6:0.25
    blue_button_pos: 7:0.25, 1:0.25, 6:0.25
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 3:1.00, 4:0.00, 7:0.00
    red_button_pos: 6:0.20, 5:0.20, 0:0.20
    blue_button_pos: 6:0.20, 5:0.20, 0:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 16:0.63; 14:0.09; 13:0.09; 17:0.07; 12:0.01
  Agent2 top policies: 4:0.28; 10:0.28; 3:0.05; 0:0.05; 2:0.05
2 b r
. . .
. 1 .

Reward: +0.00, Result: neutral

--- Step 6 ---
Agent 1: LEFT, Agent 2: RIGHT
  Agent1 beliefs:
    agent_pos: 7:1.00, 8:0.00, 5:0.00
    red_button_pos: 1:0.32, 2:0.32, 6:0.32
    blue_button_pos: 1:0.32, 2:0.32, 6:0.32
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 0:1.00, 3:0.00, 4:0.00
    red_button_pos: 6:0.24, 1:0.24, 5:0.24
    blue_button_pos: 6:0.24, 1:0.24, 5:0.24
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 16:0.72; 14:0.08; 13:0.08; 17:0.06; 12:0.01
  Agent2 top policies: 22:0.63; 21:0.09; 18:0.09; 23:0.07; 19:0.01
. 2 r
. . .
1 . .

Reward: +0.00, Result: neutral

--- Step 7 ---
Agent 1: UP, Agent 2: RIGHT
  Agent1 beliefs:
    agent_pos: 6:1.00, 7:0.00, 8:0.00
    red_button_pos: 1:0.47, 2:0.47, 0:0.02
    blue_button_pos: 1:0.47, 2:0.47, 0:0.02
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 1:1.00, 8:0.00, 5:0.00
    red_button_pos: 6:0.32, 2:0.32, 5:0.32
    blue_button_pos: 1:1.00, 2:0.00, 6:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 0:0.05; 4:0.05; 3:0.05; 2:0.04; 24:0.04
  Agent2 top policies: 22:0.34; 19:0.10; 21:0.09; 18:0.09; 23:0.07
. b 2
1 . .
. . .

Reward: +0.00, Result: neutral

--- Step 8 ---
Agent 1: UP, Agent 2: PRESS
  Agent1 beliefs:
    agent_pos: 3:1.00, 6:0.00, 7:0.00
    red_button_pos: 1:0.47, 2:0.47, 0:0.02
    blue_button_pos: 1:0.47, 2:0.47, 0:0.02
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 2:1.00, 8:0.00, 7:0.00
    red_button_pos: 2:1.00, 5:0.00, 6:0.00
    blue_button_pos: 1:0.99, 5:0.00, 6:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 3:0.24; 18:0.21; 4:0.05; 0:0.03; 2:0.03
  Agent2 top policies: 26:0.06; 24:0.06; 27:0.06; 22:0.05; 4:0.05
1 b 2
. . .
. . .

Reward: +0.00, Result: neutral
Button pressed: red by Agent 2

--- Step 9 ---
Agent 1: RIGHT, Agent 2: LEFT
  Agent1 beliefs:
    agent_pos: 0:1.00, 3:0.00, 6:0.00
    red_button_pos: 1:0.48, 2:0.48, 4:0.01
    blue_button_pos: 1:0.48, 2:0.48, 4:0.01
    red_button_state: 0:0.50, 1:0.50
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 2:1.00, 8:0.00, 7:0.00
    red_button_pos: 2:1.00, 5:0.00, 6:0.00
    blue_button_pos: 1:0.98, 5:0.00, 6:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 22:0.59; 18:0.12; 21:0.12; 23:0.10; 19:0.01
  Agent2 top policies: 16:0.35; 12:0.03; 26:0.02; 20:0.02; 2:0.02
. 1 2
. . .
. . .

Reward: +0.00, Result: neutral

--- Step 10 ---
Agent 1: PRESS, Agent 2: LEFT
  Agent1 beliefs:
    agent_pos: 1:1.00, 8:0.00, 5:0.00
    red_button_pos: 2:0.91, 4:0.03, 5:0.02
    blue_button_pos: 1:1.00, 2:0.00, 4:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 2:1.00, 1:0.00, 8:0.00
    red_button_pos: 2:1.00, 8:0.00, 7:0.00
    blue_button_pos: 1:0.97, 5:0.00, 6:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 27:0.24; 25:0.16; 24:0.15; 26:0.13; 28:0.12
  Agent2 top policies: 16:0.37; 12:0.03; 26:0.02; 2:0.02; 20:0.02
. 1 2
. . .
. . .

Reward: +1.00, Result: win
Button pressed: blue by Agent 1

Result: ✅ WIN - win (steps: 10, reward: +1.00)

================================================================================
EPISODE 37
================================================================================
Environment: Red at (2, 0), Blue at (1, 0)

Initial state:
1 b r
. . .
. . 2


--- Step 1 ---
Agent 1: DOWN, Agent 2: LEFT
  Agent1 beliefs:
    agent_pos: 0:1.00, 8:0.00, 7:0.00
    red_button_pos: 8:0.12, 7:0.12, 6:0.12
    blue_button_pos: 8:0.12, 7:0.12, 6:0.12
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 8:1.00, 7:0.00, 6:0.00
    red_button_pos: 7:0.12, 3:0.12, 6:0.12
    blue_button_pos: 7:0.12, 3:0.12, 6:0.12
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 10:0.21; 22:0.21; 9:0.06; 19:0.06; 21:0.05
  Agent2 top policies: 16:0.21; 4:0.21; 12:0.06; 2:0.06; 0:0.05
. b r
1 . .
. 2 .

Reward: +0.00, Result: neutral

--- Step 2 ---
Agent 1: RIGHT, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 3:1.00, 0:0.00, 8:0.00
    red_button_pos: 8:0.14, 7:0.14, 6:0.14
    blue_button_pos: 8:0.14, 7:0.14, 6:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 7:1.00, 8:0.00, 6:0.00
    red_button_pos: 6:0.14, 1:0.14, 5:0.14
    blue_button_pos: 6:0.14, 1:0.14, 5:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 22:0.23; 10:0.23; 9:0.06; 21:0.05; 19:0.05
  Agent2 top policies: 4:0.23; 16:0.23; 12:0.06; 0:0.05; 2:0.05
. b r
. 1 .
. 2 .

Reward: +0.00, Result: neutral

--- Step 3 ---
Agent 1: RIGHT, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 4:1.00, 3:0.00, 0:0.00
    red_button_pos: 8:0.17, 7:0.17, 6:0.17
    blue_button_pos: 8:0.17, 7:0.17, 6:0.17
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 7:0.87, 4:0.12, 8:0.00
    red_button_pos: 6:0.14, 1:0.14, 5:0.14
    blue_button_pos: 6:0.14, 1:0.14, 5:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 22:0.18; 10:0.18; 4:0.18; 21:0.04; 9:0.04
  Agent2 top policies: 4:0.24; 16:0.23; 12:0.06; 2:0.05; 14:0.05
. b r
. 2 1
. . .

Reward: +0.00, Result: neutral

--- Step 4 ---
Agent 1: DOWN, Agent 2: LEFT
  Agent1 beliefs:
    agent_pos: 5:1.00, 4:0.00, 3:0.00
    red_button_pos: 8:0.20, 7:0.20, 6:0.20
    blue_button_pos: 8:0.20, 7:0.20, 6:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 4:1.00, 1:0.00, 7:0.00
    red_button_pos: 6:0.17, 1:0.17, 5:0.17
    blue_button_pos: 6:0.17, 1:0.17, 5:0.17
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 10:0.27; 4:0.27; 8:0.05; 2:0.05; 7:0.05
  Agent2 top policies: 16:0.18; 22:0.18; 4:0.18; 12:0.04; 18:0.04
. b r
2 . .
. . 1

Reward: +0.00, Result: neutral

--- Step 5 ---
Agent 1: LEFT, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 8:1.00, 5:0.00, 4:0.00
    red_button_pos: 7:0.25, 1:0.25, 6:0.25
    blue_button_pos: 7:0.25, 1:0.25, 6:0.25
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 3:1.00, 4:0.00, 7:0.00
    red_button_pos: 6:0.20, 5:0.20, 0:0.20
    blue_button_pos: 6:0.20, 5:0.20, 0:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 16:0.63; 14:0.09; 13:0.09; 17:0.07; 12:0.01
  Agent2 top policies: 4:0.28; 10:0.28; 3:0.05; 0:0.05; 2:0.05
2 b r
. . .
. 1 .

Reward: +0.00, Result: neutral

--- Step 6 ---
Agent 1: LEFT, Agent 2: RIGHT
  Agent1 beliefs:
    agent_pos: 7:1.00, 8:0.00, 5:0.00
    red_button_pos: 1:0.32, 2:0.32, 6:0.32
    blue_button_pos: 1:0.32, 2:0.32, 6:0.32
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 0:1.00, 3:0.00, 4:0.00
    red_button_pos: 6:0.24, 1:0.24, 5:0.24
    blue_button_pos: 6:0.24, 1:0.24, 5:0.24
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 16:0.72; 14:0.08; 13:0.08; 17:0.06; 12:0.01
  Agent2 top policies: 22:0.63; 21:0.09; 18:0.09; 23:0.07; 19:0.01
. 2 r
. . .
1 . .

Reward: +0.00, Result: neutral

--- Step 7 ---
Agent 1: UP, Agent 2: RIGHT
  Agent1 beliefs:
    agent_pos: 6:1.00, 7:0.00, 8:0.00
    red_button_pos: 1:0.47, 2:0.47, 0:0.02
    blue_button_pos: 1:0.47, 2:0.47, 0:0.02
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 1:1.00, 8:0.00, 5:0.00
    red_button_pos: 6:0.32, 2:0.32, 5:0.32
    blue_button_pos: 1:1.00, 2:0.00, 6:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 0:0.05; 4:0.05; 3:0.05; 2:0.04; 24:0.04
  Agent2 top policies: 22:0.34; 19:0.10; 21:0.09; 18:0.09; 23:0.07
. b 2
1 . .
. . .

Reward: +0.00, Result: neutral

--- Step 8 ---
Agent 1: UP, Agent 2: PRESS
  Agent1 beliefs:
    agent_pos: 3:1.00, 6:0.00, 7:0.00
    red_button_pos: 1:0.47, 2:0.47, 0:0.02
    blue_button_pos: 1:0.47, 2:0.47, 0:0.02
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 2:1.00, 8:0.00, 7:0.00
    red_button_pos: 2:1.00, 5:0.00, 6:0.00
    blue_button_pos: 1:0.99, 5:0.00, 6:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 3:0.24; 18:0.21; 4:0.05; 0:0.03; 2:0.03
  Agent2 top policies: 26:0.06; 24:0.06; 27:0.06; 22:0.05; 4:0.05
1 b 2
. . .
. . .

Reward: +0.00, Result: neutral
Button pressed: red by Agent 2

--- Step 9 ---
Agent 1: RIGHT, Agent 2: LEFT
  Agent1 beliefs:
    agent_pos: 0:1.00, 3:0.00, 6:0.00
    red_button_pos: 1:0.48, 2:0.48, 4:0.01
    blue_button_pos: 1:0.48, 2:0.48, 4:0.01
    red_button_state: 0:0.50, 1:0.50
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 2:1.00, 8:0.00, 7:0.00
    red_button_pos: 2:1.00, 5:0.00, 6:0.00
    blue_button_pos: 1:0.98, 5:0.00, 6:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 22:0.59; 18:0.12; 21:0.12; 23:0.10; 19:0.01
  Agent2 top policies: 16:0.35; 12:0.03; 26:0.02; 20:0.02; 2:0.02
. 1 2
. . .
. . .

Reward: +0.00, Result: neutral

--- Step 10 ---
Agent 1: PRESS, Agent 2: LEFT
  Agent1 beliefs:
    agent_pos: 1:1.00, 8:0.00, 5:0.00
    red_button_pos: 2:0.91, 4:0.03, 5:0.02
    blue_button_pos: 1:1.00, 2:0.00, 4:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 2:1.00, 1:0.00, 8:0.00
    red_button_pos: 2:1.00, 8:0.00, 7:0.00
    blue_button_pos: 1:0.97, 5:0.00, 6:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 27:0.24; 25:0.16; 24:0.15; 26:0.13; 28:0.12
  Agent2 top policies: 16:0.37; 12:0.03; 26:0.02; 2:0.02; 20:0.02
. 1 2
. . .
. . .

Reward: +1.00, Result: win
Button pressed: blue by Agent 1

Result: ✅ WIN - win (steps: 10, reward: +1.00)

================================================================================
EPISODE 38
================================================================================
Environment: Red at (2, 0), Blue at (1, 0)

Initial state:
1 b r
. . .
. . 2


--- Step 1 ---
Agent 1: DOWN, Agent 2: LEFT
  Agent1 beliefs:
    agent_pos: 0:1.00, 8:0.00, 7:0.00
    red_button_pos: 8:0.12, 7:0.12, 6:0.12
    blue_button_pos: 8:0.12, 7:0.12, 6:0.12
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 8:1.00, 7:0.00, 6:0.00
    red_button_pos: 7:0.12, 3:0.12, 6:0.12
    blue_button_pos: 7:0.12, 3:0.12, 6:0.12
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 10:0.21; 22:0.21; 9:0.06; 19:0.06; 21:0.05
  Agent2 top policies: 16:0.21; 4:0.21; 12:0.06; 2:0.06; 0:0.05
. b r
1 . .
. 2 .

Reward: +0.00, Result: neutral

--- Step 2 ---
Agent 1: RIGHT, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 3:1.00, 0:0.00, 8:0.00
    red_button_pos: 8:0.14, 7:0.14, 6:0.14
    blue_button_pos: 8:0.14, 7:0.14, 6:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 7:1.00, 8:0.00, 6:0.00
    red_button_pos: 6:0.14, 1:0.14, 5:0.14
    blue_button_pos: 6:0.14, 1:0.14, 5:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 22:0.23; 10:0.23; 9:0.06; 21:0.05; 19:0.05
  Agent2 top policies: 4:0.23; 16:0.23; 12:0.06; 0:0.05; 2:0.05
. b r
. 1 .
. 2 .

Reward: +0.00, Result: neutral

--- Step 3 ---
Agent 1: RIGHT, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 4:1.00, 3:0.00, 0:0.00
    red_button_pos: 8:0.17, 7:0.17, 6:0.17
    blue_button_pos: 8:0.17, 7:0.17, 6:0.17
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 7:0.87, 4:0.12, 8:0.00
    red_button_pos: 6:0.14, 1:0.14, 5:0.14
    blue_button_pos: 6:0.14, 1:0.14, 5:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 22:0.18; 10:0.18; 4:0.18; 21:0.04; 9:0.04
  Agent2 top policies: 4:0.24; 16:0.23; 12:0.06; 2:0.05; 14:0.05
. b r
. 2 1
. . .

Reward: +0.00, Result: neutral

--- Step 4 ---
Agent 1: DOWN, Agent 2: LEFT
  Agent1 beliefs:
    agent_pos: 5:1.00, 4:0.00, 3:0.00
    red_button_pos: 8:0.20, 7:0.20, 6:0.20
    blue_button_pos: 8:0.20, 7:0.20, 6:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 4:1.00, 1:0.00, 7:0.00
    red_button_pos: 6:0.17, 1:0.17, 5:0.17
    blue_button_pos: 6:0.17, 1:0.17, 5:0.17
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 10:0.27; 4:0.27; 8:0.05; 2:0.05; 7:0.05
  Agent2 top policies: 16:0.18; 22:0.18; 4:0.18; 12:0.04; 18:0.04
. b r
2 . .
. . 1

Reward: +0.00, Result: neutral

--- Step 5 ---
Agent 1: LEFT, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 8:1.00, 5:0.00, 4:0.00
    red_button_pos: 7:0.25, 1:0.25, 6:0.25
    blue_button_pos: 7:0.25, 1:0.25, 6:0.25
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 3:1.00, 4:0.00, 7:0.00
    red_button_pos: 6:0.20, 5:0.20, 0:0.20
    blue_button_pos: 6:0.20, 5:0.20, 0:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 16:0.63; 14:0.09; 13:0.09; 17:0.07; 12:0.01
  Agent2 top policies: 4:0.28; 10:0.28; 3:0.05; 0:0.05; 2:0.05
2 b r
. . .
. 1 .

Reward: +0.00, Result: neutral

--- Step 6 ---
Agent 1: LEFT, Agent 2: RIGHT
  Agent1 beliefs:
    agent_pos: 7:1.00, 8:0.00, 5:0.00
    red_button_pos: 1:0.32, 2:0.32, 6:0.32
    blue_button_pos: 1:0.32, 2:0.32, 6:0.32
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 0:1.00, 3:0.00, 4:0.00
    red_button_pos: 6:0.24, 1:0.24, 5:0.24
    blue_button_pos: 6:0.24, 1:0.24, 5:0.24
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 16:0.72; 14:0.08; 13:0.08; 17:0.06; 12:0.01
  Agent2 top policies: 22:0.63; 21:0.09; 18:0.09; 23:0.07; 19:0.01
. 2 r
. . .
1 . .

Reward: +0.00, Result: neutral

--- Step 7 ---
Agent 1: UP, Agent 2: RIGHT
  Agent1 beliefs:
    agent_pos: 6:1.00, 7:0.00, 8:0.00
    red_button_pos: 1:0.47, 2:0.47, 0:0.02
    blue_button_pos: 1:0.47, 2:0.47, 0:0.02
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 1:1.00, 8:0.00, 5:0.00
    red_button_pos: 6:0.32, 2:0.32, 5:0.32
    blue_button_pos: 1:1.00, 2:0.00, 6:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 0:0.05; 4:0.05; 3:0.05; 2:0.04; 24:0.04
  Agent2 top policies: 22:0.34; 19:0.10; 21:0.09; 18:0.09; 23:0.07
. b 2
1 . .
. . .

Reward: +0.00, Result: neutral

--- Step 8 ---
Agent 1: UP, Agent 2: PRESS
  Agent1 beliefs:
    agent_pos: 3:1.00, 6:0.00, 7:0.00
    red_button_pos: 1:0.47, 2:0.47, 0:0.02
    blue_button_pos: 1:0.47, 2:0.47, 0:0.02
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 2:1.00, 8:0.00, 7:0.00
    red_button_pos: 2:1.00, 5:0.00, 6:0.00
    blue_button_pos: 1:0.99, 5:0.00, 6:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 3:0.24; 18:0.21; 4:0.05; 0:0.03; 2:0.03
  Agent2 top policies: 26:0.06; 24:0.06; 27:0.06; 22:0.05; 4:0.05
1 b 2
. . .
. . .

Reward: +0.00, Result: neutral
Button pressed: red by Agent 2

--- Step 9 ---
Agent 1: RIGHT, Agent 2: LEFT
  Agent1 beliefs:
    agent_pos: 0:1.00, 3:0.00, 6:0.00
    red_button_pos: 1:0.48, 2:0.48, 4:0.01
    blue_button_pos: 1:0.48, 2:0.48, 4:0.01
    red_button_state: 0:0.50, 1:0.50
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 2:1.00, 8:0.00, 7:0.00
    red_button_pos: 2:1.00, 5:0.00, 6:0.00
    blue_button_pos: 1:0.98, 5:0.00, 6:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 22:0.59; 18:0.12; 21:0.12; 23:0.10; 19:0.01
  Agent2 top policies: 16:0.35; 12:0.03; 26:0.02; 20:0.02; 2:0.02
. 1 2
. . .
. . .

Reward: +0.00, Result: neutral

--- Step 10 ---
Agent 1: PRESS, Agent 2: LEFT
  Agent1 beliefs:
    agent_pos: 1:1.00, 8:0.00, 5:0.00
    red_button_pos: 2:0.91, 4:0.03, 5:0.02
    blue_button_pos: 1:1.00, 2:0.00, 4:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 2:1.00, 1:0.00, 8:0.00
    red_button_pos: 2:1.00, 8:0.00, 7:0.00
    blue_button_pos: 1:0.97, 5:0.00, 6:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 27:0.24; 25:0.16; 24:0.15; 26:0.13; 28:0.12
  Agent2 top policies: 16:0.37; 12:0.03; 26:0.02; 2:0.02; 20:0.02
. 1 2
. . .
. . .

Reward: +1.00, Result: win
Button pressed: blue by Agent 1

Result: ✅ WIN - win (steps: 10, reward: +1.00)

================================================================================
EPISODE 39
================================================================================
Environment: Red at (2, 0), Blue at (1, 0)

Initial state:
1 b r
. . .
. . 2


--- Step 1 ---
Agent 1: DOWN, Agent 2: LEFT
  Agent1 beliefs:
    agent_pos: 0:1.00, 8:0.00, 7:0.00
    red_button_pos: 8:0.12, 7:0.12, 6:0.12
    blue_button_pos: 8:0.12, 7:0.12, 6:0.12
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 8:1.00, 7:0.00, 6:0.00
    red_button_pos: 7:0.12, 3:0.12, 6:0.12
    blue_button_pos: 7:0.12, 3:0.12, 6:0.12
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 10:0.21; 22:0.21; 9:0.06; 19:0.06; 21:0.05
  Agent2 top policies: 16:0.21; 4:0.21; 12:0.06; 2:0.06; 0:0.05
. b r
1 . .
. 2 .

Reward: +0.00, Result: neutral

--- Step 2 ---
Agent 1: RIGHT, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 3:1.00, 0:0.00, 8:0.00
    red_button_pos: 8:0.14, 7:0.14, 6:0.14
    blue_button_pos: 8:0.14, 7:0.14, 6:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 7:1.00, 8:0.00, 6:0.00
    red_button_pos: 6:0.14, 1:0.14, 5:0.14
    blue_button_pos: 6:0.14, 1:0.14, 5:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 22:0.23; 10:0.23; 9:0.06; 21:0.05; 19:0.05
  Agent2 top policies: 4:0.23; 16:0.23; 12:0.06; 0:0.05; 2:0.05
. b r
. 1 .
. 2 .

Reward: +0.00, Result: neutral

--- Step 3 ---
Agent 1: RIGHT, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 4:1.00, 3:0.00, 0:0.00
    red_button_pos: 8:0.17, 7:0.17, 6:0.17
    blue_button_pos: 8:0.17, 7:0.17, 6:0.17
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 7:0.87, 4:0.12, 8:0.00
    red_button_pos: 6:0.14, 1:0.14, 5:0.14
    blue_button_pos: 6:0.14, 1:0.14, 5:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 22:0.18; 10:0.18; 4:0.18; 21:0.04; 9:0.04
  Agent2 top policies: 4:0.24; 16:0.23; 12:0.06; 2:0.05; 14:0.05
. b r
. 2 1
. . .

Reward: +0.00, Result: neutral

--- Step 4 ---
Agent 1: DOWN, Agent 2: LEFT
  Agent1 beliefs:
    agent_pos: 5:1.00, 4:0.00, 3:0.00
    red_button_pos: 8:0.20, 7:0.20, 6:0.20
    blue_button_pos: 8:0.20, 7:0.20, 6:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 4:1.00, 1:0.00, 7:0.00
    red_button_pos: 6:0.17, 1:0.17, 5:0.17
    blue_button_pos: 6:0.17, 1:0.17, 5:0.17
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 10:0.27; 4:0.27; 8:0.05; 2:0.05; 7:0.05
  Agent2 top policies: 16:0.18; 22:0.18; 4:0.18; 12:0.04; 18:0.04
. b r
2 . .
. . 1

Reward: +0.00, Result: neutral

--- Step 5 ---
Agent 1: LEFT, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 8:1.00, 5:0.00, 4:0.00
    red_button_pos: 7:0.25, 1:0.25, 6:0.25
    blue_button_pos: 7:0.25, 1:0.25, 6:0.25
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 3:1.00, 4:0.00, 7:0.00
    red_button_pos: 6:0.20, 5:0.20, 0:0.20
    blue_button_pos: 6:0.20, 5:0.20, 0:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 16:0.63; 14:0.09; 13:0.09; 17:0.07; 12:0.01
  Agent2 top policies: 4:0.28; 10:0.28; 3:0.05; 0:0.05; 2:0.05
2 b r
. . .
. 1 .

Reward: +0.00, Result: neutral

--- Step 6 ---
Agent 1: LEFT, Agent 2: RIGHT
  Agent1 beliefs:
    agent_pos: 7:1.00, 8:0.00, 5:0.00
    red_button_pos: 1:0.32, 2:0.32, 6:0.32
    blue_button_pos: 1:0.32, 2:0.32, 6:0.32
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 0:1.00, 3:0.00, 4:0.00
    red_button_pos: 6:0.24, 1:0.24, 5:0.24
    blue_button_pos: 6:0.24, 1:0.24, 5:0.24
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 16:0.72; 14:0.08; 13:0.08; 17:0.06; 12:0.01
  Agent2 top policies: 22:0.63; 21:0.09; 18:0.09; 23:0.07; 19:0.01
. 2 r
. . .
1 . .

Reward: +0.00, Result: neutral

--- Step 7 ---
Agent 1: UP, Agent 2: RIGHT
  Agent1 beliefs:
    agent_pos: 6:1.00, 7:0.00, 8:0.00
    red_button_pos: 1:0.47, 2:0.47, 0:0.02
    blue_button_pos: 1:0.47, 2:0.47, 0:0.02
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 1:1.00, 8:0.00, 5:0.00
    red_button_pos: 6:0.32, 2:0.32, 5:0.32
    blue_button_pos: 1:1.00, 2:0.00, 6:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 0:0.05; 4:0.05; 3:0.05; 2:0.04; 24:0.04
  Agent2 top policies: 22:0.34; 19:0.10; 21:0.09; 18:0.09; 23:0.07
. b 2
1 . .
. . .

Reward: +0.00, Result: neutral

--- Step 8 ---
Agent 1: UP, Agent 2: PRESS
  Agent1 beliefs:
    agent_pos: 3:1.00, 6:0.00, 7:0.00
    red_button_pos: 1:0.47, 2:0.47, 0:0.02
    blue_button_pos: 1:0.47, 2:0.47, 0:0.02
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 2:1.00, 8:0.00, 7:0.00
    red_button_pos: 2:1.00, 5:0.00, 6:0.00
    blue_button_pos: 1:0.99, 5:0.00, 6:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 3:0.24; 18:0.21; 4:0.05; 0:0.03; 2:0.03
  Agent2 top policies: 26:0.06; 24:0.06; 27:0.06; 22:0.05; 4:0.05
1 b 2
. . .
. . .

Reward: +0.00, Result: neutral
Button pressed: red by Agent 2

--- Step 9 ---
Agent 1: RIGHT, Agent 2: LEFT
  Agent1 beliefs:
    agent_pos: 0:1.00, 3:0.00, 6:0.00
    red_button_pos: 1:0.48, 2:0.48, 4:0.01
    blue_button_pos: 1:0.48, 2:0.48, 4:0.01
    red_button_state: 0:0.50, 1:0.50
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 2:1.00, 8:0.00, 7:0.00
    red_button_pos: 2:1.00, 5:0.00, 6:0.00
    blue_button_pos: 1:0.98, 5:0.00, 6:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 22:0.59; 18:0.12; 21:0.12; 23:0.10; 19:0.01
  Agent2 top policies: 16:0.35; 12:0.03; 26:0.02; 20:0.02; 2:0.02
. 1 2
. . .
. . .

Reward: +0.00, Result: neutral

--- Step 10 ---
Agent 1: PRESS, Agent 2: LEFT
  Agent1 beliefs:
    agent_pos: 1:1.00, 8:0.00, 5:0.00
    red_button_pos: 2:0.91, 4:0.03, 5:0.02
    blue_button_pos: 1:1.00, 2:0.00, 4:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 2:1.00, 1:0.00, 8:0.00
    red_button_pos: 2:1.00, 8:0.00, 7:0.00
    blue_button_pos: 1:0.97, 5:0.00, 6:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 27:0.24; 25:0.16; 24:0.15; 26:0.13; 28:0.12
  Agent2 top policies: 16:0.37; 12:0.03; 26:0.02; 2:0.02; 20:0.02
. 1 2
. . .
. . .

Reward: +1.00, Result: win
Button pressed: blue by Agent 1

Result: ✅ WIN - win (steps: 10, reward: +1.00)

================================================================================
EPISODE 40
================================================================================
Environment: Red at (2, 0), Blue at (1, 0)

Initial state:
1 b r
. . .
. . 2


--- Step 1 ---
Agent 1: DOWN, Agent 2: LEFT
  Agent1 beliefs:
    agent_pos: 0:1.00, 8:0.00, 7:0.00
    red_button_pos: 8:0.12, 7:0.12, 6:0.12
    blue_button_pos: 8:0.12, 7:0.12, 6:0.12
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 8:1.00, 7:0.00, 6:0.00
    red_button_pos: 7:0.12, 3:0.12, 6:0.12
    blue_button_pos: 7:0.12, 3:0.12, 6:0.12
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 10:0.21; 22:0.21; 9:0.06; 19:0.06; 21:0.05
  Agent2 top policies: 16:0.21; 4:0.21; 12:0.06; 2:0.06; 0:0.05
. b r
1 . .
. 2 .

Reward: +0.00, Result: neutral

--- Step 2 ---
Agent 1: RIGHT, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 3:1.00, 0:0.00, 8:0.00
    red_button_pos: 8:0.14, 7:0.14, 6:0.14
    blue_button_pos: 8:0.14, 7:0.14, 6:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 7:1.00, 8:0.00, 6:0.00
    red_button_pos: 6:0.14, 1:0.14, 5:0.14
    blue_button_pos: 6:0.14, 1:0.14, 5:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 22:0.23; 10:0.23; 9:0.06; 21:0.05; 19:0.05
  Agent2 top policies: 4:0.23; 16:0.23; 12:0.06; 0:0.05; 2:0.05
. b r
. 1 .
. 2 .

Reward: +0.00, Result: neutral

--- Step 3 ---
Agent 1: RIGHT, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 4:1.00, 3:0.00, 0:0.00
    red_button_pos: 8:0.17, 7:0.17, 6:0.17
    blue_button_pos: 8:0.17, 7:0.17, 6:0.17
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 7:0.87, 4:0.12, 8:0.00
    red_button_pos: 6:0.14, 1:0.14, 5:0.14
    blue_button_pos: 6:0.14, 1:0.14, 5:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 22:0.18; 10:0.18; 4:0.18; 21:0.04; 9:0.04
  Agent2 top policies: 4:0.24; 16:0.23; 12:0.06; 2:0.05; 14:0.05
. b r
. 2 1
. . .

Reward: +0.00, Result: neutral

--- Step 4 ---
Agent 1: DOWN, Agent 2: LEFT
  Agent1 beliefs:
    agent_pos: 5:1.00, 4:0.00, 3:0.00
    red_button_pos: 8:0.20, 7:0.20, 6:0.20
    blue_button_pos: 8:0.20, 7:0.20, 6:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 4:1.00, 1:0.00, 7:0.00
    red_button_pos: 6:0.17, 1:0.17, 5:0.17
    blue_button_pos: 6:0.17, 1:0.17, 5:0.17
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 10:0.27; 4:0.27; 8:0.05; 2:0.05; 7:0.05
  Agent2 top policies: 16:0.18; 22:0.18; 4:0.18; 12:0.04; 18:0.04
. b r
2 . .
. . 1

Reward: +0.00, Result: neutral

--- Step 5 ---
Agent 1: LEFT, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 8:1.00, 5:0.00, 4:0.00
    red_button_pos: 7:0.25, 1:0.25, 6:0.25
    blue_button_pos: 7:0.25, 1:0.25, 6:0.25
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 3:1.00, 4:0.00, 7:0.00
    red_button_pos: 6:0.20, 5:0.20, 0:0.20
    blue_button_pos: 6:0.20, 5:0.20, 0:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 16:0.63; 14:0.09; 13:0.09; 17:0.07; 12:0.01
  Agent2 top policies: 4:0.28; 10:0.28; 3:0.05; 0:0.05; 2:0.05
2 b r
. . .
. 1 .

Reward: +0.00, Result: neutral

--- Step 6 ---
Agent 1: LEFT, Agent 2: RIGHT
  Agent1 beliefs:
    agent_pos: 7:1.00, 8:0.00, 5:0.00
    red_button_pos: 1:0.32, 2:0.32, 6:0.32
    blue_button_pos: 1:0.32, 2:0.32, 6:0.32
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 0:1.00, 3:0.00, 4:0.00
    red_button_pos: 6:0.24, 1:0.24, 5:0.24
    blue_button_pos: 6:0.24, 1:0.24, 5:0.24
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 16:0.72; 14:0.08; 13:0.08; 17:0.06; 12:0.01
  Agent2 top policies: 22:0.63; 21:0.09; 18:0.09; 23:0.07; 19:0.01
. 2 r
. . .
1 . .

Reward: +0.00, Result: neutral

--- Step 7 ---
Agent 1: UP, Agent 2: RIGHT
  Agent1 beliefs:
    agent_pos: 6:1.00, 7:0.00, 8:0.00
    red_button_pos: 1:0.47, 2:0.47, 0:0.02
    blue_button_pos: 1:0.47, 2:0.47, 0:0.02
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 1:1.00, 8:0.00, 5:0.00
    red_button_pos: 6:0.32, 2:0.32, 5:0.32
    blue_button_pos: 1:1.00, 2:0.00, 6:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 0:0.05; 4:0.05; 3:0.05; 2:0.04; 24:0.04
  Agent2 top policies: 22:0.34; 19:0.10; 21:0.09; 18:0.09; 23:0.07
. b 2
1 . .
. . .

Reward: +0.00, Result: neutral

--- Step 8 ---
Agent 1: UP, Agent 2: PRESS
  Agent1 beliefs:
    agent_pos: 3:1.00, 6:0.00, 7:0.00
    red_button_pos: 1:0.47, 2:0.47, 0:0.02
    blue_button_pos: 1:0.47, 2:0.47, 0:0.02
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 2:1.00, 8:0.00, 7:0.00
    red_button_pos: 2:1.00, 5:0.00, 6:0.00
    blue_button_pos: 1:0.99, 5:0.00, 6:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 3:0.24; 18:0.21; 4:0.05; 0:0.03; 2:0.03
  Agent2 top policies: 26:0.06; 24:0.06; 27:0.06; 22:0.05; 4:0.05
1 b 2
. . .
. . .

Reward: +0.00, Result: neutral
Button pressed: red by Agent 2

--- Step 9 ---
Agent 1: RIGHT, Agent 2: LEFT
  Agent1 beliefs:
    agent_pos: 0:1.00, 3:0.00, 6:0.00
    red_button_pos: 1:0.48, 2:0.48, 4:0.01
    blue_button_pos: 1:0.48, 2:0.48, 4:0.01
    red_button_state: 0:0.50, 1:0.50
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 2:1.00, 8:0.00, 7:0.00
    red_button_pos: 2:1.00, 5:0.00, 6:0.00
    blue_button_pos: 1:0.98, 5:0.00, 6:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 22:0.59; 18:0.12; 21:0.12; 23:0.10; 19:0.01
  Agent2 top policies: 16:0.35; 12:0.03; 26:0.02; 20:0.02; 2:0.02
. 1 2
. . .
. . .

Reward: +0.00, Result: neutral

--- Step 10 ---
Agent 1: PRESS, Agent 2: LEFT
  Agent1 beliefs:
    agent_pos: 1:1.00, 8:0.00, 5:0.00
    red_button_pos: 2:0.91, 4:0.03, 5:0.02
    blue_button_pos: 1:1.00, 2:0.00, 4:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 2:1.00, 1:0.00, 8:0.00
    red_button_pos: 2:1.00, 8:0.00, 7:0.00
    blue_button_pos: 1:0.97, 5:0.00, 6:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 27:0.24; 25:0.16; 24:0.15; 26:0.13; 28:0.12
  Agent2 top policies: 16:0.37; 12:0.03; 26:0.02; 2:0.02; 20:0.02
. 1 2
. . .
. . .

Reward: +1.00, Result: win
Button pressed: blue by Agent 1

Result: ✅ WIN - win (steps: 10, reward: +1.00)

================================================================================
SEED 0 - CONFIG 3
Red at (1, 0), Blue at (0, 2)
Episodes 41-60
================================================================================

================================================================================
EPISODE 41
================================================================================
Environment: Red at (1, 0), Blue at (0, 2)

Initial state:
1 r .
. . .
b . 2


--- Step 1 ---
Agent 1: DOWN, Agent 2: LEFT
  Agent1 beliefs:
    agent_pos: 0:1.00, 8:0.00, 7:0.00
    red_button_pos: 8:0.12, 7:0.12, 6:0.12
    blue_button_pos: 8:0.12, 7:0.12, 6:0.12
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 8:1.00, 7:0.00, 6:0.00
    red_button_pos: 7:0.12, 3:0.12, 6:0.12
    blue_button_pos: 7:0.12, 3:0.12, 6:0.12
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 10:0.21; 22:0.21; 9:0.06; 19:0.06; 21:0.05
  Agent2 top policies: 16:0.21; 4:0.21; 12:0.06; 2:0.06; 0:0.05
. r .
1 . .
b 2 .

Reward: +0.00, Result: neutral

--- Step 2 ---
Agent 1: RIGHT, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 3:1.00, 0:0.00, 8:0.00
    red_button_pos: 8:0.14, 7:0.14, 6:0.14
    blue_button_pos: 8:0.14, 7:0.14, 6:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 7:1.00, 8:0.00, 6:0.00
    red_button_pos: 6:0.14, 1:0.14, 5:0.14
    blue_button_pos: 6:0.14, 1:0.14, 5:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 22:0.23; 10:0.23; 9:0.06; 21:0.05; 19:0.05
  Agent2 top policies: 4:0.23; 16:0.23; 12:0.06; 0:0.05; 2:0.05
. r .
. 1 .
b 2 .

Reward: +0.00, Result: neutral

--- Step 3 ---
Agent 1: RIGHT, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 4:1.00, 3:0.00, 0:0.00
    red_button_pos: 8:0.17, 7:0.17, 6:0.17
    blue_button_pos: 8:0.17, 7:0.17, 6:0.17
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 7:0.87, 4:0.12, 8:0.00
    red_button_pos: 6:0.14, 1:0.14, 5:0.14
    blue_button_pos: 6:0.14, 1:0.14, 5:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 22:0.18; 10:0.18; 4:0.18; 21:0.04; 9:0.04
  Agent2 top policies: 4:0.24; 16:0.23; 12:0.06; 2:0.05; 14:0.05
. r .
. 2 1
b . .

Reward: +0.00, Result: neutral

--- Step 4 ---
Agent 1: DOWN, Agent 2: LEFT
  Agent1 beliefs:
    agent_pos: 5:1.00, 4:0.00, 3:0.00
    red_button_pos: 8:0.20, 7:0.20, 6:0.20
    blue_button_pos: 8:0.20, 7:0.20, 6:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 4:1.00, 1:0.00, 7:0.00
    red_button_pos: 6:0.17, 1:0.17, 5:0.17
    blue_button_pos: 6:0.17, 1:0.17, 5:0.17
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 10:0.27; 4:0.27; 8:0.05; 2:0.05; 7:0.05
  Agent2 top policies: 16:0.18; 22:0.18; 4:0.18; 12:0.04; 18:0.04
. r .
2 . .
b . 1

Reward: +0.00, Result: neutral

--- Step 5 ---
Agent 1: LEFT, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 8:1.00, 5:0.00, 4:0.00
    red_button_pos: 7:0.25, 1:0.25, 6:0.25
    blue_button_pos: 7:0.25, 1:0.25, 6:0.25
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 3:1.00, 4:0.00, 7:0.00
    red_button_pos: 6:0.20, 5:0.20, 0:0.20
    blue_button_pos: 6:0.20, 5:0.20, 0:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 16:0.63; 14:0.09; 13:0.09; 17:0.07; 12:0.01
  Agent2 top policies: 4:0.28; 10:0.28; 3:0.05; 0:0.05; 2:0.05
2 r .
. . .
b 1 .

Reward: +0.00, Result: neutral

--- Step 6 ---
Agent 1: LEFT, Agent 2: RIGHT
  Agent1 beliefs:
    agent_pos: 7:1.00, 8:0.00, 5:0.00
    red_button_pos: 1:0.32, 2:0.32, 6:0.32
    blue_button_pos: 1:0.32, 2:0.32, 6:0.32
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 0:1.00, 3:0.00, 4:0.00
    red_button_pos: 6:0.24, 1:0.24, 5:0.24
    blue_button_pos: 6:0.24, 1:0.24, 5:0.24
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 16:0.72; 14:0.08; 13:0.08; 17:0.06; 12:0.01
  Agent2 top policies: 22:0.63; 21:0.09; 18:0.09; 23:0.07; 19:0.01
. 2 .
. . .
1 . .

Reward: +0.00, Result: neutral

--- Step 7 ---
Agent 1: UP, Agent 2: RIGHT
  Agent1 beliefs:
    agent_pos: 6:1.00, 3:0.00, 0:0.00
    red_button_pos: 1:0.47, 2:0.47, 0:0.02
    blue_button_pos: 6:1.00, 1:0.00, 2:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 1:1.00, 8:0.00, 5:0.00
    red_button_pos: 1:1.00, 2:0.00, 6:0.00
    blue_button_pos: 6:0.32, 2:0.32, 5:0.32
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 4:0.05; 1:0.05; 0:0.05; 3:0.05; 2:0.04
  Agent2 top policies: 22:0.18; 19:0.09; 21:0.09; 18:0.09; 23:0.07
. r 2
1 . .
b . .

Reward: +0.00, Result: neutral

--- Step 8 ---
Agent 1: UP, Agent 2: DOWN
  Agent1 beliefs:
    agent_pos: 3:1.00, 7:0.00, 8:0.00
    red_button_pos: 1:0.47, 2:0.47, 0:0.02
    blue_button_pos: 6:0.99, 1:0.00, 2:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 2:1.00, 0:0.00, 3:0.00
    red_button_pos: 1:0.99, 5:0.00, 6:0.00
    blue_button_pos: 6:0.47, 5:0.47, 8:0.02
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 3:0.10; 18:0.09; 4:0.04; 8:0.04; 7:0.04
  Agent2 top policies: 10:0.23; 9:0.13; 11:0.10; 7:0.05; 8:0.04
1 r .
. . 2
b . .

Reward: +0.00, Result: neutral

--- Step 9 ---
Agent 1: RIGHT, Agent 2: DOWN
  Agent1 beliefs:
    agent_pos: 0:1.00, 3:0.00, 7:0.00
    red_button_pos: 1:0.48, 2:0.48, 4:0.01
    blue_button_pos: 6:0.98, 1:0.00, 2:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 5:1.00, 2:0.00, 0:0.00
    red_button_pos: 1:0.98, 6:0.00, 8:0.00
    blue_button_pos: 6:0.87, 8:0.05, 7:0.03
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 22:0.40; 18:0.10; 21:0.10; 23:0.08; 19:0.03
  Agent2 top policies: 10:0.06; 7:0.05; 9:0.05; 16:0.04; 8:0.04
. 1 .
. . .
b . 2

Reward: +0.00, Result: neutral

--- Step 10 ---
Agent 1: PRESS, Agent 2: LEFT
  Agent1 beliefs:
    agent_pos: 1:1.00, 8:0.00, 5:0.00
    red_button_pos: 1:1.00, 2:0.00, 4:0.00
    blue_button_pos: 6:0.98, 2:0.00, 4:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 8:1.00, 5:0.00, 2:0.00
    red_button_pos: 1:0.98, 6:0.00, 7:0.00
    blue_button_pos: 6:0.90, 7:0.03, 4:0.02
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 24:0.06; 4:0.06; 25:0.06; 27:0.05; 26:0.05
  Agent2 top policies: 16:0.07; 14:0.07; 13:0.04; 12:0.04; 26:0.03
. 1 .
. . .
b 2 .

Reward: +0.00, Result: neutral
Button pressed: red by Agent 1

--- Step 11 ---
Agent 1: UP, Agent 2: LEFT
  Agent1 beliefs:
    agent_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 2:0.00, 8:0.00
    blue_button_pos: 6:0.97, 2:0.00, 4:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 7:1.00, 8:0.00, 5:0.00
    red_button_pos: 1:0.97, 6:0.00, 4:0.00
    blue_button_pos: 6:0.92, 4:0.03, 3:0.02
    red_button_state: 0:0.50, 1:0.50
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 4:0.04; 28:0.04; 24:0.04; 0:0.04; 22:0.04
  Agent2 top policies: 16:0.16; 14:0.06; 13:0.06; 17:0.05; 12:0.04
. 1 .
. . .
2 . .

Reward: +0.00, Result: neutral

--- Step 12 ---
Agent 1: UP, Agent 2: PRESS
  Agent1 beliefs:
    agent_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 8:0.00, 7:0.00
    blue_button_pos: 6:0.96, 2:0.01, 8:0.01
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 6:1.00, 3:0.00, 0:0.00
    red_button_pos: 1:0.97, 4:0.01, 3:0.01
    blue_button_pos: 6:1.00, 4:0.00, 3:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 4:0.04; 28:0.04; 22:0.04; 10:0.04; 24:0.03
  Agent2 top policies: 26:0.17; 25:0.17; 24:0.16; 27:0.15; 28:0.14
. 1 .
. . .
2 . .

Reward: +1.00, Result: win
Button pressed: blue by Agent 2

Result: ✅ WIN - win (steps: 12, reward: +1.00)

================================================================================
EPISODE 42
================================================================================
Environment: Red at (1, 0), Blue at (0, 2)

Initial state:
1 r .
. . .
b . 2


--- Step 1 ---
Agent 1: DOWN, Agent 2: LEFT
  Agent1 beliefs:
    agent_pos: 0:1.00, 8:0.00, 7:0.00
    red_button_pos: 8:0.12, 7:0.12, 6:0.12
    blue_button_pos: 8:0.12, 7:0.12, 6:0.12
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 8:1.00, 7:0.00, 6:0.00
    red_button_pos: 7:0.12, 3:0.12, 6:0.12
    blue_button_pos: 7:0.12, 3:0.12, 6:0.12
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 10:0.21; 22:0.21; 9:0.06; 19:0.06; 21:0.05
  Agent2 top policies: 16:0.21; 4:0.21; 12:0.06; 2:0.06; 0:0.05
. r .
1 . .
b 2 .

Reward: +0.00, Result: neutral

--- Step 2 ---
Agent 1: RIGHT, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 3:1.00, 0:0.00, 8:0.00
    red_button_pos: 8:0.14, 7:0.14, 6:0.14
    blue_button_pos: 8:0.14, 7:0.14, 6:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 7:1.00, 8:0.00, 6:0.00
    red_button_pos: 6:0.14, 1:0.14, 5:0.14
    blue_button_pos: 6:0.14, 1:0.14, 5:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 22:0.23; 10:0.23; 9:0.06; 21:0.05; 19:0.05
  Agent2 top policies: 4:0.23; 16:0.23; 12:0.06; 0:0.05; 2:0.05
. r .
. 1 .
b 2 .

Reward: +0.00, Result: neutral

--- Step 3 ---
Agent 1: RIGHT, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 4:1.00, 3:0.00, 0:0.00
    red_button_pos: 8:0.17, 7:0.17, 6:0.17
    blue_button_pos: 8:0.17, 7:0.17, 6:0.17
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 7:0.87, 4:0.12, 8:0.00
    red_button_pos: 6:0.14, 1:0.14, 5:0.14
    blue_button_pos: 6:0.14, 1:0.14, 5:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 22:0.18; 10:0.18; 4:0.18; 21:0.04; 9:0.04
  Agent2 top policies: 4:0.24; 16:0.23; 12:0.06; 2:0.05; 14:0.05
. r .
. 2 1
b . .

Reward: +0.00, Result: neutral

--- Step 4 ---
Agent 1: DOWN, Agent 2: LEFT
  Agent1 beliefs:
    agent_pos: 5:1.00, 4:0.00, 3:0.00
    red_button_pos: 8:0.20, 7:0.20, 6:0.20
    blue_button_pos: 8:0.20, 7:0.20, 6:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 4:1.00, 1:0.00, 7:0.00
    red_button_pos: 6:0.17, 1:0.17, 5:0.17
    blue_button_pos: 6:0.17, 1:0.17, 5:0.17
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 10:0.27; 4:0.27; 8:0.05; 2:0.05; 7:0.05
  Agent2 top policies: 16:0.18; 22:0.18; 4:0.18; 12:0.04; 18:0.04
. r .
2 . .
b . 1

Reward: +0.00, Result: neutral

--- Step 5 ---
Agent 1: LEFT, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 8:1.00, 5:0.00, 4:0.00
    red_button_pos: 7:0.25, 1:0.25, 6:0.25
    blue_button_pos: 7:0.25, 1:0.25, 6:0.25
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 3:1.00, 4:0.00, 7:0.00
    red_button_pos: 6:0.20, 5:0.20, 0:0.20
    blue_button_pos: 6:0.20, 5:0.20, 0:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 16:0.63; 14:0.09; 13:0.09; 17:0.07; 12:0.01
  Agent2 top policies: 4:0.28; 10:0.28; 3:0.05; 0:0.05; 2:0.05
2 r .
. . .
b 1 .

Reward: +0.00, Result: neutral

--- Step 6 ---
Agent 1: LEFT, Agent 2: RIGHT
  Agent1 beliefs:
    agent_pos: 7:1.00, 8:0.00, 5:0.00
    red_button_pos: 1:0.32, 2:0.32, 6:0.32
    blue_button_pos: 1:0.32, 2:0.32, 6:0.32
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 0:1.00, 3:0.00, 4:0.00
    red_button_pos: 6:0.24, 1:0.24, 5:0.24
    blue_button_pos: 6:0.24, 1:0.24, 5:0.24
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 16:0.72; 14:0.08; 13:0.08; 17:0.06; 12:0.01
  Agent2 top policies: 22:0.63; 21:0.09; 18:0.09; 23:0.07; 19:0.01
. 2 .
. . .
1 . .

Reward: +0.00, Result: neutral

--- Step 7 ---
Agent 1: UP, Agent 2: RIGHT
  Agent1 beliefs:
    agent_pos: 6:1.00, 3:0.00, 0:0.00
    red_button_pos: 1:0.47, 2:0.47, 0:0.02
    blue_button_pos: 6:1.00, 1:0.00, 2:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 1:1.00, 8:0.00, 5:0.00
    red_button_pos: 1:1.00, 2:0.00, 6:0.00
    blue_button_pos: 6:0.32, 2:0.32, 5:0.32
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 4:0.05; 1:0.05; 0:0.05; 3:0.05; 2:0.04
  Agent2 top policies: 22:0.18; 19:0.09; 21:0.09; 18:0.09; 23:0.07
. r 2
1 . .
b . .

Reward: +0.00, Result: neutral

--- Step 8 ---
Agent 1: UP, Agent 2: DOWN
  Agent1 beliefs:
    agent_pos: 3:1.00, 7:0.00, 8:0.00
    red_button_pos: 1:0.47, 2:0.47, 0:0.02
    blue_button_pos: 6:0.99, 1:0.00, 2:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 2:1.00, 0:0.00, 3:0.00
    red_button_pos: 1:0.99, 5:0.00, 6:0.00
    blue_button_pos: 6:0.47, 5:0.47, 8:0.02
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 3:0.10; 18:0.09; 4:0.04; 8:0.04; 7:0.04
  Agent2 top policies: 10:0.23; 9:0.13; 11:0.10; 7:0.05; 8:0.04
1 r .
. . 2
b . .

Reward: +0.00, Result: neutral

--- Step 9 ---
Agent 1: RIGHT, Agent 2: DOWN
  Agent1 beliefs:
    agent_pos: 0:1.00, 3:0.00, 7:0.00
    red_button_pos: 1:0.48, 2:0.48, 4:0.01
    blue_button_pos: 6:0.98, 1:0.00, 2:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 5:1.00, 2:0.00, 0:0.00
    red_button_pos: 1:0.98, 6:0.00, 8:0.00
    blue_button_pos: 6:0.87, 8:0.05, 7:0.03
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 22:0.40; 18:0.10; 21:0.10; 23:0.08; 19:0.03
  Agent2 top policies: 10:0.06; 7:0.05; 9:0.05; 16:0.04; 8:0.04
. 1 .
. . .
b . 2

Reward: +0.00, Result: neutral

--- Step 10 ---
Agent 1: PRESS, Agent 2: LEFT
  Agent1 beliefs:
    agent_pos: 1:1.00, 8:0.00, 5:0.00
    red_button_pos: 1:1.00, 2:0.00, 4:0.00
    blue_button_pos: 6:0.98, 2:0.00, 4:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 8:1.00, 5:0.00, 2:0.00
    red_button_pos: 1:0.98, 6:0.00, 7:0.00
    blue_button_pos: 6:0.90, 7:0.03, 4:0.02
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 24:0.06; 4:0.06; 25:0.06; 27:0.05; 26:0.05
  Agent2 top policies: 16:0.07; 14:0.07; 13:0.04; 12:0.04; 26:0.03
. 1 .
. . .
b 2 .

Reward: +0.00, Result: neutral
Button pressed: red by Agent 1

--- Step 11 ---
Agent 1: UP, Agent 2: LEFT
  Agent1 beliefs:
    agent_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 2:0.00, 8:0.00
    blue_button_pos: 6:0.97, 2:0.00, 4:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 7:1.00, 8:0.00, 5:0.00
    red_button_pos: 1:0.97, 6:0.00, 4:0.00
    blue_button_pos: 6:0.92, 4:0.03, 3:0.02
    red_button_state: 0:0.50, 1:0.50
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 4:0.04; 28:0.04; 24:0.04; 0:0.04; 22:0.04
  Agent2 top policies: 16:0.16; 14:0.06; 13:0.06; 17:0.05; 12:0.04
. 1 .
. . .
2 . .

Reward: +0.00, Result: neutral

--- Step 12 ---
Agent 1: UP, Agent 2: PRESS
  Agent1 beliefs:
    agent_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 8:0.00, 7:0.00
    blue_button_pos: 6:0.96, 2:0.01, 8:0.01
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 6:1.00, 3:0.00, 0:0.00
    red_button_pos: 1:0.97, 4:0.01, 3:0.01
    blue_button_pos: 6:1.00, 4:0.00, 3:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 4:0.04; 28:0.04; 22:0.04; 10:0.04; 24:0.03
  Agent2 top policies: 26:0.17; 25:0.17; 24:0.16; 27:0.15; 28:0.14
. 1 .
. . .
2 . .

Reward: +1.00, Result: win
Button pressed: blue by Agent 2

Result: ✅ WIN - win (steps: 12, reward: +1.00)

================================================================================
EPISODE 43
================================================================================
Environment: Red at (1, 0), Blue at (0, 2)

Initial state:
1 r .
. . .
b . 2


--- Step 1 ---
Agent 1: DOWN, Agent 2: LEFT
  Agent1 beliefs:
    agent_pos: 0:1.00, 8:0.00, 7:0.00
    red_button_pos: 8:0.12, 7:0.12, 6:0.12
    blue_button_pos: 8:0.12, 7:0.12, 6:0.12
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 8:1.00, 7:0.00, 6:0.00
    red_button_pos: 7:0.12, 3:0.12, 6:0.12
    blue_button_pos: 7:0.12, 3:0.12, 6:0.12
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 10:0.21; 22:0.21; 9:0.06; 19:0.06; 21:0.05
  Agent2 top policies: 16:0.21; 4:0.21; 12:0.06; 2:0.06; 0:0.05
. r .
1 . .
b 2 .

Reward: +0.00, Result: neutral

--- Step 2 ---
Agent 1: RIGHT, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 3:1.00, 0:0.00, 8:0.00
    red_button_pos: 8:0.14, 7:0.14, 6:0.14
    blue_button_pos: 8:0.14, 7:0.14, 6:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 7:1.00, 8:0.00, 6:0.00
    red_button_pos: 6:0.14, 1:0.14, 5:0.14
    blue_button_pos: 6:0.14, 1:0.14, 5:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 22:0.23; 10:0.23; 9:0.06; 21:0.05; 19:0.05
  Agent2 top policies: 4:0.23; 16:0.23; 12:0.06; 0:0.05; 2:0.05
. r .
. 1 .
b 2 .

Reward: +0.00, Result: neutral

--- Step 3 ---
Agent 1: RIGHT, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 4:1.00, 3:0.00, 0:0.00
    red_button_pos: 8:0.17, 7:0.17, 6:0.17
    blue_button_pos: 8:0.17, 7:0.17, 6:0.17
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 7:0.87, 4:0.12, 8:0.00
    red_button_pos: 6:0.14, 1:0.14, 5:0.14
    blue_button_pos: 6:0.14, 1:0.14, 5:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 22:0.18; 10:0.18; 4:0.18; 21:0.04; 9:0.04
  Agent2 top policies: 4:0.24; 16:0.23; 12:0.06; 2:0.05; 14:0.05
. r .
. 2 1
b . .

Reward: +0.00, Result: neutral

--- Step 4 ---
Agent 1: DOWN, Agent 2: LEFT
  Agent1 beliefs:
    agent_pos: 5:1.00, 4:0.00, 3:0.00
    red_button_pos: 8:0.20, 7:0.20, 6:0.20
    blue_button_pos: 8:0.20, 7:0.20, 6:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 4:1.00, 1:0.00, 7:0.00
    red_button_pos: 6:0.17, 1:0.17, 5:0.17
    blue_button_pos: 6:0.17, 1:0.17, 5:0.17
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 10:0.27; 4:0.27; 8:0.05; 2:0.05; 7:0.05
  Agent2 top policies: 16:0.18; 22:0.18; 4:0.18; 12:0.04; 18:0.04
. r .
2 . .
b . 1

Reward: +0.00, Result: neutral

--- Step 5 ---
Agent 1: LEFT, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 8:1.00, 5:0.00, 4:0.00
    red_button_pos: 7:0.25, 1:0.25, 6:0.25
    blue_button_pos: 7:0.25, 1:0.25, 6:0.25
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 3:1.00, 4:0.00, 7:0.00
    red_button_pos: 6:0.20, 5:0.20, 0:0.20
    blue_button_pos: 6:0.20, 5:0.20, 0:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 16:0.63; 14:0.09; 13:0.09; 17:0.07; 12:0.01
  Agent2 top policies: 4:0.28; 10:0.28; 3:0.05; 0:0.05; 2:0.05
2 r .
. . .
b 1 .

Reward: +0.00, Result: neutral

--- Step 6 ---
Agent 1: LEFT, Agent 2: RIGHT
  Agent1 beliefs:
    agent_pos: 7:1.00, 8:0.00, 5:0.00
    red_button_pos: 1:0.32, 2:0.32, 6:0.32
    blue_button_pos: 1:0.32, 2:0.32, 6:0.32
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 0:1.00, 3:0.00, 4:0.00
    red_button_pos: 6:0.24, 1:0.24, 5:0.24
    blue_button_pos: 6:0.24, 1:0.24, 5:0.24
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 16:0.72; 14:0.08; 13:0.08; 17:0.06; 12:0.01
  Agent2 top policies: 22:0.63; 21:0.09; 18:0.09; 23:0.07; 19:0.01
. 2 .
. . .
1 . .

Reward: +0.00, Result: neutral

--- Step 7 ---
Agent 1: UP, Agent 2: RIGHT
  Agent1 beliefs:
    agent_pos: 6:1.00, 3:0.00, 0:0.00
    red_button_pos: 1:0.47, 2:0.47, 0:0.02
    blue_button_pos: 6:1.00, 1:0.00, 2:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 1:1.00, 8:0.00, 5:0.00
    red_button_pos: 1:1.00, 2:0.00, 6:0.00
    blue_button_pos: 6:0.32, 2:0.32, 5:0.32
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 4:0.05; 1:0.05; 0:0.05; 3:0.05; 2:0.04
  Agent2 top policies: 22:0.18; 19:0.09; 21:0.09; 18:0.09; 23:0.07
. r 2
1 . .
b . .

Reward: +0.00, Result: neutral

--- Step 8 ---
Agent 1: UP, Agent 2: DOWN
  Agent1 beliefs:
    agent_pos: 3:1.00, 7:0.00, 8:0.00
    red_button_pos: 1:0.47, 2:0.47, 0:0.02
    blue_button_pos: 6:0.99, 1:0.00, 2:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 2:1.00, 0:0.00, 3:0.00
    red_button_pos: 1:0.99, 5:0.00, 6:0.00
    blue_button_pos: 6:0.47, 5:0.47, 8:0.02
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 3:0.10; 18:0.09; 4:0.04; 8:0.04; 7:0.04
  Agent2 top policies: 10:0.23; 9:0.13; 11:0.10; 7:0.05; 8:0.04
1 r .
. . 2
b . .

Reward: +0.00, Result: neutral

--- Step 9 ---
Agent 1: RIGHT, Agent 2: DOWN
  Agent1 beliefs:
    agent_pos: 0:1.00, 3:0.00, 7:0.00
    red_button_pos: 1:0.48, 2:0.48, 4:0.01
    blue_button_pos: 6:0.98, 1:0.00, 2:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 5:1.00, 2:0.00, 0:0.00
    red_button_pos: 1:0.98, 6:0.00, 8:0.00
    blue_button_pos: 6:0.87, 8:0.05, 7:0.03
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 22:0.40; 18:0.10; 21:0.10; 23:0.08; 19:0.03
  Agent2 top policies: 10:0.06; 7:0.05; 9:0.05; 16:0.04; 8:0.04
. 1 .
. . .
b . 2

Reward: +0.00, Result: neutral

--- Step 10 ---
Agent 1: PRESS, Agent 2: LEFT
  Agent1 beliefs:
    agent_pos: 1:1.00, 8:0.00, 5:0.00
    red_button_pos: 1:1.00, 2:0.00, 4:0.00
    blue_button_pos: 6:0.98, 2:0.00, 4:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 8:1.00, 5:0.00, 2:0.00
    red_button_pos: 1:0.98, 6:0.00, 7:0.00
    blue_button_pos: 6:0.90, 7:0.03, 4:0.02
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 24:0.06; 4:0.06; 25:0.06; 27:0.05; 26:0.05
  Agent2 top policies: 16:0.07; 14:0.07; 13:0.04; 12:0.04; 26:0.03
. 1 .
. . .
b 2 .

Reward: +0.00, Result: neutral
Button pressed: red by Agent 1

--- Step 11 ---
Agent 1: UP, Agent 2: LEFT
  Agent1 beliefs:
    agent_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 2:0.00, 8:0.00
    blue_button_pos: 6:0.97, 2:0.00, 4:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 7:1.00, 8:0.00, 5:0.00
    red_button_pos: 1:0.97, 6:0.00, 4:0.00
    blue_button_pos: 6:0.92, 4:0.03, 3:0.02
    red_button_state: 0:0.50, 1:0.50
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 4:0.04; 28:0.04; 24:0.04; 0:0.04; 22:0.04
  Agent2 top policies: 16:0.16; 14:0.06; 13:0.06; 17:0.05; 12:0.04
. 1 .
. . .
2 . .

Reward: +0.00, Result: neutral

--- Step 12 ---
Agent 1: UP, Agent 2: PRESS
  Agent1 beliefs:
    agent_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 8:0.00, 7:0.00
    blue_button_pos: 6:0.96, 2:0.01, 8:0.01
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 6:1.00, 3:0.00, 0:0.00
    red_button_pos: 1:0.97, 4:0.01, 3:0.01
    blue_button_pos: 6:1.00, 4:0.00, 3:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 4:0.04; 28:0.04; 22:0.04; 10:0.04; 24:0.03
  Agent2 top policies: 26:0.17; 25:0.17; 24:0.16; 27:0.15; 28:0.14
. 1 .
. . .
2 . .

Reward: +1.00, Result: win
Button pressed: blue by Agent 2

Result: ✅ WIN - win (steps: 12, reward: +1.00)

================================================================================
EPISODE 44
================================================================================
Environment: Red at (1, 0), Blue at (0, 2)

Initial state:
1 r .
. . .
b . 2


--- Step 1 ---
Agent 1: DOWN, Agent 2: LEFT
  Agent1 beliefs:
    agent_pos: 0:1.00, 8:0.00, 7:0.00
    red_button_pos: 8:0.12, 7:0.12, 6:0.12
    blue_button_pos: 8:0.12, 7:0.12, 6:0.12
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 8:1.00, 7:0.00, 6:0.00
    red_button_pos: 7:0.12, 3:0.12, 6:0.12
    blue_button_pos: 7:0.12, 3:0.12, 6:0.12
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 10:0.21; 22:0.21; 9:0.06; 19:0.06; 21:0.05
  Agent2 top policies: 16:0.21; 4:0.21; 12:0.06; 2:0.06; 0:0.05
. r .
1 . .
b 2 .

Reward: +0.00, Result: neutral

--- Step 2 ---
Agent 1: RIGHT, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 3:1.00, 0:0.00, 8:0.00
    red_button_pos: 8:0.14, 7:0.14, 6:0.14
    blue_button_pos: 8:0.14, 7:0.14, 6:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 7:1.00, 8:0.00, 6:0.00
    red_button_pos: 6:0.14, 1:0.14, 5:0.14
    blue_button_pos: 6:0.14, 1:0.14, 5:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 22:0.23; 10:0.23; 9:0.06; 21:0.05; 19:0.05
  Agent2 top policies: 4:0.23; 16:0.23; 12:0.06; 0:0.05; 2:0.05
. r .
. 1 .
b 2 .

Reward: +0.00, Result: neutral

--- Step 3 ---
Agent 1: RIGHT, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 4:1.00, 3:0.00, 0:0.00
    red_button_pos: 8:0.17, 7:0.17, 6:0.17
    blue_button_pos: 8:0.17, 7:0.17, 6:0.17
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 7:0.87, 4:0.12, 8:0.00
    red_button_pos: 6:0.14, 1:0.14, 5:0.14
    blue_button_pos: 6:0.14, 1:0.14, 5:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 22:0.18; 10:0.18; 4:0.18; 21:0.04; 9:0.04
  Agent2 top policies: 4:0.24; 16:0.23; 12:0.06; 2:0.05; 14:0.05
. r .
. 2 1
b . .

Reward: +0.00, Result: neutral

--- Step 4 ---
Agent 1: DOWN, Agent 2: LEFT
  Agent1 beliefs:
    agent_pos: 5:1.00, 4:0.00, 3:0.00
    red_button_pos: 8:0.20, 7:0.20, 6:0.20
    blue_button_pos: 8:0.20, 7:0.20, 6:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 4:1.00, 1:0.00, 7:0.00
    red_button_pos: 6:0.17, 1:0.17, 5:0.17
    blue_button_pos: 6:0.17, 1:0.17, 5:0.17
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 10:0.27; 4:0.27; 8:0.05; 2:0.05; 7:0.05
  Agent2 top policies: 16:0.18; 22:0.18; 4:0.18; 12:0.04; 18:0.04
. r .
2 . .
b . 1

Reward: +0.00, Result: neutral

--- Step 5 ---
Agent 1: LEFT, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 8:1.00, 5:0.00, 4:0.00
    red_button_pos: 7:0.25, 1:0.25, 6:0.25
    blue_button_pos: 7:0.25, 1:0.25, 6:0.25
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 3:1.00, 4:0.00, 7:0.00
    red_button_pos: 6:0.20, 5:0.20, 0:0.20
    blue_button_pos: 6:0.20, 5:0.20, 0:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 16:0.63; 14:0.09; 13:0.09; 17:0.07; 12:0.01
  Agent2 top policies: 4:0.28; 10:0.28; 3:0.05; 0:0.05; 2:0.05
2 r .
. . .
b 1 .

Reward: +0.00, Result: neutral

--- Step 6 ---
Agent 1: LEFT, Agent 2: RIGHT
  Agent1 beliefs:
    agent_pos: 7:1.00, 8:0.00, 5:0.00
    red_button_pos: 1:0.32, 2:0.32, 6:0.32
    blue_button_pos: 1:0.32, 2:0.32, 6:0.32
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 0:1.00, 3:0.00, 4:0.00
    red_button_pos: 6:0.24, 1:0.24, 5:0.24
    blue_button_pos: 6:0.24, 1:0.24, 5:0.24
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 16:0.72; 14:0.08; 13:0.08; 17:0.06; 12:0.01
  Agent2 top policies: 22:0.63; 21:0.09; 18:0.09; 23:0.07; 19:0.01
. 2 .
. . .
1 . .

Reward: +0.00, Result: neutral

--- Step 7 ---
Agent 1: UP, Agent 2: RIGHT
  Agent1 beliefs:
    agent_pos: 6:1.00, 3:0.00, 0:0.00
    red_button_pos: 1:0.47, 2:0.47, 0:0.02
    blue_button_pos: 6:1.00, 1:0.00, 2:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 1:1.00, 8:0.00, 5:0.00
    red_button_pos: 1:1.00, 2:0.00, 6:0.00
    blue_button_pos: 6:0.32, 2:0.32, 5:0.32
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 4:0.05; 1:0.05; 0:0.05; 3:0.05; 2:0.04
  Agent2 top policies: 22:0.18; 19:0.09; 21:0.09; 18:0.09; 23:0.07
. r 2
1 . .
b . .

Reward: +0.00, Result: neutral

--- Step 8 ---
Agent 1: UP, Agent 2: DOWN
  Agent1 beliefs:
    agent_pos: 3:1.00, 7:0.00, 8:0.00
    red_button_pos: 1:0.47, 2:0.47, 0:0.02
    blue_button_pos: 6:0.99, 1:0.00, 2:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 2:1.00, 0:0.00, 3:0.00
    red_button_pos: 1:0.99, 5:0.00, 6:0.00
    blue_button_pos: 6:0.47, 5:0.47, 8:0.02
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 3:0.10; 18:0.09; 4:0.04; 8:0.04; 7:0.04
  Agent2 top policies: 10:0.23; 9:0.13; 11:0.10; 7:0.05; 8:0.04
1 r .
. . 2
b . .

Reward: +0.00, Result: neutral

--- Step 9 ---
Agent 1: RIGHT, Agent 2: DOWN
  Agent1 beliefs:
    agent_pos: 0:1.00, 3:0.00, 7:0.00
    red_button_pos: 1:0.48, 2:0.48, 4:0.01
    blue_button_pos: 6:0.98, 1:0.00, 2:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 5:1.00, 2:0.00, 0:0.00
    red_button_pos: 1:0.98, 6:0.00, 8:0.00
    blue_button_pos: 6:0.87, 8:0.05, 7:0.03
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 22:0.40; 18:0.10; 21:0.10; 23:0.08; 19:0.03
  Agent2 top policies: 10:0.06; 7:0.05; 9:0.05; 16:0.04; 8:0.04
. 1 .
. . .
b . 2

Reward: +0.00, Result: neutral

--- Step 10 ---
Agent 1: PRESS, Agent 2: LEFT
  Agent1 beliefs:
    agent_pos: 1:1.00, 8:0.00, 5:0.00
    red_button_pos: 1:1.00, 2:0.00, 4:0.00
    blue_button_pos: 6:0.98, 2:0.00, 4:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 8:1.00, 5:0.00, 2:0.00
    red_button_pos: 1:0.98, 6:0.00, 7:0.00
    blue_button_pos: 6:0.90, 7:0.03, 4:0.02
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 24:0.06; 4:0.06; 25:0.06; 27:0.05; 26:0.05
  Agent2 top policies: 16:0.07; 14:0.07; 13:0.04; 12:0.04; 26:0.03
. 1 .
. . .
b 2 .

Reward: +0.00, Result: neutral
Button pressed: red by Agent 1

--- Step 11 ---
Agent 1: UP, Agent 2: LEFT
  Agent1 beliefs:
    agent_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 2:0.00, 8:0.00
    blue_button_pos: 6:0.97, 2:0.00, 4:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 7:1.00, 8:0.00, 5:0.00
    red_button_pos: 1:0.97, 6:0.00, 4:0.00
    blue_button_pos: 6:0.92, 4:0.03, 3:0.02
    red_button_state: 0:0.50, 1:0.50
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 4:0.04; 28:0.04; 24:0.04; 0:0.04; 22:0.04
  Agent2 top policies: 16:0.16; 14:0.06; 13:0.06; 17:0.05; 12:0.04
. 1 .
. . .
2 . .

Reward: +0.00, Result: neutral

--- Step 12 ---
Agent 1: UP, Agent 2: PRESS
  Agent1 beliefs:
    agent_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 8:0.00, 7:0.00
    blue_button_pos: 6:0.96, 2:0.01, 8:0.01
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 6:1.00, 3:0.00, 0:0.00
    red_button_pos: 1:0.97, 4:0.01, 3:0.01
    blue_button_pos: 6:1.00, 4:0.00, 3:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 4:0.04; 28:0.04; 22:0.04; 10:0.04; 24:0.03
  Agent2 top policies: 26:0.17; 25:0.17; 24:0.16; 27:0.15; 28:0.14
. 1 .
. . .
2 . .

Reward: +1.00, Result: win
Button pressed: blue by Agent 2

Result: ✅ WIN - win (steps: 12, reward: +1.00)

================================================================================
EPISODE 45
================================================================================
Environment: Red at (1, 0), Blue at (0, 2)

Initial state:
1 r .
. . .
b . 2


--- Step 1 ---
Agent 1: DOWN, Agent 2: LEFT
  Agent1 beliefs:
    agent_pos: 0:1.00, 8:0.00, 7:0.00
    red_button_pos: 8:0.12, 7:0.12, 6:0.12
    blue_button_pos: 8:0.12, 7:0.12, 6:0.12
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 8:1.00, 7:0.00, 6:0.00
    red_button_pos: 7:0.12, 3:0.12, 6:0.12
    blue_button_pos: 7:0.12, 3:0.12, 6:0.12
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 10:0.21; 22:0.21; 9:0.06; 19:0.06; 21:0.05
  Agent2 top policies: 16:0.21; 4:0.21; 12:0.06; 2:0.06; 0:0.05
. r .
1 . .
b 2 .

Reward: +0.00, Result: neutral

--- Step 2 ---
Agent 1: RIGHT, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 3:1.00, 0:0.00, 8:0.00
    red_button_pos: 8:0.14, 7:0.14, 6:0.14
    blue_button_pos: 8:0.14, 7:0.14, 6:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 7:1.00, 8:0.00, 6:0.00
    red_button_pos: 6:0.14, 1:0.14, 5:0.14
    blue_button_pos: 6:0.14, 1:0.14, 5:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 22:0.23; 10:0.23; 9:0.06; 21:0.05; 19:0.05
  Agent2 top policies: 4:0.23; 16:0.23; 12:0.06; 0:0.05; 2:0.05
. r .
. 1 .
b 2 .

Reward: +0.00, Result: neutral

--- Step 3 ---
Agent 1: RIGHT, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 4:1.00, 3:0.00, 0:0.00
    red_button_pos: 8:0.17, 7:0.17, 6:0.17
    blue_button_pos: 8:0.17, 7:0.17, 6:0.17
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 7:0.87, 4:0.12, 8:0.00
    red_button_pos: 6:0.14, 1:0.14, 5:0.14
    blue_button_pos: 6:0.14, 1:0.14, 5:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 22:0.18; 10:0.18; 4:0.18; 21:0.04; 9:0.04
  Agent2 top policies: 4:0.24; 16:0.23; 12:0.06; 2:0.05; 14:0.05
. r .
. 2 1
b . .

Reward: +0.00, Result: neutral

--- Step 4 ---
Agent 1: DOWN, Agent 2: LEFT
  Agent1 beliefs:
    agent_pos: 5:1.00, 4:0.00, 3:0.00
    red_button_pos: 8:0.20, 7:0.20, 6:0.20
    blue_button_pos: 8:0.20, 7:0.20, 6:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 4:1.00, 1:0.00, 7:0.00
    red_button_pos: 6:0.17, 1:0.17, 5:0.17
    blue_button_pos: 6:0.17, 1:0.17, 5:0.17
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 10:0.27; 4:0.27; 8:0.05; 2:0.05; 7:0.05
  Agent2 top policies: 16:0.18; 22:0.18; 4:0.18; 12:0.04; 18:0.04
. r .
2 . .
b . 1

Reward: +0.00, Result: neutral

--- Step 5 ---
Agent 1: LEFT, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 8:1.00, 5:0.00, 4:0.00
    red_button_pos: 7:0.25, 1:0.25, 6:0.25
    blue_button_pos: 7:0.25, 1:0.25, 6:0.25
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 3:1.00, 4:0.00, 7:0.00
    red_button_pos: 6:0.20, 5:0.20, 0:0.20
    blue_button_pos: 6:0.20, 5:0.20, 0:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 16:0.63; 14:0.09; 13:0.09; 17:0.07; 12:0.01
  Agent2 top policies: 4:0.28; 10:0.28; 3:0.05; 0:0.05; 2:0.05
2 r .
. . .
b 1 .

Reward: +0.00, Result: neutral

--- Step 6 ---
Agent 1: LEFT, Agent 2: RIGHT
  Agent1 beliefs:
    agent_pos: 7:1.00, 8:0.00, 5:0.00
    red_button_pos: 1:0.32, 2:0.32, 6:0.32
    blue_button_pos: 1:0.32, 2:0.32, 6:0.32
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 0:1.00, 3:0.00, 4:0.00
    red_button_pos: 6:0.24, 1:0.24, 5:0.24
    blue_button_pos: 6:0.24, 1:0.24, 5:0.24
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 16:0.72; 14:0.08; 13:0.08; 17:0.06; 12:0.01
  Agent2 top policies: 22:0.63; 21:0.09; 18:0.09; 23:0.07; 19:0.01
. 2 .
. . .
1 . .

Reward: +0.00, Result: neutral

--- Step 7 ---
Agent 1: UP, Agent 2: RIGHT
  Agent1 beliefs:
    agent_pos: 6:1.00, 3:0.00, 0:0.00
    red_button_pos: 1:0.47, 2:0.47, 0:0.02
    blue_button_pos: 6:1.00, 1:0.00, 2:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 1:1.00, 8:0.00, 5:0.00
    red_button_pos: 1:1.00, 2:0.00, 6:0.00
    blue_button_pos: 6:0.32, 2:0.32, 5:0.32
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 4:0.05; 1:0.05; 0:0.05; 3:0.05; 2:0.04
  Agent2 top policies: 22:0.18; 19:0.09; 21:0.09; 18:0.09; 23:0.07
. r 2
1 . .
b . .

Reward: +0.00, Result: neutral

--- Step 8 ---
Agent 1: UP, Agent 2: DOWN
  Agent1 beliefs:
    agent_pos: 3:1.00, 7:0.00, 8:0.00
    red_button_pos: 1:0.47, 2:0.47, 0:0.02
    blue_button_pos: 6:0.99, 1:0.00, 2:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 2:1.00, 0:0.00, 3:0.00
    red_button_pos: 1:0.99, 5:0.00, 6:0.00
    blue_button_pos: 6:0.47, 5:0.47, 8:0.02
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 3:0.10; 18:0.09; 4:0.04; 8:0.04; 7:0.04
  Agent2 top policies: 10:0.23; 9:0.13; 11:0.10; 7:0.05; 8:0.04
1 r .
. . 2
b . .

Reward: +0.00, Result: neutral

--- Step 9 ---
Agent 1: RIGHT, Agent 2: DOWN
  Agent1 beliefs:
    agent_pos: 0:1.00, 3:0.00, 7:0.00
    red_button_pos: 1:0.48, 2:0.48, 4:0.01
    blue_button_pos: 6:0.98, 1:0.00, 2:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 5:1.00, 2:0.00, 0:0.00
    red_button_pos: 1:0.98, 6:0.00, 8:0.00
    blue_button_pos: 6:0.87, 8:0.05, 7:0.03
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 22:0.40; 18:0.10; 21:0.10; 23:0.08; 19:0.03
  Agent2 top policies: 10:0.06; 7:0.05; 9:0.05; 16:0.04; 8:0.04
. 1 .
. . .
b . 2

Reward: +0.00, Result: neutral

--- Step 10 ---
Agent 1: PRESS, Agent 2: LEFT
  Agent1 beliefs:
    agent_pos: 1:1.00, 8:0.00, 5:0.00
    red_button_pos: 1:1.00, 2:0.00, 4:0.00
    blue_button_pos: 6:0.98, 2:0.00, 4:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 8:1.00, 5:0.00, 2:0.00
    red_button_pos: 1:0.98, 6:0.00, 7:0.00
    blue_button_pos: 6:0.90, 7:0.03, 4:0.02
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 24:0.06; 4:0.06; 25:0.06; 27:0.05; 26:0.05
  Agent2 top policies: 16:0.07; 14:0.07; 13:0.04; 12:0.04; 26:0.03
. 1 .
. . .
b 2 .

Reward: +0.00, Result: neutral
Button pressed: red by Agent 1

--- Step 11 ---
Agent 1: UP, Agent 2: LEFT
  Agent1 beliefs:
    agent_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 2:0.00, 8:0.00
    blue_button_pos: 6:0.97, 2:0.00, 4:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 7:1.00, 8:0.00, 5:0.00
    red_button_pos: 1:0.97, 6:0.00, 4:0.00
    blue_button_pos: 6:0.92, 4:0.03, 3:0.02
    red_button_state: 0:0.50, 1:0.50
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 4:0.04; 28:0.04; 24:0.04; 0:0.04; 22:0.04
  Agent2 top policies: 16:0.16; 14:0.06; 13:0.06; 17:0.05; 12:0.04
. 1 .
. . .
2 . .

Reward: +0.00, Result: neutral

--- Step 12 ---
Agent 1: UP, Agent 2: PRESS
  Agent1 beliefs:
    agent_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 8:0.00, 7:0.00
    blue_button_pos: 6:0.96, 2:0.01, 8:0.01
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 6:1.00, 3:0.00, 0:0.00
    red_button_pos: 1:0.97, 4:0.01, 3:0.01
    blue_button_pos: 6:1.00, 4:0.00, 3:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 4:0.04; 28:0.04; 22:0.04; 10:0.04; 24:0.03
  Agent2 top policies: 26:0.17; 25:0.17; 24:0.16; 27:0.15; 28:0.14
. 1 .
. . .
2 . .

Reward: +1.00, Result: win
Button pressed: blue by Agent 2

Result: ✅ WIN - win (steps: 12, reward: +1.00)

================================================================================
EPISODE 46
================================================================================
Environment: Red at (1, 0), Blue at (0, 2)

Initial state:
1 r .
. . .
b . 2


--- Step 1 ---
Agent 1: DOWN, Agent 2: LEFT
  Agent1 beliefs:
    agent_pos: 0:1.00, 8:0.00, 7:0.00
    red_button_pos: 8:0.12, 7:0.12, 6:0.12
    blue_button_pos: 8:0.12, 7:0.12, 6:0.12
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 8:1.00, 7:0.00, 6:0.00
    red_button_pos: 7:0.12, 3:0.12, 6:0.12
    blue_button_pos: 7:0.12, 3:0.12, 6:0.12
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 10:0.21; 22:0.21; 9:0.06; 19:0.06; 21:0.05
  Agent2 top policies: 16:0.21; 4:0.21; 12:0.06; 2:0.06; 0:0.05
. r .
1 . .
b 2 .

Reward: +0.00, Result: neutral

--- Step 2 ---
Agent 1: RIGHT, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 3:1.00, 0:0.00, 8:0.00
    red_button_pos: 8:0.14, 7:0.14, 6:0.14
    blue_button_pos: 8:0.14, 7:0.14, 6:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 7:1.00, 8:0.00, 6:0.00
    red_button_pos: 6:0.14, 1:0.14, 5:0.14
    blue_button_pos: 6:0.14, 1:0.14, 5:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 22:0.23; 10:0.23; 9:0.06; 21:0.05; 19:0.05
  Agent2 top policies: 4:0.23; 16:0.23; 12:0.06; 0:0.05; 2:0.05
. r .
. 1 .
b 2 .

Reward: +0.00, Result: neutral

--- Step 3 ---
Agent 1: RIGHT, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 4:1.00, 3:0.00, 0:0.00
    red_button_pos: 8:0.17, 7:0.17, 6:0.17
    blue_button_pos: 8:0.17, 7:0.17, 6:0.17
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 7:0.87, 4:0.12, 8:0.00
    red_button_pos: 6:0.14, 1:0.14, 5:0.14
    blue_button_pos: 6:0.14, 1:0.14, 5:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 22:0.18; 10:0.18; 4:0.18; 21:0.04; 9:0.04
  Agent2 top policies: 4:0.24; 16:0.23; 12:0.06; 2:0.05; 14:0.05
. r .
. 2 1
b . .

Reward: +0.00, Result: neutral

--- Step 4 ---
Agent 1: DOWN, Agent 2: LEFT
  Agent1 beliefs:
    agent_pos: 5:1.00, 4:0.00, 3:0.00
    red_button_pos: 8:0.20, 7:0.20, 6:0.20
    blue_button_pos: 8:0.20, 7:0.20, 6:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 4:1.00, 1:0.00, 7:0.00
    red_button_pos: 6:0.17, 1:0.17, 5:0.17
    blue_button_pos: 6:0.17, 1:0.17, 5:0.17
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 10:0.27; 4:0.27; 8:0.05; 2:0.05; 7:0.05
  Agent2 top policies: 16:0.18; 22:0.18; 4:0.18; 12:0.04; 18:0.04
. r .
2 . .
b . 1

Reward: +0.00, Result: neutral

--- Step 5 ---
Agent 1: LEFT, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 8:1.00, 5:0.00, 4:0.00
    red_button_pos: 7:0.25, 1:0.25, 6:0.25
    blue_button_pos: 7:0.25, 1:0.25, 6:0.25
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 3:1.00, 4:0.00, 7:0.00
    red_button_pos: 6:0.20, 5:0.20, 0:0.20
    blue_button_pos: 6:0.20, 5:0.20, 0:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 16:0.63; 14:0.09; 13:0.09; 17:0.07; 12:0.01
  Agent2 top policies: 4:0.28; 10:0.28; 3:0.05; 0:0.05; 2:0.05
2 r .
. . .
b 1 .

Reward: +0.00, Result: neutral

--- Step 6 ---
Agent 1: LEFT, Agent 2: RIGHT
  Agent1 beliefs:
    agent_pos: 7:1.00, 8:0.00, 5:0.00
    red_button_pos: 1:0.32, 2:0.32, 6:0.32
    blue_button_pos: 1:0.32, 2:0.32, 6:0.32
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 0:1.00, 3:0.00, 4:0.00
    red_button_pos: 6:0.24, 1:0.24, 5:0.24
    blue_button_pos: 6:0.24, 1:0.24, 5:0.24
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 16:0.72; 14:0.08; 13:0.08; 17:0.06; 12:0.01
  Agent2 top policies: 22:0.63; 21:0.09; 18:0.09; 23:0.07; 19:0.01
. 2 .
. . .
1 . .

Reward: +0.00, Result: neutral

--- Step 7 ---
Agent 1: UP, Agent 2: RIGHT
  Agent1 beliefs:
    agent_pos: 6:1.00, 3:0.00, 0:0.00
    red_button_pos: 1:0.47, 2:0.47, 0:0.02
    blue_button_pos: 6:1.00, 1:0.00, 2:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 1:1.00, 8:0.00, 5:0.00
    red_button_pos: 1:1.00, 2:0.00, 6:0.00
    blue_button_pos: 6:0.32, 2:0.32, 5:0.32
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 4:0.05; 1:0.05; 0:0.05; 3:0.05; 2:0.04
  Agent2 top policies: 22:0.18; 19:0.09; 21:0.09; 18:0.09; 23:0.07
. r 2
1 . .
b . .

Reward: +0.00, Result: neutral

--- Step 8 ---
Agent 1: UP, Agent 2: DOWN
  Agent1 beliefs:
    agent_pos: 3:1.00, 7:0.00, 8:0.00
    red_button_pos: 1:0.47, 2:0.47, 0:0.02
    blue_button_pos: 6:0.99, 1:0.00, 2:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 2:1.00, 0:0.00, 3:0.00
    red_button_pos: 1:0.99, 5:0.00, 6:0.00
    blue_button_pos: 6:0.47, 5:0.47, 8:0.02
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 3:0.10; 18:0.09; 4:0.04; 8:0.04; 7:0.04
  Agent2 top policies: 10:0.23; 9:0.13; 11:0.10; 7:0.05; 8:0.04
1 r .
. . 2
b . .

Reward: +0.00, Result: neutral

--- Step 9 ---
Agent 1: RIGHT, Agent 2: DOWN
  Agent1 beliefs:
    agent_pos: 0:1.00, 3:0.00, 7:0.00
    red_button_pos: 1:0.48, 2:0.48, 4:0.01
    blue_button_pos: 6:0.98, 1:0.00, 2:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 5:1.00, 2:0.00, 0:0.00
    red_button_pos: 1:0.98, 6:0.00, 8:0.00
    blue_button_pos: 6:0.87, 8:0.05, 7:0.03
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 22:0.40; 18:0.10; 21:0.10; 23:0.08; 19:0.03
  Agent2 top policies: 10:0.06; 7:0.05; 9:0.05; 16:0.04; 8:0.04
. 1 .
. . .
b . 2

Reward: +0.00, Result: neutral

--- Step 10 ---
Agent 1: PRESS, Agent 2: LEFT
  Agent1 beliefs:
    agent_pos: 1:1.00, 8:0.00, 5:0.00
    red_button_pos: 1:1.00, 2:0.00, 4:0.00
    blue_button_pos: 6:0.98, 2:0.00, 4:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 8:1.00, 5:0.00, 2:0.00
    red_button_pos: 1:0.98, 6:0.00, 7:0.00
    blue_button_pos: 6:0.90, 7:0.03, 4:0.02
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 24:0.06; 4:0.06; 25:0.06; 27:0.05; 26:0.05
  Agent2 top policies: 16:0.07; 14:0.07; 13:0.04; 12:0.04; 26:0.03
. 1 .
. . .
b 2 .

Reward: +0.00, Result: neutral
Button pressed: red by Agent 1

--- Step 11 ---
Agent 1: UP, Agent 2: LEFT
  Agent1 beliefs:
    agent_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 2:0.00, 8:0.00
    blue_button_pos: 6:0.97, 2:0.00, 4:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 7:1.00, 8:0.00, 5:0.00
    red_button_pos: 1:0.97, 6:0.00, 4:0.00
    blue_button_pos: 6:0.92, 4:0.03, 3:0.02
    red_button_state: 0:0.50, 1:0.50
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 4:0.04; 28:0.04; 24:0.04; 0:0.04; 22:0.04
  Agent2 top policies: 16:0.16; 14:0.06; 13:0.06; 17:0.05; 12:0.04
. 1 .
. . .
2 . .

Reward: +0.00, Result: neutral

--- Step 12 ---
Agent 1: UP, Agent 2: PRESS
  Agent1 beliefs:
    agent_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 8:0.00, 7:0.00
    blue_button_pos: 6:0.96, 2:0.01, 8:0.01
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 6:1.00, 3:0.00, 0:0.00
    red_button_pos: 1:0.97, 4:0.01, 3:0.01
    blue_button_pos: 6:1.00, 4:0.00, 3:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 4:0.04; 28:0.04; 22:0.04; 10:0.04; 24:0.03
  Agent2 top policies: 26:0.17; 25:0.17; 24:0.16; 27:0.15; 28:0.14
. 1 .
. . .
2 . .

Reward: +1.00, Result: win
Button pressed: blue by Agent 2

Result: ✅ WIN - win (steps: 12, reward: +1.00)

================================================================================
EPISODE 47
================================================================================
Environment: Red at (1, 0), Blue at (0, 2)

Initial state:
1 r .
. . .
b . 2


--- Step 1 ---
Agent 1: DOWN, Agent 2: LEFT
  Agent1 beliefs:
    agent_pos: 0:1.00, 8:0.00, 7:0.00
    red_button_pos: 8:0.12, 7:0.12, 6:0.12
    blue_button_pos: 8:0.12, 7:0.12, 6:0.12
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 8:1.00, 7:0.00, 6:0.00
    red_button_pos: 7:0.12, 3:0.12, 6:0.12
    blue_button_pos: 7:0.12, 3:0.12, 6:0.12
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 10:0.21; 22:0.21; 9:0.06; 19:0.06; 21:0.05
  Agent2 top policies: 16:0.21; 4:0.21; 12:0.06; 2:0.06; 0:0.05
. r .
1 . .
b 2 .

Reward: +0.00, Result: neutral

--- Step 2 ---
Agent 1: RIGHT, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 3:1.00, 0:0.00, 8:0.00
    red_button_pos: 8:0.14, 7:0.14, 6:0.14
    blue_button_pos: 8:0.14, 7:0.14, 6:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 7:1.00, 8:0.00, 6:0.00
    red_button_pos: 6:0.14, 1:0.14, 5:0.14
    blue_button_pos: 6:0.14, 1:0.14, 5:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 22:0.23; 10:0.23; 9:0.06; 21:0.05; 19:0.05
  Agent2 top policies: 4:0.23; 16:0.23; 12:0.06; 0:0.05; 2:0.05
. r .
. 1 .
b 2 .

Reward: +0.00, Result: neutral

--- Step 3 ---
Agent 1: RIGHT, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 4:1.00, 3:0.00, 0:0.00
    red_button_pos: 8:0.17, 7:0.17, 6:0.17
    blue_button_pos: 8:0.17, 7:0.17, 6:0.17
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 7:0.87, 4:0.12, 8:0.00
    red_button_pos: 6:0.14, 1:0.14, 5:0.14
    blue_button_pos: 6:0.14, 1:0.14, 5:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 22:0.18; 10:0.18; 4:0.18; 21:0.04; 9:0.04
  Agent2 top policies: 4:0.24; 16:0.23; 12:0.06; 2:0.05; 14:0.05
. r .
. 2 1
b . .

Reward: +0.00, Result: neutral

--- Step 4 ---
Agent 1: DOWN, Agent 2: LEFT
  Agent1 beliefs:
    agent_pos: 5:1.00, 4:0.00, 3:0.00
    red_button_pos: 8:0.20, 7:0.20, 6:0.20
    blue_button_pos: 8:0.20, 7:0.20, 6:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 4:1.00, 1:0.00, 7:0.00
    red_button_pos: 6:0.17, 1:0.17, 5:0.17
    blue_button_pos: 6:0.17, 1:0.17, 5:0.17
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 10:0.27; 4:0.27; 8:0.05; 2:0.05; 7:0.05
  Agent2 top policies: 16:0.18; 22:0.18; 4:0.18; 12:0.04; 18:0.04
. r .
2 . .
b . 1

Reward: +0.00, Result: neutral

--- Step 5 ---
Agent 1: LEFT, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 8:1.00, 5:0.00, 4:0.00
    red_button_pos: 7:0.25, 1:0.25, 6:0.25
    blue_button_pos: 7:0.25, 1:0.25, 6:0.25
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 3:1.00, 4:0.00, 7:0.00
    red_button_pos: 6:0.20, 5:0.20, 0:0.20
    blue_button_pos: 6:0.20, 5:0.20, 0:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 16:0.63; 14:0.09; 13:0.09; 17:0.07; 12:0.01
  Agent2 top policies: 4:0.28; 10:0.28; 3:0.05; 0:0.05; 2:0.05
2 r .
. . .
b 1 .

Reward: +0.00, Result: neutral

--- Step 6 ---
Agent 1: LEFT, Agent 2: RIGHT
  Agent1 beliefs:
    agent_pos: 7:1.00, 8:0.00, 5:0.00
    red_button_pos: 1:0.32, 2:0.32, 6:0.32
    blue_button_pos: 1:0.32, 2:0.32, 6:0.32
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 0:1.00, 3:0.00, 4:0.00
    red_button_pos: 6:0.24, 1:0.24, 5:0.24
    blue_button_pos: 6:0.24, 1:0.24, 5:0.24
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 16:0.72; 14:0.08; 13:0.08; 17:0.06; 12:0.01
  Agent2 top policies: 22:0.63; 21:0.09; 18:0.09; 23:0.07; 19:0.01
. 2 .
. . .
1 . .

Reward: +0.00, Result: neutral

--- Step 7 ---
Agent 1: UP, Agent 2: RIGHT
  Agent1 beliefs:
    agent_pos: 6:1.00, 3:0.00, 0:0.00
    red_button_pos: 1:0.47, 2:0.47, 0:0.02
    blue_button_pos: 6:1.00, 1:0.00, 2:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 1:1.00, 8:0.00, 5:0.00
    red_button_pos: 1:1.00, 2:0.00, 6:0.00
    blue_button_pos: 6:0.32, 2:0.32, 5:0.32
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 4:0.05; 1:0.05; 0:0.05; 3:0.05; 2:0.04
  Agent2 top policies: 22:0.18; 19:0.09; 21:0.09; 18:0.09; 23:0.07
. r 2
1 . .
b . .

Reward: +0.00, Result: neutral

--- Step 8 ---
Agent 1: UP, Agent 2: DOWN
  Agent1 beliefs:
    agent_pos: 3:1.00, 7:0.00, 8:0.00
    red_button_pos: 1:0.47, 2:0.47, 0:0.02
    blue_button_pos: 6:0.99, 1:0.00, 2:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 2:1.00, 0:0.00, 3:0.00
    red_button_pos: 1:0.99, 5:0.00, 6:0.00
    blue_button_pos: 6:0.47, 5:0.47, 8:0.02
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 3:0.10; 18:0.09; 4:0.04; 8:0.04; 7:0.04
  Agent2 top policies: 10:0.23; 9:0.13; 11:0.10; 7:0.05; 8:0.04
1 r .
. . 2
b . .

Reward: +0.00, Result: neutral

--- Step 9 ---
Agent 1: RIGHT, Agent 2: DOWN
  Agent1 beliefs:
    agent_pos: 0:1.00, 3:0.00, 7:0.00
    red_button_pos: 1:0.48, 2:0.48, 4:0.01
    blue_button_pos: 6:0.98, 1:0.00, 2:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 5:1.00, 2:0.00, 0:0.00
    red_button_pos: 1:0.98, 6:0.00, 8:0.00
    blue_button_pos: 6:0.87, 8:0.05, 7:0.03
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 22:0.40; 18:0.10; 21:0.10; 23:0.08; 19:0.03
  Agent2 top policies: 10:0.06; 7:0.05; 9:0.05; 16:0.04; 8:0.04
. 1 .
. . .
b . 2

Reward: +0.00, Result: neutral

--- Step 10 ---
Agent 1: PRESS, Agent 2: LEFT
  Agent1 beliefs:
    agent_pos: 1:1.00, 8:0.00, 5:0.00
    red_button_pos: 1:1.00, 2:0.00, 4:0.00
    blue_button_pos: 6:0.98, 2:0.00, 4:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 8:1.00, 5:0.00, 2:0.00
    red_button_pos: 1:0.98, 6:0.00, 7:0.00
    blue_button_pos: 6:0.90, 7:0.03, 4:0.02
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 24:0.06; 4:0.06; 25:0.06; 27:0.05; 26:0.05
  Agent2 top policies: 16:0.07; 14:0.07; 13:0.04; 12:0.04; 26:0.03
. 1 .
. . .
b 2 .

Reward: +0.00, Result: neutral
Button pressed: red by Agent 1

--- Step 11 ---
Agent 1: UP, Agent 2: LEFT
  Agent1 beliefs:
    agent_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 2:0.00, 8:0.00
    blue_button_pos: 6:0.97, 2:0.00, 4:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 7:1.00, 8:0.00, 5:0.00
    red_button_pos: 1:0.97, 6:0.00, 4:0.00
    blue_button_pos: 6:0.92, 4:0.03, 3:0.02
    red_button_state: 0:0.50, 1:0.50
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 4:0.04; 28:0.04; 24:0.04; 0:0.04; 22:0.04
  Agent2 top policies: 16:0.16; 14:0.06; 13:0.06; 17:0.05; 12:0.04
. 1 .
. . .
2 . .

Reward: +0.00, Result: neutral

--- Step 12 ---
Agent 1: UP, Agent 2: PRESS
  Agent1 beliefs:
    agent_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 8:0.00, 7:0.00
    blue_button_pos: 6:0.96, 2:0.01, 8:0.01
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 6:1.00, 3:0.00, 0:0.00
    red_button_pos: 1:0.97, 4:0.01, 3:0.01
    blue_button_pos: 6:1.00, 4:0.00, 3:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 4:0.04; 28:0.04; 22:0.04; 10:0.04; 24:0.03
  Agent2 top policies: 26:0.17; 25:0.17; 24:0.16; 27:0.15; 28:0.14
. 1 .
. . .
2 . .

Reward: +1.00, Result: win
Button pressed: blue by Agent 2

Result: ✅ WIN - win (steps: 12, reward: +1.00)

================================================================================
EPISODE 48
================================================================================
Environment: Red at (1, 0), Blue at (0, 2)

Initial state:
1 r .
. . .
b . 2


--- Step 1 ---
Agent 1: DOWN, Agent 2: LEFT
  Agent1 beliefs:
    agent_pos: 0:1.00, 8:0.00, 7:0.00
    red_button_pos: 8:0.12, 7:0.12, 6:0.12
    blue_button_pos: 8:0.12, 7:0.12, 6:0.12
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 8:1.00, 7:0.00, 6:0.00
    red_button_pos: 7:0.12, 3:0.12, 6:0.12
    blue_button_pos: 7:0.12, 3:0.12, 6:0.12
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 10:0.21; 22:0.21; 9:0.06; 19:0.06; 21:0.05
  Agent2 top policies: 16:0.21; 4:0.21; 12:0.06; 2:0.06; 0:0.05
. r .
1 . .
b 2 .

Reward: +0.00, Result: neutral

--- Step 2 ---
Agent 1: RIGHT, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 3:1.00, 0:0.00, 8:0.00
    red_button_pos: 8:0.14, 7:0.14, 6:0.14
    blue_button_pos: 8:0.14, 7:0.14, 6:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 7:1.00, 8:0.00, 6:0.00
    red_button_pos: 6:0.14, 1:0.14, 5:0.14
    blue_button_pos: 6:0.14, 1:0.14, 5:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 22:0.23; 10:0.23; 9:0.06; 21:0.05; 19:0.05
  Agent2 top policies: 4:0.23; 16:0.23; 12:0.06; 0:0.05; 2:0.05
. r .
. 1 .
b 2 .

Reward: +0.00, Result: neutral

--- Step 3 ---
Agent 1: RIGHT, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 4:1.00, 3:0.00, 0:0.00
    red_button_pos: 8:0.17, 7:0.17, 6:0.17
    blue_button_pos: 8:0.17, 7:0.17, 6:0.17
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 7:0.87, 4:0.12, 8:0.00
    red_button_pos: 6:0.14, 1:0.14, 5:0.14
    blue_button_pos: 6:0.14, 1:0.14, 5:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 22:0.18; 10:0.18; 4:0.18; 21:0.04; 9:0.04
  Agent2 top policies: 4:0.24; 16:0.23; 12:0.06; 2:0.05; 14:0.05
. r .
. 2 1
b . .

Reward: +0.00, Result: neutral

--- Step 4 ---
Agent 1: DOWN, Agent 2: LEFT
  Agent1 beliefs:
    agent_pos: 5:1.00, 4:0.00, 3:0.00
    red_button_pos: 8:0.20, 7:0.20, 6:0.20
    blue_button_pos: 8:0.20, 7:0.20, 6:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 4:1.00, 1:0.00, 7:0.00
    red_button_pos: 6:0.17, 1:0.17, 5:0.17
    blue_button_pos: 6:0.17, 1:0.17, 5:0.17
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 10:0.27; 4:0.27; 8:0.05; 2:0.05; 7:0.05
  Agent2 top policies: 16:0.18; 22:0.18; 4:0.18; 12:0.04; 18:0.04
. r .
2 . .
b . 1

Reward: +0.00, Result: neutral

--- Step 5 ---
Agent 1: LEFT, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 8:1.00, 5:0.00, 4:0.00
    red_button_pos: 7:0.25, 1:0.25, 6:0.25
    blue_button_pos: 7:0.25, 1:0.25, 6:0.25
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 3:1.00, 4:0.00, 7:0.00
    red_button_pos: 6:0.20, 5:0.20, 0:0.20
    blue_button_pos: 6:0.20, 5:0.20, 0:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 16:0.63; 14:0.09; 13:0.09; 17:0.07; 12:0.01
  Agent2 top policies: 4:0.28; 10:0.28; 3:0.05; 0:0.05; 2:0.05
2 r .
. . .
b 1 .

Reward: +0.00, Result: neutral

--- Step 6 ---
Agent 1: LEFT, Agent 2: RIGHT
  Agent1 beliefs:
    agent_pos: 7:1.00, 8:0.00, 5:0.00
    red_button_pos: 1:0.32, 2:0.32, 6:0.32
    blue_button_pos: 1:0.32, 2:0.32, 6:0.32
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 0:1.00, 3:0.00, 4:0.00
    red_button_pos: 6:0.24, 1:0.24, 5:0.24
    blue_button_pos: 6:0.24, 1:0.24, 5:0.24
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 16:0.72; 14:0.08; 13:0.08; 17:0.06; 12:0.01
  Agent2 top policies: 22:0.63; 21:0.09; 18:0.09; 23:0.07; 19:0.01
. 2 .
. . .
1 . .

Reward: +0.00, Result: neutral

--- Step 7 ---
Agent 1: UP, Agent 2: RIGHT
  Agent1 beliefs:
    agent_pos: 6:1.00, 3:0.00, 0:0.00
    red_button_pos: 1:0.47, 2:0.47, 0:0.02
    blue_button_pos: 6:1.00, 1:0.00, 2:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 1:1.00, 8:0.00, 5:0.00
    red_button_pos: 1:1.00, 2:0.00, 6:0.00
    blue_button_pos: 6:0.32, 2:0.32, 5:0.32
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 4:0.05; 1:0.05; 0:0.05; 3:0.05; 2:0.04
  Agent2 top policies: 22:0.18; 19:0.09; 21:0.09; 18:0.09; 23:0.07
. r 2
1 . .
b . .

Reward: +0.00, Result: neutral

--- Step 8 ---
Agent 1: UP, Agent 2: DOWN
  Agent1 beliefs:
    agent_pos: 3:1.00, 7:0.00, 8:0.00
    red_button_pos: 1:0.47, 2:0.47, 0:0.02
    blue_button_pos: 6:0.99, 1:0.00, 2:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 2:1.00, 0:0.00, 3:0.00
    red_button_pos: 1:0.99, 5:0.00, 6:0.00
    blue_button_pos: 6:0.47, 5:0.47, 8:0.02
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 3:0.10; 18:0.09; 4:0.04; 8:0.04; 7:0.04
  Agent2 top policies: 10:0.23; 9:0.13; 11:0.10; 7:0.05; 8:0.04
1 r .
. . 2
b . .

Reward: +0.00, Result: neutral

--- Step 9 ---
Agent 1: RIGHT, Agent 2: DOWN
  Agent1 beliefs:
    agent_pos: 0:1.00, 3:0.00, 7:0.00
    red_button_pos: 1:0.48, 2:0.48, 4:0.01
    blue_button_pos: 6:0.98, 1:0.00, 2:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 5:1.00, 2:0.00, 0:0.00
    red_button_pos: 1:0.98, 6:0.00, 8:0.00
    blue_button_pos: 6:0.87, 8:0.05, 7:0.03
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 22:0.40; 18:0.10; 21:0.10; 23:0.08; 19:0.03
  Agent2 top policies: 10:0.06; 7:0.05; 9:0.05; 16:0.04; 8:0.04
. 1 .
. . .
b . 2

Reward: +0.00, Result: neutral

--- Step 10 ---
Agent 1: PRESS, Agent 2: LEFT
  Agent1 beliefs:
    agent_pos: 1:1.00, 8:0.00, 5:0.00
    red_button_pos: 1:1.00, 2:0.00, 4:0.00
    blue_button_pos: 6:0.98, 2:0.00, 4:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 8:1.00, 5:0.00, 2:0.00
    red_button_pos: 1:0.98, 6:0.00, 7:0.00
    blue_button_pos: 6:0.90, 7:0.03, 4:0.02
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 24:0.06; 4:0.06; 25:0.06; 27:0.05; 26:0.05
  Agent2 top policies: 16:0.07; 14:0.07; 13:0.04; 12:0.04; 26:0.03
. 1 .
. . .
b 2 .

Reward: +0.00, Result: neutral
Button pressed: red by Agent 1

--- Step 11 ---
Agent 1: UP, Agent 2: LEFT
  Agent1 beliefs:
    agent_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 2:0.00, 8:0.00
    blue_button_pos: 6:0.97, 2:0.00, 4:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 7:1.00, 8:0.00, 5:0.00
    red_button_pos: 1:0.97, 6:0.00, 4:0.00
    blue_button_pos: 6:0.92, 4:0.03, 3:0.02
    red_button_state: 0:0.50, 1:0.50
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 4:0.04; 28:0.04; 24:0.04; 0:0.04; 22:0.04
  Agent2 top policies: 16:0.16; 14:0.06; 13:0.06; 17:0.05; 12:0.04
. 1 .
. . .
2 . .

Reward: +0.00, Result: neutral

--- Step 12 ---
Agent 1: UP, Agent 2: PRESS
  Agent1 beliefs:
    agent_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 8:0.00, 7:0.00
    blue_button_pos: 6:0.96, 2:0.01, 8:0.01
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 6:1.00, 3:0.00, 0:0.00
    red_button_pos: 1:0.97, 4:0.01, 3:0.01
    blue_button_pos: 6:1.00, 4:0.00, 3:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 4:0.04; 28:0.04; 22:0.04; 10:0.04; 24:0.03
  Agent2 top policies: 26:0.17; 25:0.17; 24:0.16; 27:0.15; 28:0.14
. 1 .
. . .
2 . .

Reward: +1.00, Result: win
Button pressed: blue by Agent 2

Result: ✅ WIN - win (steps: 12, reward: +1.00)

================================================================================
EPISODE 49
================================================================================
Environment: Red at (1, 0), Blue at (0, 2)

Initial state:
1 r .
. . .
b . 2


--- Step 1 ---
Agent 1: DOWN, Agent 2: LEFT
  Agent1 beliefs:
    agent_pos: 0:1.00, 8:0.00, 7:0.00
    red_button_pos: 8:0.12, 7:0.12, 6:0.12
    blue_button_pos: 8:0.12, 7:0.12, 6:0.12
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 8:1.00, 7:0.00, 6:0.00
    red_button_pos: 7:0.12, 3:0.12, 6:0.12
    blue_button_pos: 7:0.12, 3:0.12, 6:0.12
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 10:0.21; 22:0.21; 9:0.06; 19:0.06; 21:0.05
  Agent2 top policies: 16:0.21; 4:0.21; 12:0.06; 2:0.06; 0:0.05
. r .
1 . .
b 2 .

Reward: +0.00, Result: neutral

--- Step 2 ---
Agent 1: RIGHT, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 3:1.00, 0:0.00, 8:0.00
    red_button_pos: 8:0.14, 7:0.14, 6:0.14
    blue_button_pos: 8:0.14, 7:0.14, 6:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 7:1.00, 8:0.00, 6:0.00
    red_button_pos: 6:0.14, 1:0.14, 5:0.14
    blue_button_pos: 6:0.14, 1:0.14, 5:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 22:0.23; 10:0.23; 9:0.06; 21:0.05; 19:0.05
  Agent2 top policies: 4:0.23; 16:0.23; 12:0.06; 0:0.05; 2:0.05
. r .
. 1 .
b 2 .

Reward: +0.00, Result: neutral

--- Step 3 ---
Agent 1: RIGHT, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 4:1.00, 3:0.00, 0:0.00
    red_button_pos: 8:0.17, 7:0.17, 6:0.17
    blue_button_pos: 8:0.17, 7:0.17, 6:0.17
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 7:0.87, 4:0.12, 8:0.00
    red_button_pos: 6:0.14, 1:0.14, 5:0.14
    blue_button_pos: 6:0.14, 1:0.14, 5:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 22:0.18; 10:0.18; 4:0.18; 21:0.04; 9:0.04
  Agent2 top policies: 4:0.24; 16:0.23; 12:0.06; 2:0.05; 14:0.05
. r .
. 2 1
b . .

Reward: +0.00, Result: neutral

--- Step 4 ---
Agent 1: DOWN, Agent 2: LEFT
  Agent1 beliefs:
    agent_pos: 5:1.00, 4:0.00, 3:0.00
    red_button_pos: 8:0.20, 7:0.20, 6:0.20
    blue_button_pos: 8:0.20, 7:0.20, 6:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 4:1.00, 1:0.00, 7:0.00
    red_button_pos: 6:0.17, 1:0.17, 5:0.17
    blue_button_pos: 6:0.17, 1:0.17, 5:0.17
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 10:0.27; 4:0.27; 8:0.05; 2:0.05; 7:0.05
  Agent2 top policies: 16:0.18; 22:0.18; 4:0.18; 12:0.04; 18:0.04
. r .
2 . .
b . 1

Reward: +0.00, Result: neutral

--- Step 5 ---
Agent 1: LEFT, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 8:1.00, 5:0.00, 4:0.00
    red_button_pos: 7:0.25, 1:0.25, 6:0.25
    blue_button_pos: 7:0.25, 1:0.25, 6:0.25
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 3:1.00, 4:0.00, 7:0.00
    red_button_pos: 6:0.20, 5:0.20, 0:0.20
    blue_button_pos: 6:0.20, 5:0.20, 0:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 16:0.63; 14:0.09; 13:0.09; 17:0.07; 12:0.01
  Agent2 top policies: 4:0.28; 10:0.28; 3:0.05; 0:0.05; 2:0.05
2 r .
. . .
b 1 .

Reward: +0.00, Result: neutral

--- Step 6 ---
Agent 1: LEFT, Agent 2: RIGHT
  Agent1 beliefs:
    agent_pos: 7:1.00, 8:0.00, 5:0.00
    red_button_pos: 1:0.32, 2:0.32, 6:0.32
    blue_button_pos: 1:0.32, 2:0.32, 6:0.32
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 0:1.00, 3:0.00, 4:0.00
    red_button_pos: 6:0.24, 1:0.24, 5:0.24
    blue_button_pos: 6:0.24, 1:0.24, 5:0.24
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 16:0.72; 14:0.08; 13:0.08; 17:0.06; 12:0.01
  Agent2 top policies: 22:0.63; 21:0.09; 18:0.09; 23:0.07; 19:0.01
. 2 .
. . .
1 . .

Reward: +0.00, Result: neutral

--- Step 7 ---
Agent 1: UP, Agent 2: RIGHT
  Agent1 beliefs:
    agent_pos: 6:1.00, 3:0.00, 0:0.00
    red_button_pos: 1:0.47, 2:0.47, 0:0.02
    blue_button_pos: 6:1.00, 1:0.00, 2:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 1:1.00, 8:0.00, 5:0.00
    red_button_pos: 1:1.00, 2:0.00, 6:0.00
    blue_button_pos: 6:0.32, 2:0.32, 5:0.32
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 4:0.05; 1:0.05; 0:0.05; 3:0.05; 2:0.04
  Agent2 top policies: 22:0.18; 19:0.09; 21:0.09; 18:0.09; 23:0.07
. r 2
1 . .
b . .

Reward: +0.00, Result: neutral

--- Step 8 ---
Agent 1: UP, Agent 2: DOWN
  Agent1 beliefs:
    agent_pos: 3:1.00, 7:0.00, 8:0.00
    red_button_pos: 1:0.47, 2:0.47, 0:0.02
    blue_button_pos: 6:0.99, 1:0.00, 2:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 2:1.00, 0:0.00, 3:0.00
    red_button_pos: 1:0.99, 5:0.00, 6:0.00
    blue_button_pos: 6:0.47, 5:0.47, 8:0.02
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 3:0.10; 18:0.09; 4:0.04; 8:0.04; 7:0.04
  Agent2 top policies: 10:0.23; 9:0.13; 11:0.10; 7:0.05; 8:0.04
1 r .
. . 2
b . .

Reward: +0.00, Result: neutral

--- Step 9 ---
Agent 1: RIGHT, Agent 2: DOWN
  Agent1 beliefs:
    agent_pos: 0:1.00, 3:0.00, 7:0.00
    red_button_pos: 1:0.48, 2:0.48, 4:0.01
    blue_button_pos: 6:0.98, 1:0.00, 2:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 5:1.00, 2:0.00, 0:0.00
    red_button_pos: 1:0.98, 6:0.00, 8:0.00
    blue_button_pos: 6:0.87, 8:0.05, 7:0.03
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 22:0.40; 18:0.10; 21:0.10; 23:0.08; 19:0.03
  Agent2 top policies: 10:0.06; 7:0.05; 9:0.05; 16:0.04; 8:0.04
. 1 .
. . .
b . 2

Reward: +0.00, Result: neutral

--- Step 10 ---
Agent 1: PRESS, Agent 2: LEFT
  Agent1 beliefs:
    agent_pos: 1:1.00, 8:0.00, 5:0.00
    red_button_pos: 1:1.00, 2:0.00, 4:0.00
    blue_button_pos: 6:0.98, 2:0.00, 4:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 8:1.00, 5:0.00, 2:0.00
    red_button_pos: 1:0.98, 6:0.00, 7:0.00
    blue_button_pos: 6:0.90, 7:0.03, 4:0.02
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 24:0.06; 4:0.06; 25:0.06; 27:0.05; 26:0.05
  Agent2 top policies: 16:0.07; 14:0.07; 13:0.04; 12:0.04; 26:0.03
. 1 .
. . .
b 2 .

Reward: +0.00, Result: neutral
Button pressed: red by Agent 1

--- Step 11 ---
Agent 1: UP, Agent 2: LEFT
  Agent1 beliefs:
    agent_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 2:0.00, 8:0.00
    blue_button_pos: 6:0.97, 2:0.00, 4:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 7:1.00, 8:0.00, 5:0.00
    red_button_pos: 1:0.97, 6:0.00, 4:0.00
    blue_button_pos: 6:0.92, 4:0.03, 3:0.02
    red_button_state: 0:0.50, 1:0.50
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 4:0.04; 28:0.04; 24:0.04; 0:0.04; 22:0.04
  Agent2 top policies: 16:0.16; 14:0.06; 13:0.06; 17:0.05; 12:0.04
. 1 .
. . .
2 . .

Reward: +0.00, Result: neutral

--- Step 12 ---
Agent 1: UP, Agent 2: PRESS
  Agent1 beliefs:
    agent_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 8:0.00, 7:0.00
    blue_button_pos: 6:0.96, 2:0.01, 8:0.01
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 6:1.00, 3:0.00, 0:0.00
    red_button_pos: 1:0.97, 4:0.01, 3:0.01
    blue_button_pos: 6:1.00, 4:0.00, 3:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 4:0.04; 28:0.04; 22:0.04; 10:0.04; 24:0.03
  Agent2 top policies: 26:0.17; 25:0.17; 24:0.16; 27:0.15; 28:0.14
. 1 .
. . .
2 . .

Reward: +1.00, Result: win
Button pressed: blue by Agent 2

Result: ✅ WIN - win (steps: 12, reward: +1.00)

================================================================================
EPISODE 50
================================================================================
Environment: Red at (1, 0), Blue at (0, 2)

Initial state:
1 r .
. . .
b . 2


--- Step 1 ---
Agent 1: DOWN, Agent 2: LEFT
  Agent1 beliefs:
    agent_pos: 0:1.00, 8:0.00, 7:0.00
    red_button_pos: 8:0.12, 7:0.12, 6:0.12
    blue_button_pos: 8:0.12, 7:0.12, 6:0.12
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 8:1.00, 7:0.00, 6:0.00
    red_button_pos: 7:0.12, 3:0.12, 6:0.12
    blue_button_pos: 7:0.12, 3:0.12, 6:0.12
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 10:0.21; 22:0.21; 9:0.06; 19:0.06; 21:0.05
  Agent2 top policies: 16:0.21; 4:0.21; 12:0.06; 2:0.06; 0:0.05
. r .
1 . .
b 2 .

Reward: +0.00, Result: neutral

--- Step 2 ---
Agent 1: RIGHT, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 3:1.00, 0:0.00, 8:0.00
    red_button_pos: 8:0.14, 7:0.14, 6:0.14
    blue_button_pos: 8:0.14, 7:0.14, 6:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 7:1.00, 8:0.00, 6:0.00
    red_button_pos: 6:0.14, 1:0.14, 5:0.14
    blue_button_pos: 6:0.14, 1:0.14, 5:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 22:0.23; 10:0.23; 9:0.06; 21:0.05; 19:0.05
  Agent2 top policies: 4:0.23; 16:0.23; 12:0.06; 0:0.05; 2:0.05
. r .
. 1 .
b 2 .

Reward: +0.00, Result: neutral

--- Step 3 ---
Agent 1: RIGHT, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 4:1.00, 3:0.00, 0:0.00
    red_button_pos: 8:0.17, 7:0.17, 6:0.17
    blue_button_pos: 8:0.17, 7:0.17, 6:0.17
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 7:0.87, 4:0.12, 8:0.00
    red_button_pos: 6:0.14, 1:0.14, 5:0.14
    blue_button_pos: 6:0.14, 1:0.14, 5:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 22:0.18; 10:0.18; 4:0.18; 21:0.04; 9:0.04
  Agent2 top policies: 4:0.24; 16:0.23; 12:0.06; 2:0.05; 14:0.05
. r .
. 2 1
b . .

Reward: +0.00, Result: neutral

--- Step 4 ---
Agent 1: DOWN, Agent 2: LEFT
  Agent1 beliefs:
    agent_pos: 5:1.00, 4:0.00, 3:0.00
    red_button_pos: 8:0.20, 7:0.20, 6:0.20
    blue_button_pos: 8:0.20, 7:0.20, 6:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 4:1.00, 1:0.00, 7:0.00
    red_button_pos: 6:0.17, 1:0.17, 5:0.17
    blue_button_pos: 6:0.17, 1:0.17, 5:0.17
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 10:0.27; 4:0.27; 8:0.05; 2:0.05; 7:0.05
  Agent2 top policies: 16:0.18; 22:0.18; 4:0.18; 12:0.04; 18:0.04
. r .
2 . .
b . 1

Reward: +0.00, Result: neutral

--- Step 5 ---
Agent 1: LEFT, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 8:1.00, 5:0.00, 4:0.00
    red_button_pos: 7:0.25, 1:0.25, 6:0.25
    blue_button_pos: 7:0.25, 1:0.25, 6:0.25
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 3:1.00, 4:0.00, 7:0.00
    red_button_pos: 6:0.20, 5:0.20, 0:0.20
    blue_button_pos: 6:0.20, 5:0.20, 0:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 16:0.63; 14:0.09; 13:0.09; 17:0.07; 12:0.01
  Agent2 top policies: 4:0.28; 10:0.28; 3:0.05; 0:0.05; 2:0.05
2 r .
. . .
b 1 .

Reward: +0.00, Result: neutral

--- Step 6 ---
Agent 1: LEFT, Agent 2: RIGHT
  Agent1 beliefs:
    agent_pos: 7:1.00, 8:0.00, 5:0.00
    red_button_pos: 1:0.32, 2:0.32, 6:0.32
    blue_button_pos: 1:0.32, 2:0.32, 6:0.32
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 0:1.00, 3:0.00, 4:0.00
    red_button_pos: 6:0.24, 1:0.24, 5:0.24
    blue_button_pos: 6:0.24, 1:0.24, 5:0.24
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 16:0.72; 14:0.08; 13:0.08; 17:0.06; 12:0.01
  Agent2 top policies: 22:0.63; 21:0.09; 18:0.09; 23:0.07; 19:0.01
. 2 .
. . .
1 . .

Reward: +0.00, Result: neutral

--- Step 7 ---
Agent 1: UP, Agent 2: RIGHT
  Agent1 beliefs:
    agent_pos: 6:1.00, 3:0.00, 0:0.00
    red_button_pos: 1:0.47, 2:0.47, 0:0.02
    blue_button_pos: 6:1.00, 1:0.00, 2:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 1:1.00, 8:0.00, 5:0.00
    red_button_pos: 1:1.00, 2:0.00, 6:0.00
    blue_button_pos: 6:0.32, 2:0.32, 5:0.32
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 4:0.05; 1:0.05; 0:0.05; 3:0.05; 2:0.04
  Agent2 top policies: 22:0.18; 19:0.09; 21:0.09; 18:0.09; 23:0.07
. r 2
1 . .
b . .

Reward: +0.00, Result: neutral

--- Step 8 ---
Agent 1: UP, Agent 2: DOWN
  Agent1 beliefs:
    agent_pos: 3:1.00, 7:0.00, 8:0.00
    red_button_pos: 1:0.47, 2:0.47, 0:0.02
    blue_button_pos: 6:0.99, 1:0.00, 2:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 2:1.00, 0:0.00, 3:0.00
    red_button_pos: 1:0.99, 5:0.00, 6:0.00
    blue_button_pos: 6:0.47, 5:0.47, 8:0.02
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 3:0.10; 18:0.09; 4:0.04; 8:0.04; 7:0.04
  Agent2 top policies: 10:0.23; 9:0.13; 11:0.10; 7:0.05; 8:0.04
1 r .
. . 2
b . .

Reward: +0.00, Result: neutral

--- Step 9 ---
Agent 1: RIGHT, Agent 2: DOWN
  Agent1 beliefs:
    agent_pos: 0:1.00, 3:0.00, 7:0.00
    red_button_pos: 1:0.48, 2:0.48, 4:0.01
    blue_button_pos: 6:0.98, 1:0.00, 2:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 5:1.00, 2:0.00, 0:0.00
    red_button_pos: 1:0.98, 6:0.00, 8:0.00
    blue_button_pos: 6:0.87, 8:0.05, 7:0.03
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 22:0.40; 18:0.10; 21:0.10; 23:0.08; 19:0.03
  Agent2 top policies: 10:0.06; 7:0.05; 9:0.05; 16:0.04; 8:0.04
. 1 .
. . .
b . 2

Reward: +0.00, Result: neutral

--- Step 10 ---
Agent 1: PRESS, Agent 2: LEFT
  Agent1 beliefs:
    agent_pos: 1:1.00, 8:0.00, 5:0.00
    red_button_pos: 1:1.00, 2:0.00, 4:0.00
    blue_button_pos: 6:0.98, 2:0.00, 4:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 8:1.00, 5:0.00, 2:0.00
    red_button_pos: 1:0.98, 6:0.00, 7:0.00
    blue_button_pos: 6:0.90, 7:0.03, 4:0.02
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 24:0.06; 4:0.06; 25:0.06; 27:0.05; 26:0.05
  Agent2 top policies: 16:0.07; 14:0.07; 13:0.04; 12:0.04; 26:0.03
. 1 .
. . .
b 2 .

Reward: +0.00, Result: neutral
Button pressed: red by Agent 1

--- Step 11 ---
Agent 1: UP, Agent 2: LEFT
  Agent1 beliefs:
    agent_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 2:0.00, 8:0.00
    blue_button_pos: 6:0.97, 2:0.00, 4:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 7:1.00, 8:0.00, 5:0.00
    red_button_pos: 1:0.97, 6:0.00, 4:0.00
    blue_button_pos: 6:0.92, 4:0.03, 3:0.02
    red_button_state: 0:0.50, 1:0.50
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 4:0.04; 28:0.04; 24:0.04; 0:0.04; 22:0.04
  Agent2 top policies: 16:0.16; 14:0.06; 13:0.06; 17:0.05; 12:0.04
. 1 .
. . .
2 . .

Reward: +0.00, Result: neutral

--- Step 12 ---
Agent 1: UP, Agent 2: PRESS
  Agent1 beliefs:
    agent_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 8:0.00, 7:0.00
    blue_button_pos: 6:0.96, 2:0.01, 8:0.01
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 6:1.00, 3:0.00, 0:0.00
    red_button_pos: 1:0.97, 4:0.01, 3:0.01
    blue_button_pos: 6:1.00, 4:0.00, 3:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 4:0.04; 28:0.04; 22:0.04; 10:0.04; 24:0.03
  Agent2 top policies: 26:0.17; 25:0.17; 24:0.16; 27:0.15; 28:0.14
. 1 .
. . .
2 . .

Reward: +1.00, Result: win
Button pressed: blue by Agent 2

Result: ✅ WIN - win (steps: 12, reward: +1.00)

================================================================================
EPISODE 51
================================================================================
Environment: Red at (1, 0), Blue at (0, 2)

Initial state:
1 r .
. . .
b . 2


--- Step 1 ---
Agent 1: DOWN, Agent 2: LEFT
  Agent1 beliefs:
    agent_pos: 0:1.00, 8:0.00, 7:0.00
    red_button_pos: 8:0.12, 7:0.12, 6:0.12
    blue_button_pos: 8:0.12, 7:0.12, 6:0.12
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 8:1.00, 7:0.00, 6:0.00
    red_button_pos: 7:0.12, 3:0.12, 6:0.12
    blue_button_pos: 7:0.12, 3:0.12, 6:0.12
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 10:0.21; 22:0.21; 9:0.06; 19:0.06; 21:0.05
  Agent2 top policies: 16:0.21; 4:0.21; 12:0.06; 2:0.06; 0:0.05
. r .
1 . .
b 2 .

Reward: +0.00, Result: neutral

--- Step 2 ---
Agent 1: RIGHT, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 3:1.00, 0:0.00, 8:0.00
    red_button_pos: 8:0.14, 7:0.14, 6:0.14
    blue_button_pos: 8:0.14, 7:0.14, 6:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 7:1.00, 8:0.00, 6:0.00
    red_button_pos: 6:0.14, 1:0.14, 5:0.14
    blue_button_pos: 6:0.14, 1:0.14, 5:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 22:0.23; 10:0.23; 9:0.06; 21:0.05; 19:0.05
  Agent2 top policies: 4:0.23; 16:0.23; 12:0.06; 0:0.05; 2:0.05
. r .
. 1 .
b 2 .

Reward: +0.00, Result: neutral

--- Step 3 ---
Agent 1: RIGHT, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 4:1.00, 3:0.00, 0:0.00
    red_button_pos: 8:0.17, 7:0.17, 6:0.17
    blue_button_pos: 8:0.17, 7:0.17, 6:0.17
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 7:0.87, 4:0.12, 8:0.00
    red_button_pos: 6:0.14, 1:0.14, 5:0.14
    blue_button_pos: 6:0.14, 1:0.14, 5:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 22:0.18; 10:0.18; 4:0.18; 21:0.04; 9:0.04
  Agent2 top policies: 4:0.24; 16:0.23; 12:0.06; 2:0.05; 14:0.05
. r .
. 2 1
b . .

Reward: +0.00, Result: neutral

--- Step 4 ---
Agent 1: DOWN, Agent 2: LEFT
  Agent1 beliefs:
    agent_pos: 5:1.00, 4:0.00, 3:0.00
    red_button_pos: 8:0.20, 7:0.20, 6:0.20
    blue_button_pos: 8:0.20, 7:0.20, 6:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 4:1.00, 1:0.00, 7:0.00
    red_button_pos: 6:0.17, 1:0.17, 5:0.17
    blue_button_pos: 6:0.17, 1:0.17, 5:0.17
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 10:0.27; 4:0.27; 8:0.05; 2:0.05; 7:0.05
  Agent2 top policies: 16:0.18; 22:0.18; 4:0.18; 12:0.04; 18:0.04
. r .
2 . .
b . 1

Reward: +0.00, Result: neutral

--- Step 5 ---
Agent 1: LEFT, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 8:1.00, 5:0.00, 4:0.00
    red_button_pos: 7:0.25, 1:0.25, 6:0.25
    blue_button_pos: 7:0.25, 1:0.25, 6:0.25
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 3:1.00, 4:0.00, 7:0.00
    red_button_pos: 6:0.20, 5:0.20, 0:0.20
    blue_button_pos: 6:0.20, 5:0.20, 0:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 16:0.63; 14:0.09; 13:0.09; 17:0.07; 12:0.01
  Agent2 top policies: 4:0.28; 10:0.28; 3:0.05; 0:0.05; 2:0.05
2 r .
. . .
b 1 .

Reward: +0.00, Result: neutral

--- Step 6 ---
Agent 1: LEFT, Agent 2: RIGHT
  Agent1 beliefs:
    agent_pos: 7:1.00, 8:0.00, 5:0.00
    red_button_pos: 1:0.32, 2:0.32, 6:0.32
    blue_button_pos: 1:0.32, 2:0.32, 6:0.32
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 0:1.00, 3:0.00, 4:0.00
    red_button_pos: 6:0.24, 1:0.24, 5:0.24
    blue_button_pos: 6:0.24, 1:0.24, 5:0.24
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 16:0.72; 14:0.08; 13:0.08; 17:0.06; 12:0.01
  Agent2 top policies: 22:0.63; 21:0.09; 18:0.09; 23:0.07; 19:0.01
. 2 .
. . .
1 . .

Reward: +0.00, Result: neutral

--- Step 7 ---
Agent 1: UP, Agent 2: RIGHT
  Agent1 beliefs:
    agent_pos: 6:1.00, 3:0.00, 0:0.00
    red_button_pos: 1:0.47, 2:0.47, 0:0.02
    blue_button_pos: 6:1.00, 1:0.00, 2:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 1:1.00, 8:0.00, 5:0.00
    red_button_pos: 1:1.00, 2:0.00, 6:0.00
    blue_button_pos: 6:0.32, 2:0.32, 5:0.32
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 4:0.05; 1:0.05; 0:0.05; 3:0.05; 2:0.04
  Agent2 top policies: 22:0.18; 19:0.09; 21:0.09; 18:0.09; 23:0.07
. r 2
1 . .
b . .

Reward: +0.00, Result: neutral

--- Step 8 ---
Agent 1: UP, Agent 2: DOWN
  Agent1 beliefs:
    agent_pos: 3:1.00, 7:0.00, 8:0.00
    red_button_pos: 1:0.47, 2:0.47, 0:0.02
    blue_button_pos: 6:0.99, 1:0.00, 2:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 2:1.00, 0:0.00, 3:0.00
    red_button_pos: 1:0.99, 5:0.00, 6:0.00
    blue_button_pos: 6:0.47, 5:0.47, 8:0.02
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 3:0.10; 18:0.09; 4:0.04; 8:0.04; 7:0.04
  Agent2 top policies: 10:0.23; 9:0.13; 11:0.10; 7:0.05; 8:0.04
1 r .
. . 2
b . .

Reward: +0.00, Result: neutral

--- Step 9 ---
Agent 1: RIGHT, Agent 2: DOWN
  Agent1 beliefs:
    agent_pos: 0:1.00, 3:0.00, 7:0.00
    red_button_pos: 1:0.48, 2:0.48, 4:0.01
    blue_button_pos: 6:0.98, 1:0.00, 2:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 5:1.00, 2:0.00, 0:0.00
    red_button_pos: 1:0.98, 6:0.00, 8:0.00
    blue_button_pos: 6:0.87, 8:0.05, 7:0.03
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 22:0.40; 18:0.10; 21:0.10; 23:0.08; 19:0.03
  Agent2 top policies: 10:0.06; 7:0.05; 9:0.05; 16:0.04; 8:0.04
. 1 .
. . .
b . 2

Reward: +0.00, Result: neutral

--- Step 10 ---
Agent 1: PRESS, Agent 2: LEFT
  Agent1 beliefs:
    agent_pos: 1:1.00, 8:0.00, 5:0.00
    red_button_pos: 1:1.00, 2:0.00, 4:0.00
    blue_button_pos: 6:0.98, 2:0.00, 4:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 8:1.00, 5:0.00, 2:0.00
    red_button_pos: 1:0.98, 6:0.00, 7:0.00
    blue_button_pos: 6:0.90, 7:0.03, 4:0.02
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 24:0.06; 4:0.06; 25:0.06; 27:0.05; 26:0.05
  Agent2 top policies: 16:0.07; 14:0.07; 13:0.04; 12:0.04; 26:0.03
. 1 .
. . .
b 2 .

Reward: +0.00, Result: neutral
Button pressed: red by Agent 1

--- Step 11 ---
Agent 1: UP, Agent 2: LEFT
  Agent1 beliefs:
    agent_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 2:0.00, 8:0.00
    blue_button_pos: 6:0.97, 2:0.00, 4:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 7:1.00, 8:0.00, 5:0.00
    red_button_pos: 1:0.97, 6:0.00, 4:0.00
    blue_button_pos: 6:0.92, 4:0.03, 3:0.02
    red_button_state: 0:0.50, 1:0.50
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 4:0.04; 28:0.04; 24:0.04; 0:0.04; 22:0.04
  Agent2 top policies: 16:0.16; 14:0.06; 13:0.06; 17:0.05; 12:0.04
. 1 .
. . .
2 . .

Reward: +0.00, Result: neutral

--- Step 12 ---
Agent 1: UP, Agent 2: PRESS
  Agent1 beliefs:
    agent_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 8:0.00, 7:0.00
    blue_button_pos: 6:0.96, 2:0.01, 8:0.01
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 6:1.00, 3:0.00, 0:0.00
    red_button_pos: 1:0.97, 4:0.01, 3:0.01
    blue_button_pos: 6:1.00, 4:0.00, 3:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 4:0.04; 28:0.04; 22:0.04; 10:0.04; 24:0.03
  Agent2 top policies: 26:0.17; 25:0.17; 24:0.16; 27:0.15; 28:0.14
. 1 .
. . .
2 . .

Reward: +1.00, Result: win
Button pressed: blue by Agent 2

Result: ✅ WIN - win (steps: 12, reward: +1.00)

================================================================================
EPISODE 52
================================================================================
Environment: Red at (1, 0), Blue at (0, 2)

Initial state:
1 r .
. . .
b . 2


--- Step 1 ---
Agent 1: DOWN, Agent 2: LEFT
  Agent1 beliefs:
    agent_pos: 0:1.00, 8:0.00, 7:0.00
    red_button_pos: 8:0.12, 7:0.12, 6:0.12
    blue_button_pos: 8:0.12, 7:0.12, 6:0.12
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 8:1.00, 7:0.00, 6:0.00
    red_button_pos: 7:0.12, 3:0.12, 6:0.12
    blue_button_pos: 7:0.12, 3:0.12, 6:0.12
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 10:0.21; 22:0.21; 9:0.06; 19:0.06; 21:0.05
  Agent2 top policies: 16:0.21; 4:0.21; 12:0.06; 2:0.06; 0:0.05
. r .
1 . .
b 2 .

Reward: +0.00, Result: neutral

--- Step 2 ---
Agent 1: RIGHT, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 3:1.00, 0:0.00, 8:0.00
    red_button_pos: 8:0.14, 7:0.14, 6:0.14
    blue_button_pos: 8:0.14, 7:0.14, 6:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 7:1.00, 8:0.00, 6:0.00
    red_button_pos: 6:0.14, 1:0.14, 5:0.14
    blue_button_pos: 6:0.14, 1:0.14, 5:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 22:0.23; 10:0.23; 9:0.06; 21:0.05; 19:0.05
  Agent2 top policies: 4:0.23; 16:0.23; 12:0.06; 0:0.05; 2:0.05
. r .
. 1 .
b 2 .

Reward: +0.00, Result: neutral

--- Step 3 ---
Agent 1: RIGHT, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 4:1.00, 3:0.00, 0:0.00
    red_button_pos: 8:0.17, 7:0.17, 6:0.17
    blue_button_pos: 8:0.17, 7:0.17, 6:0.17
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 7:0.87, 4:0.12, 8:0.00
    red_button_pos: 6:0.14, 1:0.14, 5:0.14
    blue_button_pos: 6:0.14, 1:0.14, 5:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 22:0.18; 10:0.18; 4:0.18; 21:0.04; 9:0.04
  Agent2 top policies: 4:0.24; 16:0.23; 12:0.06; 2:0.05; 14:0.05
. r .
. 2 1
b . .

Reward: +0.00, Result: neutral

--- Step 4 ---
Agent 1: DOWN, Agent 2: LEFT
  Agent1 beliefs:
    agent_pos: 5:1.00, 4:0.00, 3:0.00
    red_button_pos: 8:0.20, 7:0.20, 6:0.20
    blue_button_pos: 8:0.20, 7:0.20, 6:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 4:1.00, 1:0.00, 7:0.00
    red_button_pos: 6:0.17, 1:0.17, 5:0.17
    blue_button_pos: 6:0.17, 1:0.17, 5:0.17
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 10:0.27; 4:0.27; 8:0.05; 2:0.05; 7:0.05
  Agent2 top policies: 16:0.18; 22:0.18; 4:0.18; 12:0.04; 18:0.04
. r .
2 . .
b . 1

Reward: +0.00, Result: neutral

--- Step 5 ---
Agent 1: LEFT, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 8:1.00, 5:0.00, 4:0.00
    red_button_pos: 7:0.25, 1:0.25, 6:0.25
    blue_button_pos: 7:0.25, 1:0.25, 6:0.25
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 3:1.00, 4:0.00, 7:0.00
    red_button_pos: 6:0.20, 5:0.20, 0:0.20
    blue_button_pos: 6:0.20, 5:0.20, 0:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 16:0.63; 14:0.09; 13:0.09; 17:0.07; 12:0.01
  Agent2 top policies: 4:0.28; 10:0.28; 3:0.05; 0:0.05; 2:0.05
2 r .
. . .
b 1 .

Reward: +0.00, Result: neutral

--- Step 6 ---
Agent 1: LEFT, Agent 2: RIGHT
  Agent1 beliefs:
    agent_pos: 7:1.00, 8:0.00, 5:0.00
    red_button_pos: 1:0.32, 2:0.32, 6:0.32
    blue_button_pos: 1:0.32, 2:0.32, 6:0.32
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 0:1.00, 3:0.00, 4:0.00
    red_button_pos: 6:0.24, 1:0.24, 5:0.24
    blue_button_pos: 6:0.24, 1:0.24, 5:0.24
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 16:0.72; 14:0.08; 13:0.08; 17:0.06; 12:0.01
  Agent2 top policies: 22:0.63; 21:0.09; 18:0.09; 23:0.07; 19:0.01
. 2 .
. . .
1 . .

Reward: +0.00, Result: neutral

--- Step 7 ---
Agent 1: UP, Agent 2: RIGHT
  Agent1 beliefs:
    agent_pos: 6:1.00, 3:0.00, 0:0.00
    red_button_pos: 1:0.47, 2:0.47, 0:0.02
    blue_button_pos: 6:1.00, 1:0.00, 2:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 1:1.00, 8:0.00, 5:0.00
    red_button_pos: 1:1.00, 2:0.00, 6:0.00
    blue_button_pos: 6:0.32, 2:0.32, 5:0.32
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 4:0.05; 1:0.05; 0:0.05; 3:0.05; 2:0.04
  Agent2 top policies: 22:0.18; 19:0.09; 21:0.09; 18:0.09; 23:0.07
. r 2
1 . .
b . .

Reward: +0.00, Result: neutral

--- Step 8 ---
Agent 1: UP, Agent 2: DOWN
  Agent1 beliefs:
    agent_pos: 3:1.00, 7:0.00, 8:0.00
    red_button_pos: 1:0.47, 2:0.47, 0:0.02
    blue_button_pos: 6:0.99, 1:0.00, 2:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 2:1.00, 0:0.00, 3:0.00
    red_button_pos: 1:0.99, 5:0.00, 6:0.00
    blue_button_pos: 6:0.47, 5:0.47, 8:0.02
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 3:0.10; 18:0.09; 4:0.04; 8:0.04; 7:0.04
  Agent2 top policies: 10:0.23; 9:0.13; 11:0.10; 7:0.05; 8:0.04
1 r .
. . 2
b . .

Reward: +0.00, Result: neutral

--- Step 9 ---
Agent 1: RIGHT, Agent 2: DOWN
  Agent1 beliefs:
    agent_pos: 0:1.00, 3:0.00, 7:0.00
    red_button_pos: 1:0.48, 2:0.48, 4:0.01
    blue_button_pos: 6:0.98, 1:0.00, 2:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 5:1.00, 2:0.00, 0:0.00
    red_button_pos: 1:0.98, 6:0.00, 8:0.00
    blue_button_pos: 6:0.87, 8:0.05, 7:0.03
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 22:0.40; 18:0.10; 21:0.10; 23:0.08; 19:0.03
  Agent2 top policies: 10:0.06; 7:0.05; 9:0.05; 16:0.04; 8:0.04
. 1 .
. . .
b . 2

Reward: +0.00, Result: neutral

--- Step 10 ---
Agent 1: PRESS, Agent 2: LEFT
  Agent1 beliefs:
    agent_pos: 1:1.00, 8:0.00, 5:0.00
    red_button_pos: 1:1.00, 2:0.00, 4:0.00
    blue_button_pos: 6:0.98, 2:0.00, 4:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 8:1.00, 5:0.00, 2:0.00
    red_button_pos: 1:0.98, 6:0.00, 7:0.00
    blue_button_pos: 6:0.90, 7:0.03, 4:0.02
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 24:0.06; 4:0.06; 25:0.06; 27:0.05; 26:0.05
  Agent2 top policies: 16:0.07; 14:0.07; 13:0.04; 12:0.04; 26:0.03
. 1 .
. . .
b 2 .

Reward: +0.00, Result: neutral
Button pressed: red by Agent 1

--- Step 11 ---
Agent 1: UP, Agent 2: LEFT
  Agent1 beliefs:
    agent_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 2:0.00, 8:0.00
    blue_button_pos: 6:0.97, 2:0.00, 4:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 7:1.00, 8:0.00, 5:0.00
    red_button_pos: 1:0.97, 6:0.00, 4:0.00
    blue_button_pos: 6:0.92, 4:0.03, 3:0.02
    red_button_state: 0:0.50, 1:0.50
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 4:0.04; 28:0.04; 24:0.04; 0:0.04; 22:0.04
  Agent2 top policies: 16:0.16; 14:0.06; 13:0.06; 17:0.05; 12:0.04
. 1 .
. . .
2 . .

Reward: +0.00, Result: neutral

--- Step 12 ---
Agent 1: UP, Agent 2: PRESS
  Agent1 beliefs:
    agent_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 8:0.00, 7:0.00
    blue_button_pos: 6:0.96, 2:0.01, 8:0.01
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 6:1.00, 3:0.00, 0:0.00
    red_button_pos: 1:0.97, 4:0.01, 3:0.01
    blue_button_pos: 6:1.00, 4:0.00, 3:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 4:0.04; 28:0.04; 22:0.04; 10:0.04; 24:0.03
  Agent2 top policies: 26:0.17; 25:0.17; 24:0.16; 27:0.15; 28:0.14
. 1 .
. . .
2 . .

Reward: +1.00, Result: win
Button pressed: blue by Agent 2

Result: ✅ WIN - win (steps: 12, reward: +1.00)

================================================================================
EPISODE 53
================================================================================
Environment: Red at (1, 0), Blue at (0, 2)

Initial state:
1 r .
. . .
b . 2


--- Step 1 ---
Agent 1: DOWN, Agent 2: LEFT
  Agent1 beliefs:
    agent_pos: 0:1.00, 8:0.00, 7:0.00
    red_button_pos: 8:0.12, 7:0.12, 6:0.12
    blue_button_pos: 8:0.12, 7:0.12, 6:0.12
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 8:1.00, 7:0.00, 6:0.00
    red_button_pos: 7:0.12, 3:0.12, 6:0.12
    blue_button_pos: 7:0.12, 3:0.12, 6:0.12
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 10:0.21; 22:0.21; 9:0.06; 19:0.06; 21:0.05
  Agent2 top policies: 16:0.21; 4:0.21; 12:0.06; 2:0.06; 0:0.05
. r .
1 . .
b 2 .

Reward: +0.00, Result: neutral

--- Step 2 ---
Agent 1: RIGHT, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 3:1.00, 0:0.00, 8:0.00
    red_button_pos: 8:0.14, 7:0.14, 6:0.14
    blue_button_pos: 8:0.14, 7:0.14, 6:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 7:1.00, 8:0.00, 6:0.00
    red_button_pos: 6:0.14, 1:0.14, 5:0.14
    blue_button_pos: 6:0.14, 1:0.14, 5:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 22:0.23; 10:0.23; 9:0.06; 21:0.05; 19:0.05
  Agent2 top policies: 4:0.23; 16:0.23; 12:0.06; 0:0.05; 2:0.05
. r .
. 1 .
b 2 .

Reward: +0.00, Result: neutral

--- Step 3 ---
Agent 1: RIGHT, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 4:1.00, 3:0.00, 0:0.00
    red_button_pos: 8:0.17, 7:0.17, 6:0.17
    blue_button_pos: 8:0.17, 7:0.17, 6:0.17
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 7:0.87, 4:0.12, 8:0.00
    red_button_pos: 6:0.14, 1:0.14, 5:0.14
    blue_button_pos: 6:0.14, 1:0.14, 5:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 22:0.18; 10:0.18; 4:0.18; 21:0.04; 9:0.04
  Agent2 top policies: 4:0.24; 16:0.23; 12:0.06; 2:0.05; 14:0.05
. r .
. 2 1
b . .

Reward: +0.00, Result: neutral

--- Step 4 ---
Agent 1: DOWN, Agent 2: LEFT
  Agent1 beliefs:
    agent_pos: 5:1.00, 4:0.00, 3:0.00
    red_button_pos: 8:0.20, 7:0.20, 6:0.20
    blue_button_pos: 8:0.20, 7:0.20, 6:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 4:1.00, 1:0.00, 7:0.00
    red_button_pos: 6:0.17, 1:0.17, 5:0.17
    blue_button_pos: 6:0.17, 1:0.17, 5:0.17
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 10:0.27; 4:0.27; 8:0.05; 2:0.05; 7:0.05
  Agent2 top policies: 16:0.18; 22:0.18; 4:0.18; 12:0.04; 18:0.04
. r .
2 . .
b . 1

Reward: +0.00, Result: neutral

--- Step 5 ---
Agent 1: LEFT, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 8:1.00, 5:0.00, 4:0.00
    red_button_pos: 7:0.25, 1:0.25, 6:0.25
    blue_button_pos: 7:0.25, 1:0.25, 6:0.25
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 3:1.00, 4:0.00, 7:0.00
    red_button_pos: 6:0.20, 5:0.20, 0:0.20
    blue_button_pos: 6:0.20, 5:0.20, 0:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 16:0.63; 14:0.09; 13:0.09; 17:0.07; 12:0.01
  Agent2 top policies: 4:0.28; 10:0.28; 3:0.05; 0:0.05; 2:0.05
2 r .
. . .
b 1 .

Reward: +0.00, Result: neutral

--- Step 6 ---
Agent 1: LEFT, Agent 2: RIGHT
  Agent1 beliefs:
    agent_pos: 7:1.00, 8:0.00, 5:0.00
    red_button_pos: 1:0.32, 2:0.32, 6:0.32
    blue_button_pos: 1:0.32, 2:0.32, 6:0.32
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 0:1.00, 3:0.00, 4:0.00
    red_button_pos: 6:0.24, 1:0.24, 5:0.24
    blue_button_pos: 6:0.24, 1:0.24, 5:0.24
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 16:0.72; 14:0.08; 13:0.08; 17:0.06; 12:0.01
  Agent2 top policies: 22:0.63; 21:0.09; 18:0.09; 23:0.07; 19:0.01
. 2 .
. . .
1 . .

Reward: +0.00, Result: neutral

--- Step 7 ---
Agent 1: UP, Agent 2: RIGHT
  Agent1 beliefs:
    agent_pos: 6:1.00, 3:0.00, 0:0.00
    red_button_pos: 1:0.47, 2:0.47, 0:0.02
    blue_button_pos: 6:1.00, 1:0.00, 2:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 1:1.00, 8:0.00, 5:0.00
    red_button_pos: 1:1.00, 2:0.00, 6:0.00
    blue_button_pos: 6:0.32, 2:0.32, 5:0.32
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 4:0.05; 1:0.05; 0:0.05; 3:0.05; 2:0.04
  Agent2 top policies: 22:0.18; 19:0.09; 21:0.09; 18:0.09; 23:0.07
. r 2
1 . .
b . .

Reward: +0.00, Result: neutral

--- Step 8 ---
Agent 1: UP, Agent 2: DOWN
  Agent1 beliefs:
    agent_pos: 3:1.00, 7:0.00, 8:0.00
    red_button_pos: 1:0.47, 2:0.47, 0:0.02
    blue_button_pos: 6:0.99, 1:0.00, 2:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 2:1.00, 0:0.00, 3:0.00
    red_button_pos: 1:0.99, 5:0.00, 6:0.00
    blue_button_pos: 6:0.47, 5:0.47, 8:0.02
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 3:0.10; 18:0.09; 4:0.04; 8:0.04; 7:0.04
  Agent2 top policies: 10:0.23; 9:0.13; 11:0.10; 7:0.05; 8:0.04
1 r .
. . 2
b . .

Reward: +0.00, Result: neutral

--- Step 9 ---
Agent 1: RIGHT, Agent 2: DOWN
  Agent1 beliefs:
    agent_pos: 0:1.00, 3:0.00, 7:0.00
    red_button_pos: 1:0.48, 2:0.48, 4:0.01
    blue_button_pos: 6:0.98, 1:0.00, 2:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 5:1.00, 2:0.00, 0:0.00
    red_button_pos: 1:0.98, 6:0.00, 8:0.00
    blue_button_pos: 6:0.87, 8:0.05, 7:0.03
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 22:0.40; 18:0.10; 21:0.10; 23:0.08; 19:0.03
  Agent2 top policies: 10:0.06; 7:0.05; 9:0.05; 16:0.04; 8:0.04
. 1 .
. . .
b . 2

Reward: +0.00, Result: neutral

--- Step 10 ---
Agent 1: PRESS, Agent 2: LEFT
  Agent1 beliefs:
    agent_pos: 1:1.00, 8:0.00, 5:0.00
    red_button_pos: 1:1.00, 2:0.00, 4:0.00
    blue_button_pos: 6:0.98, 2:0.00, 4:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 8:1.00, 5:0.00, 2:0.00
    red_button_pos: 1:0.98, 6:0.00, 7:0.00
    blue_button_pos: 6:0.90, 7:0.03, 4:0.02
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 24:0.06; 4:0.06; 25:0.06; 27:0.05; 26:0.05
  Agent2 top policies: 16:0.07; 14:0.07; 13:0.04; 12:0.04; 26:0.03
. 1 .
. . .
b 2 .

Reward: +0.00, Result: neutral
Button pressed: red by Agent 1

--- Step 11 ---
Agent 1: UP, Agent 2: LEFT
  Agent1 beliefs:
    agent_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 2:0.00, 8:0.00
    blue_button_pos: 6:0.97, 2:0.00, 4:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 7:1.00, 8:0.00, 5:0.00
    red_button_pos: 1:0.97, 6:0.00, 4:0.00
    blue_button_pos: 6:0.92, 4:0.03, 3:0.02
    red_button_state: 0:0.50, 1:0.50
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 4:0.04; 28:0.04; 24:0.04; 0:0.04; 22:0.04
  Agent2 top policies: 16:0.16; 14:0.06; 13:0.06; 17:0.05; 12:0.04
. 1 .
. . .
2 . .

Reward: +0.00, Result: neutral

--- Step 12 ---
Agent 1: UP, Agent 2: PRESS
  Agent1 beliefs:
    agent_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 8:0.00, 7:0.00
    blue_button_pos: 6:0.96, 2:0.01, 8:0.01
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 6:1.00, 3:0.00, 0:0.00
    red_button_pos: 1:0.97, 4:0.01, 3:0.01
    blue_button_pos: 6:1.00, 4:0.00, 3:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 4:0.04; 28:0.04; 22:0.04; 10:0.04; 24:0.03
  Agent2 top policies: 26:0.17; 25:0.17; 24:0.16; 27:0.15; 28:0.14
. 1 .
. . .
2 . .

Reward: +1.00, Result: win
Button pressed: blue by Agent 2

Result: ✅ WIN - win (steps: 12, reward: +1.00)

================================================================================
EPISODE 54
================================================================================
Environment: Red at (1, 0), Blue at (0, 2)

Initial state:
1 r .
. . .
b . 2


--- Step 1 ---
Agent 1: DOWN, Agent 2: LEFT
  Agent1 beliefs:
    agent_pos: 0:1.00, 8:0.00, 7:0.00
    red_button_pos: 8:0.12, 7:0.12, 6:0.12
    blue_button_pos: 8:0.12, 7:0.12, 6:0.12
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 8:1.00, 7:0.00, 6:0.00
    red_button_pos: 7:0.12, 3:0.12, 6:0.12
    blue_button_pos: 7:0.12, 3:0.12, 6:0.12
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 10:0.21; 22:0.21; 9:0.06; 19:0.06; 21:0.05
  Agent2 top policies: 16:0.21; 4:0.21; 12:0.06; 2:0.06; 0:0.05
. r .
1 . .
b 2 .

Reward: +0.00, Result: neutral

--- Step 2 ---
Agent 1: RIGHT, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 3:1.00, 0:0.00, 8:0.00
    red_button_pos: 8:0.14, 7:0.14, 6:0.14
    blue_button_pos: 8:0.14, 7:0.14, 6:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 7:1.00, 8:0.00, 6:0.00
    red_button_pos: 6:0.14, 1:0.14, 5:0.14
    blue_button_pos: 6:0.14, 1:0.14, 5:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 22:0.23; 10:0.23; 9:0.06; 21:0.05; 19:0.05
  Agent2 top policies: 4:0.23; 16:0.23; 12:0.06; 0:0.05; 2:0.05
. r .
. 1 .
b 2 .

Reward: +0.00, Result: neutral

--- Step 3 ---
Agent 1: RIGHT, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 4:1.00, 3:0.00, 0:0.00
    red_button_pos: 8:0.17, 7:0.17, 6:0.17
    blue_button_pos: 8:0.17, 7:0.17, 6:0.17
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 7:0.87, 4:0.12, 8:0.00
    red_button_pos: 6:0.14, 1:0.14, 5:0.14
    blue_button_pos: 6:0.14, 1:0.14, 5:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 22:0.18; 10:0.18; 4:0.18; 21:0.04; 9:0.04
  Agent2 top policies: 4:0.24; 16:0.23; 12:0.06; 2:0.05; 14:0.05
. r .
. 2 1
b . .

Reward: +0.00, Result: neutral

--- Step 4 ---
Agent 1: DOWN, Agent 2: LEFT
  Agent1 beliefs:
    agent_pos: 5:1.00, 4:0.00, 3:0.00
    red_button_pos: 8:0.20, 7:0.20, 6:0.20
    blue_button_pos: 8:0.20, 7:0.20, 6:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 4:1.00, 1:0.00, 7:0.00
    red_button_pos: 6:0.17, 1:0.17, 5:0.17
    blue_button_pos: 6:0.17, 1:0.17, 5:0.17
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 10:0.27; 4:0.27; 8:0.05; 2:0.05; 7:0.05
  Agent2 top policies: 16:0.18; 22:0.18; 4:0.18; 12:0.04; 18:0.04
. r .
2 . .
b . 1

Reward: +0.00, Result: neutral

--- Step 5 ---
Agent 1: LEFT, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 8:1.00, 5:0.00, 4:0.00
    red_button_pos: 7:0.25, 1:0.25, 6:0.25
    blue_button_pos: 7:0.25, 1:0.25, 6:0.25
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 3:1.00, 4:0.00, 7:0.00
    red_button_pos: 6:0.20, 5:0.20, 0:0.20
    blue_button_pos: 6:0.20, 5:0.20, 0:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 16:0.63; 14:0.09; 13:0.09; 17:0.07; 12:0.01
  Agent2 top policies: 4:0.28; 10:0.28; 3:0.05; 0:0.05; 2:0.05
2 r .
. . .
b 1 .

Reward: +0.00, Result: neutral

--- Step 6 ---
Agent 1: LEFT, Agent 2: RIGHT
  Agent1 beliefs:
    agent_pos: 7:1.00, 8:0.00, 5:0.00
    red_button_pos: 1:0.32, 2:0.32, 6:0.32
    blue_button_pos: 1:0.32, 2:0.32, 6:0.32
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 0:1.00, 3:0.00, 4:0.00
    red_button_pos: 6:0.24, 1:0.24, 5:0.24
    blue_button_pos: 6:0.24, 1:0.24, 5:0.24
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 16:0.72; 14:0.08; 13:0.08; 17:0.06; 12:0.01
  Agent2 top policies: 22:0.63; 21:0.09; 18:0.09; 23:0.07; 19:0.01
. 2 .
. . .
1 . .

Reward: +0.00, Result: neutral

--- Step 7 ---
Agent 1: UP, Agent 2: RIGHT
  Agent1 beliefs:
    agent_pos: 6:1.00, 3:0.00, 0:0.00
    red_button_pos: 1:0.47, 2:0.47, 0:0.02
    blue_button_pos: 6:1.00, 1:0.00, 2:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 1:1.00, 8:0.00, 5:0.00
    red_button_pos: 1:1.00, 2:0.00, 6:0.00
    blue_button_pos: 6:0.32, 2:0.32, 5:0.32
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 4:0.05; 1:0.05; 0:0.05; 3:0.05; 2:0.04
  Agent2 top policies: 22:0.18; 19:0.09; 21:0.09; 18:0.09; 23:0.07
. r 2
1 . .
b . .

Reward: +0.00, Result: neutral

--- Step 8 ---
Agent 1: UP, Agent 2: DOWN
  Agent1 beliefs:
    agent_pos: 3:1.00, 7:0.00, 8:0.00
    red_button_pos: 1:0.47, 2:0.47, 0:0.02
    blue_button_pos: 6:0.99, 1:0.00, 2:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 2:1.00, 0:0.00, 3:0.00
    red_button_pos: 1:0.99, 5:0.00, 6:0.00
    blue_button_pos: 6:0.47, 5:0.47, 8:0.02
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 3:0.10; 18:0.09; 4:0.04; 8:0.04; 7:0.04
  Agent2 top policies: 10:0.23; 9:0.13; 11:0.10; 7:0.05; 8:0.04
1 r .
. . 2
b . .

Reward: +0.00, Result: neutral

--- Step 9 ---
Agent 1: RIGHT, Agent 2: DOWN
  Agent1 beliefs:
    agent_pos: 0:1.00, 3:0.00, 7:0.00
    red_button_pos: 1:0.48, 2:0.48, 4:0.01
    blue_button_pos: 6:0.98, 1:0.00, 2:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 5:1.00, 2:0.00, 0:0.00
    red_button_pos: 1:0.98, 6:0.00, 8:0.00
    blue_button_pos: 6:0.87, 8:0.05, 7:0.03
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 22:0.40; 18:0.10; 21:0.10; 23:0.08; 19:0.03
  Agent2 top policies: 10:0.06; 7:0.05; 9:0.05; 16:0.04; 8:0.04
. 1 .
. . .
b . 2

Reward: +0.00, Result: neutral

--- Step 10 ---
Agent 1: PRESS, Agent 2: LEFT
  Agent1 beliefs:
    agent_pos: 1:1.00, 8:0.00, 5:0.00
    red_button_pos: 1:1.00, 2:0.00, 4:0.00
    blue_button_pos: 6:0.98, 2:0.00, 4:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 8:1.00, 5:0.00, 2:0.00
    red_button_pos: 1:0.98, 6:0.00, 7:0.00
    blue_button_pos: 6:0.90, 7:0.03, 4:0.02
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 24:0.06; 4:0.06; 25:0.06; 27:0.05; 26:0.05
  Agent2 top policies: 16:0.07; 14:0.07; 13:0.04; 12:0.04; 26:0.03
. 1 .
. . .
b 2 .

Reward: +0.00, Result: neutral
Button pressed: red by Agent 1

--- Step 11 ---
Agent 1: UP, Agent 2: LEFT
  Agent1 beliefs:
    agent_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 2:0.00, 8:0.00
    blue_button_pos: 6:0.97, 2:0.00, 4:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 7:1.00, 8:0.00, 5:0.00
    red_button_pos: 1:0.97, 6:0.00, 4:0.00
    blue_button_pos: 6:0.92, 4:0.03, 3:0.02
    red_button_state: 0:0.50, 1:0.50
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 4:0.04; 28:0.04; 24:0.04; 0:0.04; 22:0.04
  Agent2 top policies: 16:0.16; 14:0.06; 13:0.06; 17:0.05; 12:0.04
. 1 .
. . .
2 . .

Reward: +0.00, Result: neutral

--- Step 12 ---
Agent 1: UP, Agent 2: PRESS
  Agent1 beliefs:
    agent_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 8:0.00, 7:0.00
    blue_button_pos: 6:0.96, 2:0.01, 8:0.01
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 6:1.00, 3:0.00, 0:0.00
    red_button_pos: 1:0.97, 4:0.01, 3:0.01
    blue_button_pos: 6:1.00, 4:0.00, 3:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 4:0.04; 28:0.04; 22:0.04; 10:0.04; 24:0.03
  Agent2 top policies: 26:0.17; 25:0.17; 24:0.16; 27:0.15; 28:0.14
. 1 .
. . .
2 . .

Reward: +1.00, Result: win
Button pressed: blue by Agent 2

Result: ✅ WIN - win (steps: 12, reward: +1.00)

================================================================================
EPISODE 55
================================================================================
Environment: Red at (1, 0), Blue at (0, 2)

Initial state:
1 r .
. . .
b . 2


--- Step 1 ---
Agent 1: DOWN, Agent 2: LEFT
  Agent1 beliefs:
    agent_pos: 0:1.00, 8:0.00, 7:0.00
    red_button_pos: 8:0.12, 7:0.12, 6:0.12
    blue_button_pos: 8:0.12, 7:0.12, 6:0.12
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 8:1.00, 7:0.00, 6:0.00
    red_button_pos: 7:0.12, 3:0.12, 6:0.12
    blue_button_pos: 7:0.12, 3:0.12, 6:0.12
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 10:0.21; 22:0.21; 9:0.06; 19:0.06; 21:0.05
  Agent2 top policies: 16:0.21; 4:0.21; 12:0.06; 2:0.06; 0:0.05
. r .
1 . .
b 2 .

Reward: +0.00, Result: neutral

--- Step 2 ---
Agent 1: RIGHT, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 3:1.00, 0:0.00, 8:0.00
    red_button_pos: 8:0.14, 7:0.14, 6:0.14
    blue_button_pos: 8:0.14, 7:0.14, 6:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 7:1.00, 8:0.00, 6:0.00
    red_button_pos: 6:0.14, 1:0.14, 5:0.14
    blue_button_pos: 6:0.14, 1:0.14, 5:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 22:0.23; 10:0.23; 9:0.06; 21:0.05; 19:0.05
  Agent2 top policies: 4:0.23; 16:0.23; 12:0.06; 0:0.05; 2:0.05
. r .
. 1 .
b 2 .

Reward: +0.00, Result: neutral

--- Step 3 ---
Agent 1: RIGHT, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 4:1.00, 3:0.00, 0:0.00
    red_button_pos: 8:0.17, 7:0.17, 6:0.17
    blue_button_pos: 8:0.17, 7:0.17, 6:0.17
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 7:0.87, 4:0.12, 8:0.00
    red_button_pos: 6:0.14, 1:0.14, 5:0.14
    blue_button_pos: 6:0.14, 1:0.14, 5:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 22:0.18; 10:0.18; 4:0.18; 21:0.04; 9:0.04
  Agent2 top policies: 4:0.24; 16:0.23; 12:0.06; 2:0.05; 14:0.05
. r .
. 2 1
b . .

Reward: +0.00, Result: neutral

--- Step 4 ---
Agent 1: DOWN, Agent 2: LEFT
  Agent1 beliefs:
    agent_pos: 5:1.00, 4:0.00, 3:0.00
    red_button_pos: 8:0.20, 7:0.20, 6:0.20
    blue_button_pos: 8:0.20, 7:0.20, 6:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 4:1.00, 1:0.00, 7:0.00
    red_button_pos: 6:0.17, 1:0.17, 5:0.17
    blue_button_pos: 6:0.17, 1:0.17, 5:0.17
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 10:0.27; 4:0.27; 8:0.05; 2:0.05; 7:0.05
  Agent2 top policies: 16:0.18; 22:0.18; 4:0.18; 12:0.04; 18:0.04
. r .
2 . .
b . 1

Reward: +0.00, Result: neutral

--- Step 5 ---
Agent 1: LEFT, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 8:1.00, 5:0.00, 4:0.00
    red_button_pos: 7:0.25, 1:0.25, 6:0.25
    blue_button_pos: 7:0.25, 1:0.25, 6:0.25
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 3:1.00, 4:0.00, 7:0.00
    red_button_pos: 6:0.20, 5:0.20, 0:0.20
    blue_button_pos: 6:0.20, 5:0.20, 0:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 16:0.63; 14:0.09; 13:0.09; 17:0.07; 12:0.01
  Agent2 top policies: 4:0.28; 10:0.28; 3:0.05; 0:0.05; 2:0.05
2 r .
. . .
b 1 .

Reward: +0.00, Result: neutral

--- Step 6 ---
Agent 1: LEFT, Agent 2: RIGHT
  Agent1 beliefs:
    agent_pos: 7:1.00, 8:0.00, 5:0.00
    red_button_pos: 1:0.32, 2:0.32, 6:0.32
    blue_button_pos: 1:0.32, 2:0.32, 6:0.32
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 0:1.00, 3:0.00, 4:0.00
    red_button_pos: 6:0.24, 1:0.24, 5:0.24
    blue_button_pos: 6:0.24, 1:0.24, 5:0.24
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 16:0.72; 14:0.08; 13:0.08; 17:0.06; 12:0.01
  Agent2 top policies: 22:0.63; 21:0.09; 18:0.09; 23:0.07; 19:0.01
. 2 .
. . .
1 . .

Reward: +0.00, Result: neutral

--- Step 7 ---
Agent 1: UP, Agent 2: RIGHT
  Agent1 beliefs:
    agent_pos: 6:1.00, 3:0.00, 0:0.00
    red_button_pos: 1:0.47, 2:0.47, 0:0.02
    blue_button_pos: 6:1.00, 1:0.00, 2:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 1:1.00, 8:0.00, 5:0.00
    red_button_pos: 1:1.00, 2:0.00, 6:0.00
    blue_button_pos: 6:0.32, 2:0.32, 5:0.32
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 4:0.05; 1:0.05; 0:0.05; 3:0.05; 2:0.04
  Agent2 top policies: 22:0.18; 19:0.09; 21:0.09; 18:0.09; 23:0.07
. r 2
1 . .
b . .

Reward: +0.00, Result: neutral

--- Step 8 ---
Agent 1: UP, Agent 2: DOWN
  Agent1 beliefs:
    agent_pos: 3:1.00, 7:0.00, 8:0.00
    red_button_pos: 1:0.47, 2:0.47, 0:0.02
    blue_button_pos: 6:0.99, 1:0.00, 2:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 2:1.00, 0:0.00, 3:0.00
    red_button_pos: 1:0.99, 5:0.00, 6:0.00
    blue_button_pos: 6:0.47, 5:0.47, 8:0.02
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 3:0.10; 18:0.09; 4:0.04; 8:0.04; 7:0.04
  Agent2 top policies: 10:0.23; 9:0.13; 11:0.10; 7:0.05; 8:0.04
1 r .
. . 2
b . .

Reward: +0.00, Result: neutral

--- Step 9 ---
Agent 1: RIGHT, Agent 2: DOWN
  Agent1 beliefs:
    agent_pos: 0:1.00, 3:0.00, 7:0.00
    red_button_pos: 1:0.48, 2:0.48, 4:0.01
    blue_button_pos: 6:0.98, 1:0.00, 2:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 5:1.00, 2:0.00, 0:0.00
    red_button_pos: 1:0.98, 6:0.00, 8:0.00
    blue_button_pos: 6:0.87, 8:0.05, 7:0.03
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 22:0.40; 18:0.10; 21:0.10; 23:0.08; 19:0.03
  Agent2 top policies: 10:0.06; 7:0.05; 9:0.05; 16:0.04; 8:0.04
. 1 .
. . .
b . 2

Reward: +0.00, Result: neutral

--- Step 10 ---
Agent 1: PRESS, Agent 2: LEFT
  Agent1 beliefs:
    agent_pos: 1:1.00, 8:0.00, 5:0.00
    red_button_pos: 1:1.00, 2:0.00, 4:0.00
    blue_button_pos: 6:0.98, 2:0.00, 4:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 8:1.00, 5:0.00, 2:0.00
    red_button_pos: 1:0.98, 6:0.00, 7:0.00
    blue_button_pos: 6:0.90, 7:0.03, 4:0.02
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 24:0.06; 4:0.06; 25:0.06; 27:0.05; 26:0.05
  Agent2 top policies: 16:0.07; 14:0.07; 13:0.04; 12:0.04; 26:0.03
. 1 .
. . .
b 2 .

Reward: +0.00, Result: neutral
Button pressed: red by Agent 1

--- Step 11 ---
Agent 1: UP, Agent 2: LEFT
  Agent1 beliefs:
    agent_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 2:0.00, 8:0.00
    blue_button_pos: 6:0.97, 2:0.00, 4:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 7:1.00, 8:0.00, 5:0.00
    red_button_pos: 1:0.97, 6:0.00, 4:0.00
    blue_button_pos: 6:0.92, 4:0.03, 3:0.02
    red_button_state: 0:0.50, 1:0.50
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 4:0.04; 28:0.04; 24:0.04; 0:0.04; 22:0.04
  Agent2 top policies: 16:0.16; 14:0.06; 13:0.06; 17:0.05; 12:0.04
. 1 .
. . .
2 . .

Reward: +0.00, Result: neutral

--- Step 12 ---
Agent 1: UP, Agent 2: PRESS
  Agent1 beliefs:
    agent_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 8:0.00, 7:0.00
    blue_button_pos: 6:0.96, 2:0.01, 8:0.01
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 6:1.00, 3:0.00, 0:0.00
    red_button_pos: 1:0.97, 4:0.01, 3:0.01
    blue_button_pos: 6:1.00, 4:0.00, 3:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 4:0.04; 28:0.04; 22:0.04; 10:0.04; 24:0.03
  Agent2 top policies: 26:0.17; 25:0.17; 24:0.16; 27:0.15; 28:0.14
. 1 .
. . .
2 . .

Reward: +1.00, Result: win
Button pressed: blue by Agent 2

Result: ✅ WIN - win (steps: 12, reward: +1.00)

================================================================================
EPISODE 56
================================================================================
Environment: Red at (1, 0), Blue at (0, 2)

Initial state:
1 r .
. . .
b . 2


--- Step 1 ---
Agent 1: DOWN, Agent 2: LEFT
  Agent1 beliefs:
    agent_pos: 0:1.00, 8:0.00, 7:0.00
    red_button_pos: 8:0.12, 7:0.12, 6:0.12
    blue_button_pos: 8:0.12, 7:0.12, 6:0.12
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 8:1.00, 7:0.00, 6:0.00
    red_button_pos: 7:0.12, 3:0.12, 6:0.12
    blue_button_pos: 7:0.12, 3:0.12, 6:0.12
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 10:0.21; 22:0.21; 9:0.06; 19:0.06; 21:0.05
  Agent2 top policies: 16:0.21; 4:0.21; 12:0.06; 2:0.06; 0:0.05
. r .
1 . .
b 2 .

Reward: +0.00, Result: neutral

--- Step 2 ---
Agent 1: RIGHT, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 3:1.00, 0:0.00, 8:0.00
    red_button_pos: 8:0.14, 7:0.14, 6:0.14
    blue_button_pos: 8:0.14, 7:0.14, 6:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 7:1.00, 8:0.00, 6:0.00
    red_button_pos: 6:0.14, 1:0.14, 5:0.14
    blue_button_pos: 6:0.14, 1:0.14, 5:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 22:0.23; 10:0.23; 9:0.06; 21:0.05; 19:0.05
  Agent2 top policies: 4:0.23; 16:0.23; 12:0.06; 0:0.05; 2:0.05
. r .
. 1 .
b 2 .

Reward: +0.00, Result: neutral

--- Step 3 ---
Agent 1: RIGHT, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 4:1.00, 3:0.00, 0:0.00
    red_button_pos: 8:0.17, 7:0.17, 6:0.17
    blue_button_pos: 8:0.17, 7:0.17, 6:0.17
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 7:0.87, 4:0.12, 8:0.00
    red_button_pos: 6:0.14, 1:0.14, 5:0.14
    blue_button_pos: 6:0.14, 1:0.14, 5:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 22:0.18; 10:0.18; 4:0.18; 21:0.04; 9:0.04
  Agent2 top policies: 4:0.24; 16:0.23; 12:0.06; 2:0.05; 14:0.05
. r .
. 2 1
b . .

Reward: +0.00, Result: neutral

--- Step 4 ---
Agent 1: DOWN, Agent 2: LEFT
  Agent1 beliefs:
    agent_pos: 5:1.00, 4:0.00, 3:0.00
    red_button_pos: 8:0.20, 7:0.20, 6:0.20
    blue_button_pos: 8:0.20, 7:0.20, 6:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 4:1.00, 1:0.00, 7:0.00
    red_button_pos: 6:0.17, 1:0.17, 5:0.17
    blue_button_pos: 6:0.17, 1:0.17, 5:0.17
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 10:0.27; 4:0.27; 8:0.05; 2:0.05; 7:0.05
  Agent2 top policies: 16:0.18; 22:0.18; 4:0.18; 12:0.04; 18:0.04
. r .
2 . .
b . 1

Reward: +0.00, Result: neutral

--- Step 5 ---
Agent 1: LEFT, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 8:1.00, 5:0.00, 4:0.00
    red_button_pos: 7:0.25, 1:0.25, 6:0.25
    blue_button_pos: 7:0.25, 1:0.25, 6:0.25
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 3:1.00, 4:0.00, 7:0.00
    red_button_pos: 6:0.20, 5:0.20, 0:0.20
    blue_button_pos: 6:0.20, 5:0.20, 0:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 16:0.63; 14:0.09; 13:0.09; 17:0.07; 12:0.01
  Agent2 top policies: 4:0.28; 10:0.28; 3:0.05; 0:0.05; 2:0.05
2 r .
. . .
b 1 .

Reward: +0.00, Result: neutral

--- Step 6 ---
Agent 1: LEFT, Agent 2: RIGHT
  Agent1 beliefs:
    agent_pos: 7:1.00, 8:0.00, 5:0.00
    red_button_pos: 1:0.32, 2:0.32, 6:0.32
    blue_button_pos: 1:0.32, 2:0.32, 6:0.32
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 0:1.00, 3:0.00, 4:0.00
    red_button_pos: 6:0.24, 1:0.24, 5:0.24
    blue_button_pos: 6:0.24, 1:0.24, 5:0.24
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 16:0.72; 14:0.08; 13:0.08; 17:0.06; 12:0.01
  Agent2 top policies: 22:0.63; 21:0.09; 18:0.09; 23:0.07; 19:0.01
. 2 .
. . .
1 . .

Reward: +0.00, Result: neutral

--- Step 7 ---
Agent 1: UP, Agent 2: RIGHT
  Agent1 beliefs:
    agent_pos: 6:1.00, 3:0.00, 0:0.00
    red_button_pos: 1:0.47, 2:0.47, 0:0.02
    blue_button_pos: 6:1.00, 1:0.00, 2:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 1:1.00, 8:0.00, 5:0.00
    red_button_pos: 1:1.00, 2:0.00, 6:0.00
    blue_button_pos: 6:0.32, 2:0.32, 5:0.32
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 4:0.05; 1:0.05; 0:0.05; 3:0.05; 2:0.04
  Agent2 top policies: 22:0.18; 19:0.09; 21:0.09; 18:0.09; 23:0.07
. r 2
1 . .
b . .

Reward: +0.00, Result: neutral

--- Step 8 ---
Agent 1: UP, Agent 2: DOWN
  Agent1 beliefs:
    agent_pos: 3:1.00, 7:0.00, 8:0.00
    red_button_pos: 1:0.47, 2:0.47, 0:0.02
    blue_button_pos: 6:0.99, 1:0.00, 2:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 2:1.00, 0:0.00, 3:0.00
    red_button_pos: 1:0.99, 5:0.00, 6:0.00
    blue_button_pos: 6:0.47, 5:0.47, 8:0.02
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 3:0.10; 18:0.09; 4:0.04; 8:0.04; 7:0.04
  Agent2 top policies: 10:0.23; 9:0.13; 11:0.10; 7:0.05; 8:0.04
1 r .
. . 2
b . .

Reward: +0.00, Result: neutral

--- Step 9 ---
Agent 1: RIGHT, Agent 2: DOWN
  Agent1 beliefs:
    agent_pos: 0:1.00, 3:0.00, 7:0.00
    red_button_pos: 1:0.48, 2:0.48, 4:0.01
    blue_button_pos: 6:0.98, 1:0.00, 2:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 5:1.00, 2:0.00, 0:0.00
    red_button_pos: 1:0.98, 6:0.00, 8:0.00
    blue_button_pos: 6:0.87, 8:0.05, 7:0.03
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 22:0.40; 18:0.10; 21:0.10; 23:0.08; 19:0.03
  Agent2 top policies: 10:0.06; 7:0.05; 9:0.05; 16:0.04; 8:0.04
. 1 .
. . .
b . 2

Reward: +0.00, Result: neutral

--- Step 10 ---
Agent 1: PRESS, Agent 2: LEFT
  Agent1 beliefs:
    agent_pos: 1:1.00, 8:0.00, 5:0.00
    red_button_pos: 1:1.00, 2:0.00, 4:0.00
    blue_button_pos: 6:0.98, 2:0.00, 4:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 8:1.00, 5:0.00, 2:0.00
    red_button_pos: 1:0.98, 6:0.00, 7:0.00
    blue_button_pos: 6:0.90, 7:0.03, 4:0.02
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 24:0.06; 4:0.06; 25:0.06; 27:0.05; 26:0.05
  Agent2 top policies: 16:0.07; 14:0.07; 13:0.04; 12:0.04; 26:0.03
. 1 .
. . .
b 2 .

Reward: +0.00, Result: neutral
Button pressed: red by Agent 1

--- Step 11 ---
Agent 1: UP, Agent 2: LEFT
  Agent1 beliefs:
    agent_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 2:0.00, 8:0.00
    blue_button_pos: 6:0.97, 2:0.00, 4:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 7:1.00, 8:0.00, 5:0.00
    red_button_pos: 1:0.97, 6:0.00, 4:0.00
    blue_button_pos: 6:0.92, 4:0.03, 3:0.02
    red_button_state: 0:0.50, 1:0.50
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 4:0.04; 28:0.04; 24:0.04; 0:0.04; 22:0.04
  Agent2 top policies: 16:0.16; 14:0.06; 13:0.06; 17:0.05; 12:0.04
. 1 .
. . .
2 . .

Reward: +0.00, Result: neutral

--- Step 12 ---
Agent 1: UP, Agent 2: PRESS
  Agent1 beliefs:
    agent_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 8:0.00, 7:0.00
    blue_button_pos: 6:0.96, 2:0.01, 8:0.01
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 6:1.00, 3:0.00, 0:0.00
    red_button_pos: 1:0.97, 4:0.01, 3:0.01
    blue_button_pos: 6:1.00, 4:0.00, 3:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 4:0.04; 28:0.04; 22:0.04; 10:0.04; 24:0.03
  Agent2 top policies: 26:0.17; 25:0.17; 24:0.16; 27:0.15; 28:0.14
. 1 .
. . .
2 . .

Reward: +1.00, Result: win
Button pressed: blue by Agent 2

Result: ✅ WIN - win (steps: 12, reward: +1.00)

================================================================================
EPISODE 57
================================================================================
Environment: Red at (1, 0), Blue at (0, 2)

Initial state:
1 r .
. . .
b . 2


--- Step 1 ---
Agent 1: DOWN, Agent 2: LEFT
  Agent1 beliefs:
    agent_pos: 0:1.00, 8:0.00, 7:0.00
    red_button_pos: 8:0.12, 7:0.12, 6:0.12
    blue_button_pos: 8:0.12, 7:0.12, 6:0.12
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 8:1.00, 7:0.00, 6:0.00
    red_button_pos: 7:0.12, 3:0.12, 6:0.12
    blue_button_pos: 7:0.12, 3:0.12, 6:0.12
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 10:0.21; 22:0.21; 9:0.06; 19:0.06; 21:0.05
  Agent2 top policies: 16:0.21; 4:0.21; 12:0.06; 2:0.06; 0:0.05
. r .
1 . .
b 2 .

Reward: +0.00, Result: neutral

--- Step 2 ---
Agent 1: RIGHT, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 3:1.00, 0:0.00, 8:0.00
    red_button_pos: 8:0.14, 7:0.14, 6:0.14
    blue_button_pos: 8:0.14, 7:0.14, 6:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 7:1.00, 8:0.00, 6:0.00
    red_button_pos: 6:0.14, 1:0.14, 5:0.14
    blue_button_pos: 6:0.14, 1:0.14, 5:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 22:0.23; 10:0.23; 9:0.06; 21:0.05; 19:0.05
  Agent2 top policies: 4:0.23; 16:0.23; 12:0.06; 0:0.05; 2:0.05
. r .
. 1 .
b 2 .

Reward: +0.00, Result: neutral

--- Step 3 ---
Agent 1: RIGHT, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 4:1.00, 3:0.00, 0:0.00
    red_button_pos: 8:0.17, 7:0.17, 6:0.17
    blue_button_pos: 8:0.17, 7:0.17, 6:0.17
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 7:0.87, 4:0.12, 8:0.00
    red_button_pos: 6:0.14, 1:0.14, 5:0.14
    blue_button_pos: 6:0.14, 1:0.14, 5:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 22:0.18; 10:0.18; 4:0.18; 21:0.04; 9:0.04
  Agent2 top policies: 4:0.24; 16:0.23; 12:0.06; 2:0.05; 14:0.05
. r .
. 2 1
b . .

Reward: +0.00, Result: neutral

--- Step 4 ---
Agent 1: DOWN, Agent 2: LEFT
  Agent1 beliefs:
    agent_pos: 5:1.00, 4:0.00, 3:0.00
    red_button_pos: 8:0.20, 7:0.20, 6:0.20
    blue_button_pos: 8:0.20, 7:0.20, 6:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 4:1.00, 1:0.00, 7:0.00
    red_button_pos: 6:0.17, 1:0.17, 5:0.17
    blue_button_pos: 6:0.17, 1:0.17, 5:0.17
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 10:0.27; 4:0.27; 8:0.05; 2:0.05; 7:0.05
  Agent2 top policies: 16:0.18; 22:0.18; 4:0.18; 12:0.04; 18:0.04
. r .
2 . .
b . 1

Reward: +0.00, Result: neutral

--- Step 5 ---
Agent 1: LEFT, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 8:1.00, 5:0.00, 4:0.00
    red_button_pos: 7:0.25, 1:0.25, 6:0.25
    blue_button_pos: 7:0.25, 1:0.25, 6:0.25
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 3:1.00, 4:0.00, 7:0.00
    red_button_pos: 6:0.20, 5:0.20, 0:0.20
    blue_button_pos: 6:0.20, 5:0.20, 0:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 16:0.63; 14:0.09; 13:0.09; 17:0.07; 12:0.01
  Agent2 top policies: 4:0.28; 10:0.28; 3:0.05; 0:0.05; 2:0.05
2 r .
. . .
b 1 .

Reward: +0.00, Result: neutral

--- Step 6 ---
Agent 1: LEFT, Agent 2: RIGHT
  Agent1 beliefs:
    agent_pos: 7:1.00, 8:0.00, 5:0.00
    red_button_pos: 1:0.32, 2:0.32, 6:0.32
    blue_button_pos: 1:0.32, 2:0.32, 6:0.32
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 0:1.00, 3:0.00, 4:0.00
    red_button_pos: 6:0.24, 1:0.24, 5:0.24
    blue_button_pos: 6:0.24, 1:0.24, 5:0.24
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 16:0.72; 14:0.08; 13:0.08; 17:0.06; 12:0.01
  Agent2 top policies: 22:0.63; 21:0.09; 18:0.09; 23:0.07; 19:0.01
. 2 .
. . .
1 . .

Reward: +0.00, Result: neutral

--- Step 7 ---
Agent 1: UP, Agent 2: RIGHT
  Agent1 beliefs:
    agent_pos: 6:1.00, 3:0.00, 0:0.00
    red_button_pos: 1:0.47, 2:0.47, 0:0.02
    blue_button_pos: 6:1.00, 1:0.00, 2:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 1:1.00, 8:0.00, 5:0.00
    red_button_pos: 1:1.00, 2:0.00, 6:0.00
    blue_button_pos: 6:0.32, 2:0.32, 5:0.32
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 4:0.05; 1:0.05; 0:0.05; 3:0.05; 2:0.04
  Agent2 top policies: 22:0.18; 19:0.09; 21:0.09; 18:0.09; 23:0.07
. r 2
1 . .
b . .

Reward: +0.00, Result: neutral

--- Step 8 ---
Agent 1: UP, Agent 2: DOWN
  Agent1 beliefs:
    agent_pos: 3:1.00, 7:0.00, 8:0.00
    red_button_pos: 1:0.47, 2:0.47, 0:0.02
    blue_button_pos: 6:0.99, 1:0.00, 2:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 2:1.00, 0:0.00, 3:0.00
    red_button_pos: 1:0.99, 5:0.00, 6:0.00
    blue_button_pos: 6:0.47, 5:0.47, 8:0.02
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 3:0.10; 18:0.09; 4:0.04; 8:0.04; 7:0.04
  Agent2 top policies: 10:0.23; 9:0.13; 11:0.10; 7:0.05; 8:0.04
1 r .
. . 2
b . .

Reward: +0.00, Result: neutral

--- Step 9 ---
Agent 1: RIGHT, Agent 2: DOWN
  Agent1 beliefs:
    agent_pos: 0:1.00, 3:0.00, 7:0.00
    red_button_pos: 1:0.48, 2:0.48, 4:0.01
    blue_button_pos: 6:0.98, 1:0.00, 2:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 5:1.00, 2:0.00, 0:0.00
    red_button_pos: 1:0.98, 6:0.00, 8:0.00
    blue_button_pos: 6:0.87, 8:0.05, 7:0.03
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 22:0.40; 18:0.10; 21:0.10; 23:0.08; 19:0.03
  Agent2 top policies: 10:0.06; 7:0.05; 9:0.05; 16:0.04; 8:0.04
. 1 .
. . .
b . 2

Reward: +0.00, Result: neutral

--- Step 10 ---
Agent 1: PRESS, Agent 2: LEFT
  Agent1 beliefs:
    agent_pos: 1:1.00, 8:0.00, 5:0.00
    red_button_pos: 1:1.00, 2:0.00, 4:0.00
    blue_button_pos: 6:0.98, 2:0.00, 4:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 8:1.00, 5:0.00, 2:0.00
    red_button_pos: 1:0.98, 6:0.00, 7:0.00
    blue_button_pos: 6:0.90, 7:0.03, 4:0.02
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 24:0.06; 4:0.06; 25:0.06; 27:0.05; 26:0.05
  Agent2 top policies: 16:0.07; 14:0.07; 13:0.04; 12:0.04; 26:0.03
. 1 .
. . .
b 2 .

Reward: +0.00, Result: neutral
Button pressed: red by Agent 1

--- Step 11 ---
Agent 1: UP, Agent 2: LEFT
  Agent1 beliefs:
    agent_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 2:0.00, 8:0.00
    blue_button_pos: 6:0.97, 2:0.00, 4:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 7:1.00, 8:0.00, 5:0.00
    red_button_pos: 1:0.97, 6:0.00, 4:0.00
    blue_button_pos: 6:0.92, 4:0.03, 3:0.02
    red_button_state: 0:0.50, 1:0.50
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 4:0.04; 28:0.04; 24:0.04; 0:0.04; 22:0.04
  Agent2 top policies: 16:0.16; 14:0.06; 13:0.06; 17:0.05; 12:0.04
. 1 .
. . .
2 . .

Reward: +0.00, Result: neutral

--- Step 12 ---
Agent 1: UP, Agent 2: PRESS
  Agent1 beliefs:
    agent_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 8:0.00, 7:0.00
    blue_button_pos: 6:0.96, 2:0.01, 8:0.01
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 6:1.00, 3:0.00, 0:0.00
    red_button_pos: 1:0.97, 4:0.01, 3:0.01
    blue_button_pos: 6:1.00, 4:0.00, 3:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 4:0.04; 28:0.04; 22:0.04; 10:0.04; 24:0.03
  Agent2 top policies: 26:0.17; 25:0.17; 24:0.16; 27:0.15; 28:0.14
. 1 .
. . .
2 . .

Reward: +1.00, Result: win
Button pressed: blue by Agent 2

Result: ✅ WIN - win (steps: 12, reward: +1.00)

================================================================================
EPISODE 58
================================================================================
Environment: Red at (1, 0), Blue at (0, 2)

Initial state:
1 r .
. . .
b . 2


--- Step 1 ---
Agent 1: DOWN, Agent 2: LEFT
  Agent1 beliefs:
    agent_pos: 0:1.00, 8:0.00, 7:0.00
    red_button_pos: 8:0.12, 7:0.12, 6:0.12
    blue_button_pos: 8:0.12, 7:0.12, 6:0.12
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 8:1.00, 7:0.00, 6:0.00
    red_button_pos: 7:0.12, 3:0.12, 6:0.12
    blue_button_pos: 7:0.12, 3:0.12, 6:0.12
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 10:0.21; 22:0.21; 9:0.06; 19:0.06; 21:0.05
  Agent2 top policies: 16:0.21; 4:0.21; 12:0.06; 2:0.06; 0:0.05
. r .
1 . .
b 2 .

Reward: +0.00, Result: neutral

--- Step 2 ---
Agent 1: RIGHT, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 3:1.00, 0:0.00, 8:0.00
    red_button_pos: 8:0.14, 7:0.14, 6:0.14
    blue_button_pos: 8:0.14, 7:0.14, 6:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 7:1.00, 8:0.00, 6:0.00
    red_button_pos: 6:0.14, 1:0.14, 5:0.14
    blue_button_pos: 6:0.14, 1:0.14, 5:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 22:0.23; 10:0.23; 9:0.06; 21:0.05; 19:0.05
  Agent2 top policies: 4:0.23; 16:0.23; 12:0.06; 0:0.05; 2:0.05
. r .
. 1 .
b 2 .

Reward: +0.00, Result: neutral

--- Step 3 ---
Agent 1: RIGHT, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 4:1.00, 3:0.00, 0:0.00
    red_button_pos: 8:0.17, 7:0.17, 6:0.17
    blue_button_pos: 8:0.17, 7:0.17, 6:0.17
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 7:0.87, 4:0.12, 8:0.00
    red_button_pos: 6:0.14, 1:0.14, 5:0.14
    blue_button_pos: 6:0.14, 1:0.14, 5:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 22:0.18; 10:0.18; 4:0.18; 21:0.04; 9:0.04
  Agent2 top policies: 4:0.24; 16:0.23; 12:0.06; 2:0.05; 14:0.05
. r .
. 2 1
b . .

Reward: +0.00, Result: neutral

--- Step 4 ---
Agent 1: DOWN, Agent 2: LEFT
  Agent1 beliefs:
    agent_pos: 5:1.00, 4:0.00, 3:0.00
    red_button_pos: 8:0.20, 7:0.20, 6:0.20
    blue_button_pos: 8:0.20, 7:0.20, 6:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 4:1.00, 1:0.00, 7:0.00
    red_button_pos: 6:0.17, 1:0.17, 5:0.17
    blue_button_pos: 6:0.17, 1:0.17, 5:0.17
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 10:0.27; 4:0.27; 8:0.05; 2:0.05; 7:0.05
  Agent2 top policies: 16:0.18; 22:0.18; 4:0.18; 12:0.04; 18:0.04
. r .
2 . .
b . 1

Reward: +0.00, Result: neutral

--- Step 5 ---
Agent 1: LEFT, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 8:1.00, 5:0.00, 4:0.00
    red_button_pos: 7:0.25, 1:0.25, 6:0.25
    blue_button_pos: 7:0.25, 1:0.25, 6:0.25
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 3:1.00, 4:0.00, 7:0.00
    red_button_pos: 6:0.20, 5:0.20, 0:0.20
    blue_button_pos: 6:0.20, 5:0.20, 0:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 16:0.63; 14:0.09; 13:0.09; 17:0.07; 12:0.01
  Agent2 top policies: 4:0.28; 10:0.28; 3:0.05; 0:0.05; 2:0.05
2 r .
. . .
b 1 .

Reward: +0.00, Result: neutral

--- Step 6 ---
Agent 1: LEFT, Agent 2: RIGHT
  Agent1 beliefs:
    agent_pos: 7:1.00, 8:0.00, 5:0.00
    red_button_pos: 1:0.32, 2:0.32, 6:0.32
    blue_button_pos: 1:0.32, 2:0.32, 6:0.32
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 0:1.00, 3:0.00, 4:0.00
    red_button_pos: 6:0.24, 1:0.24, 5:0.24
    blue_button_pos: 6:0.24, 1:0.24, 5:0.24
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 16:0.72; 14:0.08; 13:0.08; 17:0.06; 12:0.01
  Agent2 top policies: 22:0.63; 21:0.09; 18:0.09; 23:0.07; 19:0.01
. 2 .
. . .
1 . .

Reward: +0.00, Result: neutral

--- Step 7 ---
Agent 1: UP, Agent 2: RIGHT
  Agent1 beliefs:
    agent_pos: 6:1.00, 3:0.00, 0:0.00
    red_button_pos: 1:0.47, 2:0.47, 0:0.02
    blue_button_pos: 6:1.00, 1:0.00, 2:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 1:1.00, 8:0.00, 5:0.00
    red_button_pos: 1:1.00, 2:0.00, 6:0.00
    blue_button_pos: 6:0.32, 2:0.32, 5:0.32
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 4:0.05; 1:0.05; 0:0.05; 3:0.05; 2:0.04
  Agent2 top policies: 22:0.18; 19:0.09; 21:0.09; 18:0.09; 23:0.07
. r 2
1 . .
b . .

Reward: +0.00, Result: neutral

--- Step 8 ---
Agent 1: UP, Agent 2: DOWN
  Agent1 beliefs:
    agent_pos: 3:1.00, 7:0.00, 8:0.00
    red_button_pos: 1:0.47, 2:0.47, 0:0.02
    blue_button_pos: 6:0.99, 1:0.00, 2:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 2:1.00, 0:0.00, 3:0.00
    red_button_pos: 1:0.99, 5:0.00, 6:0.00
    blue_button_pos: 6:0.47, 5:0.47, 8:0.02
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 3:0.10; 18:0.09; 4:0.04; 8:0.04; 7:0.04
  Agent2 top policies: 10:0.23; 9:0.13; 11:0.10; 7:0.05; 8:0.04
1 r .
. . 2
b . .

Reward: +0.00, Result: neutral

--- Step 9 ---
Agent 1: RIGHT, Agent 2: DOWN
  Agent1 beliefs:
    agent_pos: 0:1.00, 3:0.00, 7:0.00
    red_button_pos: 1:0.48, 2:0.48, 4:0.01
    blue_button_pos: 6:0.98, 1:0.00, 2:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 5:1.00, 2:0.00, 0:0.00
    red_button_pos: 1:0.98, 6:0.00, 8:0.00
    blue_button_pos: 6:0.87, 8:0.05, 7:0.03
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 22:0.40; 18:0.10; 21:0.10; 23:0.08; 19:0.03
  Agent2 top policies: 10:0.06; 7:0.05; 9:0.05; 16:0.04; 8:0.04
. 1 .
. . .
b . 2

Reward: +0.00, Result: neutral

--- Step 10 ---
Agent 1: PRESS, Agent 2: LEFT
  Agent1 beliefs:
    agent_pos: 1:1.00, 8:0.00, 5:0.00
    red_button_pos: 1:1.00, 2:0.00, 4:0.00
    blue_button_pos: 6:0.98, 2:0.00, 4:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 8:1.00, 5:0.00, 2:0.00
    red_button_pos: 1:0.98, 6:0.00, 7:0.00
    blue_button_pos: 6:0.90, 7:0.03, 4:0.02
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 24:0.06; 4:0.06; 25:0.06; 27:0.05; 26:0.05
  Agent2 top policies: 16:0.07; 14:0.07; 13:0.04; 12:0.04; 26:0.03
. 1 .
. . .
b 2 .

Reward: +0.00, Result: neutral
Button pressed: red by Agent 1

--- Step 11 ---
Agent 1: UP, Agent 2: LEFT
  Agent1 beliefs:
    agent_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 2:0.00, 8:0.00
    blue_button_pos: 6:0.97, 2:0.00, 4:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 7:1.00, 8:0.00, 5:0.00
    red_button_pos: 1:0.97, 6:0.00, 4:0.00
    blue_button_pos: 6:0.92, 4:0.03, 3:0.02
    red_button_state: 0:0.50, 1:0.50
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 4:0.04; 28:0.04; 24:0.04; 0:0.04; 22:0.04
  Agent2 top policies: 16:0.16; 14:0.06; 13:0.06; 17:0.05; 12:0.04
. 1 .
. . .
2 . .

Reward: +0.00, Result: neutral

--- Step 12 ---
Agent 1: UP, Agent 2: PRESS
  Agent1 beliefs:
    agent_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 8:0.00, 7:0.00
    blue_button_pos: 6:0.96, 2:0.01, 8:0.01
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 6:1.00, 3:0.00, 0:0.00
    red_button_pos: 1:0.97, 4:0.01, 3:0.01
    blue_button_pos: 6:1.00, 4:0.00, 3:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 4:0.04; 28:0.04; 22:0.04; 10:0.04; 24:0.03
  Agent2 top policies: 26:0.17; 25:0.17; 24:0.16; 27:0.15; 28:0.14
. 1 .
. . .
2 . .

Reward: +1.00, Result: win
Button pressed: blue by Agent 2

Result: ✅ WIN - win (steps: 12, reward: +1.00)

================================================================================
EPISODE 59
================================================================================
Environment: Red at (1, 0), Blue at (0, 2)

Initial state:
1 r .
. . .
b . 2


--- Step 1 ---
Agent 1: DOWN, Agent 2: LEFT
  Agent1 beliefs:
    agent_pos: 0:1.00, 8:0.00, 7:0.00
    red_button_pos: 8:0.12, 7:0.12, 6:0.12
    blue_button_pos: 8:0.12, 7:0.12, 6:0.12
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 8:1.00, 7:0.00, 6:0.00
    red_button_pos: 7:0.12, 3:0.12, 6:0.12
    blue_button_pos: 7:0.12, 3:0.12, 6:0.12
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 10:0.21; 22:0.21; 9:0.06; 19:0.06; 21:0.05
  Agent2 top policies: 16:0.21; 4:0.21; 12:0.06; 2:0.06; 0:0.05
. r .
1 . .
b 2 .

Reward: +0.00, Result: neutral

--- Step 2 ---
Agent 1: RIGHT, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 3:1.00, 0:0.00, 8:0.00
    red_button_pos: 8:0.14, 7:0.14, 6:0.14
    blue_button_pos: 8:0.14, 7:0.14, 6:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 7:1.00, 8:0.00, 6:0.00
    red_button_pos: 6:0.14, 1:0.14, 5:0.14
    blue_button_pos: 6:0.14, 1:0.14, 5:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 22:0.23; 10:0.23; 9:0.06; 21:0.05; 19:0.05
  Agent2 top policies: 4:0.23; 16:0.23; 12:0.06; 0:0.05; 2:0.05
. r .
. 1 .
b 2 .

Reward: +0.00, Result: neutral

--- Step 3 ---
Agent 1: RIGHT, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 4:1.00, 3:0.00, 0:0.00
    red_button_pos: 8:0.17, 7:0.17, 6:0.17
    blue_button_pos: 8:0.17, 7:0.17, 6:0.17
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 7:0.87, 4:0.12, 8:0.00
    red_button_pos: 6:0.14, 1:0.14, 5:0.14
    blue_button_pos: 6:0.14, 1:0.14, 5:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 22:0.18; 10:0.18; 4:0.18; 21:0.04; 9:0.04
  Agent2 top policies: 4:0.24; 16:0.23; 12:0.06; 2:0.05; 14:0.05
. r .
. 2 1
b . .

Reward: +0.00, Result: neutral

--- Step 4 ---
Agent 1: DOWN, Agent 2: LEFT
  Agent1 beliefs:
    agent_pos: 5:1.00, 4:0.00, 3:0.00
    red_button_pos: 8:0.20, 7:0.20, 6:0.20
    blue_button_pos: 8:0.20, 7:0.20, 6:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 4:1.00, 1:0.00, 7:0.00
    red_button_pos: 6:0.17, 1:0.17, 5:0.17
    blue_button_pos: 6:0.17, 1:0.17, 5:0.17
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 10:0.27; 4:0.27; 8:0.05; 2:0.05; 7:0.05
  Agent2 top policies: 16:0.18; 22:0.18; 4:0.18; 12:0.04; 18:0.04
. r .
2 . .
b . 1

Reward: +0.00, Result: neutral

--- Step 5 ---
Agent 1: LEFT, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 8:1.00, 5:0.00, 4:0.00
    red_button_pos: 7:0.25, 1:0.25, 6:0.25
    blue_button_pos: 7:0.25, 1:0.25, 6:0.25
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 3:1.00, 4:0.00, 7:0.00
    red_button_pos: 6:0.20, 5:0.20, 0:0.20
    blue_button_pos: 6:0.20, 5:0.20, 0:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 16:0.63; 14:0.09; 13:0.09; 17:0.07; 12:0.01
  Agent2 top policies: 4:0.28; 10:0.28; 3:0.05; 0:0.05; 2:0.05
2 r .
. . .
b 1 .

Reward: +0.00, Result: neutral

--- Step 6 ---
Agent 1: LEFT, Agent 2: RIGHT
  Agent1 beliefs:
    agent_pos: 7:1.00, 8:0.00, 5:0.00
    red_button_pos: 1:0.32, 2:0.32, 6:0.32
    blue_button_pos: 1:0.32, 2:0.32, 6:0.32
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 0:1.00, 3:0.00, 4:0.00
    red_button_pos: 6:0.24, 1:0.24, 5:0.24
    blue_button_pos: 6:0.24, 1:0.24, 5:0.24
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 16:0.72; 14:0.08; 13:0.08; 17:0.06; 12:0.01
  Agent2 top policies: 22:0.63; 21:0.09; 18:0.09; 23:0.07; 19:0.01
. 2 .
. . .
1 . .

Reward: +0.00, Result: neutral

--- Step 7 ---
Agent 1: UP, Agent 2: RIGHT
  Agent1 beliefs:
    agent_pos: 6:1.00, 3:0.00, 0:0.00
    red_button_pos: 1:0.47, 2:0.47, 0:0.02
    blue_button_pos: 6:1.00, 1:0.00, 2:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 1:1.00, 8:0.00, 5:0.00
    red_button_pos: 1:1.00, 2:0.00, 6:0.00
    blue_button_pos: 6:0.32, 2:0.32, 5:0.32
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 4:0.05; 1:0.05; 0:0.05; 3:0.05; 2:0.04
  Agent2 top policies: 22:0.18; 19:0.09; 21:0.09; 18:0.09; 23:0.07
. r 2
1 . .
b . .

Reward: +0.00, Result: neutral

--- Step 8 ---
Agent 1: UP, Agent 2: DOWN
  Agent1 beliefs:
    agent_pos: 3:1.00, 7:0.00, 8:0.00
    red_button_pos: 1:0.47, 2:0.47, 0:0.02
    blue_button_pos: 6:0.99, 1:0.00, 2:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 2:1.00, 0:0.00, 3:0.00
    red_button_pos: 1:0.99, 5:0.00, 6:0.00
    blue_button_pos: 6:0.47, 5:0.47, 8:0.02
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 3:0.10; 18:0.09; 4:0.04; 8:0.04; 7:0.04
  Agent2 top policies: 10:0.23; 9:0.13; 11:0.10; 7:0.05; 8:0.04
1 r .
. . 2
b . .

Reward: +0.00, Result: neutral

--- Step 9 ---
Agent 1: RIGHT, Agent 2: DOWN
  Agent1 beliefs:
    agent_pos: 0:1.00, 3:0.00, 7:0.00
    red_button_pos: 1:0.48, 2:0.48, 4:0.01
    blue_button_pos: 6:0.98, 1:0.00, 2:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 5:1.00, 2:0.00, 0:0.00
    red_button_pos: 1:0.98, 6:0.00, 8:0.00
    blue_button_pos: 6:0.87, 8:0.05, 7:0.03
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 22:0.40; 18:0.10; 21:0.10; 23:0.08; 19:0.03
  Agent2 top policies: 10:0.06; 7:0.05; 9:0.05; 16:0.04; 8:0.04
. 1 .
. . .
b . 2

Reward: +0.00, Result: neutral

--- Step 10 ---
Agent 1: PRESS, Agent 2: LEFT
  Agent1 beliefs:
    agent_pos: 1:1.00, 8:0.00, 5:0.00
    red_button_pos: 1:1.00, 2:0.00, 4:0.00
    blue_button_pos: 6:0.98, 2:0.00, 4:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 8:1.00, 5:0.00, 2:0.00
    red_button_pos: 1:0.98, 6:0.00, 7:0.00
    blue_button_pos: 6:0.90, 7:0.03, 4:0.02
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 24:0.06; 4:0.06; 25:0.06; 27:0.05; 26:0.05
  Agent2 top policies: 16:0.07; 14:0.07; 13:0.04; 12:0.04; 26:0.03
. 1 .
. . .
b 2 .

Reward: +0.00, Result: neutral
Button pressed: red by Agent 1

--- Step 11 ---
Agent 1: UP, Agent 2: LEFT
  Agent1 beliefs:
    agent_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 2:0.00, 8:0.00
    blue_button_pos: 6:0.97, 2:0.00, 4:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 7:1.00, 8:0.00, 5:0.00
    red_button_pos: 1:0.97, 6:0.00, 4:0.00
    blue_button_pos: 6:0.92, 4:0.03, 3:0.02
    red_button_state: 0:0.50, 1:0.50
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 4:0.04; 28:0.04; 24:0.04; 0:0.04; 22:0.04
  Agent2 top policies: 16:0.16; 14:0.06; 13:0.06; 17:0.05; 12:0.04
. 1 .
. . .
2 . .

Reward: +0.00, Result: neutral

--- Step 12 ---
Agent 1: UP, Agent 2: PRESS
  Agent1 beliefs:
    agent_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 8:0.00, 7:0.00
    blue_button_pos: 6:0.96, 2:0.01, 8:0.01
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 6:1.00, 3:0.00, 0:0.00
    red_button_pos: 1:0.97, 4:0.01, 3:0.01
    blue_button_pos: 6:1.00, 4:0.00, 3:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 4:0.04; 28:0.04; 22:0.04; 10:0.04; 24:0.03
  Agent2 top policies: 26:0.17; 25:0.17; 24:0.16; 27:0.15; 28:0.14
. 1 .
. . .
2 . .

Reward: +1.00, Result: win
Button pressed: blue by Agent 2

Result: ✅ WIN - win (steps: 12, reward: +1.00)

================================================================================
EPISODE 60
================================================================================
Environment: Red at (1, 0), Blue at (0, 2)

Initial state:
1 r .
. . .
b . 2


--- Step 1 ---
Agent 1: DOWN, Agent 2: LEFT
  Agent1 beliefs:
    agent_pos: 0:1.00, 8:0.00, 7:0.00
    red_button_pos: 8:0.12, 7:0.12, 6:0.12
    blue_button_pos: 8:0.12, 7:0.12, 6:0.12
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 8:1.00, 7:0.00, 6:0.00
    red_button_pos: 7:0.12, 3:0.12, 6:0.12
    blue_button_pos: 7:0.12, 3:0.12, 6:0.12
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 10:0.21; 22:0.21; 9:0.06; 19:0.06; 21:0.05
  Agent2 top policies: 16:0.21; 4:0.21; 12:0.06; 2:0.06; 0:0.05
. r .
1 . .
b 2 .

Reward: +0.00, Result: neutral

--- Step 2 ---
Agent 1: RIGHT, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 3:1.00, 0:0.00, 8:0.00
    red_button_pos: 8:0.14, 7:0.14, 6:0.14
    blue_button_pos: 8:0.14, 7:0.14, 6:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 7:1.00, 8:0.00, 6:0.00
    red_button_pos: 6:0.14, 1:0.14, 5:0.14
    blue_button_pos: 6:0.14, 1:0.14, 5:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 22:0.23; 10:0.23; 9:0.06; 21:0.05; 19:0.05
  Agent2 top policies: 4:0.23; 16:0.23; 12:0.06; 0:0.05; 2:0.05
. r .
. 1 .
b 2 .

Reward: +0.00, Result: neutral

--- Step 3 ---
Agent 1: RIGHT, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 4:1.00, 3:0.00, 0:0.00
    red_button_pos: 8:0.17, 7:0.17, 6:0.17
    blue_button_pos: 8:0.17, 7:0.17, 6:0.17
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 7:0.87, 4:0.12, 8:0.00
    red_button_pos: 6:0.14, 1:0.14, 5:0.14
    blue_button_pos: 6:0.14, 1:0.14, 5:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 22:0.18; 10:0.18; 4:0.18; 21:0.04; 9:0.04
  Agent2 top policies: 4:0.24; 16:0.23; 12:0.06; 2:0.05; 14:0.05
. r .
. 2 1
b . .

Reward: +0.00, Result: neutral

--- Step 4 ---
Agent 1: DOWN, Agent 2: LEFT
  Agent1 beliefs:
    agent_pos: 5:1.00, 4:0.00, 3:0.00
    red_button_pos: 8:0.20, 7:0.20, 6:0.20
    blue_button_pos: 8:0.20, 7:0.20, 6:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 4:1.00, 1:0.00, 7:0.00
    red_button_pos: 6:0.17, 1:0.17, 5:0.17
    blue_button_pos: 6:0.17, 1:0.17, 5:0.17
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 10:0.27; 4:0.27; 8:0.05; 2:0.05; 7:0.05
  Agent2 top policies: 16:0.18; 22:0.18; 4:0.18; 12:0.04; 18:0.04
. r .
2 . .
b . 1

Reward: +0.00, Result: neutral

--- Step 5 ---
Agent 1: LEFT, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 8:1.00, 5:0.00, 4:0.00
    red_button_pos: 7:0.25, 1:0.25, 6:0.25
    blue_button_pos: 7:0.25, 1:0.25, 6:0.25
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 3:1.00, 4:0.00, 7:0.00
    red_button_pos: 6:0.20, 5:0.20, 0:0.20
    blue_button_pos: 6:0.20, 5:0.20, 0:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 16:0.63; 14:0.09; 13:0.09; 17:0.07; 12:0.01
  Agent2 top policies: 4:0.28; 10:0.28; 3:0.05; 0:0.05; 2:0.05
2 r .
. . .
b 1 .

Reward: +0.00, Result: neutral

--- Step 6 ---
Agent 1: LEFT, Agent 2: RIGHT
  Agent1 beliefs:
    agent_pos: 7:1.00, 8:0.00, 5:0.00
    red_button_pos: 1:0.32, 2:0.32, 6:0.32
    blue_button_pos: 1:0.32, 2:0.32, 6:0.32
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 0:1.00, 3:0.00, 4:0.00
    red_button_pos: 6:0.24, 1:0.24, 5:0.24
    blue_button_pos: 6:0.24, 1:0.24, 5:0.24
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 16:0.72; 14:0.08; 13:0.08; 17:0.06; 12:0.01
  Agent2 top policies: 22:0.63; 21:0.09; 18:0.09; 23:0.07; 19:0.01
. 2 .
. . .
1 . .

Reward: +0.00, Result: neutral

--- Step 7 ---
Agent 1: UP, Agent 2: RIGHT
  Agent1 beliefs:
    agent_pos: 6:1.00, 3:0.00, 0:0.00
    red_button_pos: 1:0.47, 2:0.47, 0:0.02
    blue_button_pos: 6:1.00, 1:0.00, 2:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 1:1.00, 8:0.00, 5:0.00
    red_button_pos: 1:1.00, 2:0.00, 6:0.00
    blue_button_pos: 6:0.32, 2:0.32, 5:0.32
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 4:0.05; 1:0.05; 0:0.05; 3:0.05; 2:0.04
  Agent2 top policies: 22:0.18; 19:0.09; 21:0.09; 18:0.09; 23:0.07
. r 2
1 . .
b . .

Reward: +0.00, Result: neutral

--- Step 8 ---
Agent 1: UP, Agent 2: DOWN
  Agent1 beliefs:
    agent_pos: 3:1.00, 7:0.00, 8:0.00
    red_button_pos: 1:0.47, 2:0.47, 0:0.02
    blue_button_pos: 6:0.99, 1:0.00, 2:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 2:1.00, 0:0.00, 3:0.00
    red_button_pos: 1:0.99, 5:0.00, 6:0.00
    blue_button_pos: 6:0.47, 5:0.47, 8:0.02
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 3:0.10; 18:0.09; 4:0.04; 8:0.04; 7:0.04
  Agent2 top policies: 10:0.23; 9:0.13; 11:0.10; 7:0.05; 8:0.04
1 r .
. . 2
b . .

Reward: +0.00, Result: neutral

--- Step 9 ---
Agent 1: RIGHT, Agent 2: DOWN
  Agent1 beliefs:
    agent_pos: 0:1.00, 3:0.00, 7:0.00
    red_button_pos: 1:0.48, 2:0.48, 4:0.01
    blue_button_pos: 6:0.98, 1:0.00, 2:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 5:1.00, 2:0.00, 0:0.00
    red_button_pos: 1:0.98, 6:0.00, 8:0.00
    blue_button_pos: 6:0.87, 8:0.05, 7:0.03
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 22:0.40; 18:0.10; 21:0.10; 23:0.08; 19:0.03
  Agent2 top policies: 10:0.06; 7:0.05; 9:0.05; 16:0.04; 8:0.04
. 1 .
. . .
b . 2

Reward: +0.00, Result: neutral

--- Step 10 ---
Agent 1: PRESS, Agent 2: LEFT
  Agent1 beliefs:
    agent_pos: 1:1.00, 8:0.00, 5:0.00
    red_button_pos: 1:1.00, 2:0.00, 4:0.00
    blue_button_pos: 6:0.98, 2:0.00, 4:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 8:1.00, 5:0.00, 2:0.00
    red_button_pos: 1:0.98, 6:0.00, 7:0.00
    blue_button_pos: 6:0.90, 7:0.03, 4:0.02
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 24:0.06; 4:0.06; 25:0.06; 27:0.05; 26:0.05
  Agent2 top policies: 16:0.07; 14:0.07; 13:0.04; 12:0.04; 26:0.03
. 1 .
. . .
b 2 .

Reward: +0.00, Result: neutral
Button pressed: red by Agent 1

--- Step 11 ---
Agent 1: UP, Agent 2: LEFT
  Agent1 beliefs:
    agent_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 2:0.00, 8:0.00
    blue_button_pos: 6:0.97, 2:0.00, 4:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 7:1.00, 8:0.00, 5:0.00
    red_button_pos: 1:0.97, 6:0.00, 4:0.00
    blue_button_pos: 6:0.92, 4:0.03, 3:0.02
    red_button_state: 0:0.50, 1:0.50
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 4:0.04; 28:0.04; 24:0.04; 0:0.04; 22:0.04
  Agent2 top policies: 16:0.16; 14:0.06; 13:0.06; 17:0.05; 12:0.04
. 1 .
. . .
2 . .

Reward: +0.00, Result: neutral

--- Step 12 ---
Agent 1: UP, Agent 2: PRESS
  Agent1 beliefs:
    agent_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 8:0.00, 7:0.00
    blue_button_pos: 6:0.96, 2:0.01, 8:0.01
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 6:1.00, 3:0.00, 0:0.00
    red_button_pos: 1:0.97, 4:0.01, 3:0.01
    blue_button_pos: 6:1.00, 4:0.00, 3:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 4:0.04; 28:0.04; 22:0.04; 10:0.04; 24:0.03
  Agent2 top policies: 26:0.17; 25:0.17; 24:0.16; 27:0.15; 28:0.14
. 1 .
. . .
2 . .

Reward: +1.00, Result: win
Button pressed: blue by Agent 2

Result: ✅ WIN - win (steps: 12, reward: +1.00)

================================================================================
SEED 0 - CONFIG 4
Red at (1, 2), Blue at (0, 1)
Episodes 61-80
================================================================================

================================================================================
EPISODE 61
================================================================================
Environment: Red at (1, 2), Blue at (0, 1)

Initial state:
1 . .
b . .
. r 2


--- Step 1 ---
Agent 1: DOWN, Agent 2: LEFT
  Agent1 beliefs:
    agent_pos: 0:1.00, 8:0.00, 7:0.00
    red_button_pos: 8:0.12, 7:0.12, 6:0.12
    blue_button_pos: 8:0.12, 7:0.12, 6:0.12
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 8:1.00, 7:0.00, 6:0.00
    red_button_pos: 7:0.12, 3:0.12, 6:0.12
    blue_button_pos: 7:0.12, 3:0.12, 6:0.12
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 10:0.21; 22:0.21; 9:0.06; 19:0.06; 21:0.05
  Agent2 top policies: 16:0.21; 4:0.21; 12:0.06; 2:0.06; 0:0.05
. . .
1 . .
. 2 .

Reward: +0.00, Result: neutral

--- Step 2 ---
Agent 1: RIGHT, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 3:1.00, 8:0.00, 7:0.00
    red_button_pos: 8:0.14, 7:0.14, 6:0.14
    blue_button_pos: 3:1.00, 8:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 7:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:1.00, 3:0.00, 6:0.00
    blue_button_pos: 6:0.14, 1:0.14, 5:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 22:0.13; 10:0.13; 9:0.06; 21:0.06; 19:0.06
  Agent2 top policies: 4:0.08; 16:0.08; 24:0.05; 26:0.05; 12:0.05
. . .
b 1 .
. 2 .

Reward: +0.00, Result: neutral

--- Step 3 ---
Agent 1: RIGHT, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 4:1.00, 0:0.00, 8:0.00
    red_button_pos: 8:0.17, 7:0.17, 6:0.17
    blue_button_pos: 3:0.99, 8:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 7:1.00, 4:0.00, 8:0.00
    red_button_pos: 7:1.00, 3:0.00, 6:0.00
    blue_button_pos: 6:0.14, 1:0.14, 5:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 22:0.10; 10:0.10; 4:0.10; 21:0.04; 9:0.04
  Agent2 top policies: 4:0.08; 16:0.08; 24:0.05; 26:0.05; 12:0.05
. . .
b 2 1
. r .

Reward: +0.00, Result: neutral

--- Step 4 ---
Agent 1: DOWN, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 5:1.00, 4:0.00, 0:0.00
    red_button_pos: 8:0.20, 7:0.20, 6:0.20
    blue_button_pos: 3:0.98, 8:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 4:1.00, 8:0.00, 1:0.00
    red_button_pos: 7:0.99, 8:0.00, 6:0.00
    blue_button_pos: 6:0.17, 1:0.17, 5:0.17
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 10:0.15; 4:0.15; 8:0.06; 2:0.06; 7:0.05
  Agent2 top policies: 4:0.08; 16:0.08; 22:0.08; 0:0.04; 12:0.04
. 2 .
b . .
. r 1

Reward: +0.00, Result: neutral

--- Step 5 ---
Agent 1: LEFT, Agent 2: LEFT
  Agent1 beliefs:
    agent_pos: 8:1.00, 5:0.00, 4:0.00
    red_button_pos: 7:0.25, 1:0.25, 6:0.25
    blue_button_pos: 3:0.98, 1:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 1:1.00, 4:0.00, 8:0.00
    red_button_pos: 7:0.98, 8:0.00, 6:0.00
    blue_button_pos: 6:0.20, 5:0.20, 0:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 16:0.28; 14:0.09; 13:0.09; 17:0.07; 12:0.04
  Agent2 top policies: 16:0.11; 22:0.11; 13:0.06; 19:0.06; 14:0.06
2 . .
b . .
. 1 .

Reward: +0.00, Result: neutral

--- Step 6 ---
Agent 1: PRESS, Agent 2: DOWN
  Agent1 beliefs:
    agent_pos: 7:1.00, 0:0.00, 6:0.00
    red_button_pos: 7:1.00, 1:0.00, 6:0.00
    blue_button_pos: 3:0.97, 2:0.00, 6:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 0:1.00, 1:0.00, 4:0.00
    red_button_pos: 7:0.98, 8:0.00, 6:0.00
    blue_button_pos: 6:0.24, 2:0.24, 5:0.24
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 25:0.06; 10:0.06; 24:0.06; 26:0.05; 27:0.05
  Agent2 top policies: 10:0.20; 7:0.10; 8:0.10; 11:0.08; 9:0.04
. . .
2 . .
. 1 .

Reward: +0.00, Result: neutral
Button pressed: red by Agent 1

--- Step 7 ---
Agent 1: LEFT, Agent 2: PRESS
  Agent1 beliefs:
    agent_pos: 7:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:1.00, 1:0.00, 6:0.00
    blue_button_pos: 3:0.96, 2:0.01, 6:0.01
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 3:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:0.97, 8:0.00, 6:0.00
    blue_button_pos: 3:1.00, 2:0.00, 6:0.00
    red_button_state: 0:0.50, 1:0.50
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 12:0.04; 2:0.04; 28:0.04; 10:0.04; 16:0.04
  Agent2 top policies: 26:0.06; 16:0.06; 27:0.06; 25:0.05; 24:0.05
. . .
2 . .
1 R .

Reward: +1.00, Result: win
Button pressed: blue by Agent 2

Result: ✅ WIN - win (steps: 7, reward: +1.00)

================================================================================
EPISODE 62
================================================================================
Environment: Red at (1, 2), Blue at (0, 1)

Initial state:
1 . .
b . .
. r 2


--- Step 1 ---
Agent 1: DOWN, Agent 2: LEFT
  Agent1 beliefs:
    agent_pos: 0:1.00, 8:0.00, 7:0.00
    red_button_pos: 8:0.12, 7:0.12, 6:0.12
    blue_button_pos: 8:0.12, 7:0.12, 6:0.12
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 8:1.00, 7:0.00, 6:0.00
    red_button_pos: 7:0.12, 3:0.12, 6:0.12
    blue_button_pos: 7:0.12, 3:0.12, 6:0.12
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 10:0.21; 22:0.21; 9:0.06; 19:0.06; 21:0.05
  Agent2 top policies: 16:0.21; 4:0.21; 12:0.06; 2:0.06; 0:0.05
. . .
1 . .
. 2 .

Reward: +0.00, Result: neutral

--- Step 2 ---
Agent 1: RIGHT, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 3:1.00, 8:0.00, 7:0.00
    red_button_pos: 8:0.14, 7:0.14, 6:0.14
    blue_button_pos: 3:1.00, 8:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 7:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:1.00, 3:0.00, 6:0.00
    blue_button_pos: 6:0.14, 1:0.14, 5:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 22:0.13; 10:0.13; 9:0.06; 21:0.06; 19:0.06
  Agent2 top policies: 4:0.08; 16:0.08; 24:0.05; 26:0.05; 12:0.05
. . .
b 1 .
. 2 .

Reward: +0.00, Result: neutral

--- Step 3 ---
Agent 1: RIGHT, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 4:1.00, 0:0.00, 8:0.00
    red_button_pos: 8:0.17, 7:0.17, 6:0.17
    blue_button_pos: 3:0.99, 8:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 7:1.00, 4:0.00, 8:0.00
    red_button_pos: 7:1.00, 3:0.00, 6:0.00
    blue_button_pos: 6:0.14, 1:0.14, 5:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 22:0.10; 10:0.10; 4:0.10; 21:0.04; 9:0.04
  Agent2 top policies: 4:0.08; 16:0.08; 24:0.05; 26:0.05; 12:0.05
. . .
b 2 1
. r .

Reward: +0.00, Result: neutral

--- Step 4 ---
Agent 1: DOWN, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 5:1.00, 4:0.00, 0:0.00
    red_button_pos: 8:0.20, 7:0.20, 6:0.20
    blue_button_pos: 3:0.98, 8:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 4:1.00, 8:0.00, 1:0.00
    red_button_pos: 7:0.99, 8:0.00, 6:0.00
    blue_button_pos: 6:0.17, 1:0.17, 5:0.17
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 10:0.15; 4:0.15; 8:0.06; 2:0.06; 7:0.05
  Agent2 top policies: 4:0.08; 16:0.08; 22:0.08; 0:0.04; 12:0.04
. 2 .
b . .
. r 1

Reward: +0.00, Result: neutral

--- Step 5 ---
Agent 1: LEFT, Agent 2: LEFT
  Agent1 beliefs:
    agent_pos: 8:1.00, 5:0.00, 4:0.00
    red_button_pos: 7:0.25, 1:0.25, 6:0.25
    blue_button_pos: 3:0.98, 1:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 1:1.00, 4:0.00, 8:0.00
    red_button_pos: 7:0.98, 8:0.00, 6:0.00
    blue_button_pos: 6:0.20, 5:0.20, 0:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 16:0.28; 14:0.09; 13:0.09; 17:0.07; 12:0.04
  Agent2 top policies: 16:0.11; 22:0.11; 13:0.06; 19:0.06; 14:0.06
2 . .
b . .
. 1 .

Reward: +0.00, Result: neutral

--- Step 6 ---
Agent 1: PRESS, Agent 2: DOWN
  Agent1 beliefs:
    agent_pos: 7:1.00, 0:0.00, 6:0.00
    red_button_pos: 7:1.00, 1:0.00, 6:0.00
    blue_button_pos: 3:0.97, 2:0.00, 6:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 0:1.00, 1:0.00, 4:0.00
    red_button_pos: 7:0.98, 8:0.00, 6:0.00
    blue_button_pos: 6:0.24, 2:0.24, 5:0.24
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 25:0.06; 10:0.06; 24:0.06; 26:0.05; 27:0.05
  Agent2 top policies: 10:0.20; 7:0.10; 8:0.10; 11:0.08; 9:0.04
. . .
2 . .
. 1 .

Reward: +0.00, Result: neutral
Button pressed: red by Agent 1

--- Step 7 ---
Agent 1: LEFT, Agent 2: PRESS
  Agent1 beliefs:
    agent_pos: 7:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:1.00, 1:0.00, 6:0.00
    blue_button_pos: 3:0.96, 2:0.01, 6:0.01
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 3:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:0.97, 8:0.00, 6:0.00
    blue_button_pos: 3:1.00, 2:0.00, 6:0.00
    red_button_state: 0:0.50, 1:0.50
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 12:0.04; 2:0.04; 28:0.04; 10:0.04; 16:0.04
  Agent2 top policies: 26:0.06; 16:0.06; 27:0.06; 25:0.05; 24:0.05
. . .
2 . .
1 R .

Reward: +1.00, Result: win
Button pressed: blue by Agent 2

Result: ✅ WIN - win (steps: 7, reward: +1.00)

================================================================================
EPISODE 63
================================================================================
Environment: Red at (1, 2), Blue at (0, 1)

Initial state:
1 . .
b . .
. r 2


--- Step 1 ---
Agent 1: DOWN, Agent 2: LEFT
  Agent1 beliefs:
    agent_pos: 0:1.00, 8:0.00, 7:0.00
    red_button_pos: 8:0.12, 7:0.12, 6:0.12
    blue_button_pos: 8:0.12, 7:0.12, 6:0.12
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 8:1.00, 7:0.00, 6:0.00
    red_button_pos: 7:0.12, 3:0.12, 6:0.12
    blue_button_pos: 7:0.12, 3:0.12, 6:0.12
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 10:0.21; 22:0.21; 9:0.06; 19:0.06; 21:0.05
  Agent2 top policies: 16:0.21; 4:0.21; 12:0.06; 2:0.06; 0:0.05
. . .
1 . .
. 2 .

Reward: +0.00, Result: neutral

--- Step 2 ---
Agent 1: RIGHT, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 3:1.00, 8:0.00, 7:0.00
    red_button_pos: 8:0.14, 7:0.14, 6:0.14
    blue_button_pos: 3:1.00, 8:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 7:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:1.00, 3:0.00, 6:0.00
    blue_button_pos: 6:0.14, 1:0.14, 5:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 22:0.13; 10:0.13; 9:0.06; 21:0.06; 19:0.06
  Agent2 top policies: 4:0.08; 16:0.08; 24:0.05; 26:0.05; 12:0.05
. . .
b 1 .
. 2 .

Reward: +0.00, Result: neutral

--- Step 3 ---
Agent 1: RIGHT, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 4:1.00, 0:0.00, 8:0.00
    red_button_pos: 8:0.17, 7:0.17, 6:0.17
    blue_button_pos: 3:0.99, 8:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 7:1.00, 4:0.00, 8:0.00
    red_button_pos: 7:1.00, 3:0.00, 6:0.00
    blue_button_pos: 6:0.14, 1:0.14, 5:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 22:0.10; 10:0.10; 4:0.10; 21:0.04; 9:0.04
  Agent2 top policies: 4:0.08; 16:0.08; 24:0.05; 26:0.05; 12:0.05
. . .
b 2 1
. r .

Reward: +0.00, Result: neutral

--- Step 4 ---
Agent 1: DOWN, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 5:1.00, 4:0.00, 0:0.00
    red_button_pos: 8:0.20, 7:0.20, 6:0.20
    blue_button_pos: 3:0.98, 8:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 4:1.00, 8:0.00, 1:0.00
    red_button_pos: 7:0.99, 8:0.00, 6:0.00
    blue_button_pos: 6:0.17, 1:0.17, 5:0.17
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 10:0.15; 4:0.15; 8:0.06; 2:0.06; 7:0.05
  Agent2 top policies: 4:0.08; 16:0.08; 22:0.08; 0:0.04; 12:0.04
. 2 .
b . .
. r 1

Reward: +0.00, Result: neutral

--- Step 5 ---
Agent 1: LEFT, Agent 2: LEFT
  Agent1 beliefs:
    agent_pos: 8:1.00, 5:0.00, 4:0.00
    red_button_pos: 7:0.25, 1:0.25, 6:0.25
    blue_button_pos: 3:0.98, 1:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 1:1.00, 4:0.00, 8:0.00
    red_button_pos: 7:0.98, 8:0.00, 6:0.00
    blue_button_pos: 6:0.20, 5:0.20, 0:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 16:0.28; 14:0.09; 13:0.09; 17:0.07; 12:0.04
  Agent2 top policies: 16:0.11; 22:0.11; 13:0.06; 19:0.06; 14:0.06
2 . .
b . .
. 1 .

Reward: +0.00, Result: neutral

--- Step 6 ---
Agent 1: PRESS, Agent 2: DOWN
  Agent1 beliefs:
    agent_pos: 7:1.00, 0:0.00, 6:0.00
    red_button_pos: 7:1.00, 1:0.00, 6:0.00
    blue_button_pos: 3:0.97, 2:0.00, 6:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 0:1.00, 1:0.00, 4:0.00
    red_button_pos: 7:0.98, 8:0.00, 6:0.00
    blue_button_pos: 6:0.24, 2:0.24, 5:0.24
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 25:0.06; 10:0.06; 24:0.06; 26:0.05; 27:0.05
  Agent2 top policies: 10:0.20; 7:0.10; 8:0.10; 11:0.08; 9:0.04
. . .
2 . .
. 1 .

Reward: +0.00, Result: neutral
Button pressed: red by Agent 1

--- Step 7 ---
Agent 1: LEFT, Agent 2: PRESS
  Agent1 beliefs:
    agent_pos: 7:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:1.00, 1:0.00, 6:0.00
    blue_button_pos: 3:0.96, 2:0.01, 6:0.01
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 3:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:0.97, 8:0.00, 6:0.00
    blue_button_pos: 3:1.00, 2:0.00, 6:0.00
    red_button_state: 0:0.50, 1:0.50
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 12:0.04; 2:0.04; 28:0.04; 10:0.04; 16:0.04
  Agent2 top policies: 26:0.06; 16:0.06; 27:0.06; 25:0.05; 24:0.05
. . .
2 . .
1 R .

Reward: +1.00, Result: win
Button pressed: blue by Agent 2

Result: ✅ WIN - win (steps: 7, reward: +1.00)

================================================================================
EPISODE 64
================================================================================
Environment: Red at (1, 2), Blue at (0, 1)

Initial state:
1 . .
b . .
. r 2


--- Step 1 ---
Agent 1: DOWN, Agent 2: LEFT
  Agent1 beliefs:
    agent_pos: 0:1.00, 8:0.00, 7:0.00
    red_button_pos: 8:0.12, 7:0.12, 6:0.12
    blue_button_pos: 8:0.12, 7:0.12, 6:0.12
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 8:1.00, 7:0.00, 6:0.00
    red_button_pos: 7:0.12, 3:0.12, 6:0.12
    blue_button_pos: 7:0.12, 3:0.12, 6:0.12
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 10:0.21; 22:0.21; 9:0.06; 19:0.06; 21:0.05
  Agent2 top policies: 16:0.21; 4:0.21; 12:0.06; 2:0.06; 0:0.05
. . .
1 . .
. 2 .

Reward: +0.00, Result: neutral

--- Step 2 ---
Agent 1: RIGHT, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 3:1.00, 8:0.00, 7:0.00
    red_button_pos: 8:0.14, 7:0.14, 6:0.14
    blue_button_pos: 3:1.00, 8:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 7:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:1.00, 3:0.00, 6:0.00
    blue_button_pos: 6:0.14, 1:0.14, 5:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 22:0.13; 10:0.13; 9:0.06; 21:0.06; 19:0.06
  Agent2 top policies: 4:0.08; 16:0.08; 24:0.05; 26:0.05; 12:0.05
. . .
b 1 .
. 2 .

Reward: +0.00, Result: neutral

--- Step 3 ---
Agent 1: RIGHT, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 4:1.00, 0:0.00, 8:0.00
    red_button_pos: 8:0.17, 7:0.17, 6:0.17
    blue_button_pos: 3:0.99, 8:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 7:1.00, 4:0.00, 8:0.00
    red_button_pos: 7:1.00, 3:0.00, 6:0.00
    blue_button_pos: 6:0.14, 1:0.14, 5:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 22:0.10; 10:0.10; 4:0.10; 21:0.04; 9:0.04
  Agent2 top policies: 4:0.08; 16:0.08; 24:0.05; 26:0.05; 12:0.05
. . .
b 2 1
. r .

Reward: +0.00, Result: neutral

--- Step 4 ---
Agent 1: DOWN, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 5:1.00, 4:0.00, 0:0.00
    red_button_pos: 8:0.20, 7:0.20, 6:0.20
    blue_button_pos: 3:0.98, 8:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 4:1.00, 8:0.00, 1:0.00
    red_button_pos: 7:0.99, 8:0.00, 6:0.00
    blue_button_pos: 6:0.17, 1:0.17, 5:0.17
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 10:0.15; 4:0.15; 8:0.06; 2:0.06; 7:0.05
  Agent2 top policies: 4:0.08; 16:0.08; 22:0.08; 0:0.04; 12:0.04
. 2 .
b . .
. r 1

Reward: +0.00, Result: neutral

--- Step 5 ---
Agent 1: LEFT, Agent 2: LEFT
  Agent1 beliefs:
    agent_pos: 8:1.00, 5:0.00, 4:0.00
    red_button_pos: 7:0.25, 1:0.25, 6:0.25
    blue_button_pos: 3:0.98, 1:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 1:1.00, 4:0.00, 8:0.00
    red_button_pos: 7:0.98, 8:0.00, 6:0.00
    blue_button_pos: 6:0.20, 5:0.20, 0:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 16:0.28; 14:0.09; 13:0.09; 17:0.07; 12:0.04
  Agent2 top policies: 16:0.11; 22:0.11; 13:0.06; 19:0.06; 14:0.06
2 . .
b . .
. 1 .

Reward: +0.00, Result: neutral

--- Step 6 ---
Agent 1: PRESS, Agent 2: DOWN
  Agent1 beliefs:
    agent_pos: 7:1.00, 0:0.00, 6:0.00
    red_button_pos: 7:1.00, 1:0.00, 6:0.00
    blue_button_pos: 3:0.97, 2:0.00, 6:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 0:1.00, 1:0.00, 4:0.00
    red_button_pos: 7:0.98, 8:0.00, 6:0.00
    blue_button_pos: 6:0.24, 2:0.24, 5:0.24
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 25:0.06; 10:0.06; 24:0.06; 26:0.05; 27:0.05
  Agent2 top policies: 10:0.20; 7:0.10; 8:0.10; 11:0.08; 9:0.04
. . .
2 . .
. 1 .

Reward: +0.00, Result: neutral
Button pressed: red by Agent 1

--- Step 7 ---
Agent 1: LEFT, Agent 2: PRESS
  Agent1 beliefs:
    agent_pos: 7:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:1.00, 1:0.00, 6:0.00
    blue_button_pos: 3:0.96, 2:0.01, 6:0.01
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 3:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:0.97, 8:0.00, 6:0.00
    blue_button_pos: 3:1.00, 2:0.00, 6:0.00
    red_button_state: 0:0.50, 1:0.50
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 12:0.04; 2:0.04; 28:0.04; 10:0.04; 16:0.04
  Agent2 top policies: 26:0.06; 16:0.06; 27:0.06; 25:0.05; 24:0.05
. . .
2 . .
1 R .

Reward: +1.00, Result: win
Button pressed: blue by Agent 2

Result: ✅ WIN - win (steps: 7, reward: +1.00)

================================================================================
EPISODE 65
================================================================================
Environment: Red at (1, 2), Blue at (0, 1)

Initial state:
1 . .
b . .
. r 2


--- Step 1 ---
Agent 1: DOWN, Agent 2: LEFT
  Agent1 beliefs:
    agent_pos: 0:1.00, 8:0.00, 7:0.00
    red_button_pos: 8:0.12, 7:0.12, 6:0.12
    blue_button_pos: 8:0.12, 7:0.12, 6:0.12
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 8:1.00, 7:0.00, 6:0.00
    red_button_pos: 7:0.12, 3:0.12, 6:0.12
    blue_button_pos: 7:0.12, 3:0.12, 6:0.12
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 10:0.21; 22:0.21; 9:0.06; 19:0.06; 21:0.05
  Agent2 top policies: 16:0.21; 4:0.21; 12:0.06; 2:0.06; 0:0.05
. . .
1 . .
. 2 .

Reward: +0.00, Result: neutral

--- Step 2 ---
Agent 1: RIGHT, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 3:1.00, 8:0.00, 7:0.00
    red_button_pos: 8:0.14, 7:0.14, 6:0.14
    blue_button_pos: 3:1.00, 8:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 7:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:1.00, 3:0.00, 6:0.00
    blue_button_pos: 6:0.14, 1:0.14, 5:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 22:0.13; 10:0.13; 9:0.06; 21:0.06; 19:0.06
  Agent2 top policies: 4:0.08; 16:0.08; 24:0.05; 26:0.05; 12:0.05
. . .
b 1 .
. 2 .

Reward: +0.00, Result: neutral

--- Step 3 ---
Agent 1: RIGHT, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 4:1.00, 0:0.00, 8:0.00
    red_button_pos: 8:0.17, 7:0.17, 6:0.17
    blue_button_pos: 3:0.99, 8:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 7:1.00, 4:0.00, 8:0.00
    red_button_pos: 7:1.00, 3:0.00, 6:0.00
    blue_button_pos: 6:0.14, 1:0.14, 5:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 22:0.10; 10:0.10; 4:0.10; 21:0.04; 9:0.04
  Agent2 top policies: 4:0.08; 16:0.08; 24:0.05; 26:0.05; 12:0.05
. . .
b 2 1
. r .

Reward: +0.00, Result: neutral

--- Step 4 ---
Agent 1: DOWN, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 5:1.00, 4:0.00, 0:0.00
    red_button_pos: 8:0.20, 7:0.20, 6:0.20
    blue_button_pos: 3:0.98, 8:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 4:1.00, 8:0.00, 1:0.00
    red_button_pos: 7:0.99, 8:0.00, 6:0.00
    blue_button_pos: 6:0.17, 1:0.17, 5:0.17
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 10:0.15; 4:0.15; 8:0.06; 2:0.06; 7:0.05
  Agent2 top policies: 4:0.08; 16:0.08; 22:0.08; 0:0.04; 12:0.04
. 2 .
b . .
. r 1

Reward: +0.00, Result: neutral

--- Step 5 ---
Agent 1: LEFT, Agent 2: LEFT
  Agent1 beliefs:
    agent_pos: 8:1.00, 5:0.00, 4:0.00
    red_button_pos: 7:0.25, 1:0.25, 6:0.25
    blue_button_pos: 3:0.98, 1:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 1:1.00, 4:0.00, 8:0.00
    red_button_pos: 7:0.98, 8:0.00, 6:0.00
    blue_button_pos: 6:0.20, 5:0.20, 0:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 16:0.28; 14:0.09; 13:0.09; 17:0.07; 12:0.04
  Agent2 top policies: 16:0.11; 22:0.11; 13:0.06; 19:0.06; 14:0.06
2 . .
b . .
. 1 .

Reward: +0.00, Result: neutral

--- Step 6 ---
Agent 1: PRESS, Agent 2: DOWN
  Agent1 beliefs:
    agent_pos: 7:1.00, 0:0.00, 6:0.00
    red_button_pos: 7:1.00, 1:0.00, 6:0.00
    blue_button_pos: 3:0.97, 2:0.00, 6:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 0:1.00, 1:0.00, 4:0.00
    red_button_pos: 7:0.98, 8:0.00, 6:0.00
    blue_button_pos: 6:0.24, 2:0.24, 5:0.24
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 25:0.06; 10:0.06; 24:0.06; 26:0.05; 27:0.05
  Agent2 top policies: 10:0.20; 7:0.10; 8:0.10; 11:0.08; 9:0.04
. . .
2 . .
. 1 .

Reward: +0.00, Result: neutral
Button pressed: red by Agent 1

--- Step 7 ---
Agent 1: LEFT, Agent 2: PRESS
  Agent1 beliefs:
    agent_pos: 7:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:1.00, 1:0.00, 6:0.00
    blue_button_pos: 3:0.96, 2:0.01, 6:0.01
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 3:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:0.97, 8:0.00, 6:0.00
    blue_button_pos: 3:1.00, 2:0.00, 6:0.00
    red_button_state: 0:0.50, 1:0.50
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 12:0.04; 2:0.04; 28:0.04; 10:0.04; 16:0.04
  Agent2 top policies: 26:0.06; 16:0.06; 27:0.06; 25:0.05; 24:0.05
. . .
2 . .
1 R .

Reward: +1.00, Result: win
Button pressed: blue by Agent 2

Result: ✅ WIN - win (steps: 7, reward: +1.00)

================================================================================
EPISODE 66
================================================================================
Environment: Red at (1, 2), Blue at (0, 1)

Initial state:
1 . .
b . .
. r 2


--- Step 1 ---
Agent 1: DOWN, Agent 2: LEFT
  Agent1 beliefs:
    agent_pos: 0:1.00, 8:0.00, 7:0.00
    red_button_pos: 8:0.12, 7:0.12, 6:0.12
    blue_button_pos: 8:0.12, 7:0.12, 6:0.12
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 8:1.00, 7:0.00, 6:0.00
    red_button_pos: 7:0.12, 3:0.12, 6:0.12
    blue_button_pos: 7:0.12, 3:0.12, 6:0.12
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 10:0.21; 22:0.21; 9:0.06; 19:0.06; 21:0.05
  Agent2 top policies: 16:0.21; 4:0.21; 12:0.06; 2:0.06; 0:0.05
. . .
1 . .
. 2 .

Reward: +0.00, Result: neutral

--- Step 2 ---
Agent 1: RIGHT, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 3:1.00, 8:0.00, 7:0.00
    red_button_pos: 8:0.14, 7:0.14, 6:0.14
    blue_button_pos: 3:1.00, 8:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 7:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:1.00, 3:0.00, 6:0.00
    blue_button_pos: 6:0.14, 1:0.14, 5:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 22:0.13; 10:0.13; 9:0.06; 21:0.06; 19:0.06
  Agent2 top policies: 4:0.08; 16:0.08; 24:0.05; 26:0.05; 12:0.05
. . .
b 1 .
. 2 .

Reward: +0.00, Result: neutral

--- Step 3 ---
Agent 1: RIGHT, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 4:1.00, 0:0.00, 8:0.00
    red_button_pos: 8:0.17, 7:0.17, 6:0.17
    blue_button_pos: 3:0.99, 8:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 7:1.00, 4:0.00, 8:0.00
    red_button_pos: 7:1.00, 3:0.00, 6:0.00
    blue_button_pos: 6:0.14, 1:0.14, 5:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 22:0.10; 10:0.10; 4:0.10; 21:0.04; 9:0.04
  Agent2 top policies: 4:0.08; 16:0.08; 24:0.05; 26:0.05; 12:0.05
. . .
b 2 1
. r .

Reward: +0.00, Result: neutral

--- Step 4 ---
Agent 1: DOWN, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 5:1.00, 4:0.00, 0:0.00
    red_button_pos: 8:0.20, 7:0.20, 6:0.20
    blue_button_pos: 3:0.98, 8:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 4:1.00, 8:0.00, 1:0.00
    red_button_pos: 7:0.99, 8:0.00, 6:0.00
    blue_button_pos: 6:0.17, 1:0.17, 5:0.17
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 10:0.15; 4:0.15; 8:0.06; 2:0.06; 7:0.05
  Agent2 top policies: 4:0.08; 16:0.08; 22:0.08; 0:0.04; 12:0.04
. 2 .
b . .
. r 1

Reward: +0.00, Result: neutral

--- Step 5 ---
Agent 1: LEFT, Agent 2: LEFT
  Agent1 beliefs:
    agent_pos: 8:1.00, 5:0.00, 4:0.00
    red_button_pos: 7:0.25, 1:0.25, 6:0.25
    blue_button_pos: 3:0.98, 1:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 1:1.00, 4:0.00, 8:0.00
    red_button_pos: 7:0.98, 8:0.00, 6:0.00
    blue_button_pos: 6:0.20, 5:0.20, 0:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 16:0.28; 14:0.09; 13:0.09; 17:0.07; 12:0.04
  Agent2 top policies: 16:0.11; 22:0.11; 13:0.06; 19:0.06; 14:0.06
2 . .
b . .
. 1 .

Reward: +0.00, Result: neutral

--- Step 6 ---
Agent 1: PRESS, Agent 2: DOWN
  Agent1 beliefs:
    agent_pos: 7:1.00, 0:0.00, 6:0.00
    red_button_pos: 7:1.00, 1:0.00, 6:0.00
    blue_button_pos: 3:0.97, 2:0.00, 6:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 0:1.00, 1:0.00, 4:0.00
    red_button_pos: 7:0.98, 8:0.00, 6:0.00
    blue_button_pos: 6:0.24, 2:0.24, 5:0.24
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 25:0.06; 10:0.06; 24:0.06; 26:0.05; 27:0.05
  Agent2 top policies: 10:0.20; 7:0.10; 8:0.10; 11:0.08; 9:0.04
. . .
2 . .
. 1 .

Reward: +0.00, Result: neutral
Button pressed: red by Agent 1

--- Step 7 ---
Agent 1: LEFT, Agent 2: PRESS
  Agent1 beliefs:
    agent_pos: 7:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:1.00, 1:0.00, 6:0.00
    blue_button_pos: 3:0.96, 2:0.01, 6:0.01
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 3:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:0.97, 8:0.00, 6:0.00
    blue_button_pos: 3:1.00, 2:0.00, 6:0.00
    red_button_state: 0:0.50, 1:0.50
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 12:0.04; 2:0.04; 28:0.04; 10:0.04; 16:0.04
  Agent2 top policies: 26:0.06; 16:0.06; 27:0.06; 25:0.05; 24:0.05
. . .
2 . .
1 R .

Reward: +1.00, Result: win
Button pressed: blue by Agent 2

Result: ✅ WIN - win (steps: 7, reward: +1.00)

================================================================================
EPISODE 67
================================================================================
Environment: Red at (1, 2), Blue at (0, 1)

Initial state:
1 . .
b . .
. r 2


--- Step 1 ---
Agent 1: DOWN, Agent 2: LEFT
  Agent1 beliefs:
    agent_pos: 0:1.00, 8:0.00, 7:0.00
    red_button_pos: 8:0.12, 7:0.12, 6:0.12
    blue_button_pos: 8:0.12, 7:0.12, 6:0.12
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 8:1.00, 7:0.00, 6:0.00
    red_button_pos: 7:0.12, 3:0.12, 6:0.12
    blue_button_pos: 7:0.12, 3:0.12, 6:0.12
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 10:0.21; 22:0.21; 9:0.06; 19:0.06; 21:0.05
  Agent2 top policies: 16:0.21; 4:0.21; 12:0.06; 2:0.06; 0:0.05
. . .
1 . .
. 2 .

Reward: +0.00, Result: neutral

--- Step 2 ---
Agent 1: RIGHT, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 3:1.00, 8:0.00, 7:0.00
    red_button_pos: 8:0.14, 7:0.14, 6:0.14
    blue_button_pos: 3:1.00, 8:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 7:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:1.00, 3:0.00, 6:0.00
    blue_button_pos: 6:0.14, 1:0.14, 5:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 22:0.13; 10:0.13; 9:0.06; 21:0.06; 19:0.06
  Agent2 top policies: 4:0.08; 16:0.08; 24:0.05; 26:0.05; 12:0.05
. . .
b 1 .
. 2 .

Reward: +0.00, Result: neutral

--- Step 3 ---
Agent 1: RIGHT, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 4:1.00, 0:0.00, 8:0.00
    red_button_pos: 8:0.17, 7:0.17, 6:0.17
    blue_button_pos: 3:0.99, 8:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 7:1.00, 4:0.00, 8:0.00
    red_button_pos: 7:1.00, 3:0.00, 6:0.00
    blue_button_pos: 6:0.14, 1:0.14, 5:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 22:0.10; 10:0.10; 4:0.10; 21:0.04; 9:0.04
  Agent2 top policies: 4:0.08; 16:0.08; 24:0.05; 26:0.05; 12:0.05
. . .
b 2 1
. r .

Reward: +0.00, Result: neutral

--- Step 4 ---
Agent 1: DOWN, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 5:1.00, 4:0.00, 0:0.00
    red_button_pos: 8:0.20, 7:0.20, 6:0.20
    blue_button_pos: 3:0.98, 8:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 4:1.00, 8:0.00, 1:0.00
    red_button_pos: 7:0.99, 8:0.00, 6:0.00
    blue_button_pos: 6:0.17, 1:0.17, 5:0.17
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 10:0.15; 4:0.15; 8:0.06; 2:0.06; 7:0.05
  Agent2 top policies: 4:0.08; 16:0.08; 22:0.08; 0:0.04; 12:0.04
. 2 .
b . .
. r 1

Reward: +0.00, Result: neutral

--- Step 5 ---
Agent 1: LEFT, Agent 2: LEFT
  Agent1 beliefs:
    agent_pos: 8:1.00, 5:0.00, 4:0.00
    red_button_pos: 7:0.25, 1:0.25, 6:0.25
    blue_button_pos: 3:0.98, 1:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 1:1.00, 4:0.00, 8:0.00
    red_button_pos: 7:0.98, 8:0.00, 6:0.00
    blue_button_pos: 6:0.20, 5:0.20, 0:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 16:0.28; 14:0.09; 13:0.09; 17:0.07; 12:0.04
  Agent2 top policies: 16:0.11; 22:0.11; 13:0.06; 19:0.06; 14:0.06
2 . .
b . .
. 1 .

Reward: +0.00, Result: neutral

--- Step 6 ---
Agent 1: PRESS, Agent 2: DOWN
  Agent1 beliefs:
    agent_pos: 7:1.00, 0:0.00, 6:0.00
    red_button_pos: 7:1.00, 1:0.00, 6:0.00
    blue_button_pos: 3:0.97, 2:0.00, 6:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 0:1.00, 1:0.00, 4:0.00
    red_button_pos: 7:0.98, 8:0.00, 6:0.00
    blue_button_pos: 6:0.24, 2:0.24, 5:0.24
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 25:0.06; 10:0.06; 24:0.06; 26:0.05; 27:0.05
  Agent2 top policies: 10:0.20; 7:0.10; 8:0.10; 11:0.08; 9:0.04
. . .
2 . .
. 1 .

Reward: +0.00, Result: neutral
Button pressed: red by Agent 1

--- Step 7 ---
Agent 1: LEFT, Agent 2: PRESS
  Agent1 beliefs:
    agent_pos: 7:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:1.00, 1:0.00, 6:0.00
    blue_button_pos: 3:0.96, 2:0.01, 6:0.01
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 3:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:0.97, 8:0.00, 6:0.00
    blue_button_pos: 3:1.00, 2:0.00, 6:0.00
    red_button_state: 0:0.50, 1:0.50
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 12:0.04; 2:0.04; 28:0.04; 10:0.04; 16:0.04
  Agent2 top policies: 26:0.06; 16:0.06; 27:0.06; 25:0.05; 24:0.05
. . .
2 . .
1 R .

Reward: +1.00, Result: win
Button pressed: blue by Agent 2

Result: ✅ WIN - win (steps: 7, reward: +1.00)

================================================================================
EPISODE 68
================================================================================
Environment: Red at (1, 2), Blue at (0, 1)

Initial state:
1 . .
b . .
. r 2


--- Step 1 ---
Agent 1: DOWN, Agent 2: LEFT
  Agent1 beliefs:
    agent_pos: 0:1.00, 8:0.00, 7:0.00
    red_button_pos: 8:0.12, 7:0.12, 6:0.12
    blue_button_pos: 8:0.12, 7:0.12, 6:0.12
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 8:1.00, 7:0.00, 6:0.00
    red_button_pos: 7:0.12, 3:0.12, 6:0.12
    blue_button_pos: 7:0.12, 3:0.12, 6:0.12
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 10:0.21; 22:0.21; 9:0.06; 19:0.06; 21:0.05
  Agent2 top policies: 16:0.21; 4:0.21; 12:0.06; 2:0.06; 0:0.05
. . .
1 . .
. 2 .

Reward: +0.00, Result: neutral

--- Step 2 ---
Agent 1: RIGHT, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 3:1.00, 8:0.00, 7:0.00
    red_button_pos: 8:0.14, 7:0.14, 6:0.14
    blue_button_pos: 3:1.00, 8:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 7:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:1.00, 3:0.00, 6:0.00
    blue_button_pos: 6:0.14, 1:0.14, 5:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 22:0.13; 10:0.13; 9:0.06; 21:0.06; 19:0.06
  Agent2 top policies: 4:0.08; 16:0.08; 24:0.05; 26:0.05; 12:0.05
. . .
b 1 .
. 2 .

Reward: +0.00, Result: neutral

--- Step 3 ---
Agent 1: RIGHT, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 4:1.00, 0:0.00, 8:0.00
    red_button_pos: 8:0.17, 7:0.17, 6:0.17
    blue_button_pos: 3:0.99, 8:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 7:1.00, 4:0.00, 8:0.00
    red_button_pos: 7:1.00, 3:0.00, 6:0.00
    blue_button_pos: 6:0.14, 1:0.14, 5:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 22:0.10; 10:0.10; 4:0.10; 21:0.04; 9:0.04
  Agent2 top policies: 4:0.08; 16:0.08; 24:0.05; 26:0.05; 12:0.05
. . .
b 2 1
. r .

Reward: +0.00, Result: neutral

--- Step 4 ---
Agent 1: DOWN, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 5:1.00, 4:0.00, 0:0.00
    red_button_pos: 8:0.20, 7:0.20, 6:0.20
    blue_button_pos: 3:0.98, 8:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 4:1.00, 8:0.00, 1:0.00
    red_button_pos: 7:0.99, 8:0.00, 6:0.00
    blue_button_pos: 6:0.17, 1:0.17, 5:0.17
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 10:0.15; 4:0.15; 8:0.06; 2:0.06; 7:0.05
  Agent2 top policies: 4:0.08; 16:0.08; 22:0.08; 0:0.04; 12:0.04
. 2 .
b . .
. r 1

Reward: +0.00, Result: neutral

--- Step 5 ---
Agent 1: LEFT, Agent 2: LEFT
  Agent1 beliefs:
    agent_pos: 8:1.00, 5:0.00, 4:0.00
    red_button_pos: 7:0.25, 1:0.25, 6:0.25
    blue_button_pos: 3:0.98, 1:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 1:1.00, 4:0.00, 8:0.00
    red_button_pos: 7:0.98, 8:0.00, 6:0.00
    blue_button_pos: 6:0.20, 5:0.20, 0:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 16:0.28; 14:0.09; 13:0.09; 17:0.07; 12:0.04
  Agent2 top policies: 16:0.11; 22:0.11; 13:0.06; 19:0.06; 14:0.06
2 . .
b . .
. 1 .

Reward: +0.00, Result: neutral

--- Step 6 ---
Agent 1: PRESS, Agent 2: DOWN
  Agent1 beliefs:
    agent_pos: 7:1.00, 0:0.00, 6:0.00
    red_button_pos: 7:1.00, 1:0.00, 6:0.00
    blue_button_pos: 3:0.97, 2:0.00, 6:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 0:1.00, 1:0.00, 4:0.00
    red_button_pos: 7:0.98, 8:0.00, 6:0.00
    blue_button_pos: 6:0.24, 2:0.24, 5:0.24
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 25:0.06; 10:0.06; 24:0.06; 26:0.05; 27:0.05
  Agent2 top policies: 10:0.20; 7:0.10; 8:0.10; 11:0.08; 9:0.04
. . .
2 . .
. 1 .

Reward: +0.00, Result: neutral
Button pressed: red by Agent 1

--- Step 7 ---
Agent 1: LEFT, Agent 2: PRESS
  Agent1 beliefs:
    agent_pos: 7:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:1.00, 1:0.00, 6:0.00
    blue_button_pos: 3:0.96, 2:0.01, 6:0.01
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 3:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:0.97, 8:0.00, 6:0.00
    blue_button_pos: 3:1.00, 2:0.00, 6:0.00
    red_button_state: 0:0.50, 1:0.50
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 12:0.04; 2:0.04; 28:0.04; 10:0.04; 16:0.04
  Agent2 top policies: 26:0.06; 16:0.06; 27:0.06; 25:0.05; 24:0.05
. . .
2 . .
1 R .

Reward: +1.00, Result: win
Button pressed: blue by Agent 2

Result: ✅ WIN - win (steps: 7, reward: +1.00)

================================================================================
EPISODE 69
================================================================================
Environment: Red at (1, 2), Blue at (0, 1)

Initial state:
1 . .
b . .
. r 2


--- Step 1 ---
Agent 1: DOWN, Agent 2: LEFT
  Agent1 beliefs:
    agent_pos: 0:1.00, 8:0.00, 7:0.00
    red_button_pos: 8:0.12, 7:0.12, 6:0.12
    blue_button_pos: 8:0.12, 7:0.12, 6:0.12
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 8:1.00, 7:0.00, 6:0.00
    red_button_pos: 7:0.12, 3:0.12, 6:0.12
    blue_button_pos: 7:0.12, 3:0.12, 6:0.12
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 10:0.21; 22:0.21; 9:0.06; 19:0.06; 21:0.05
  Agent2 top policies: 16:0.21; 4:0.21; 12:0.06; 2:0.06; 0:0.05
. . .
1 . .
. 2 .

Reward: +0.00, Result: neutral

--- Step 2 ---
Agent 1: RIGHT, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 3:1.00, 8:0.00, 7:0.00
    red_button_pos: 8:0.14, 7:0.14, 6:0.14
    blue_button_pos: 3:1.00, 8:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 7:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:1.00, 3:0.00, 6:0.00
    blue_button_pos: 6:0.14, 1:0.14, 5:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 22:0.13; 10:0.13; 9:0.06; 21:0.06; 19:0.06
  Agent2 top policies: 4:0.08; 16:0.08; 24:0.05; 26:0.05; 12:0.05
. . .
b 1 .
. 2 .

Reward: +0.00, Result: neutral

--- Step 3 ---
Agent 1: RIGHT, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 4:1.00, 0:0.00, 8:0.00
    red_button_pos: 8:0.17, 7:0.17, 6:0.17
    blue_button_pos: 3:0.99, 8:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 7:1.00, 4:0.00, 8:0.00
    red_button_pos: 7:1.00, 3:0.00, 6:0.00
    blue_button_pos: 6:0.14, 1:0.14, 5:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 22:0.10; 10:0.10; 4:0.10; 21:0.04; 9:0.04
  Agent2 top policies: 4:0.08; 16:0.08; 24:0.05; 26:0.05; 12:0.05
. . .
b 2 1
. r .

Reward: +0.00, Result: neutral

--- Step 4 ---
Agent 1: DOWN, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 5:1.00, 4:0.00, 0:0.00
    red_button_pos: 8:0.20, 7:0.20, 6:0.20
    blue_button_pos: 3:0.98, 8:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 4:1.00, 8:0.00, 1:0.00
    red_button_pos: 7:0.99, 8:0.00, 6:0.00
    blue_button_pos: 6:0.17, 1:0.17, 5:0.17
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 10:0.15; 4:0.15; 8:0.06; 2:0.06; 7:0.05
  Agent2 top policies: 4:0.08; 16:0.08; 22:0.08; 0:0.04; 12:0.04
. 2 .
b . .
. r 1

Reward: +0.00, Result: neutral

--- Step 5 ---
Agent 1: LEFT, Agent 2: LEFT
  Agent1 beliefs:
    agent_pos: 8:1.00, 5:0.00, 4:0.00
    red_button_pos: 7:0.25, 1:0.25, 6:0.25
    blue_button_pos: 3:0.98, 1:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 1:1.00, 4:0.00, 8:0.00
    red_button_pos: 7:0.98, 8:0.00, 6:0.00
    blue_button_pos: 6:0.20, 5:0.20, 0:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 16:0.28; 14:0.09; 13:0.09; 17:0.07; 12:0.04
  Agent2 top policies: 16:0.11; 22:0.11; 13:0.06; 19:0.06; 14:0.06
2 . .
b . .
. 1 .

Reward: +0.00, Result: neutral

--- Step 6 ---
Agent 1: PRESS, Agent 2: DOWN
  Agent1 beliefs:
    agent_pos: 7:1.00, 0:0.00, 6:0.00
    red_button_pos: 7:1.00, 1:0.00, 6:0.00
    blue_button_pos: 3:0.97, 2:0.00, 6:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 0:1.00, 1:0.00, 4:0.00
    red_button_pos: 7:0.98, 8:0.00, 6:0.00
    blue_button_pos: 6:0.24, 2:0.24, 5:0.24
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 25:0.06; 10:0.06; 24:0.06; 26:0.05; 27:0.05
  Agent2 top policies: 10:0.20; 7:0.10; 8:0.10; 11:0.08; 9:0.04
. . .
2 . .
. 1 .

Reward: +0.00, Result: neutral
Button pressed: red by Agent 1

--- Step 7 ---
Agent 1: LEFT, Agent 2: PRESS
  Agent1 beliefs:
    agent_pos: 7:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:1.00, 1:0.00, 6:0.00
    blue_button_pos: 3:0.96, 2:0.01, 6:0.01
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 3:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:0.97, 8:0.00, 6:0.00
    blue_button_pos: 3:1.00, 2:0.00, 6:0.00
    red_button_state: 0:0.50, 1:0.50
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 12:0.04; 2:0.04; 28:0.04; 10:0.04; 16:0.04
  Agent2 top policies: 26:0.06; 16:0.06; 27:0.06; 25:0.05; 24:0.05
. . .
2 . .
1 R .

Reward: +1.00, Result: win
Button pressed: blue by Agent 2

Result: ✅ WIN - win (steps: 7, reward: +1.00)

================================================================================
EPISODE 70
================================================================================
Environment: Red at (1, 2), Blue at (0, 1)

Initial state:
1 . .
b . .
. r 2


--- Step 1 ---
Agent 1: DOWN, Agent 2: LEFT
  Agent1 beliefs:
    agent_pos: 0:1.00, 8:0.00, 7:0.00
    red_button_pos: 8:0.12, 7:0.12, 6:0.12
    blue_button_pos: 8:0.12, 7:0.12, 6:0.12
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 8:1.00, 7:0.00, 6:0.00
    red_button_pos: 7:0.12, 3:0.12, 6:0.12
    blue_button_pos: 7:0.12, 3:0.12, 6:0.12
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 10:0.21; 22:0.21; 9:0.06; 19:0.06; 21:0.05
  Agent2 top policies: 16:0.21; 4:0.21; 12:0.06; 2:0.06; 0:0.05
. . .
1 . .
. 2 .

Reward: +0.00, Result: neutral

--- Step 2 ---
Agent 1: RIGHT, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 3:1.00, 8:0.00, 7:0.00
    red_button_pos: 8:0.14, 7:0.14, 6:0.14
    blue_button_pos: 3:1.00, 8:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 7:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:1.00, 3:0.00, 6:0.00
    blue_button_pos: 6:0.14, 1:0.14, 5:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 22:0.13; 10:0.13; 9:0.06; 21:0.06; 19:0.06
  Agent2 top policies: 4:0.08; 16:0.08; 24:0.05; 26:0.05; 12:0.05
. . .
b 1 .
. 2 .

Reward: +0.00, Result: neutral

--- Step 3 ---
Agent 1: RIGHT, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 4:1.00, 0:0.00, 8:0.00
    red_button_pos: 8:0.17, 7:0.17, 6:0.17
    blue_button_pos: 3:0.99, 8:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 7:1.00, 4:0.00, 8:0.00
    red_button_pos: 7:1.00, 3:0.00, 6:0.00
    blue_button_pos: 6:0.14, 1:0.14, 5:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 22:0.10; 10:0.10; 4:0.10; 21:0.04; 9:0.04
  Agent2 top policies: 4:0.08; 16:0.08; 24:0.05; 26:0.05; 12:0.05
. . .
b 2 1
. r .

Reward: +0.00, Result: neutral

--- Step 4 ---
Agent 1: DOWN, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 5:1.00, 4:0.00, 0:0.00
    red_button_pos: 8:0.20, 7:0.20, 6:0.20
    blue_button_pos: 3:0.98, 8:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 4:1.00, 8:0.00, 1:0.00
    red_button_pos: 7:0.99, 8:0.00, 6:0.00
    blue_button_pos: 6:0.17, 1:0.17, 5:0.17
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 10:0.15; 4:0.15; 8:0.06; 2:0.06; 7:0.05
  Agent2 top policies: 4:0.08; 16:0.08; 22:0.08; 0:0.04; 12:0.04
. 2 .
b . .
. r 1

Reward: +0.00, Result: neutral

--- Step 5 ---
Agent 1: LEFT, Agent 2: LEFT
  Agent1 beliefs:
    agent_pos: 8:1.00, 5:0.00, 4:0.00
    red_button_pos: 7:0.25, 1:0.25, 6:0.25
    blue_button_pos: 3:0.98, 1:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 1:1.00, 4:0.00, 8:0.00
    red_button_pos: 7:0.98, 8:0.00, 6:0.00
    blue_button_pos: 6:0.20, 5:0.20, 0:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 16:0.28; 14:0.09; 13:0.09; 17:0.07; 12:0.04
  Agent2 top policies: 16:0.11; 22:0.11; 13:0.06; 19:0.06; 14:0.06
2 . .
b . .
. 1 .

Reward: +0.00, Result: neutral

--- Step 6 ---
Agent 1: PRESS, Agent 2: DOWN
  Agent1 beliefs:
    agent_pos: 7:1.00, 0:0.00, 6:0.00
    red_button_pos: 7:1.00, 1:0.00, 6:0.00
    blue_button_pos: 3:0.97, 2:0.00, 6:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 0:1.00, 1:0.00, 4:0.00
    red_button_pos: 7:0.98, 8:0.00, 6:0.00
    blue_button_pos: 6:0.24, 2:0.24, 5:0.24
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 25:0.06; 10:0.06; 24:0.06; 26:0.05; 27:0.05
  Agent2 top policies: 10:0.20; 7:0.10; 8:0.10; 11:0.08; 9:0.04
. . .
2 . .
. 1 .

Reward: +0.00, Result: neutral
Button pressed: red by Agent 1

--- Step 7 ---
Agent 1: LEFT, Agent 2: PRESS
  Agent1 beliefs:
    agent_pos: 7:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:1.00, 1:0.00, 6:0.00
    blue_button_pos: 3:0.96, 2:0.01, 6:0.01
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 3:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:0.97, 8:0.00, 6:0.00
    blue_button_pos: 3:1.00, 2:0.00, 6:0.00
    red_button_state: 0:0.50, 1:0.50
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 12:0.04; 2:0.04; 28:0.04; 10:0.04; 16:0.04
  Agent2 top policies: 26:0.06; 16:0.06; 27:0.06; 25:0.05; 24:0.05
. . .
2 . .
1 R .

Reward: +1.00, Result: win
Button pressed: blue by Agent 2

Result: ✅ WIN - win (steps: 7, reward: +1.00)

================================================================================
EPISODE 71
================================================================================
Environment: Red at (1, 2), Blue at (0, 1)

Initial state:
1 . .
b . .
. r 2


--- Step 1 ---
Agent 1: DOWN, Agent 2: LEFT
  Agent1 beliefs:
    agent_pos: 0:1.00, 8:0.00, 7:0.00
    red_button_pos: 8:0.12, 7:0.12, 6:0.12
    blue_button_pos: 8:0.12, 7:0.12, 6:0.12
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 8:1.00, 7:0.00, 6:0.00
    red_button_pos: 7:0.12, 3:0.12, 6:0.12
    blue_button_pos: 7:0.12, 3:0.12, 6:0.12
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 10:0.21; 22:0.21; 9:0.06; 19:0.06; 21:0.05
  Agent2 top policies: 16:0.21; 4:0.21; 12:0.06; 2:0.06; 0:0.05
. . .
1 . .
. 2 .

Reward: +0.00, Result: neutral

--- Step 2 ---
Agent 1: RIGHT, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 3:1.00, 8:0.00, 7:0.00
    red_button_pos: 8:0.14, 7:0.14, 6:0.14
    blue_button_pos: 3:1.00, 8:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 7:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:1.00, 3:0.00, 6:0.00
    blue_button_pos: 6:0.14, 1:0.14, 5:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 22:0.13; 10:0.13; 9:0.06; 21:0.06; 19:0.06
  Agent2 top policies: 4:0.08; 16:0.08; 24:0.05; 26:0.05; 12:0.05
. . .
b 1 .
. 2 .

Reward: +0.00, Result: neutral

--- Step 3 ---
Agent 1: RIGHT, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 4:1.00, 0:0.00, 8:0.00
    red_button_pos: 8:0.17, 7:0.17, 6:0.17
    blue_button_pos: 3:0.99, 8:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 7:1.00, 4:0.00, 8:0.00
    red_button_pos: 7:1.00, 3:0.00, 6:0.00
    blue_button_pos: 6:0.14, 1:0.14, 5:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 22:0.10; 10:0.10; 4:0.10; 21:0.04; 9:0.04
  Agent2 top policies: 4:0.08; 16:0.08; 24:0.05; 26:0.05; 12:0.05
. . .
b 2 1
. r .

Reward: +0.00, Result: neutral

--- Step 4 ---
Agent 1: DOWN, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 5:1.00, 4:0.00, 0:0.00
    red_button_pos: 8:0.20, 7:0.20, 6:0.20
    blue_button_pos: 3:0.98, 8:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 4:1.00, 8:0.00, 1:0.00
    red_button_pos: 7:0.99, 8:0.00, 6:0.00
    blue_button_pos: 6:0.17, 1:0.17, 5:0.17
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 10:0.15; 4:0.15; 8:0.06; 2:0.06; 7:0.05
  Agent2 top policies: 4:0.08; 16:0.08; 22:0.08; 0:0.04; 12:0.04
. 2 .
b . .
. r 1

Reward: +0.00, Result: neutral

--- Step 5 ---
Agent 1: LEFT, Agent 2: LEFT
  Agent1 beliefs:
    agent_pos: 8:1.00, 5:0.00, 4:0.00
    red_button_pos: 7:0.25, 1:0.25, 6:0.25
    blue_button_pos: 3:0.98, 1:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 1:1.00, 4:0.00, 8:0.00
    red_button_pos: 7:0.98, 8:0.00, 6:0.00
    blue_button_pos: 6:0.20, 5:0.20, 0:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 16:0.28; 14:0.09; 13:0.09; 17:0.07; 12:0.04
  Agent2 top policies: 16:0.11; 22:0.11; 13:0.06; 19:0.06; 14:0.06
2 . .
b . .
. 1 .

Reward: +0.00, Result: neutral

--- Step 6 ---
Agent 1: PRESS, Agent 2: DOWN
  Agent1 beliefs:
    agent_pos: 7:1.00, 0:0.00, 6:0.00
    red_button_pos: 7:1.00, 1:0.00, 6:0.00
    blue_button_pos: 3:0.97, 2:0.00, 6:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 0:1.00, 1:0.00, 4:0.00
    red_button_pos: 7:0.98, 8:0.00, 6:0.00
    blue_button_pos: 6:0.24, 2:0.24, 5:0.24
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 25:0.06; 10:0.06; 24:0.06; 26:0.05; 27:0.05
  Agent2 top policies: 10:0.20; 7:0.10; 8:0.10; 11:0.08; 9:0.04
. . .
2 . .
. 1 .

Reward: +0.00, Result: neutral
Button pressed: red by Agent 1

--- Step 7 ---
Agent 1: LEFT, Agent 2: PRESS
  Agent1 beliefs:
    agent_pos: 7:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:1.00, 1:0.00, 6:0.00
    blue_button_pos: 3:0.96, 2:0.01, 6:0.01
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 3:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:0.97, 8:0.00, 6:0.00
    blue_button_pos: 3:1.00, 2:0.00, 6:0.00
    red_button_state: 0:0.50, 1:0.50
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 12:0.04; 2:0.04; 28:0.04; 10:0.04; 16:0.04
  Agent2 top policies: 26:0.06; 16:0.06; 27:0.06; 25:0.05; 24:0.05
. . .
2 . .
1 R .

Reward: +1.00, Result: win
Button pressed: blue by Agent 2

Result: ✅ WIN - win (steps: 7, reward: +1.00)

================================================================================
EPISODE 72
================================================================================
Environment: Red at (1, 2), Blue at (0, 1)

Initial state:
1 . .
b . .
. r 2


--- Step 1 ---
Agent 1: DOWN, Agent 2: LEFT
  Agent1 beliefs:
    agent_pos: 0:1.00, 8:0.00, 7:0.00
    red_button_pos: 8:0.12, 7:0.12, 6:0.12
    blue_button_pos: 8:0.12, 7:0.12, 6:0.12
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 8:1.00, 7:0.00, 6:0.00
    red_button_pos: 7:0.12, 3:0.12, 6:0.12
    blue_button_pos: 7:0.12, 3:0.12, 6:0.12
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 10:0.21; 22:0.21; 9:0.06; 19:0.06; 21:0.05
  Agent2 top policies: 16:0.21; 4:0.21; 12:0.06; 2:0.06; 0:0.05
. . .
1 . .
. 2 .

Reward: +0.00, Result: neutral

--- Step 2 ---
Agent 1: RIGHT, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 3:1.00, 8:0.00, 7:0.00
    red_button_pos: 8:0.14, 7:0.14, 6:0.14
    blue_button_pos: 3:1.00, 8:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 7:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:1.00, 3:0.00, 6:0.00
    blue_button_pos: 6:0.14, 1:0.14, 5:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 22:0.13; 10:0.13; 9:0.06; 21:0.06; 19:0.06
  Agent2 top policies: 4:0.08; 16:0.08; 24:0.05; 26:0.05; 12:0.05
. . .
b 1 .
. 2 .

Reward: +0.00, Result: neutral

--- Step 3 ---
Agent 1: RIGHT, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 4:1.00, 0:0.00, 8:0.00
    red_button_pos: 8:0.17, 7:0.17, 6:0.17
    blue_button_pos: 3:0.99, 8:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 7:1.00, 4:0.00, 8:0.00
    red_button_pos: 7:1.00, 3:0.00, 6:0.00
    blue_button_pos: 6:0.14, 1:0.14, 5:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 22:0.10; 10:0.10; 4:0.10; 21:0.04; 9:0.04
  Agent2 top policies: 4:0.08; 16:0.08; 24:0.05; 26:0.05; 12:0.05
. . .
b 2 1
. r .

Reward: +0.00, Result: neutral

--- Step 4 ---
Agent 1: DOWN, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 5:1.00, 4:0.00, 0:0.00
    red_button_pos: 8:0.20, 7:0.20, 6:0.20
    blue_button_pos: 3:0.98, 8:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 4:1.00, 8:0.00, 1:0.00
    red_button_pos: 7:0.99, 8:0.00, 6:0.00
    blue_button_pos: 6:0.17, 1:0.17, 5:0.17
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 10:0.15; 4:0.15; 8:0.06; 2:0.06; 7:0.05
  Agent2 top policies: 4:0.08; 16:0.08; 22:0.08; 0:0.04; 12:0.04
. 2 .
b . .
. r 1

Reward: +0.00, Result: neutral

--- Step 5 ---
Agent 1: LEFT, Agent 2: LEFT
  Agent1 beliefs:
    agent_pos: 8:1.00, 5:0.00, 4:0.00
    red_button_pos: 7:0.25, 1:0.25, 6:0.25
    blue_button_pos: 3:0.98, 1:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 1:1.00, 4:0.00, 8:0.00
    red_button_pos: 7:0.98, 8:0.00, 6:0.00
    blue_button_pos: 6:0.20, 5:0.20, 0:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 16:0.28; 14:0.09; 13:0.09; 17:0.07; 12:0.04
  Agent2 top policies: 16:0.11; 22:0.11; 13:0.06; 19:0.06; 14:0.06
2 . .
b . .
. 1 .

Reward: +0.00, Result: neutral

--- Step 6 ---
Agent 1: PRESS, Agent 2: DOWN
  Agent1 beliefs:
    agent_pos: 7:1.00, 0:0.00, 6:0.00
    red_button_pos: 7:1.00, 1:0.00, 6:0.00
    blue_button_pos: 3:0.97, 2:0.00, 6:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 0:1.00, 1:0.00, 4:0.00
    red_button_pos: 7:0.98, 8:0.00, 6:0.00
    blue_button_pos: 6:0.24, 2:0.24, 5:0.24
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 25:0.06; 10:0.06; 24:0.06; 26:0.05; 27:0.05
  Agent2 top policies: 10:0.20; 7:0.10; 8:0.10; 11:0.08; 9:0.04
. . .
2 . .
. 1 .

Reward: +0.00, Result: neutral
Button pressed: red by Agent 1

--- Step 7 ---
Agent 1: LEFT, Agent 2: PRESS
  Agent1 beliefs:
    agent_pos: 7:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:1.00, 1:0.00, 6:0.00
    blue_button_pos: 3:0.96, 2:0.01, 6:0.01
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 3:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:0.97, 8:0.00, 6:0.00
    blue_button_pos: 3:1.00, 2:0.00, 6:0.00
    red_button_state: 0:0.50, 1:0.50
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 12:0.04; 2:0.04; 28:0.04; 10:0.04; 16:0.04
  Agent2 top policies: 26:0.06; 16:0.06; 27:0.06; 25:0.05; 24:0.05
. . .
2 . .
1 R .

Reward: +1.00, Result: win
Button pressed: blue by Agent 2

Result: ✅ WIN - win (steps: 7, reward: +1.00)

================================================================================
EPISODE 73
================================================================================
Environment: Red at (1, 2), Blue at (0, 1)

Initial state:
1 . .
b . .
. r 2


--- Step 1 ---
Agent 1: DOWN, Agent 2: LEFT
  Agent1 beliefs:
    agent_pos: 0:1.00, 8:0.00, 7:0.00
    red_button_pos: 8:0.12, 7:0.12, 6:0.12
    blue_button_pos: 8:0.12, 7:0.12, 6:0.12
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 8:1.00, 7:0.00, 6:0.00
    red_button_pos: 7:0.12, 3:0.12, 6:0.12
    blue_button_pos: 7:0.12, 3:0.12, 6:0.12
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 10:0.21; 22:0.21; 9:0.06; 19:0.06; 21:0.05
  Agent2 top policies: 16:0.21; 4:0.21; 12:0.06; 2:0.06; 0:0.05
. . .
1 . .
. 2 .

Reward: +0.00, Result: neutral

--- Step 2 ---
Agent 1: RIGHT, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 3:1.00, 8:0.00, 7:0.00
    red_button_pos: 8:0.14, 7:0.14, 6:0.14
    blue_button_pos: 3:1.00, 8:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 7:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:1.00, 3:0.00, 6:0.00
    blue_button_pos: 6:0.14, 1:0.14, 5:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 22:0.13; 10:0.13; 9:0.06; 21:0.06; 19:0.06
  Agent2 top policies: 4:0.08; 16:0.08; 24:0.05; 26:0.05; 12:0.05
. . .
b 1 .
. 2 .

Reward: +0.00, Result: neutral

--- Step 3 ---
Agent 1: RIGHT, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 4:1.00, 0:0.00, 8:0.00
    red_button_pos: 8:0.17, 7:0.17, 6:0.17
    blue_button_pos: 3:0.99, 8:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 7:1.00, 4:0.00, 8:0.00
    red_button_pos: 7:1.00, 3:0.00, 6:0.00
    blue_button_pos: 6:0.14, 1:0.14, 5:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 22:0.10; 10:0.10; 4:0.10; 21:0.04; 9:0.04
  Agent2 top policies: 4:0.08; 16:0.08; 24:0.05; 26:0.05; 12:0.05
. . .
b 2 1
. r .

Reward: +0.00, Result: neutral

--- Step 4 ---
Agent 1: DOWN, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 5:1.00, 4:0.00, 0:0.00
    red_button_pos: 8:0.20, 7:0.20, 6:0.20
    blue_button_pos: 3:0.98, 8:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 4:1.00, 8:0.00, 1:0.00
    red_button_pos: 7:0.99, 8:0.00, 6:0.00
    blue_button_pos: 6:0.17, 1:0.17, 5:0.17
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 10:0.15; 4:0.15; 8:0.06; 2:0.06; 7:0.05
  Agent2 top policies: 4:0.08; 16:0.08; 22:0.08; 0:0.04; 12:0.04
. 2 .
b . .
. r 1

Reward: +0.00, Result: neutral

--- Step 5 ---
Agent 1: LEFT, Agent 2: LEFT
  Agent1 beliefs:
    agent_pos: 8:1.00, 5:0.00, 4:0.00
    red_button_pos: 7:0.25, 1:0.25, 6:0.25
    blue_button_pos: 3:0.98, 1:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 1:1.00, 4:0.00, 8:0.00
    red_button_pos: 7:0.98, 8:0.00, 6:0.00
    blue_button_pos: 6:0.20, 5:0.20, 0:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 16:0.28; 14:0.09; 13:0.09; 17:0.07; 12:0.04
  Agent2 top policies: 16:0.11; 22:0.11; 13:0.06; 19:0.06; 14:0.06
2 . .
b . .
. 1 .

Reward: +0.00, Result: neutral

--- Step 6 ---
Agent 1: PRESS, Agent 2: DOWN
  Agent1 beliefs:
    agent_pos: 7:1.00, 0:0.00, 6:0.00
    red_button_pos: 7:1.00, 1:0.00, 6:0.00
    blue_button_pos: 3:0.97, 2:0.00, 6:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 0:1.00, 1:0.00, 4:0.00
    red_button_pos: 7:0.98, 8:0.00, 6:0.00
    blue_button_pos: 6:0.24, 2:0.24, 5:0.24
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 25:0.06; 10:0.06; 24:0.06; 26:0.05; 27:0.05
  Agent2 top policies: 10:0.20; 7:0.10; 8:0.10; 11:0.08; 9:0.04
. . .
2 . .
. 1 .

Reward: +0.00, Result: neutral
Button pressed: red by Agent 1

--- Step 7 ---
Agent 1: LEFT, Agent 2: PRESS
  Agent1 beliefs:
    agent_pos: 7:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:1.00, 1:0.00, 6:0.00
    blue_button_pos: 3:0.96, 2:0.01, 6:0.01
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 3:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:0.97, 8:0.00, 6:0.00
    blue_button_pos: 3:1.00, 2:0.00, 6:0.00
    red_button_state: 0:0.50, 1:0.50
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 12:0.04; 2:0.04; 28:0.04; 10:0.04; 16:0.04
  Agent2 top policies: 26:0.06; 16:0.06; 27:0.06; 25:0.05; 24:0.05
. . .
2 . .
1 R .

Reward: +1.00, Result: win
Button pressed: blue by Agent 2

Result: ✅ WIN - win (steps: 7, reward: +1.00)

================================================================================
EPISODE 74
================================================================================
Environment: Red at (1, 2), Blue at (0, 1)

Initial state:
1 . .
b . .
. r 2


--- Step 1 ---
Agent 1: DOWN, Agent 2: LEFT
  Agent1 beliefs:
    agent_pos: 0:1.00, 8:0.00, 7:0.00
    red_button_pos: 8:0.12, 7:0.12, 6:0.12
    blue_button_pos: 8:0.12, 7:0.12, 6:0.12
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 8:1.00, 7:0.00, 6:0.00
    red_button_pos: 7:0.12, 3:0.12, 6:0.12
    blue_button_pos: 7:0.12, 3:0.12, 6:0.12
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 10:0.21; 22:0.21; 9:0.06; 19:0.06; 21:0.05
  Agent2 top policies: 16:0.21; 4:0.21; 12:0.06; 2:0.06; 0:0.05
. . .
1 . .
. 2 .

Reward: +0.00, Result: neutral

--- Step 2 ---
Agent 1: RIGHT, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 3:1.00, 8:0.00, 7:0.00
    red_button_pos: 8:0.14, 7:0.14, 6:0.14
    blue_button_pos: 3:1.00, 8:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 7:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:1.00, 3:0.00, 6:0.00
    blue_button_pos: 6:0.14, 1:0.14, 5:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 22:0.13; 10:0.13; 9:0.06; 21:0.06; 19:0.06
  Agent2 top policies: 4:0.08; 16:0.08; 24:0.05; 26:0.05; 12:0.05
. . .
b 1 .
. 2 .

Reward: +0.00, Result: neutral

--- Step 3 ---
Agent 1: RIGHT, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 4:1.00, 0:0.00, 8:0.00
    red_button_pos: 8:0.17, 7:0.17, 6:0.17
    blue_button_pos: 3:0.99, 8:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 7:1.00, 4:0.00, 8:0.00
    red_button_pos: 7:1.00, 3:0.00, 6:0.00
    blue_button_pos: 6:0.14, 1:0.14, 5:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 22:0.10; 10:0.10; 4:0.10; 21:0.04; 9:0.04
  Agent2 top policies: 4:0.08; 16:0.08; 24:0.05; 26:0.05; 12:0.05
. . .
b 2 1
. r .

Reward: +0.00, Result: neutral

--- Step 4 ---
Agent 1: DOWN, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 5:1.00, 4:0.00, 0:0.00
    red_button_pos: 8:0.20, 7:0.20, 6:0.20
    blue_button_pos: 3:0.98, 8:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 4:1.00, 8:0.00, 1:0.00
    red_button_pos: 7:0.99, 8:0.00, 6:0.00
    blue_button_pos: 6:0.17, 1:0.17, 5:0.17
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 10:0.15; 4:0.15; 8:0.06; 2:0.06; 7:0.05
  Agent2 top policies: 4:0.08; 16:0.08; 22:0.08; 0:0.04; 12:0.04
. 2 .
b . .
. r 1

Reward: +0.00, Result: neutral

--- Step 5 ---
Agent 1: LEFT, Agent 2: LEFT
  Agent1 beliefs:
    agent_pos: 8:1.00, 5:0.00, 4:0.00
    red_button_pos: 7:0.25, 1:0.25, 6:0.25
    blue_button_pos: 3:0.98, 1:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 1:1.00, 4:0.00, 8:0.00
    red_button_pos: 7:0.98, 8:0.00, 6:0.00
    blue_button_pos: 6:0.20, 5:0.20, 0:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 16:0.28; 14:0.09; 13:0.09; 17:0.07; 12:0.04
  Agent2 top policies: 16:0.11; 22:0.11; 13:0.06; 19:0.06; 14:0.06
2 . .
b . .
. 1 .

Reward: +0.00, Result: neutral

--- Step 6 ---
Agent 1: PRESS, Agent 2: DOWN
  Agent1 beliefs:
    agent_pos: 7:1.00, 0:0.00, 6:0.00
    red_button_pos: 7:1.00, 1:0.00, 6:0.00
    blue_button_pos: 3:0.97, 2:0.00, 6:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 0:1.00, 1:0.00, 4:0.00
    red_button_pos: 7:0.98, 8:0.00, 6:0.00
    blue_button_pos: 6:0.24, 2:0.24, 5:0.24
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 25:0.06; 10:0.06; 24:0.06; 26:0.05; 27:0.05
  Agent2 top policies: 10:0.20; 7:0.10; 8:0.10; 11:0.08; 9:0.04
. . .
2 . .
. 1 .

Reward: +0.00, Result: neutral
Button pressed: red by Agent 1

--- Step 7 ---
Agent 1: LEFT, Agent 2: PRESS
  Agent1 beliefs:
    agent_pos: 7:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:1.00, 1:0.00, 6:0.00
    blue_button_pos: 3:0.96, 2:0.01, 6:0.01
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 3:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:0.97, 8:0.00, 6:0.00
    blue_button_pos: 3:1.00, 2:0.00, 6:0.00
    red_button_state: 0:0.50, 1:0.50
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 12:0.04; 2:0.04; 28:0.04; 10:0.04; 16:0.04
  Agent2 top policies: 26:0.06; 16:0.06; 27:0.06; 25:0.05; 24:0.05
. . .
2 . .
1 R .

Reward: +1.00, Result: win
Button pressed: blue by Agent 2

Result: ✅ WIN - win (steps: 7, reward: +1.00)

================================================================================
EPISODE 75
================================================================================
Environment: Red at (1, 2), Blue at (0, 1)

Initial state:
1 . .
b . .
. r 2


--- Step 1 ---
Agent 1: DOWN, Agent 2: LEFT
  Agent1 beliefs:
    agent_pos: 0:1.00, 8:0.00, 7:0.00
    red_button_pos: 8:0.12, 7:0.12, 6:0.12
    blue_button_pos: 8:0.12, 7:0.12, 6:0.12
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 8:1.00, 7:0.00, 6:0.00
    red_button_pos: 7:0.12, 3:0.12, 6:0.12
    blue_button_pos: 7:0.12, 3:0.12, 6:0.12
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 10:0.21; 22:0.21; 9:0.06; 19:0.06; 21:0.05
  Agent2 top policies: 16:0.21; 4:0.21; 12:0.06; 2:0.06; 0:0.05
. . .
1 . .
. 2 .

Reward: +0.00, Result: neutral

--- Step 2 ---
Agent 1: RIGHT, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 3:1.00, 8:0.00, 7:0.00
    red_button_pos: 8:0.14, 7:0.14, 6:0.14
    blue_button_pos: 3:1.00, 8:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 7:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:1.00, 3:0.00, 6:0.00
    blue_button_pos: 6:0.14, 1:0.14, 5:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 22:0.13; 10:0.13; 9:0.06; 21:0.06; 19:0.06
  Agent2 top policies: 4:0.08; 16:0.08; 24:0.05; 26:0.05; 12:0.05
. . .
b 1 .
. 2 .

Reward: +0.00, Result: neutral

--- Step 3 ---
Agent 1: RIGHT, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 4:1.00, 0:0.00, 8:0.00
    red_button_pos: 8:0.17, 7:0.17, 6:0.17
    blue_button_pos: 3:0.99, 8:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 7:1.00, 4:0.00, 8:0.00
    red_button_pos: 7:1.00, 3:0.00, 6:0.00
    blue_button_pos: 6:0.14, 1:0.14, 5:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 22:0.10; 10:0.10; 4:0.10; 21:0.04; 9:0.04
  Agent2 top policies: 4:0.08; 16:0.08; 24:0.05; 26:0.05; 12:0.05
. . .
b 2 1
. r .

Reward: +0.00, Result: neutral

--- Step 4 ---
Agent 1: DOWN, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 5:1.00, 4:0.00, 0:0.00
    red_button_pos: 8:0.20, 7:0.20, 6:0.20
    blue_button_pos: 3:0.98, 8:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 4:1.00, 8:0.00, 1:0.00
    red_button_pos: 7:0.99, 8:0.00, 6:0.00
    blue_button_pos: 6:0.17, 1:0.17, 5:0.17
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 10:0.15; 4:0.15; 8:0.06; 2:0.06; 7:0.05
  Agent2 top policies: 4:0.08; 16:0.08; 22:0.08; 0:0.04; 12:0.04
. 2 .
b . .
. r 1

Reward: +0.00, Result: neutral

--- Step 5 ---
Agent 1: LEFT, Agent 2: LEFT
  Agent1 beliefs:
    agent_pos: 8:1.00, 5:0.00, 4:0.00
    red_button_pos: 7:0.25, 1:0.25, 6:0.25
    blue_button_pos: 3:0.98, 1:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 1:1.00, 4:0.00, 8:0.00
    red_button_pos: 7:0.98, 8:0.00, 6:0.00
    blue_button_pos: 6:0.20, 5:0.20, 0:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 16:0.28; 14:0.09; 13:0.09; 17:0.07; 12:0.04
  Agent2 top policies: 16:0.11; 22:0.11; 13:0.06; 19:0.06; 14:0.06
2 . .
b . .
. 1 .

Reward: +0.00, Result: neutral

--- Step 6 ---
Agent 1: PRESS, Agent 2: DOWN
  Agent1 beliefs:
    agent_pos: 7:1.00, 0:0.00, 6:0.00
    red_button_pos: 7:1.00, 1:0.00, 6:0.00
    blue_button_pos: 3:0.97, 2:0.00, 6:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 0:1.00, 1:0.00, 4:0.00
    red_button_pos: 7:0.98, 8:0.00, 6:0.00
    blue_button_pos: 6:0.24, 2:0.24, 5:0.24
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 25:0.06; 10:0.06; 24:0.06; 26:0.05; 27:0.05
  Agent2 top policies: 10:0.20; 7:0.10; 8:0.10; 11:0.08; 9:0.04
. . .
2 . .
. 1 .

Reward: +0.00, Result: neutral
Button pressed: red by Agent 1

--- Step 7 ---
Agent 1: LEFT, Agent 2: PRESS
  Agent1 beliefs:
    agent_pos: 7:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:1.00, 1:0.00, 6:0.00
    blue_button_pos: 3:0.96, 2:0.01, 6:0.01
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 3:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:0.97, 8:0.00, 6:0.00
    blue_button_pos: 3:1.00, 2:0.00, 6:0.00
    red_button_state: 0:0.50, 1:0.50
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 12:0.04; 2:0.04; 28:0.04; 10:0.04; 16:0.04
  Agent2 top policies: 26:0.06; 16:0.06; 27:0.06; 25:0.05; 24:0.05
. . .
2 . .
1 R .

Reward: +1.00, Result: win
Button pressed: blue by Agent 2

Result: ✅ WIN - win (steps: 7, reward: +1.00)

================================================================================
EPISODE 76
================================================================================
Environment: Red at (1, 2), Blue at (0, 1)

Initial state:
1 . .
b . .
. r 2


--- Step 1 ---
Agent 1: DOWN, Agent 2: LEFT
  Agent1 beliefs:
    agent_pos: 0:1.00, 8:0.00, 7:0.00
    red_button_pos: 8:0.12, 7:0.12, 6:0.12
    blue_button_pos: 8:0.12, 7:0.12, 6:0.12
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 8:1.00, 7:0.00, 6:0.00
    red_button_pos: 7:0.12, 3:0.12, 6:0.12
    blue_button_pos: 7:0.12, 3:0.12, 6:0.12
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 10:0.21; 22:0.21; 9:0.06; 19:0.06; 21:0.05
  Agent2 top policies: 16:0.21; 4:0.21; 12:0.06; 2:0.06; 0:0.05
. . .
1 . .
. 2 .

Reward: +0.00, Result: neutral

--- Step 2 ---
Agent 1: RIGHT, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 3:1.00, 8:0.00, 7:0.00
    red_button_pos: 8:0.14, 7:0.14, 6:0.14
    blue_button_pos: 3:1.00, 8:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 7:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:1.00, 3:0.00, 6:0.00
    blue_button_pos: 6:0.14, 1:0.14, 5:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 22:0.13; 10:0.13; 9:0.06; 21:0.06; 19:0.06
  Agent2 top policies: 4:0.08; 16:0.08; 24:0.05; 26:0.05; 12:0.05
. . .
b 1 .
. 2 .

Reward: +0.00, Result: neutral

--- Step 3 ---
Agent 1: RIGHT, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 4:1.00, 0:0.00, 8:0.00
    red_button_pos: 8:0.17, 7:0.17, 6:0.17
    blue_button_pos: 3:0.99, 8:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 7:1.00, 4:0.00, 8:0.00
    red_button_pos: 7:1.00, 3:0.00, 6:0.00
    blue_button_pos: 6:0.14, 1:0.14, 5:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 22:0.10; 10:0.10; 4:0.10; 21:0.04; 9:0.04
  Agent2 top policies: 4:0.08; 16:0.08; 24:0.05; 26:0.05; 12:0.05
. . .
b 2 1
. r .

Reward: +0.00, Result: neutral

--- Step 4 ---
Agent 1: DOWN, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 5:1.00, 4:0.00, 0:0.00
    red_button_pos: 8:0.20, 7:0.20, 6:0.20
    blue_button_pos: 3:0.98, 8:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 4:1.00, 8:0.00, 1:0.00
    red_button_pos: 7:0.99, 8:0.00, 6:0.00
    blue_button_pos: 6:0.17, 1:0.17, 5:0.17
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 10:0.15; 4:0.15; 8:0.06; 2:0.06; 7:0.05
  Agent2 top policies: 4:0.08; 16:0.08; 22:0.08; 0:0.04; 12:0.04
. 2 .
b . .
. r 1

Reward: +0.00, Result: neutral

--- Step 5 ---
Agent 1: LEFT, Agent 2: LEFT
  Agent1 beliefs:
    agent_pos: 8:1.00, 5:0.00, 4:0.00
    red_button_pos: 7:0.25, 1:0.25, 6:0.25
    blue_button_pos: 3:0.98, 1:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 1:1.00, 4:0.00, 8:0.00
    red_button_pos: 7:0.98, 8:0.00, 6:0.00
    blue_button_pos: 6:0.20, 5:0.20, 0:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 16:0.28; 14:0.09; 13:0.09; 17:0.07; 12:0.04
  Agent2 top policies: 16:0.11; 22:0.11; 13:0.06; 19:0.06; 14:0.06
2 . .
b . .
. 1 .

Reward: +0.00, Result: neutral

--- Step 6 ---
Agent 1: PRESS, Agent 2: DOWN
  Agent1 beliefs:
    agent_pos: 7:1.00, 0:0.00, 6:0.00
    red_button_pos: 7:1.00, 1:0.00, 6:0.00
    blue_button_pos: 3:0.97, 2:0.00, 6:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 0:1.00, 1:0.00, 4:0.00
    red_button_pos: 7:0.98, 8:0.00, 6:0.00
    blue_button_pos: 6:0.24, 2:0.24, 5:0.24
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 25:0.06; 10:0.06; 24:0.06; 26:0.05; 27:0.05
  Agent2 top policies: 10:0.20; 7:0.10; 8:0.10; 11:0.08; 9:0.04
. . .
2 . .
. 1 .

Reward: +0.00, Result: neutral
Button pressed: red by Agent 1

--- Step 7 ---
Agent 1: LEFT, Agent 2: PRESS
  Agent1 beliefs:
    agent_pos: 7:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:1.00, 1:0.00, 6:0.00
    blue_button_pos: 3:0.96, 2:0.01, 6:0.01
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 3:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:0.97, 8:0.00, 6:0.00
    blue_button_pos: 3:1.00, 2:0.00, 6:0.00
    red_button_state: 0:0.50, 1:0.50
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 12:0.04; 2:0.04; 28:0.04; 10:0.04; 16:0.04
  Agent2 top policies: 26:0.06; 16:0.06; 27:0.06; 25:0.05; 24:0.05
. . .
2 . .
1 R .

Reward: +1.00, Result: win
Button pressed: blue by Agent 2

Result: ✅ WIN - win (steps: 7, reward: +1.00)

================================================================================
EPISODE 77
================================================================================
Environment: Red at (1, 2), Blue at (0, 1)

Initial state:
1 . .
b . .
. r 2


--- Step 1 ---
Agent 1: DOWN, Agent 2: LEFT
  Agent1 beliefs:
    agent_pos: 0:1.00, 8:0.00, 7:0.00
    red_button_pos: 8:0.12, 7:0.12, 6:0.12
    blue_button_pos: 8:0.12, 7:0.12, 6:0.12
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 8:1.00, 7:0.00, 6:0.00
    red_button_pos: 7:0.12, 3:0.12, 6:0.12
    blue_button_pos: 7:0.12, 3:0.12, 6:0.12
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 10:0.21; 22:0.21; 9:0.06; 19:0.06; 21:0.05
  Agent2 top policies: 16:0.21; 4:0.21; 12:0.06; 2:0.06; 0:0.05
. . .
1 . .
. 2 .

Reward: +0.00, Result: neutral

--- Step 2 ---
Agent 1: RIGHT, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 3:1.00, 8:0.00, 7:0.00
    red_button_pos: 8:0.14, 7:0.14, 6:0.14
    blue_button_pos: 3:1.00, 8:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 7:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:1.00, 3:0.00, 6:0.00
    blue_button_pos: 6:0.14, 1:0.14, 5:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 22:0.13; 10:0.13; 9:0.06; 21:0.06; 19:0.06
  Agent2 top policies: 4:0.08; 16:0.08; 24:0.05; 26:0.05; 12:0.05
. . .
b 1 .
. 2 .

Reward: +0.00, Result: neutral

--- Step 3 ---
Agent 1: RIGHT, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 4:1.00, 0:0.00, 8:0.00
    red_button_pos: 8:0.17, 7:0.17, 6:0.17
    blue_button_pos: 3:0.99, 8:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 7:1.00, 4:0.00, 8:0.00
    red_button_pos: 7:1.00, 3:0.00, 6:0.00
    blue_button_pos: 6:0.14, 1:0.14, 5:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 22:0.10; 10:0.10; 4:0.10; 21:0.04; 9:0.04
  Agent2 top policies: 4:0.08; 16:0.08; 24:0.05; 26:0.05; 12:0.05
. . .
b 2 1
. r .

Reward: +0.00, Result: neutral

--- Step 4 ---
Agent 1: DOWN, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 5:1.00, 4:0.00, 0:0.00
    red_button_pos: 8:0.20, 7:0.20, 6:0.20
    blue_button_pos: 3:0.98, 8:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 4:1.00, 8:0.00, 1:0.00
    red_button_pos: 7:0.99, 8:0.00, 6:0.00
    blue_button_pos: 6:0.17, 1:0.17, 5:0.17
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 10:0.15; 4:0.15; 8:0.06; 2:0.06; 7:0.05
  Agent2 top policies: 4:0.08; 16:0.08; 22:0.08; 0:0.04; 12:0.04
. 2 .
b . .
. r 1

Reward: +0.00, Result: neutral

--- Step 5 ---
Agent 1: LEFT, Agent 2: LEFT
  Agent1 beliefs:
    agent_pos: 8:1.00, 5:0.00, 4:0.00
    red_button_pos: 7:0.25, 1:0.25, 6:0.25
    blue_button_pos: 3:0.98, 1:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 1:1.00, 4:0.00, 8:0.00
    red_button_pos: 7:0.98, 8:0.00, 6:0.00
    blue_button_pos: 6:0.20, 5:0.20, 0:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 16:0.28; 14:0.09; 13:0.09; 17:0.07; 12:0.04
  Agent2 top policies: 16:0.11; 22:0.11; 13:0.06; 19:0.06; 14:0.06
2 . .
b . .
. 1 .

Reward: +0.00, Result: neutral

--- Step 6 ---
Agent 1: PRESS, Agent 2: DOWN
  Agent1 beliefs:
    agent_pos: 7:1.00, 0:0.00, 6:0.00
    red_button_pos: 7:1.00, 1:0.00, 6:0.00
    blue_button_pos: 3:0.97, 2:0.00, 6:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 0:1.00, 1:0.00, 4:0.00
    red_button_pos: 7:0.98, 8:0.00, 6:0.00
    blue_button_pos: 6:0.24, 2:0.24, 5:0.24
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 25:0.06; 10:0.06; 24:0.06; 26:0.05; 27:0.05
  Agent2 top policies: 10:0.20; 7:0.10; 8:0.10; 11:0.08; 9:0.04
. . .
2 . .
. 1 .

Reward: +0.00, Result: neutral
Button pressed: red by Agent 1

--- Step 7 ---
Agent 1: LEFT, Agent 2: PRESS
  Agent1 beliefs:
    agent_pos: 7:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:1.00, 1:0.00, 6:0.00
    blue_button_pos: 3:0.96, 2:0.01, 6:0.01
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 3:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:0.97, 8:0.00, 6:0.00
    blue_button_pos: 3:1.00, 2:0.00, 6:0.00
    red_button_state: 0:0.50, 1:0.50
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 12:0.04; 2:0.04; 28:0.04; 10:0.04; 16:0.04
  Agent2 top policies: 26:0.06; 16:0.06; 27:0.06; 25:0.05; 24:0.05
. . .
2 . .
1 R .

Reward: +1.00, Result: win
Button pressed: blue by Agent 2

Result: ✅ WIN - win (steps: 7, reward: +1.00)

================================================================================
EPISODE 78
================================================================================
Environment: Red at (1, 2), Blue at (0, 1)

Initial state:
1 . .
b . .
. r 2


--- Step 1 ---
Agent 1: DOWN, Agent 2: LEFT
  Agent1 beliefs:
    agent_pos: 0:1.00, 8:0.00, 7:0.00
    red_button_pos: 8:0.12, 7:0.12, 6:0.12
    blue_button_pos: 8:0.12, 7:0.12, 6:0.12
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 8:1.00, 7:0.00, 6:0.00
    red_button_pos: 7:0.12, 3:0.12, 6:0.12
    blue_button_pos: 7:0.12, 3:0.12, 6:0.12
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 10:0.21; 22:0.21; 9:0.06; 19:0.06; 21:0.05
  Agent2 top policies: 16:0.21; 4:0.21; 12:0.06; 2:0.06; 0:0.05
. . .
1 . .
. 2 .

Reward: +0.00, Result: neutral

--- Step 2 ---
Agent 1: RIGHT, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 3:1.00, 8:0.00, 7:0.00
    red_button_pos: 8:0.14, 7:0.14, 6:0.14
    blue_button_pos: 3:1.00, 8:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 7:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:1.00, 3:0.00, 6:0.00
    blue_button_pos: 6:0.14, 1:0.14, 5:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 22:0.13; 10:0.13; 9:0.06; 21:0.06; 19:0.06
  Agent2 top policies: 4:0.08; 16:0.08; 24:0.05; 26:0.05; 12:0.05
. . .
b 1 .
. 2 .

Reward: +0.00, Result: neutral

--- Step 3 ---
Agent 1: RIGHT, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 4:1.00, 0:0.00, 8:0.00
    red_button_pos: 8:0.17, 7:0.17, 6:0.17
    blue_button_pos: 3:0.99, 8:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 7:1.00, 4:0.00, 8:0.00
    red_button_pos: 7:1.00, 3:0.00, 6:0.00
    blue_button_pos: 6:0.14, 1:0.14, 5:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 22:0.10; 10:0.10; 4:0.10; 21:0.04; 9:0.04
  Agent2 top policies: 4:0.08; 16:0.08; 24:0.05; 26:0.05; 12:0.05
. . .
b 2 1
. r .

Reward: +0.00, Result: neutral

--- Step 4 ---
Agent 1: DOWN, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 5:1.00, 4:0.00, 0:0.00
    red_button_pos: 8:0.20, 7:0.20, 6:0.20
    blue_button_pos: 3:0.98, 8:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 4:1.00, 8:0.00, 1:0.00
    red_button_pos: 7:0.99, 8:0.00, 6:0.00
    blue_button_pos: 6:0.17, 1:0.17, 5:0.17
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 10:0.15; 4:0.15; 8:0.06; 2:0.06; 7:0.05
  Agent2 top policies: 4:0.08; 16:0.08; 22:0.08; 0:0.04; 12:0.04
. 2 .
b . .
. r 1

Reward: +0.00, Result: neutral

--- Step 5 ---
Agent 1: LEFT, Agent 2: LEFT
  Agent1 beliefs:
    agent_pos: 8:1.00, 5:0.00, 4:0.00
    red_button_pos: 7:0.25, 1:0.25, 6:0.25
    blue_button_pos: 3:0.98, 1:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 1:1.00, 4:0.00, 8:0.00
    red_button_pos: 7:0.98, 8:0.00, 6:0.00
    blue_button_pos: 6:0.20, 5:0.20, 0:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 16:0.28; 14:0.09; 13:0.09; 17:0.07; 12:0.04
  Agent2 top policies: 16:0.11; 22:0.11; 13:0.06; 19:0.06; 14:0.06
2 . .
b . .
. 1 .

Reward: +0.00, Result: neutral

--- Step 6 ---
Agent 1: PRESS, Agent 2: DOWN
  Agent1 beliefs:
    agent_pos: 7:1.00, 0:0.00, 6:0.00
    red_button_pos: 7:1.00, 1:0.00, 6:0.00
    blue_button_pos: 3:0.97, 2:0.00, 6:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 0:1.00, 1:0.00, 4:0.00
    red_button_pos: 7:0.98, 8:0.00, 6:0.00
    blue_button_pos: 6:0.24, 2:0.24, 5:0.24
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 25:0.06; 10:0.06; 24:0.06; 26:0.05; 27:0.05
  Agent2 top policies: 10:0.20; 7:0.10; 8:0.10; 11:0.08; 9:0.04
. . .
2 . .
. 1 .

Reward: +0.00, Result: neutral
Button pressed: red by Agent 1

--- Step 7 ---
Agent 1: LEFT, Agent 2: PRESS
  Agent1 beliefs:
    agent_pos: 7:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:1.00, 1:0.00, 6:0.00
    blue_button_pos: 3:0.96, 2:0.01, 6:0.01
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 3:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:0.97, 8:0.00, 6:0.00
    blue_button_pos: 3:1.00, 2:0.00, 6:0.00
    red_button_state: 0:0.50, 1:0.50
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 12:0.04; 2:0.04; 28:0.04; 10:0.04; 16:0.04
  Agent2 top policies: 26:0.06; 16:0.06; 27:0.06; 25:0.05; 24:0.05
. . .
2 . .
1 R .

Reward: +1.00, Result: win
Button pressed: blue by Agent 2

Result: ✅ WIN - win (steps: 7, reward: +1.00)

================================================================================
EPISODE 79
================================================================================
Environment: Red at (1, 2), Blue at (0, 1)

Initial state:
1 . .
b . .
. r 2


--- Step 1 ---
Agent 1: DOWN, Agent 2: LEFT
  Agent1 beliefs:
    agent_pos: 0:1.00, 8:0.00, 7:0.00
    red_button_pos: 8:0.12, 7:0.12, 6:0.12
    blue_button_pos: 8:0.12, 7:0.12, 6:0.12
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 8:1.00, 7:0.00, 6:0.00
    red_button_pos: 7:0.12, 3:0.12, 6:0.12
    blue_button_pos: 7:0.12, 3:0.12, 6:0.12
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 10:0.21; 22:0.21; 9:0.06; 19:0.06; 21:0.05
  Agent2 top policies: 16:0.21; 4:0.21; 12:0.06; 2:0.06; 0:0.05
. . .
1 . .
. 2 .

Reward: +0.00, Result: neutral

--- Step 2 ---
Agent 1: RIGHT, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 3:1.00, 8:0.00, 7:0.00
    red_button_pos: 8:0.14, 7:0.14, 6:0.14
    blue_button_pos: 3:1.00, 8:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 7:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:1.00, 3:0.00, 6:0.00
    blue_button_pos: 6:0.14, 1:0.14, 5:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 22:0.13; 10:0.13; 9:0.06; 21:0.06; 19:0.06
  Agent2 top policies: 4:0.08; 16:0.08; 24:0.05; 26:0.05; 12:0.05
. . .
b 1 .
. 2 .

Reward: +0.00, Result: neutral

--- Step 3 ---
Agent 1: RIGHT, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 4:1.00, 0:0.00, 8:0.00
    red_button_pos: 8:0.17, 7:0.17, 6:0.17
    blue_button_pos: 3:0.99, 8:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 7:1.00, 4:0.00, 8:0.00
    red_button_pos: 7:1.00, 3:0.00, 6:0.00
    blue_button_pos: 6:0.14, 1:0.14, 5:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 22:0.10; 10:0.10; 4:0.10; 21:0.04; 9:0.04
  Agent2 top policies: 4:0.08; 16:0.08; 24:0.05; 26:0.05; 12:0.05
. . .
b 2 1
. r .

Reward: +0.00, Result: neutral

--- Step 4 ---
Agent 1: DOWN, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 5:1.00, 4:0.00, 0:0.00
    red_button_pos: 8:0.20, 7:0.20, 6:0.20
    blue_button_pos: 3:0.98, 8:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 4:1.00, 8:0.00, 1:0.00
    red_button_pos: 7:0.99, 8:0.00, 6:0.00
    blue_button_pos: 6:0.17, 1:0.17, 5:0.17
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 10:0.15; 4:0.15; 8:0.06; 2:0.06; 7:0.05
  Agent2 top policies: 4:0.08; 16:0.08; 22:0.08; 0:0.04; 12:0.04
. 2 .
b . .
. r 1

Reward: +0.00, Result: neutral

--- Step 5 ---
Agent 1: LEFT, Agent 2: LEFT
  Agent1 beliefs:
    agent_pos: 8:1.00, 5:0.00, 4:0.00
    red_button_pos: 7:0.25, 1:0.25, 6:0.25
    blue_button_pos: 3:0.98, 1:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 1:1.00, 4:0.00, 8:0.00
    red_button_pos: 7:0.98, 8:0.00, 6:0.00
    blue_button_pos: 6:0.20, 5:0.20, 0:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 16:0.28; 14:0.09; 13:0.09; 17:0.07; 12:0.04
  Agent2 top policies: 16:0.11; 22:0.11; 13:0.06; 19:0.06; 14:0.06
2 . .
b . .
. 1 .

Reward: +0.00, Result: neutral

--- Step 6 ---
Agent 1: PRESS, Agent 2: DOWN
  Agent1 beliefs:
    agent_pos: 7:1.00, 0:0.00, 6:0.00
    red_button_pos: 7:1.00, 1:0.00, 6:0.00
    blue_button_pos: 3:0.97, 2:0.00, 6:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 0:1.00, 1:0.00, 4:0.00
    red_button_pos: 7:0.98, 8:0.00, 6:0.00
    blue_button_pos: 6:0.24, 2:0.24, 5:0.24
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 25:0.06; 10:0.06; 24:0.06; 26:0.05; 27:0.05
  Agent2 top policies: 10:0.20; 7:0.10; 8:0.10; 11:0.08; 9:0.04
. . .
2 . .
. 1 .

Reward: +0.00, Result: neutral
Button pressed: red by Agent 1

--- Step 7 ---
Agent 1: LEFT, Agent 2: PRESS
  Agent1 beliefs:
    agent_pos: 7:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:1.00, 1:0.00, 6:0.00
    blue_button_pos: 3:0.96, 2:0.01, 6:0.01
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 3:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:0.97, 8:0.00, 6:0.00
    blue_button_pos: 3:1.00, 2:0.00, 6:0.00
    red_button_state: 0:0.50, 1:0.50
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 12:0.04; 2:0.04; 28:0.04; 10:0.04; 16:0.04
  Agent2 top policies: 26:0.06; 16:0.06; 27:0.06; 25:0.05; 24:0.05
. . .
2 . .
1 R .

Reward: +1.00, Result: win
Button pressed: blue by Agent 2

Result: ✅ WIN - win (steps: 7, reward: +1.00)

================================================================================
EPISODE 80
================================================================================
Environment: Red at (1, 2), Blue at (0, 1)

Initial state:
1 . .
b . .
. r 2


--- Step 1 ---
Agent 1: DOWN, Agent 2: LEFT
  Agent1 beliefs:
    agent_pos: 0:1.00, 8:0.00, 7:0.00
    red_button_pos: 8:0.12, 7:0.12, 6:0.12
    blue_button_pos: 8:0.12, 7:0.12, 6:0.12
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 8:1.00, 7:0.00, 6:0.00
    red_button_pos: 7:0.12, 3:0.12, 6:0.12
    blue_button_pos: 7:0.12, 3:0.12, 6:0.12
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 10:0.21; 22:0.21; 9:0.06; 19:0.06; 21:0.05
  Agent2 top policies: 16:0.21; 4:0.21; 12:0.06; 2:0.06; 0:0.05
. . .
1 . .
. 2 .

Reward: +0.00, Result: neutral

--- Step 2 ---
Agent 1: RIGHT, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 3:1.00, 8:0.00, 7:0.00
    red_button_pos: 8:0.14, 7:0.14, 6:0.14
    blue_button_pos: 3:1.00, 8:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 7:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:1.00, 3:0.00, 6:0.00
    blue_button_pos: 6:0.14, 1:0.14, 5:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 22:0.13; 10:0.13; 9:0.06; 21:0.06; 19:0.06
  Agent2 top policies: 4:0.08; 16:0.08; 24:0.05; 26:0.05; 12:0.05
. . .
b 1 .
. 2 .

Reward: +0.00, Result: neutral

--- Step 3 ---
Agent 1: RIGHT, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 4:1.00, 0:0.00, 8:0.00
    red_button_pos: 8:0.17, 7:0.17, 6:0.17
    blue_button_pos: 3:0.99, 8:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 7:1.00, 4:0.00, 8:0.00
    red_button_pos: 7:1.00, 3:0.00, 6:0.00
    blue_button_pos: 6:0.14, 1:0.14, 5:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 22:0.10; 10:0.10; 4:0.10; 21:0.04; 9:0.04
  Agent2 top policies: 4:0.08; 16:0.08; 24:0.05; 26:0.05; 12:0.05
. . .
b 2 1
. r .

Reward: +0.00, Result: neutral

--- Step 4 ---
Agent 1: DOWN, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 5:1.00, 4:0.00, 0:0.00
    red_button_pos: 8:0.20, 7:0.20, 6:0.20
    blue_button_pos: 3:0.98, 8:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 4:1.00, 8:0.00, 1:0.00
    red_button_pos: 7:0.99, 8:0.00, 6:0.00
    blue_button_pos: 6:0.17, 1:0.17, 5:0.17
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 10:0.15; 4:0.15; 8:0.06; 2:0.06; 7:0.05
  Agent2 top policies: 4:0.08; 16:0.08; 22:0.08; 0:0.04; 12:0.04
. 2 .
b . .
. r 1

Reward: +0.00, Result: neutral

--- Step 5 ---
Agent 1: LEFT, Agent 2: LEFT
  Agent1 beliefs:
    agent_pos: 8:1.00, 5:0.00, 4:0.00
    red_button_pos: 7:0.25, 1:0.25, 6:0.25
    blue_button_pos: 3:0.98, 1:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 1:1.00, 4:0.00, 8:0.00
    red_button_pos: 7:0.98, 8:0.00, 6:0.00
    blue_button_pos: 6:0.20, 5:0.20, 0:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 16:0.28; 14:0.09; 13:0.09; 17:0.07; 12:0.04
  Agent2 top policies: 16:0.11; 22:0.11; 13:0.06; 19:0.06; 14:0.06
2 . .
b . .
. 1 .

Reward: +0.00, Result: neutral

--- Step 6 ---
Agent 1: PRESS, Agent 2: DOWN
  Agent1 beliefs:
    agent_pos: 7:1.00, 0:0.00, 6:0.00
    red_button_pos: 7:1.00, 1:0.00, 6:0.00
    blue_button_pos: 3:0.97, 2:0.00, 6:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 0:1.00, 1:0.00, 4:0.00
    red_button_pos: 7:0.98, 8:0.00, 6:0.00
    blue_button_pos: 6:0.24, 2:0.24, 5:0.24
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 25:0.06; 10:0.06; 24:0.06; 26:0.05; 27:0.05
  Agent2 top policies: 10:0.20; 7:0.10; 8:0.10; 11:0.08; 9:0.04
. . .
2 . .
. 1 .

Reward: +0.00, Result: neutral
Button pressed: red by Agent 1

--- Step 7 ---
Agent 1: LEFT, Agent 2: PRESS
  Agent1 beliefs:
    agent_pos: 7:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:1.00, 1:0.00, 6:0.00
    blue_button_pos: 3:0.96, 2:0.01, 6:0.01
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 3:1.00, 8:0.00, 6:0.00
    red_button_pos: 7:0.97, 8:0.00, 6:0.00
    blue_button_pos: 3:1.00, 2:0.00, 6:0.00
    red_button_state: 0:0.50, 1:0.50
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 12:0.04; 2:0.04; 28:0.04; 10:0.04; 16:0.04
  Agent2 top policies: 26:0.06; 16:0.06; 27:0.06; 25:0.05; 24:0.05
. . .
2 . .
1 R .

Reward: +1.00, Result: win
Button pressed: blue by Agent 2

Result: ✅ WIN - win (steps: 7, reward: +1.00)

================================================================================
SEED 0 - CONFIG 5
Red at (1, 0), Blue at (1, 1)
Episodes 81-100
================================================================================

================================================================================
EPISODE 81
================================================================================
Environment: Red at (1, 0), Blue at (1, 1)

Initial state:
1 r .
. b .
. . 2


--- Step 1 ---
Agent 1: DOWN, Agent 2: LEFT
  Agent1 beliefs:
    agent_pos: 0:1.00, 8:0.00, 7:0.00
    red_button_pos: 8:0.12, 7:0.12, 6:0.12
    blue_button_pos: 8:0.12, 7:0.12, 6:0.12
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 8:1.00, 7:0.00, 6:0.00
    red_button_pos: 7:0.12, 3:0.12, 6:0.12
    blue_button_pos: 7:0.12, 3:0.12, 6:0.12
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 10:0.21; 22:0.21; 9:0.06; 19:0.06; 21:0.05
  Agent2 top policies: 16:0.21; 4:0.21; 12:0.06; 2:0.06; 0:0.05
. r .
1 b .
. 2 .

Reward: +0.00, Result: neutral

--- Step 2 ---
Agent 1: RIGHT, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 3:1.00, 0:0.00, 8:0.00
    red_button_pos: 8:0.14, 7:0.14, 6:0.14
    blue_button_pos: 8:0.14, 7:0.14, 6:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 7:1.00, 8:0.00, 6:0.00
    red_button_pos: 6:0.14, 1:0.14, 5:0.14
    blue_button_pos: 6:0.14, 1:0.14, 5:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 22:0.23; 10:0.23; 9:0.06; 21:0.05; 19:0.05
  Agent2 top policies: 4:0.23; 16:0.23; 12:0.06; 0:0.05; 2:0.05
. r .
. 1 .
. 2 .

Reward: +0.00, Result: neutral

--- Step 3 ---
Agent 1: DOWN, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 4:1.00, 8:0.00, 5:0.00
    red_button_pos: 8:0.17, 7:0.17, 6:0.17
    blue_button_pos: 4:1.00, 8:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 7:0.87, 4:0.12, 8:0.00
    red_button_pos: 6:0.14, 1:0.14, 5:0.14
    blue_button_pos: 6:0.14, 1:0.14, 5:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 10:0.11; 22:0.11; 4:0.11; 3:0.04; 21:0.04
  Agent2 top policies: 4:0.24; 16:0.23; 12:0.06; 2:0.05; 14:0.05
. r .
. 1 .
. 2 .

Reward: +0.00, Result: neutral

--- Step 4 ---
Agent 1: RIGHT, Agent 2: LEFT
  Agent1 beliefs:
    agent_pos: 4:1.00, 7:0.00, 8:0.00
    red_button_pos: 8:0.17, 7:0.17, 6:0.17
    blue_button_pos: 4:1.00, 8:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 7:0.87, 4:0.11, 1:0.02
    red_button_pos: 6:0.14, 1:0.14, 5:0.14
    blue_button_pos: 6:0.14, 1:0.14, 5:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 22:0.11; 4:0.11; 10:0.11; 21:0.04; 3:0.04
  Agent2 top policies: 16:0.24; 4:0.22; 12:0.06; 14:0.06; 2:0.05
. r .
. b 1
2 . .

Reward: +0.00, Result: neutral

--- Step 5 ---
Agent 1: DOWN, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 5:1.00, 3:0.00, 0:0.00
    red_button_pos: 8:0.20, 7:0.20, 6:0.20
    blue_button_pos: 4:0.99, 8:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 6:1.00, 3:0.00, 0:0.00
    red_button_pos: 4:0.17, 5:0.17, 2:0.17
    blue_button_pos: 4:0.17, 5:0.17, 2:0.17
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 10:0.14; 4:0.14; 8:0.05; 2:0.05; 7:0.05
  Agent2 top policies: 4:0.45; 3:0.10; 0:0.10; 2:0.09; 5:0.07
. r .
2 b .
. . 1

Reward: +0.00, Result: neutral

--- Step 6 ---
Agent 1: LEFT, Agent 2: RIGHT
  Agent1 beliefs:
    agent_pos: 8:1.00, 5:0.00, 3:0.00
    red_button_pos: 7:0.24, 6:0.24, 1:0.24
    blue_button_pos: 4:0.98, 1:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 3:1.00, 6:0.00, 7:0.00
    red_button_pos: 4:0.20, 5:0.20, 2:0.20
    blue_button_pos: 4:0.20, 5:0.20, 2:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 16:0.27; 14:0.09; 13:0.09; 17:0.07; 12:0.05
  Agent2 top policies: 22:0.28; 4:0.28; 3:0.05; 18:0.05; 0:0.05
. r .
. 2 .
. 1 .

Reward: +0.00, Result: neutral

--- Step 7 ---
Agent 1: LEFT, Agent 2: RIGHT
  Agent1 beliefs:
    agent_pos: 7:1.00, 8:0.00, 5:0.00
    red_button_pos: 6:0.32, 1:0.32, 2:0.32
    blue_button_pos: 4:0.98, 2:0.00, 6:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 4:1.00, 8:0.00, 2:0.00
    red_button_pos: 5:0.24, 2:0.24, 1:0.24
    blue_button_pos: 4:1.00, 0:0.00, 5:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 16:0.33; 14:0.09; 13:0.09; 17:0.07; 0:0.04
  Agent2 top policies: 22:0.18; 4:0.18; 18:0.06; 0:0.06; 3:0.06
. r .
. b 2
1 . .

Reward: +0.00, Result: neutral

--- Step 8 ---
Agent 1: UP, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 6:1.00, 7:0.00, 8:0.00
    red_button_pos: 1:0.47, 2:0.47, 0:0.02
    blue_button_pos: 4:0.97, 2:0.00, 3:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 5:1.00, 3:0.00, 6:0.00
    red_button_pos: 2:0.32, 0:0.32, 1:0.32
    blue_button_pos: 4:0.99, 1:0.00, 0:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 3:0.05; 4:0.05; 18:0.05; 0:0.04; 2:0.04
  Agent2 top policies: 4:0.31; 2:0.09; 0:0.09; 3:0.09; 5:0.07
. r 2
1 b .
. . .

Reward: +0.00, Result: neutral

--- Step 9 ---
Agent 1: RIGHT, Agent 2: LEFT
  Agent1 beliefs:
    agent_pos: 3:1.00, 6:0.00, 7:0.00
    red_button_pos: 1:0.47, 2:0.47, 0:0.02
    blue_button_pos: 4:0.97, 2:0.01, 1:0.01
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 2:1.00, 5:0.00, 3:0.00
    red_button_pos: 1:0.47, 0:0.47, 8:0.03
    blue_button_pos: 4:0.98, 1:0.00, 0:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 18:0.12; 3:0.10; 4:0.05; 23:0.04; 21:0.04
  Agent2 top policies: 16:0.40; 12:0.10; 14:0.10; 17:0.08; 13:0.04
. 2 .
. 1 .
. . .

Reward: +0.00, Result: neutral

--- Step 10 ---
Agent 1: UP, Agent 2: PRESS
  Agent1 beliefs:
    agent_pos: 4:1.00, 8:0.00, 2:0.00
    red_button_pos: 1:0.47, 2:0.47, 0:0.03
    blue_button_pos: 4:1.00, 1:0.00, 0:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 1:1.00, 6:0.00, 0:0.00
    red_button_pos: 1:1.00, 0:0.00, 8:0.00
    blue_button_pos: 4:0.98, 0:0.00, 8:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 4:0.42; 0:0.10; 3:0.10; 5:0.08; 1:0.04
  Agent2 top policies: 25:0.07; 24:0.06; 4:0.06; 26:0.05; 27:0.05
. 2 .
. 1 .
. . .

Reward: +0.00, Result: neutral
Button pressed: red by Agent 2

--- Step 11 ---
Agent 1: UP, Agent 2: DOWN
  Agent1 beliefs:
    agent_pos: 4:1.00, 1:0.00, 8:0.00
    red_button_pos: 1:0.47, 2:0.47, 0:0.03
    blue_button_pos: 4:1.00, 8:0.00, 7:0.00
    red_button_state: 0:0.50, 1:0.50
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 0:0.00, 8:0.00
    blue_button_pos: 4:0.97, 0:0.00, 8:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 0:0.12; 3:0.12; 4:0.11; 5:0.10; 24:0.08
  Agent2 top policies: 10:0.40; 25:0.03; 1:0.03; 6:0.03; 11:0.02
. 2 .
. 1 .
. . .

Reward: +0.00, Result: neutral

--- Step 12 ---
Agent 1: PRESS, Agent 2: DOWN
  Agent1 beliefs:
    agent_pos: 4:1.00, 1:0.00, 2:0.00
    red_button_pos: 1:0.47, 2:0.47, 0:0.03
    blue_button_pos: 4:1.00, 8:0.00, 7:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 1:1.00, 4:0.00, 8:0.00
    red_button_pos: 1:1.00, 8:0.00, 7:0.00
    blue_button_pos: 4:0.96, 0:0.01, 8:0.01
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 24:0.36; 27:0.12; 25:0.11; 26:0.11; 28:0.10
  Agent2 top policies: 10:0.41; 25:0.02; 1:0.02; 6:0.02; 11:0.02
. 2 .
. 1 .
. . .

Reward: +1.00, Result: win
Button pressed: blue by Agent 1

Result: ✅ WIN - win (steps: 12, reward: +1.00)

================================================================================
EPISODE 82
================================================================================
Environment: Red at (1, 0), Blue at (1, 1)

Initial state:
1 r .
. b .
. . 2


--- Step 1 ---
Agent 1: DOWN, Agent 2: LEFT
  Agent1 beliefs:
    agent_pos: 0:1.00, 8:0.00, 7:0.00
    red_button_pos: 8:0.12, 7:0.12, 6:0.12
    blue_button_pos: 8:0.12, 7:0.12, 6:0.12
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 8:1.00, 7:0.00, 6:0.00
    red_button_pos: 7:0.12, 3:0.12, 6:0.12
    blue_button_pos: 7:0.12, 3:0.12, 6:0.12
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 10:0.21; 22:0.21; 9:0.06; 19:0.06; 21:0.05
  Agent2 top policies: 16:0.21; 4:0.21; 12:0.06; 2:0.06; 0:0.05
. r .
1 b .
. 2 .

Reward: +0.00, Result: neutral

--- Step 2 ---
Agent 1: RIGHT, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 3:1.00, 0:0.00, 8:0.00
    red_button_pos: 8:0.14, 7:0.14, 6:0.14
    blue_button_pos: 8:0.14, 7:0.14, 6:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 7:1.00, 8:0.00, 6:0.00
    red_button_pos: 6:0.14, 1:0.14, 5:0.14
    blue_button_pos: 6:0.14, 1:0.14, 5:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 22:0.23; 10:0.23; 9:0.06; 21:0.05; 19:0.05
  Agent2 top policies: 4:0.23; 16:0.23; 12:0.06; 0:0.05; 2:0.05
. r .
. 1 .
. 2 .

Reward: +0.00, Result: neutral

--- Step 3 ---
Agent 1: DOWN, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 4:1.00, 8:0.00, 5:0.00
    red_button_pos: 8:0.17, 7:0.17, 6:0.17
    blue_button_pos: 4:1.00, 8:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 7:0.87, 4:0.12, 8:0.00
    red_button_pos: 6:0.14, 1:0.14, 5:0.14
    blue_button_pos: 6:0.14, 1:0.14, 5:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 10:0.11; 22:0.11; 4:0.11; 3:0.04; 21:0.04
  Agent2 top policies: 4:0.24; 16:0.23; 12:0.06; 2:0.05; 14:0.05
. r .
. 1 .
. 2 .

Reward: +0.00, Result: neutral

--- Step 4 ---
Agent 1: RIGHT, Agent 2: LEFT
  Agent1 beliefs:
    agent_pos: 4:1.00, 7:0.00, 8:0.00
    red_button_pos: 8:0.17, 7:0.17, 6:0.17
    blue_button_pos: 4:1.00, 8:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 7:0.87, 4:0.11, 1:0.02
    red_button_pos: 6:0.14, 1:0.14, 5:0.14
    blue_button_pos: 6:0.14, 1:0.14, 5:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 22:0.11; 4:0.11; 10:0.11; 21:0.04; 3:0.04
  Agent2 top policies: 16:0.24; 4:0.22; 12:0.06; 14:0.06; 2:0.05
. r .
. b 1
2 . .

Reward: +0.00, Result: neutral

--- Step 5 ---
Agent 1: DOWN, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 5:1.00, 3:0.00, 0:0.00
    red_button_pos: 8:0.20, 7:0.20, 6:0.20
    blue_button_pos: 4:0.99, 8:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 6:1.00, 3:0.00, 0:0.00
    red_button_pos: 4:0.17, 5:0.17, 2:0.17
    blue_button_pos: 4:0.17, 5:0.17, 2:0.17
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 10:0.14; 4:0.14; 8:0.05; 2:0.05; 7:0.05
  Agent2 top policies: 4:0.45; 3:0.10; 0:0.10; 2:0.09; 5:0.07
. r .
2 b .
. . 1

Reward: +0.00, Result: neutral

--- Step 6 ---
Agent 1: LEFT, Agent 2: RIGHT
  Agent1 beliefs:
    agent_pos: 8:1.00, 5:0.00, 3:0.00
    red_button_pos: 7:0.24, 6:0.24, 1:0.24
    blue_button_pos: 4:0.98, 1:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 3:1.00, 6:0.00, 7:0.00
    red_button_pos: 4:0.20, 5:0.20, 2:0.20
    blue_button_pos: 4:0.20, 5:0.20, 2:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 16:0.27; 14:0.09; 13:0.09; 17:0.07; 12:0.05
  Agent2 top policies: 22:0.28; 4:0.28; 3:0.05; 18:0.05; 0:0.05
. r .
. 2 .
. 1 .

Reward: +0.00, Result: neutral

--- Step 7 ---
Agent 1: LEFT, Agent 2: RIGHT
  Agent1 beliefs:
    agent_pos: 7:1.00, 8:0.00, 5:0.00
    red_button_pos: 6:0.32, 1:0.32, 2:0.32
    blue_button_pos: 4:0.98, 2:0.00, 6:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 4:1.00, 8:0.00, 2:0.00
    red_button_pos: 5:0.24, 2:0.24, 1:0.24
    blue_button_pos: 4:1.00, 0:0.00, 5:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 16:0.33; 14:0.09; 13:0.09; 17:0.07; 0:0.04
  Agent2 top policies: 22:0.18; 4:0.18; 18:0.06; 0:0.06; 3:0.06
. r .
. b 2
1 . .

Reward: +0.00, Result: neutral

--- Step 8 ---
Agent 1: UP, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 6:1.00, 7:0.00, 8:0.00
    red_button_pos: 1:0.47, 2:0.47, 0:0.02
    blue_button_pos: 4:0.97, 2:0.00, 3:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 5:1.00, 3:0.00, 6:0.00
    red_button_pos: 2:0.32, 0:0.32, 1:0.32
    blue_button_pos: 4:0.99, 1:0.00, 0:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 3:0.05; 4:0.05; 18:0.05; 0:0.04; 2:0.04
  Agent2 top policies: 4:0.31; 2:0.09; 0:0.09; 3:0.09; 5:0.07
. r 2
1 b .
. . .

Reward: +0.00, Result: neutral

--- Step 9 ---
Agent 1: RIGHT, Agent 2: LEFT
  Agent1 beliefs:
    agent_pos: 3:1.00, 6:0.00, 7:0.00
    red_button_pos: 1:0.47, 2:0.47, 0:0.02
    blue_button_pos: 4:0.97, 2:0.01, 1:0.01
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 2:1.00, 5:0.00, 3:0.00
    red_button_pos: 1:0.47, 0:0.47, 8:0.03
    blue_button_pos: 4:0.98, 1:0.00, 0:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 18:0.12; 3:0.10; 4:0.05; 23:0.04; 21:0.04
  Agent2 top policies: 16:0.40; 12:0.10; 14:0.10; 17:0.08; 13:0.04
. 2 .
. 1 .
. . .

Reward: +0.00, Result: neutral

--- Step 10 ---
Agent 1: UP, Agent 2: PRESS
  Agent1 beliefs:
    agent_pos: 4:1.00, 8:0.00, 2:0.00
    red_button_pos: 1:0.47, 2:0.47, 0:0.03
    blue_button_pos: 4:1.00, 1:0.00, 0:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 1:1.00, 6:0.00, 0:0.00
    red_button_pos: 1:1.00, 0:0.00, 8:0.00
    blue_button_pos: 4:0.98, 0:0.00, 8:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 4:0.42; 0:0.10; 3:0.10; 5:0.08; 1:0.04
  Agent2 top policies: 25:0.07; 24:0.06; 4:0.06; 26:0.05; 27:0.05
. 2 .
. 1 .
. . .

Reward: +0.00, Result: neutral
Button pressed: red by Agent 2

--- Step 11 ---
Agent 1: UP, Agent 2: DOWN
  Agent1 beliefs:
    agent_pos: 4:1.00, 1:0.00, 8:0.00
    red_button_pos: 1:0.47, 2:0.47, 0:0.03
    blue_button_pos: 4:1.00, 8:0.00, 7:0.00
    red_button_state: 0:0.50, 1:0.50
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 0:0.00, 8:0.00
    blue_button_pos: 4:0.97, 0:0.00, 8:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 0:0.12; 3:0.12; 4:0.11; 5:0.10; 24:0.08
  Agent2 top policies: 10:0.40; 25:0.03; 1:0.03; 6:0.03; 11:0.02
. 2 .
. 1 .
. . .

Reward: +0.00, Result: neutral

--- Step 12 ---
Agent 1: PRESS, Agent 2: DOWN
  Agent1 beliefs:
    agent_pos: 4:1.00, 1:0.00, 2:0.00
    red_button_pos: 1:0.47, 2:0.47, 0:0.03
    blue_button_pos: 4:1.00, 8:0.00, 7:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 1:1.00, 4:0.00, 8:0.00
    red_button_pos: 1:1.00, 8:0.00, 7:0.00
    blue_button_pos: 4:0.96, 0:0.01, 8:0.01
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 24:0.36; 27:0.12; 25:0.11; 26:0.11; 28:0.10
  Agent2 top policies: 10:0.41; 25:0.02; 1:0.02; 6:0.02; 11:0.02
. 2 .
. 1 .
. . .

Reward: +1.00, Result: win
Button pressed: blue by Agent 1

Result: ✅ WIN - win (steps: 12, reward: +1.00)

================================================================================
EPISODE 83
================================================================================
Environment: Red at (1, 0), Blue at (1, 1)

Initial state:
1 r .
. b .
. . 2


--- Step 1 ---
Agent 1: DOWN, Agent 2: LEFT
  Agent1 beliefs:
    agent_pos: 0:1.00, 8:0.00, 7:0.00
    red_button_pos: 8:0.12, 7:0.12, 6:0.12
    blue_button_pos: 8:0.12, 7:0.12, 6:0.12
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 8:1.00, 7:0.00, 6:0.00
    red_button_pos: 7:0.12, 3:0.12, 6:0.12
    blue_button_pos: 7:0.12, 3:0.12, 6:0.12
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 10:0.21; 22:0.21; 9:0.06; 19:0.06; 21:0.05
  Agent2 top policies: 16:0.21; 4:0.21; 12:0.06; 2:0.06; 0:0.05
. r .
1 b .
. 2 .

Reward: +0.00, Result: neutral

--- Step 2 ---
Agent 1: RIGHT, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 3:1.00, 0:0.00, 8:0.00
    red_button_pos: 8:0.14, 7:0.14, 6:0.14
    blue_button_pos: 8:0.14, 7:0.14, 6:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 7:1.00, 8:0.00, 6:0.00
    red_button_pos: 6:0.14, 1:0.14, 5:0.14
    blue_button_pos: 6:0.14, 1:0.14, 5:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 22:0.23; 10:0.23; 9:0.06; 21:0.05; 19:0.05
  Agent2 top policies: 4:0.23; 16:0.23; 12:0.06; 0:0.05; 2:0.05
. r .
. 1 .
. 2 .

Reward: +0.00, Result: neutral

--- Step 3 ---
Agent 1: DOWN, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 4:1.00, 8:0.00, 5:0.00
    red_button_pos: 8:0.17, 7:0.17, 6:0.17
    blue_button_pos: 4:1.00, 8:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 7:0.87, 4:0.12, 8:0.00
    red_button_pos: 6:0.14, 1:0.14, 5:0.14
    blue_button_pos: 6:0.14, 1:0.14, 5:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 10:0.11; 22:0.11; 4:0.11; 3:0.04; 21:0.04
  Agent2 top policies: 4:0.24; 16:0.23; 12:0.06; 2:0.05; 14:0.05
. r .
. 1 .
. 2 .

Reward: +0.00, Result: neutral

--- Step 4 ---
Agent 1: RIGHT, Agent 2: LEFT
  Agent1 beliefs:
    agent_pos: 4:1.00, 7:0.00, 8:0.00
    red_button_pos: 8:0.17, 7:0.17, 6:0.17
    blue_button_pos: 4:1.00, 8:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 7:0.87, 4:0.11, 1:0.02
    red_button_pos: 6:0.14, 1:0.14, 5:0.14
    blue_button_pos: 6:0.14, 1:0.14, 5:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 22:0.11; 4:0.11; 10:0.11; 21:0.04; 3:0.04
  Agent2 top policies: 16:0.24; 4:0.22; 12:0.06; 14:0.06; 2:0.05
. r .
. b 1
2 . .

Reward: +0.00, Result: neutral

--- Step 5 ---
Agent 1: DOWN, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 5:1.00, 3:0.00, 0:0.00
    red_button_pos: 8:0.20, 7:0.20, 6:0.20
    blue_button_pos: 4:0.99, 8:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 6:1.00, 3:0.00, 0:0.00
    red_button_pos: 4:0.17, 5:0.17, 2:0.17
    blue_button_pos: 4:0.17, 5:0.17, 2:0.17
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 10:0.14; 4:0.14; 8:0.05; 2:0.05; 7:0.05
  Agent2 top policies: 4:0.45; 3:0.10; 0:0.10; 2:0.09; 5:0.07
. r .
2 b .
. . 1

Reward: +0.00, Result: neutral

--- Step 6 ---
Agent 1: LEFT, Agent 2: RIGHT
  Agent1 beliefs:
    agent_pos: 8:1.00, 5:0.00, 3:0.00
    red_button_pos: 7:0.24, 6:0.24, 1:0.24
    blue_button_pos: 4:0.98, 1:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 3:1.00, 6:0.00, 7:0.00
    red_button_pos: 4:0.20, 5:0.20, 2:0.20
    blue_button_pos: 4:0.20, 5:0.20, 2:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 16:0.27; 14:0.09; 13:0.09; 17:0.07; 12:0.05
  Agent2 top policies: 22:0.28; 4:0.28; 3:0.05; 18:0.05; 0:0.05
. r .
. 2 .
. 1 .

Reward: +0.00, Result: neutral

--- Step 7 ---
Agent 1: LEFT, Agent 2: RIGHT
  Agent1 beliefs:
    agent_pos: 7:1.00, 8:0.00, 5:0.00
    red_button_pos: 6:0.32, 1:0.32, 2:0.32
    blue_button_pos: 4:0.98, 2:0.00, 6:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 4:1.00, 8:0.00, 2:0.00
    red_button_pos: 5:0.24, 2:0.24, 1:0.24
    blue_button_pos: 4:1.00, 0:0.00, 5:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 16:0.33; 14:0.09; 13:0.09; 17:0.07; 0:0.04
  Agent2 top policies: 22:0.18; 4:0.18; 18:0.06; 0:0.06; 3:0.06
. r .
. b 2
1 . .

Reward: +0.00, Result: neutral

--- Step 8 ---
Agent 1: UP, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 6:1.00, 7:0.00, 8:0.00
    red_button_pos: 1:0.47, 2:0.47, 0:0.02
    blue_button_pos: 4:0.97, 2:0.00, 3:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 5:1.00, 3:0.00, 6:0.00
    red_button_pos: 2:0.32, 0:0.32, 1:0.32
    blue_button_pos: 4:0.99, 1:0.00, 0:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 3:0.05; 4:0.05; 18:0.05; 0:0.04; 2:0.04
  Agent2 top policies: 4:0.31; 2:0.09; 0:0.09; 3:0.09; 5:0.07
. r 2
1 b .
. . .

Reward: +0.00, Result: neutral

--- Step 9 ---
Agent 1: RIGHT, Agent 2: LEFT
  Agent1 beliefs:
    agent_pos: 3:1.00, 6:0.00, 7:0.00
    red_button_pos: 1:0.47, 2:0.47, 0:0.02
    blue_button_pos: 4:0.97, 2:0.01, 1:0.01
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 2:1.00, 5:0.00, 3:0.00
    red_button_pos: 1:0.47, 0:0.47, 8:0.03
    blue_button_pos: 4:0.98, 1:0.00, 0:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 18:0.12; 3:0.10; 4:0.05; 23:0.04; 21:0.04
  Agent2 top policies: 16:0.40; 12:0.10; 14:0.10; 17:0.08; 13:0.04
. 2 .
. 1 .
. . .

Reward: +0.00, Result: neutral

--- Step 10 ---
Agent 1: UP, Agent 2: PRESS
  Agent1 beliefs:
    agent_pos: 4:1.00, 8:0.00, 2:0.00
    red_button_pos: 1:0.47, 2:0.47, 0:0.03
    blue_button_pos: 4:1.00, 1:0.00, 0:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 1:1.00, 6:0.00, 0:0.00
    red_button_pos: 1:1.00, 0:0.00, 8:0.00
    blue_button_pos: 4:0.98, 0:0.00, 8:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 4:0.42; 0:0.10; 3:0.10; 5:0.08; 1:0.04
  Agent2 top policies: 25:0.07; 24:0.06; 4:0.06; 26:0.05; 27:0.05
. 2 .
. 1 .
. . .

Reward: +0.00, Result: neutral
Button pressed: red by Agent 2

--- Step 11 ---
Agent 1: UP, Agent 2: DOWN
  Agent1 beliefs:
    agent_pos: 4:1.00, 1:0.00, 8:0.00
    red_button_pos: 1:0.47, 2:0.47, 0:0.03
    blue_button_pos: 4:1.00, 8:0.00, 7:0.00
    red_button_state: 0:0.50, 1:0.50
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 0:0.00, 8:0.00
    blue_button_pos: 4:0.97, 0:0.00, 8:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 0:0.12; 3:0.12; 4:0.11; 5:0.10; 24:0.08
  Agent2 top policies: 10:0.40; 25:0.03; 1:0.03; 6:0.03; 11:0.02
. 2 .
. 1 .
. . .

Reward: +0.00, Result: neutral

--- Step 12 ---
Agent 1: PRESS, Agent 2: DOWN
  Agent1 beliefs:
    agent_pos: 4:1.00, 1:0.00, 2:0.00
    red_button_pos: 1:0.47, 2:0.47, 0:0.03
    blue_button_pos: 4:1.00, 8:0.00, 7:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 1:1.00, 4:0.00, 8:0.00
    red_button_pos: 1:1.00, 8:0.00, 7:0.00
    blue_button_pos: 4:0.96, 0:0.01, 8:0.01
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 24:0.36; 27:0.12; 25:0.11; 26:0.11; 28:0.10
  Agent2 top policies: 10:0.41; 25:0.02; 1:0.02; 6:0.02; 11:0.02
. 2 .
. 1 .
. . .

Reward: +1.00, Result: win
Button pressed: blue by Agent 1

Result: ✅ WIN - win (steps: 12, reward: +1.00)

================================================================================
EPISODE 84
================================================================================
Environment: Red at (1, 0), Blue at (1, 1)

Initial state:
1 r .
. b .
. . 2


--- Step 1 ---
Agent 1: DOWN, Agent 2: LEFT
  Agent1 beliefs:
    agent_pos: 0:1.00, 8:0.00, 7:0.00
    red_button_pos: 8:0.12, 7:0.12, 6:0.12
    blue_button_pos: 8:0.12, 7:0.12, 6:0.12
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 8:1.00, 7:0.00, 6:0.00
    red_button_pos: 7:0.12, 3:0.12, 6:0.12
    blue_button_pos: 7:0.12, 3:0.12, 6:0.12
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 10:0.21; 22:0.21; 9:0.06; 19:0.06; 21:0.05
  Agent2 top policies: 16:0.21; 4:0.21; 12:0.06; 2:0.06; 0:0.05
. r .
1 b .
. 2 .

Reward: +0.00, Result: neutral

--- Step 2 ---
Agent 1: RIGHT, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 3:1.00, 0:0.00, 8:0.00
    red_button_pos: 8:0.14, 7:0.14, 6:0.14
    blue_button_pos: 8:0.14, 7:0.14, 6:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 7:1.00, 8:0.00, 6:0.00
    red_button_pos: 6:0.14, 1:0.14, 5:0.14
    blue_button_pos: 6:0.14, 1:0.14, 5:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 22:0.23; 10:0.23; 9:0.06; 21:0.05; 19:0.05
  Agent2 top policies: 4:0.23; 16:0.23; 12:0.06; 0:0.05; 2:0.05
. r .
. 1 .
. 2 .

Reward: +0.00, Result: neutral

--- Step 3 ---
Agent 1: DOWN, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 4:1.00, 8:0.00, 5:0.00
    red_button_pos: 8:0.17, 7:0.17, 6:0.17
    blue_button_pos: 4:1.00, 8:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 7:0.87, 4:0.12, 8:0.00
    red_button_pos: 6:0.14, 1:0.14, 5:0.14
    blue_button_pos: 6:0.14, 1:0.14, 5:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 10:0.11; 22:0.11; 4:0.11; 3:0.04; 21:0.04
  Agent2 top policies: 4:0.24; 16:0.23; 12:0.06; 2:0.05; 14:0.05
. r .
. 1 .
. 2 .

Reward: +0.00, Result: neutral

--- Step 4 ---
Agent 1: RIGHT, Agent 2: LEFT
  Agent1 beliefs:
    agent_pos: 4:1.00, 7:0.00, 8:0.00
    red_button_pos: 8:0.17, 7:0.17, 6:0.17
    blue_button_pos: 4:1.00, 8:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 7:0.87, 4:0.11, 1:0.02
    red_button_pos: 6:0.14, 1:0.14, 5:0.14
    blue_button_pos: 6:0.14, 1:0.14, 5:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 22:0.11; 4:0.11; 10:0.11; 21:0.04; 3:0.04
  Agent2 top policies: 16:0.24; 4:0.22; 12:0.06; 14:0.06; 2:0.05
. r .
. b 1
2 . .

Reward: +0.00, Result: neutral

--- Step 5 ---
Agent 1: DOWN, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 5:1.00, 3:0.00, 0:0.00
    red_button_pos: 8:0.20, 7:0.20, 6:0.20
    blue_button_pos: 4:0.99, 8:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 6:1.00, 3:0.00, 0:0.00
    red_button_pos: 4:0.17, 5:0.17, 2:0.17
    blue_button_pos: 4:0.17, 5:0.17, 2:0.17
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 10:0.14; 4:0.14; 8:0.05; 2:0.05; 7:0.05
  Agent2 top policies: 4:0.45; 3:0.10; 0:0.10; 2:0.09; 5:0.07
. r .
2 b .
. . 1

Reward: +0.00, Result: neutral

--- Step 6 ---
Agent 1: LEFT, Agent 2: RIGHT
  Agent1 beliefs:
    agent_pos: 8:1.00, 5:0.00, 3:0.00
    red_button_pos: 7:0.24, 6:0.24, 1:0.24
    blue_button_pos: 4:0.98, 1:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 3:1.00, 6:0.00, 7:0.00
    red_button_pos: 4:0.20, 5:0.20, 2:0.20
    blue_button_pos: 4:0.20, 5:0.20, 2:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 16:0.27; 14:0.09; 13:0.09; 17:0.07; 12:0.05
  Agent2 top policies: 22:0.28; 4:0.28; 3:0.05; 18:0.05; 0:0.05
. r .
. 2 .
. 1 .

Reward: +0.00, Result: neutral

--- Step 7 ---
Agent 1: LEFT, Agent 2: RIGHT
  Agent1 beliefs:
    agent_pos: 7:1.00, 8:0.00, 5:0.00
    red_button_pos: 6:0.32, 1:0.32, 2:0.32
    blue_button_pos: 4:0.98, 2:0.00, 6:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 4:1.00, 8:0.00, 2:0.00
    red_button_pos: 5:0.24, 2:0.24, 1:0.24
    blue_button_pos: 4:1.00, 0:0.00, 5:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 16:0.33; 14:0.09; 13:0.09; 17:0.07; 0:0.04
  Agent2 top policies: 22:0.18; 4:0.18; 18:0.06; 0:0.06; 3:0.06
. r .
. b 2
1 . .

Reward: +0.00, Result: neutral

--- Step 8 ---
Agent 1: UP, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 6:1.00, 7:0.00, 8:0.00
    red_button_pos: 1:0.47, 2:0.47, 0:0.02
    blue_button_pos: 4:0.97, 2:0.00, 3:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 5:1.00, 3:0.00, 6:0.00
    red_button_pos: 2:0.32, 0:0.32, 1:0.32
    blue_button_pos: 4:0.99, 1:0.00, 0:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 3:0.05; 4:0.05; 18:0.05; 0:0.04; 2:0.04
  Agent2 top policies: 4:0.31; 2:0.09; 0:0.09; 3:0.09; 5:0.07
. r 2
1 b .
. . .

Reward: +0.00, Result: neutral

--- Step 9 ---
Agent 1: RIGHT, Agent 2: LEFT
  Agent1 beliefs:
    agent_pos: 3:1.00, 6:0.00, 7:0.00
    red_button_pos: 1:0.47, 2:0.47, 0:0.02
    blue_button_pos: 4:0.97, 2:0.01, 1:0.01
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 2:1.00, 5:0.00, 3:0.00
    red_button_pos: 1:0.47, 0:0.47, 8:0.03
    blue_button_pos: 4:0.98, 1:0.00, 0:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 18:0.12; 3:0.10; 4:0.05; 23:0.04; 21:0.04
  Agent2 top policies: 16:0.40; 12:0.10; 14:0.10; 17:0.08; 13:0.04
. 2 .
. 1 .
. . .

Reward: +0.00, Result: neutral

--- Step 10 ---
Agent 1: UP, Agent 2: PRESS
  Agent1 beliefs:
    agent_pos: 4:1.00, 8:0.00, 2:0.00
    red_button_pos: 1:0.47, 2:0.47, 0:0.03
    blue_button_pos: 4:1.00, 1:0.00, 0:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 1:1.00, 6:0.00, 0:0.00
    red_button_pos: 1:1.00, 0:0.00, 8:0.00
    blue_button_pos: 4:0.98, 0:0.00, 8:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 4:0.42; 0:0.10; 3:0.10; 5:0.08; 1:0.04
  Agent2 top policies: 25:0.07; 24:0.06; 4:0.06; 26:0.05; 27:0.05
. 2 .
. 1 .
. . .

Reward: +0.00, Result: neutral
Button pressed: red by Agent 2

--- Step 11 ---
Agent 1: UP, Agent 2: DOWN
  Agent1 beliefs:
    agent_pos: 4:1.00, 1:0.00, 8:0.00
    red_button_pos: 1:0.47, 2:0.47, 0:0.03
    blue_button_pos: 4:1.00, 8:0.00, 7:0.00
    red_button_state: 0:0.50, 1:0.50
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 0:0.00, 8:0.00
    blue_button_pos: 4:0.97, 0:0.00, 8:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 0:0.12; 3:0.12; 4:0.11; 5:0.10; 24:0.08
  Agent2 top policies: 10:0.40; 25:0.03; 1:0.03; 6:0.03; 11:0.02
. 2 .
. 1 .
. . .

Reward: +0.00, Result: neutral

--- Step 12 ---
Agent 1: PRESS, Agent 2: DOWN
  Agent1 beliefs:
    agent_pos: 4:1.00, 1:0.00, 2:0.00
    red_button_pos: 1:0.47, 2:0.47, 0:0.03
    blue_button_pos: 4:1.00, 8:0.00, 7:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 1:1.00, 4:0.00, 8:0.00
    red_button_pos: 1:1.00, 8:0.00, 7:0.00
    blue_button_pos: 4:0.96, 0:0.01, 8:0.01
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 24:0.36; 27:0.12; 25:0.11; 26:0.11; 28:0.10
  Agent2 top policies: 10:0.41; 25:0.02; 1:0.02; 6:0.02; 11:0.02
. 2 .
. 1 .
. . .

Reward: +1.00, Result: win
Button pressed: blue by Agent 1

Result: ✅ WIN - win (steps: 12, reward: +1.00)

================================================================================
EPISODE 85
================================================================================
Environment: Red at (1, 0), Blue at (1, 1)

Initial state:
1 r .
. b .
. . 2


--- Step 1 ---
Agent 1: DOWN, Agent 2: LEFT
  Agent1 beliefs:
    agent_pos: 0:1.00, 8:0.00, 7:0.00
    red_button_pos: 8:0.12, 7:0.12, 6:0.12
    blue_button_pos: 8:0.12, 7:0.12, 6:0.12
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 8:1.00, 7:0.00, 6:0.00
    red_button_pos: 7:0.12, 3:0.12, 6:0.12
    blue_button_pos: 7:0.12, 3:0.12, 6:0.12
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 10:0.21; 22:0.21; 9:0.06; 19:0.06; 21:0.05
  Agent2 top policies: 16:0.21; 4:0.21; 12:0.06; 2:0.06; 0:0.05
. r .
1 b .
. 2 .

Reward: +0.00, Result: neutral

--- Step 2 ---
Agent 1: RIGHT, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 3:1.00, 0:0.00, 8:0.00
    red_button_pos: 8:0.14, 7:0.14, 6:0.14
    blue_button_pos: 8:0.14, 7:0.14, 6:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 7:1.00, 8:0.00, 6:0.00
    red_button_pos: 6:0.14, 1:0.14, 5:0.14
    blue_button_pos: 6:0.14, 1:0.14, 5:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 22:0.23; 10:0.23; 9:0.06; 21:0.05; 19:0.05
  Agent2 top policies: 4:0.23; 16:0.23; 12:0.06; 0:0.05; 2:0.05
. r .
. 1 .
. 2 .

Reward: +0.00, Result: neutral

--- Step 3 ---
Agent 1: DOWN, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 4:1.00, 8:0.00, 5:0.00
    red_button_pos: 8:0.17, 7:0.17, 6:0.17
    blue_button_pos: 4:1.00, 8:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 7:0.87, 4:0.12, 8:0.00
    red_button_pos: 6:0.14, 1:0.14, 5:0.14
    blue_button_pos: 6:0.14, 1:0.14, 5:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 10:0.11; 22:0.11; 4:0.11; 3:0.04; 21:0.04
  Agent2 top policies: 4:0.24; 16:0.23; 12:0.06; 2:0.05; 14:0.05
. r .
. 1 .
. 2 .

Reward: +0.00, Result: neutral

--- Step 4 ---
Agent 1: RIGHT, Agent 2: LEFT
  Agent1 beliefs:
    agent_pos: 4:1.00, 7:0.00, 8:0.00
    red_button_pos: 8:0.17, 7:0.17, 6:0.17
    blue_button_pos: 4:1.00, 8:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 7:0.87, 4:0.11, 1:0.02
    red_button_pos: 6:0.14, 1:0.14, 5:0.14
    blue_button_pos: 6:0.14, 1:0.14, 5:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 22:0.11; 4:0.11; 10:0.11; 21:0.04; 3:0.04
  Agent2 top policies: 16:0.24; 4:0.22; 12:0.06; 14:0.06; 2:0.05
. r .
. b 1
2 . .

Reward: +0.00, Result: neutral

--- Step 5 ---
Agent 1: DOWN, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 5:1.00, 3:0.00, 0:0.00
    red_button_pos: 8:0.20, 7:0.20, 6:0.20
    blue_button_pos: 4:0.99, 8:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 6:1.00, 3:0.00, 0:0.00
    red_button_pos: 4:0.17, 5:0.17, 2:0.17
    blue_button_pos: 4:0.17, 5:0.17, 2:0.17
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 10:0.14; 4:0.14; 8:0.05; 2:0.05; 7:0.05
  Agent2 top policies: 4:0.45; 3:0.10; 0:0.10; 2:0.09; 5:0.07
. r .
2 b .
. . 1

Reward: +0.00, Result: neutral

--- Step 6 ---
Agent 1: LEFT, Agent 2: RIGHT
  Agent1 beliefs:
    agent_pos: 8:1.00, 5:0.00, 3:0.00
    red_button_pos: 7:0.24, 6:0.24, 1:0.24
    blue_button_pos: 4:0.98, 1:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 3:1.00, 6:0.00, 7:0.00
    red_button_pos: 4:0.20, 5:0.20, 2:0.20
    blue_button_pos: 4:0.20, 5:0.20, 2:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 16:0.27; 14:0.09; 13:0.09; 17:0.07; 12:0.05
  Agent2 top policies: 22:0.28; 4:0.28; 3:0.05; 18:0.05; 0:0.05
. r .
. 2 .
. 1 .

Reward: +0.00, Result: neutral

--- Step 7 ---
Agent 1: LEFT, Agent 2: RIGHT
  Agent1 beliefs:
    agent_pos: 7:1.00, 8:0.00, 5:0.00
    red_button_pos: 6:0.32, 1:0.32, 2:0.32
    blue_button_pos: 4:0.98, 2:0.00, 6:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 4:1.00, 8:0.00, 2:0.00
    red_button_pos: 5:0.24, 2:0.24, 1:0.24
    blue_button_pos: 4:1.00, 0:0.00, 5:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 16:0.33; 14:0.09; 13:0.09; 17:0.07; 0:0.04
  Agent2 top policies: 22:0.18; 4:0.18; 18:0.06; 0:0.06; 3:0.06
. r .
. b 2
1 . .

Reward: +0.00, Result: neutral

--- Step 8 ---
Agent 1: UP, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 6:1.00, 7:0.00, 8:0.00
    red_button_pos: 1:0.47, 2:0.47, 0:0.02
    blue_button_pos: 4:0.97, 2:0.00, 3:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 5:1.00, 3:0.00, 6:0.00
    red_button_pos: 2:0.32, 0:0.32, 1:0.32
    blue_button_pos: 4:0.99, 1:0.00, 0:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 3:0.05; 4:0.05; 18:0.05; 0:0.04; 2:0.04
  Agent2 top policies: 4:0.31; 2:0.09; 0:0.09; 3:0.09; 5:0.07
. r 2
1 b .
. . .

Reward: +0.00, Result: neutral

--- Step 9 ---
Agent 1: RIGHT, Agent 2: LEFT
  Agent1 beliefs:
    agent_pos: 3:1.00, 6:0.00, 7:0.00
    red_button_pos: 1:0.47, 2:0.47, 0:0.02
    blue_button_pos: 4:0.97, 2:0.01, 1:0.01
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 2:1.00, 5:0.00, 3:0.00
    red_button_pos: 1:0.47, 0:0.47, 8:0.03
    blue_button_pos: 4:0.98, 1:0.00, 0:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 18:0.12; 3:0.10; 4:0.05; 23:0.04; 21:0.04
  Agent2 top policies: 16:0.40; 12:0.10; 14:0.10; 17:0.08; 13:0.04
. 2 .
. 1 .
. . .

Reward: +0.00, Result: neutral

--- Step 10 ---
Agent 1: UP, Agent 2: PRESS
  Agent1 beliefs:
    agent_pos: 4:1.00, 8:0.00, 2:0.00
    red_button_pos: 1:0.47, 2:0.47, 0:0.03
    blue_button_pos: 4:1.00, 1:0.00, 0:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 1:1.00, 6:0.00, 0:0.00
    red_button_pos: 1:1.00, 0:0.00, 8:0.00
    blue_button_pos: 4:0.98, 0:0.00, 8:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 4:0.42; 0:0.10; 3:0.10; 5:0.08; 1:0.04
  Agent2 top policies: 25:0.07; 24:0.06; 4:0.06; 26:0.05; 27:0.05
. 2 .
. 1 .
. . .

Reward: +0.00, Result: neutral
Button pressed: red by Agent 2

--- Step 11 ---
Agent 1: UP, Agent 2: DOWN
  Agent1 beliefs:
    agent_pos: 4:1.00, 1:0.00, 8:0.00
    red_button_pos: 1:0.47, 2:0.47, 0:0.03
    blue_button_pos: 4:1.00, 8:0.00, 7:0.00
    red_button_state: 0:0.50, 1:0.50
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 0:0.00, 8:0.00
    blue_button_pos: 4:0.97, 0:0.00, 8:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 0:0.12; 3:0.12; 4:0.11; 5:0.10; 24:0.08
  Agent2 top policies: 10:0.40; 25:0.03; 1:0.03; 6:0.03; 11:0.02
. 2 .
. 1 .
. . .

Reward: +0.00, Result: neutral

--- Step 12 ---
Agent 1: PRESS, Agent 2: DOWN
  Agent1 beliefs:
    agent_pos: 4:1.00, 1:0.00, 2:0.00
    red_button_pos: 1:0.47, 2:0.47, 0:0.03
    blue_button_pos: 4:1.00, 8:0.00, 7:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 1:1.00, 4:0.00, 8:0.00
    red_button_pos: 1:1.00, 8:0.00, 7:0.00
    blue_button_pos: 4:0.96, 0:0.01, 8:0.01
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 24:0.36; 27:0.12; 25:0.11; 26:0.11; 28:0.10
  Agent2 top policies: 10:0.41; 25:0.02; 1:0.02; 6:0.02; 11:0.02
. 2 .
. 1 .
. . .

Reward: +1.00, Result: win
Button pressed: blue by Agent 1

Result: ✅ WIN - win (steps: 12, reward: +1.00)

================================================================================
EPISODE 86
================================================================================
Environment: Red at (1, 0), Blue at (1, 1)

Initial state:
1 r .
. b .
. . 2


--- Step 1 ---
Agent 1: DOWN, Agent 2: LEFT
  Agent1 beliefs:
    agent_pos: 0:1.00, 8:0.00, 7:0.00
    red_button_pos: 8:0.12, 7:0.12, 6:0.12
    blue_button_pos: 8:0.12, 7:0.12, 6:0.12
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 8:1.00, 7:0.00, 6:0.00
    red_button_pos: 7:0.12, 3:0.12, 6:0.12
    blue_button_pos: 7:0.12, 3:0.12, 6:0.12
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 10:0.21; 22:0.21; 9:0.06; 19:0.06; 21:0.05
  Agent2 top policies: 16:0.21; 4:0.21; 12:0.06; 2:0.06; 0:0.05
. r .
1 b .
. 2 .

Reward: +0.00, Result: neutral

--- Step 2 ---
Agent 1: RIGHT, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 3:1.00, 0:0.00, 8:0.00
    red_button_pos: 8:0.14, 7:0.14, 6:0.14
    blue_button_pos: 8:0.14, 7:0.14, 6:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 7:1.00, 8:0.00, 6:0.00
    red_button_pos: 6:0.14, 1:0.14, 5:0.14
    blue_button_pos: 6:0.14, 1:0.14, 5:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 22:0.23; 10:0.23; 9:0.06; 21:0.05; 19:0.05
  Agent2 top policies: 4:0.23; 16:0.23; 12:0.06; 0:0.05; 2:0.05
. r .
. 1 .
. 2 .

Reward: +0.00, Result: neutral

--- Step 3 ---
Agent 1: DOWN, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 4:1.00, 8:0.00, 5:0.00
    red_button_pos: 8:0.17, 7:0.17, 6:0.17
    blue_button_pos: 4:1.00, 8:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 7:0.87, 4:0.12, 8:0.00
    red_button_pos: 6:0.14, 1:0.14, 5:0.14
    blue_button_pos: 6:0.14, 1:0.14, 5:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 10:0.11; 22:0.11; 4:0.11; 3:0.04; 21:0.04
  Agent2 top policies: 4:0.24; 16:0.23; 12:0.06; 2:0.05; 14:0.05
. r .
. 1 .
. 2 .

Reward: +0.00, Result: neutral

--- Step 4 ---
Agent 1: RIGHT, Agent 2: LEFT
  Agent1 beliefs:
    agent_pos: 4:1.00, 7:0.00, 8:0.00
    red_button_pos: 8:0.17, 7:0.17, 6:0.17
    blue_button_pos: 4:1.00, 8:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 7:0.87, 4:0.11, 1:0.02
    red_button_pos: 6:0.14, 1:0.14, 5:0.14
    blue_button_pos: 6:0.14, 1:0.14, 5:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 22:0.11; 4:0.11; 10:0.11; 21:0.04; 3:0.04
  Agent2 top policies: 16:0.24; 4:0.22; 12:0.06; 14:0.06; 2:0.05
. r .
. b 1
2 . .

Reward: +0.00, Result: neutral

--- Step 5 ---
Agent 1: DOWN, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 5:1.00, 3:0.00, 0:0.00
    red_button_pos: 8:0.20, 7:0.20, 6:0.20
    blue_button_pos: 4:0.99, 8:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 6:1.00, 3:0.00, 0:0.00
    red_button_pos: 4:0.17, 5:0.17, 2:0.17
    blue_button_pos: 4:0.17, 5:0.17, 2:0.17
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 10:0.14; 4:0.14; 8:0.05; 2:0.05; 7:0.05
  Agent2 top policies: 4:0.45; 3:0.10; 0:0.10; 2:0.09; 5:0.07
. r .
2 b .
. . 1

Reward: +0.00, Result: neutral

--- Step 6 ---
Agent 1: LEFT, Agent 2: RIGHT
  Agent1 beliefs:
    agent_pos: 8:1.00, 5:0.00, 3:0.00
    red_button_pos: 7:0.24, 6:0.24, 1:0.24
    blue_button_pos: 4:0.98, 1:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 3:1.00, 6:0.00, 7:0.00
    red_button_pos: 4:0.20, 5:0.20, 2:0.20
    blue_button_pos: 4:0.20, 5:0.20, 2:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 16:0.27; 14:0.09; 13:0.09; 17:0.07; 12:0.05
  Agent2 top policies: 22:0.28; 4:0.28; 3:0.05; 18:0.05; 0:0.05
. r .
. 2 .
. 1 .

Reward: +0.00, Result: neutral

--- Step 7 ---
Agent 1: LEFT, Agent 2: RIGHT
  Agent1 beliefs:
    agent_pos: 7:1.00, 8:0.00, 5:0.00
    red_button_pos: 6:0.32, 1:0.32, 2:0.32
    blue_button_pos: 4:0.98, 2:0.00, 6:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 4:1.00, 8:0.00, 2:0.00
    red_button_pos: 5:0.24, 2:0.24, 1:0.24
    blue_button_pos: 4:1.00, 0:0.00, 5:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 16:0.33; 14:0.09; 13:0.09; 17:0.07; 0:0.04
  Agent2 top policies: 22:0.18; 4:0.18; 18:0.06; 0:0.06; 3:0.06
. r .
. b 2
1 . .

Reward: +0.00, Result: neutral

--- Step 8 ---
Agent 1: UP, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 6:1.00, 7:0.00, 8:0.00
    red_button_pos: 1:0.47, 2:0.47, 0:0.02
    blue_button_pos: 4:0.97, 2:0.00, 3:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 5:1.00, 3:0.00, 6:0.00
    red_button_pos: 2:0.32, 0:0.32, 1:0.32
    blue_button_pos: 4:0.99, 1:0.00, 0:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 3:0.05; 4:0.05; 18:0.05; 0:0.04; 2:0.04
  Agent2 top policies: 4:0.31; 2:0.09; 0:0.09; 3:0.09; 5:0.07
. r 2
1 b .
. . .

Reward: +0.00, Result: neutral

--- Step 9 ---
Agent 1: RIGHT, Agent 2: LEFT
  Agent1 beliefs:
    agent_pos: 3:1.00, 6:0.00, 7:0.00
    red_button_pos: 1:0.47, 2:0.47, 0:0.02
    blue_button_pos: 4:0.97, 2:0.01, 1:0.01
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 2:1.00, 5:0.00, 3:0.00
    red_button_pos: 1:0.47, 0:0.47, 8:0.03
    blue_button_pos: 4:0.98, 1:0.00, 0:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 18:0.12; 3:0.10; 4:0.05; 23:0.04; 21:0.04
  Agent2 top policies: 16:0.40; 12:0.10; 14:0.10; 17:0.08; 13:0.04
. 2 .
. 1 .
. . .

Reward: +0.00, Result: neutral

--- Step 10 ---
Agent 1: UP, Agent 2: PRESS
  Agent1 beliefs:
    agent_pos: 4:1.00, 8:0.00, 2:0.00
    red_button_pos: 1:0.47, 2:0.47, 0:0.03
    blue_button_pos: 4:1.00, 1:0.00, 0:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 1:1.00, 6:0.00, 0:0.00
    red_button_pos: 1:1.00, 0:0.00, 8:0.00
    blue_button_pos: 4:0.98, 0:0.00, 8:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 4:0.42; 0:0.10; 3:0.10; 5:0.08; 1:0.04
  Agent2 top policies: 25:0.07; 24:0.06; 4:0.06; 26:0.05; 27:0.05
. 2 .
. 1 .
. . .

Reward: +0.00, Result: neutral
Button pressed: red by Agent 2

--- Step 11 ---
Agent 1: UP, Agent 2: DOWN
  Agent1 beliefs:
    agent_pos: 4:1.00, 1:0.00, 8:0.00
    red_button_pos: 1:0.47, 2:0.47, 0:0.03
    blue_button_pos: 4:1.00, 8:0.00, 7:0.00
    red_button_state: 0:0.50, 1:0.50
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 0:0.00, 8:0.00
    blue_button_pos: 4:0.97, 0:0.00, 8:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 0:0.12; 3:0.12; 4:0.11; 5:0.10; 24:0.08
  Agent2 top policies: 10:0.40; 25:0.03; 1:0.03; 6:0.03; 11:0.02
. 2 .
. 1 .
. . .

Reward: +0.00, Result: neutral

--- Step 12 ---
Agent 1: PRESS, Agent 2: DOWN
  Agent1 beliefs:
    agent_pos: 4:1.00, 1:0.00, 2:0.00
    red_button_pos: 1:0.47, 2:0.47, 0:0.03
    blue_button_pos: 4:1.00, 8:0.00, 7:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 1:1.00, 4:0.00, 8:0.00
    red_button_pos: 1:1.00, 8:0.00, 7:0.00
    blue_button_pos: 4:0.96, 0:0.01, 8:0.01
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 24:0.36; 27:0.12; 25:0.11; 26:0.11; 28:0.10
  Agent2 top policies: 10:0.41; 25:0.02; 1:0.02; 6:0.02; 11:0.02
. 2 .
. 1 .
. . .

Reward: +1.00, Result: win
Button pressed: blue by Agent 1

Result: ✅ WIN - win (steps: 12, reward: +1.00)

================================================================================
EPISODE 87
================================================================================
Environment: Red at (1, 0), Blue at (1, 1)

Initial state:
1 r .
. b .
. . 2


--- Step 1 ---
Agent 1: DOWN, Agent 2: LEFT
  Agent1 beliefs:
    agent_pos: 0:1.00, 8:0.00, 7:0.00
    red_button_pos: 8:0.12, 7:0.12, 6:0.12
    blue_button_pos: 8:0.12, 7:0.12, 6:0.12
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 8:1.00, 7:0.00, 6:0.00
    red_button_pos: 7:0.12, 3:0.12, 6:0.12
    blue_button_pos: 7:0.12, 3:0.12, 6:0.12
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 10:0.21; 22:0.21; 9:0.06; 19:0.06; 21:0.05
  Agent2 top policies: 16:0.21; 4:0.21; 12:0.06; 2:0.06; 0:0.05
. r .
1 b .
. 2 .

Reward: +0.00, Result: neutral

--- Step 2 ---
Agent 1: RIGHT, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 3:1.00, 0:0.00, 8:0.00
    red_button_pos: 8:0.14, 7:0.14, 6:0.14
    blue_button_pos: 8:0.14, 7:0.14, 6:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 7:1.00, 8:0.00, 6:0.00
    red_button_pos: 6:0.14, 1:0.14, 5:0.14
    blue_button_pos: 6:0.14, 1:0.14, 5:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 22:0.23; 10:0.23; 9:0.06; 21:0.05; 19:0.05
  Agent2 top policies: 4:0.23; 16:0.23; 12:0.06; 0:0.05; 2:0.05
. r .
. 1 .
. 2 .

Reward: +0.00, Result: neutral

--- Step 3 ---
Agent 1: DOWN, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 4:1.00, 8:0.00, 5:0.00
    red_button_pos: 8:0.17, 7:0.17, 6:0.17
    blue_button_pos: 4:1.00, 8:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 7:0.87, 4:0.12, 8:0.00
    red_button_pos: 6:0.14, 1:0.14, 5:0.14
    blue_button_pos: 6:0.14, 1:0.14, 5:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 10:0.11; 22:0.11; 4:0.11; 3:0.04; 21:0.04
  Agent2 top policies: 4:0.24; 16:0.23; 12:0.06; 2:0.05; 14:0.05
. r .
. 1 .
. 2 .

Reward: +0.00, Result: neutral

--- Step 4 ---
Agent 1: RIGHT, Agent 2: LEFT
  Agent1 beliefs:
    agent_pos: 4:1.00, 7:0.00, 8:0.00
    red_button_pos: 8:0.17, 7:0.17, 6:0.17
    blue_button_pos: 4:1.00, 8:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 7:0.87, 4:0.11, 1:0.02
    red_button_pos: 6:0.14, 1:0.14, 5:0.14
    blue_button_pos: 6:0.14, 1:0.14, 5:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 22:0.11; 4:0.11; 10:0.11; 21:0.04; 3:0.04
  Agent2 top policies: 16:0.24; 4:0.22; 12:0.06; 14:0.06; 2:0.05
. r .
. b 1
2 . .

Reward: +0.00, Result: neutral

--- Step 5 ---
Agent 1: DOWN, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 5:1.00, 3:0.00, 0:0.00
    red_button_pos: 8:0.20, 7:0.20, 6:0.20
    blue_button_pos: 4:0.99, 8:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 6:1.00, 3:0.00, 0:0.00
    red_button_pos: 4:0.17, 5:0.17, 2:0.17
    blue_button_pos: 4:0.17, 5:0.17, 2:0.17
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 10:0.14; 4:0.14; 8:0.05; 2:0.05; 7:0.05
  Agent2 top policies: 4:0.45; 3:0.10; 0:0.10; 2:0.09; 5:0.07
. r .
2 b .
. . 1

Reward: +0.00, Result: neutral

--- Step 6 ---
Agent 1: LEFT, Agent 2: RIGHT
  Agent1 beliefs:
    agent_pos: 8:1.00, 5:0.00, 3:0.00
    red_button_pos: 7:0.24, 6:0.24, 1:0.24
    blue_button_pos: 4:0.98, 1:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 3:1.00, 6:0.00, 7:0.00
    red_button_pos: 4:0.20, 5:0.20, 2:0.20
    blue_button_pos: 4:0.20, 5:0.20, 2:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 16:0.27; 14:0.09; 13:0.09; 17:0.07; 12:0.05
  Agent2 top policies: 22:0.28; 4:0.28; 3:0.05; 18:0.05; 0:0.05
. r .
. 2 .
. 1 .

Reward: +0.00, Result: neutral

--- Step 7 ---
Agent 1: LEFT, Agent 2: RIGHT
  Agent1 beliefs:
    agent_pos: 7:1.00, 8:0.00, 5:0.00
    red_button_pos: 6:0.32, 1:0.32, 2:0.32
    blue_button_pos: 4:0.98, 2:0.00, 6:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 4:1.00, 8:0.00, 2:0.00
    red_button_pos: 5:0.24, 2:0.24, 1:0.24
    blue_button_pos: 4:1.00, 0:0.00, 5:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 16:0.33; 14:0.09; 13:0.09; 17:0.07; 0:0.04
  Agent2 top policies: 22:0.18; 4:0.18; 18:0.06; 0:0.06; 3:0.06
. r .
. b 2
1 . .

Reward: +0.00, Result: neutral

--- Step 8 ---
Agent 1: UP, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 6:1.00, 7:0.00, 8:0.00
    red_button_pos: 1:0.47, 2:0.47, 0:0.02
    blue_button_pos: 4:0.97, 2:0.00, 3:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 5:1.00, 3:0.00, 6:0.00
    red_button_pos: 2:0.32, 0:0.32, 1:0.32
    blue_button_pos: 4:0.99, 1:0.00, 0:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 3:0.05; 4:0.05; 18:0.05; 0:0.04; 2:0.04
  Agent2 top policies: 4:0.31; 2:0.09; 0:0.09; 3:0.09; 5:0.07
. r 2
1 b .
. . .

Reward: +0.00, Result: neutral

--- Step 9 ---
Agent 1: RIGHT, Agent 2: LEFT
  Agent1 beliefs:
    agent_pos: 3:1.00, 6:0.00, 7:0.00
    red_button_pos: 1:0.47, 2:0.47, 0:0.02
    blue_button_pos: 4:0.97, 2:0.01, 1:0.01
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 2:1.00, 5:0.00, 3:0.00
    red_button_pos: 1:0.47, 0:0.47, 8:0.03
    blue_button_pos: 4:0.98, 1:0.00, 0:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 18:0.12; 3:0.10; 4:0.05; 23:0.04; 21:0.04
  Agent2 top policies: 16:0.40; 12:0.10; 14:0.10; 17:0.08; 13:0.04
. 2 .
. 1 .
. . .

Reward: +0.00, Result: neutral

--- Step 10 ---
Agent 1: UP, Agent 2: PRESS
  Agent1 beliefs:
    agent_pos: 4:1.00, 8:0.00, 2:0.00
    red_button_pos: 1:0.47, 2:0.47, 0:0.03
    blue_button_pos: 4:1.00, 1:0.00, 0:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 1:1.00, 6:0.00, 0:0.00
    red_button_pos: 1:1.00, 0:0.00, 8:0.00
    blue_button_pos: 4:0.98, 0:0.00, 8:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 4:0.42; 0:0.10; 3:0.10; 5:0.08; 1:0.04
  Agent2 top policies: 25:0.07; 24:0.06; 4:0.06; 26:0.05; 27:0.05
. 2 .
. 1 .
. . .

Reward: +0.00, Result: neutral
Button pressed: red by Agent 2

--- Step 11 ---
Agent 1: UP, Agent 2: DOWN
  Agent1 beliefs:
    agent_pos: 4:1.00, 1:0.00, 8:0.00
    red_button_pos: 1:0.47, 2:0.47, 0:0.03
    blue_button_pos: 4:1.00, 8:0.00, 7:0.00
    red_button_state: 0:0.50, 1:0.50
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 0:0.00, 8:0.00
    blue_button_pos: 4:0.97, 0:0.00, 8:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 0:0.12; 3:0.12; 4:0.11; 5:0.10; 24:0.08
  Agent2 top policies: 10:0.40; 25:0.03; 1:0.03; 6:0.03; 11:0.02
. 2 .
. 1 .
. . .

Reward: +0.00, Result: neutral

--- Step 12 ---
Agent 1: PRESS, Agent 2: DOWN
  Agent1 beliefs:
    agent_pos: 4:1.00, 1:0.00, 2:0.00
    red_button_pos: 1:0.47, 2:0.47, 0:0.03
    blue_button_pos: 4:1.00, 8:0.00, 7:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 1:1.00, 4:0.00, 8:0.00
    red_button_pos: 1:1.00, 8:0.00, 7:0.00
    blue_button_pos: 4:0.96, 0:0.01, 8:0.01
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 24:0.36; 27:0.12; 25:0.11; 26:0.11; 28:0.10
  Agent2 top policies: 10:0.41; 25:0.02; 1:0.02; 6:0.02; 11:0.02
. 2 .
. 1 .
. . .

Reward: +1.00, Result: win
Button pressed: blue by Agent 1

Result: ✅ WIN - win (steps: 12, reward: +1.00)

================================================================================
EPISODE 88
================================================================================
Environment: Red at (1, 0), Blue at (1, 1)

Initial state:
1 r .
. b .
. . 2


--- Step 1 ---
Agent 1: DOWN, Agent 2: LEFT
  Agent1 beliefs:
    agent_pos: 0:1.00, 8:0.00, 7:0.00
    red_button_pos: 8:0.12, 7:0.12, 6:0.12
    blue_button_pos: 8:0.12, 7:0.12, 6:0.12
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 8:1.00, 7:0.00, 6:0.00
    red_button_pos: 7:0.12, 3:0.12, 6:0.12
    blue_button_pos: 7:0.12, 3:0.12, 6:0.12
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 10:0.21; 22:0.21; 9:0.06; 19:0.06; 21:0.05
  Agent2 top policies: 16:0.21; 4:0.21; 12:0.06; 2:0.06; 0:0.05
. r .
1 b .
. 2 .

Reward: +0.00, Result: neutral

--- Step 2 ---
Agent 1: RIGHT, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 3:1.00, 0:0.00, 8:0.00
    red_button_pos: 8:0.14, 7:0.14, 6:0.14
    blue_button_pos: 8:0.14, 7:0.14, 6:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 7:1.00, 8:0.00, 6:0.00
    red_button_pos: 6:0.14, 1:0.14, 5:0.14
    blue_button_pos: 6:0.14, 1:0.14, 5:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 22:0.23; 10:0.23; 9:0.06; 21:0.05; 19:0.05
  Agent2 top policies: 4:0.23; 16:0.23; 12:0.06; 0:0.05; 2:0.05
. r .
. 1 .
. 2 .

Reward: +0.00, Result: neutral

--- Step 3 ---
Agent 1: DOWN, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 4:1.00, 8:0.00, 5:0.00
    red_button_pos: 8:0.17, 7:0.17, 6:0.17
    blue_button_pos: 4:1.00, 8:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 7:0.87, 4:0.12, 8:0.00
    red_button_pos: 6:0.14, 1:0.14, 5:0.14
    blue_button_pos: 6:0.14, 1:0.14, 5:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 10:0.11; 22:0.11; 4:0.11; 3:0.04; 21:0.04
  Agent2 top policies: 4:0.24; 16:0.23; 12:0.06; 2:0.05; 14:0.05
. r .
. 1 .
. 2 .

Reward: +0.00, Result: neutral

--- Step 4 ---
Agent 1: RIGHT, Agent 2: LEFT
  Agent1 beliefs:
    agent_pos: 4:1.00, 7:0.00, 8:0.00
    red_button_pos: 8:0.17, 7:0.17, 6:0.17
    blue_button_pos: 4:1.00, 8:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 7:0.87, 4:0.11, 1:0.02
    red_button_pos: 6:0.14, 1:0.14, 5:0.14
    blue_button_pos: 6:0.14, 1:0.14, 5:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 22:0.11; 4:0.11; 10:0.11; 21:0.04; 3:0.04
  Agent2 top policies: 16:0.24; 4:0.22; 12:0.06; 14:0.06; 2:0.05
. r .
. b 1
2 . .

Reward: +0.00, Result: neutral

--- Step 5 ---
Agent 1: DOWN, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 5:1.00, 3:0.00, 0:0.00
    red_button_pos: 8:0.20, 7:0.20, 6:0.20
    blue_button_pos: 4:0.99, 8:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 6:1.00, 3:0.00, 0:0.00
    red_button_pos: 4:0.17, 5:0.17, 2:0.17
    blue_button_pos: 4:0.17, 5:0.17, 2:0.17
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 10:0.14; 4:0.14; 8:0.05; 2:0.05; 7:0.05
  Agent2 top policies: 4:0.45; 3:0.10; 0:0.10; 2:0.09; 5:0.07
. r .
2 b .
. . 1

Reward: +0.00, Result: neutral

--- Step 6 ---
Agent 1: LEFT, Agent 2: RIGHT
  Agent1 beliefs:
    agent_pos: 8:1.00, 5:0.00, 3:0.00
    red_button_pos: 7:0.24, 6:0.24, 1:0.24
    blue_button_pos: 4:0.98, 1:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 3:1.00, 6:0.00, 7:0.00
    red_button_pos: 4:0.20, 5:0.20, 2:0.20
    blue_button_pos: 4:0.20, 5:0.20, 2:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 16:0.27; 14:0.09; 13:0.09; 17:0.07; 12:0.05
  Agent2 top policies: 22:0.28; 4:0.28; 3:0.05; 18:0.05; 0:0.05
. r .
. 2 .
. 1 .

Reward: +0.00, Result: neutral

--- Step 7 ---
Agent 1: LEFT, Agent 2: RIGHT
  Agent1 beliefs:
    agent_pos: 7:1.00, 8:0.00, 5:0.00
    red_button_pos: 6:0.32, 1:0.32, 2:0.32
    blue_button_pos: 4:0.98, 2:0.00, 6:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 4:1.00, 8:0.00, 2:0.00
    red_button_pos: 5:0.24, 2:0.24, 1:0.24
    blue_button_pos: 4:1.00, 0:0.00, 5:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 16:0.33; 14:0.09; 13:0.09; 17:0.07; 0:0.04
  Agent2 top policies: 22:0.18; 4:0.18; 18:0.06; 0:0.06; 3:0.06
. r .
. b 2
1 . .

Reward: +0.00, Result: neutral

--- Step 8 ---
Agent 1: UP, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 6:1.00, 7:0.00, 8:0.00
    red_button_pos: 1:0.47, 2:0.47, 0:0.02
    blue_button_pos: 4:0.97, 2:0.00, 3:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 5:1.00, 3:0.00, 6:0.00
    red_button_pos: 2:0.32, 0:0.32, 1:0.32
    blue_button_pos: 4:0.99, 1:0.00, 0:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 3:0.05; 4:0.05; 18:0.05; 0:0.04; 2:0.04
  Agent2 top policies: 4:0.31; 2:0.09; 0:0.09; 3:0.09; 5:0.07
. r 2
1 b .
. . .

Reward: +0.00, Result: neutral

--- Step 9 ---
Agent 1: RIGHT, Agent 2: LEFT
  Agent1 beliefs:
    agent_pos: 3:1.00, 6:0.00, 7:0.00
    red_button_pos: 1:0.47, 2:0.47, 0:0.02
    blue_button_pos: 4:0.97, 2:0.01, 1:0.01
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 2:1.00, 5:0.00, 3:0.00
    red_button_pos: 1:0.47, 0:0.47, 8:0.03
    blue_button_pos: 4:0.98, 1:0.00, 0:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 18:0.12; 3:0.10; 4:0.05; 23:0.04; 21:0.04
  Agent2 top policies: 16:0.40; 12:0.10; 14:0.10; 17:0.08; 13:0.04
. 2 .
. 1 .
. . .

Reward: +0.00, Result: neutral

--- Step 10 ---
Agent 1: UP, Agent 2: PRESS
  Agent1 beliefs:
    agent_pos: 4:1.00, 8:0.00, 2:0.00
    red_button_pos: 1:0.47, 2:0.47, 0:0.03
    blue_button_pos: 4:1.00, 1:0.00, 0:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 1:1.00, 6:0.00, 0:0.00
    red_button_pos: 1:1.00, 0:0.00, 8:0.00
    blue_button_pos: 4:0.98, 0:0.00, 8:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 4:0.42; 0:0.10; 3:0.10; 5:0.08; 1:0.04
  Agent2 top policies: 25:0.07; 24:0.06; 4:0.06; 26:0.05; 27:0.05
. 2 .
. 1 .
. . .

Reward: +0.00, Result: neutral
Button pressed: red by Agent 2

--- Step 11 ---
Agent 1: UP, Agent 2: DOWN
  Agent1 beliefs:
    agent_pos: 4:1.00, 1:0.00, 8:0.00
    red_button_pos: 1:0.47, 2:0.47, 0:0.03
    blue_button_pos: 4:1.00, 8:0.00, 7:0.00
    red_button_state: 0:0.50, 1:0.50
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 0:0.00, 8:0.00
    blue_button_pos: 4:0.97, 0:0.00, 8:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 0:0.12; 3:0.12; 4:0.11; 5:0.10; 24:0.08
  Agent2 top policies: 10:0.40; 25:0.03; 1:0.03; 6:0.03; 11:0.02
. 2 .
. 1 .
. . .

Reward: +0.00, Result: neutral

--- Step 12 ---
Agent 1: PRESS, Agent 2: DOWN
  Agent1 beliefs:
    agent_pos: 4:1.00, 1:0.00, 2:0.00
    red_button_pos: 1:0.47, 2:0.47, 0:0.03
    blue_button_pos: 4:1.00, 8:0.00, 7:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 1:1.00, 4:0.00, 8:0.00
    red_button_pos: 1:1.00, 8:0.00, 7:0.00
    blue_button_pos: 4:0.96, 0:0.01, 8:0.01
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 24:0.36; 27:0.12; 25:0.11; 26:0.11; 28:0.10
  Agent2 top policies: 10:0.41; 25:0.02; 1:0.02; 6:0.02; 11:0.02
. 2 .
. 1 .
. . .

Reward: +1.00, Result: win
Button pressed: blue by Agent 1

Result: ✅ WIN - win (steps: 12, reward: +1.00)

================================================================================
EPISODE 89
================================================================================
Environment: Red at (1, 0), Blue at (1, 1)

Initial state:
1 r .
. b .
. . 2


--- Step 1 ---
Agent 1: DOWN, Agent 2: LEFT
  Agent1 beliefs:
    agent_pos: 0:1.00, 8:0.00, 7:0.00
    red_button_pos: 8:0.12, 7:0.12, 6:0.12
    blue_button_pos: 8:0.12, 7:0.12, 6:0.12
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 8:1.00, 7:0.00, 6:0.00
    red_button_pos: 7:0.12, 3:0.12, 6:0.12
    blue_button_pos: 7:0.12, 3:0.12, 6:0.12
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 10:0.21; 22:0.21; 9:0.06; 19:0.06; 21:0.05
  Agent2 top policies: 16:0.21; 4:0.21; 12:0.06; 2:0.06; 0:0.05
. r .
1 b .
. 2 .

Reward: +0.00, Result: neutral

--- Step 2 ---
Agent 1: RIGHT, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 3:1.00, 0:0.00, 8:0.00
    red_button_pos: 8:0.14, 7:0.14, 6:0.14
    blue_button_pos: 8:0.14, 7:0.14, 6:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 7:1.00, 8:0.00, 6:0.00
    red_button_pos: 6:0.14, 1:0.14, 5:0.14
    blue_button_pos: 6:0.14, 1:0.14, 5:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 22:0.23; 10:0.23; 9:0.06; 21:0.05; 19:0.05
  Agent2 top policies: 4:0.23; 16:0.23; 12:0.06; 0:0.05; 2:0.05
. r .
. 1 .
. 2 .

Reward: +0.00, Result: neutral

--- Step 3 ---
Agent 1: DOWN, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 4:1.00, 8:0.00, 5:0.00
    red_button_pos: 8:0.17, 7:0.17, 6:0.17
    blue_button_pos: 4:1.00, 8:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 7:0.87, 4:0.12, 8:0.00
    red_button_pos: 6:0.14, 1:0.14, 5:0.14
    blue_button_pos: 6:0.14, 1:0.14, 5:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 10:0.11; 22:0.11; 4:0.11; 3:0.04; 21:0.04
  Agent2 top policies: 4:0.24; 16:0.23; 12:0.06; 2:0.05; 14:0.05
. r .
. 1 .
. 2 .

Reward: +0.00, Result: neutral

--- Step 4 ---
Agent 1: RIGHT, Agent 2: LEFT
  Agent1 beliefs:
    agent_pos: 4:1.00, 7:0.00, 8:0.00
    red_button_pos: 8:0.17, 7:0.17, 6:0.17
    blue_button_pos: 4:1.00, 8:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 7:0.87, 4:0.11, 1:0.02
    red_button_pos: 6:0.14, 1:0.14, 5:0.14
    blue_button_pos: 6:0.14, 1:0.14, 5:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 22:0.11; 4:0.11; 10:0.11; 21:0.04; 3:0.04
  Agent2 top policies: 16:0.24; 4:0.22; 12:0.06; 14:0.06; 2:0.05
. r .
. b 1
2 . .

Reward: +0.00, Result: neutral

--- Step 5 ---
Agent 1: DOWN, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 5:1.00, 3:0.00, 0:0.00
    red_button_pos: 8:0.20, 7:0.20, 6:0.20
    blue_button_pos: 4:0.99, 8:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 6:1.00, 3:0.00, 0:0.00
    red_button_pos: 4:0.17, 5:0.17, 2:0.17
    blue_button_pos: 4:0.17, 5:0.17, 2:0.17
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 10:0.14; 4:0.14; 8:0.05; 2:0.05; 7:0.05
  Agent2 top policies: 4:0.45; 3:0.10; 0:0.10; 2:0.09; 5:0.07
. r .
2 b .
. . 1

Reward: +0.00, Result: neutral

--- Step 6 ---
Agent 1: LEFT, Agent 2: RIGHT
  Agent1 beliefs:
    agent_pos: 8:1.00, 5:0.00, 3:0.00
    red_button_pos: 7:0.24, 6:0.24, 1:0.24
    blue_button_pos: 4:0.98, 1:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 3:1.00, 6:0.00, 7:0.00
    red_button_pos: 4:0.20, 5:0.20, 2:0.20
    blue_button_pos: 4:0.20, 5:0.20, 2:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 16:0.27; 14:0.09; 13:0.09; 17:0.07; 12:0.05
  Agent2 top policies: 22:0.28; 4:0.28; 3:0.05; 18:0.05; 0:0.05
. r .
. 2 .
. 1 .

Reward: +0.00, Result: neutral

--- Step 7 ---
Agent 1: LEFT, Agent 2: RIGHT
  Agent1 beliefs:
    agent_pos: 7:1.00, 8:0.00, 5:0.00
    red_button_pos: 6:0.32, 1:0.32, 2:0.32
    blue_button_pos: 4:0.98, 2:0.00, 6:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 4:1.00, 8:0.00, 2:0.00
    red_button_pos: 5:0.24, 2:0.24, 1:0.24
    blue_button_pos: 4:1.00, 0:0.00, 5:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 16:0.33; 14:0.09; 13:0.09; 17:0.07; 0:0.04
  Agent2 top policies: 22:0.18; 4:0.18; 18:0.06; 0:0.06; 3:0.06
. r .
. b 2
1 . .

Reward: +0.00, Result: neutral

--- Step 8 ---
Agent 1: UP, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 6:1.00, 7:0.00, 8:0.00
    red_button_pos: 1:0.47, 2:0.47, 0:0.02
    blue_button_pos: 4:0.97, 2:0.00, 3:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 5:1.00, 3:0.00, 6:0.00
    red_button_pos: 2:0.32, 0:0.32, 1:0.32
    blue_button_pos: 4:0.99, 1:0.00, 0:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 3:0.05; 4:0.05; 18:0.05; 0:0.04; 2:0.04
  Agent2 top policies: 4:0.31; 2:0.09; 0:0.09; 3:0.09; 5:0.07
. r 2
1 b .
. . .

Reward: +0.00, Result: neutral

--- Step 9 ---
Agent 1: RIGHT, Agent 2: LEFT
  Agent1 beliefs:
    agent_pos: 3:1.00, 6:0.00, 7:0.00
    red_button_pos: 1:0.47, 2:0.47, 0:0.02
    blue_button_pos: 4:0.97, 2:0.01, 1:0.01
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 2:1.00, 5:0.00, 3:0.00
    red_button_pos: 1:0.47, 0:0.47, 8:0.03
    blue_button_pos: 4:0.98, 1:0.00, 0:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 18:0.12; 3:0.10; 4:0.05; 23:0.04; 21:0.04
  Agent2 top policies: 16:0.40; 12:0.10; 14:0.10; 17:0.08; 13:0.04
. 2 .
. 1 .
. . .

Reward: +0.00, Result: neutral

--- Step 10 ---
Agent 1: UP, Agent 2: PRESS
  Agent1 beliefs:
    agent_pos: 4:1.00, 8:0.00, 2:0.00
    red_button_pos: 1:0.47, 2:0.47, 0:0.03
    blue_button_pos: 4:1.00, 1:0.00, 0:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 1:1.00, 6:0.00, 0:0.00
    red_button_pos: 1:1.00, 0:0.00, 8:0.00
    blue_button_pos: 4:0.98, 0:0.00, 8:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 4:0.42; 0:0.10; 3:0.10; 5:0.08; 1:0.04
  Agent2 top policies: 25:0.07; 24:0.06; 4:0.06; 26:0.05; 27:0.05
. 2 .
. 1 .
. . .

Reward: +0.00, Result: neutral
Button pressed: red by Agent 2

--- Step 11 ---
Agent 1: UP, Agent 2: DOWN
  Agent1 beliefs:
    agent_pos: 4:1.00, 1:0.00, 8:0.00
    red_button_pos: 1:0.47, 2:0.47, 0:0.03
    blue_button_pos: 4:1.00, 8:0.00, 7:0.00
    red_button_state: 0:0.50, 1:0.50
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 0:0.00, 8:0.00
    blue_button_pos: 4:0.97, 0:0.00, 8:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 0:0.12; 3:0.12; 4:0.11; 5:0.10; 24:0.08
  Agent2 top policies: 10:0.40; 25:0.03; 1:0.03; 6:0.03; 11:0.02
. 2 .
. 1 .
. . .

Reward: +0.00, Result: neutral

--- Step 12 ---
Agent 1: PRESS, Agent 2: DOWN
  Agent1 beliefs:
    agent_pos: 4:1.00, 1:0.00, 2:0.00
    red_button_pos: 1:0.47, 2:0.47, 0:0.03
    blue_button_pos: 4:1.00, 8:0.00, 7:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 1:1.00, 4:0.00, 8:0.00
    red_button_pos: 1:1.00, 8:0.00, 7:0.00
    blue_button_pos: 4:0.96, 0:0.01, 8:0.01
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 24:0.36; 27:0.12; 25:0.11; 26:0.11; 28:0.10
  Agent2 top policies: 10:0.41; 25:0.02; 1:0.02; 6:0.02; 11:0.02
. 2 .
. 1 .
. . .

Reward: +1.00, Result: win
Button pressed: blue by Agent 1

Result: ✅ WIN - win (steps: 12, reward: +1.00)

================================================================================
EPISODE 90
================================================================================
Environment: Red at (1, 0), Blue at (1, 1)

Initial state:
1 r .
. b .
. . 2


--- Step 1 ---
Agent 1: DOWN, Agent 2: LEFT
  Agent1 beliefs:
    agent_pos: 0:1.00, 8:0.00, 7:0.00
    red_button_pos: 8:0.12, 7:0.12, 6:0.12
    blue_button_pos: 8:0.12, 7:0.12, 6:0.12
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 8:1.00, 7:0.00, 6:0.00
    red_button_pos: 7:0.12, 3:0.12, 6:0.12
    blue_button_pos: 7:0.12, 3:0.12, 6:0.12
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 10:0.21; 22:0.21; 9:0.06; 19:0.06; 21:0.05
  Agent2 top policies: 16:0.21; 4:0.21; 12:0.06; 2:0.06; 0:0.05
. r .
1 b .
. 2 .

Reward: +0.00, Result: neutral

--- Step 2 ---
Agent 1: RIGHT, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 3:1.00, 0:0.00, 8:0.00
    red_button_pos: 8:0.14, 7:0.14, 6:0.14
    blue_button_pos: 8:0.14, 7:0.14, 6:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 7:1.00, 8:0.00, 6:0.00
    red_button_pos: 6:0.14, 1:0.14, 5:0.14
    blue_button_pos: 6:0.14, 1:0.14, 5:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 22:0.23; 10:0.23; 9:0.06; 21:0.05; 19:0.05
  Agent2 top policies: 4:0.23; 16:0.23; 12:0.06; 0:0.05; 2:0.05
. r .
. 1 .
. 2 .

Reward: +0.00, Result: neutral

--- Step 3 ---
Agent 1: DOWN, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 4:1.00, 8:0.00, 5:0.00
    red_button_pos: 8:0.17, 7:0.17, 6:0.17
    blue_button_pos: 4:1.00, 8:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 7:0.87, 4:0.12, 8:0.00
    red_button_pos: 6:0.14, 1:0.14, 5:0.14
    blue_button_pos: 6:0.14, 1:0.14, 5:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 10:0.11; 22:0.11; 4:0.11; 3:0.04; 21:0.04
  Agent2 top policies: 4:0.24; 16:0.23; 12:0.06; 2:0.05; 14:0.05
. r .
. 1 .
. 2 .

Reward: +0.00, Result: neutral

--- Step 4 ---
Agent 1: RIGHT, Agent 2: LEFT
  Agent1 beliefs:
    agent_pos: 4:1.00, 7:0.00, 8:0.00
    red_button_pos: 8:0.17, 7:0.17, 6:0.17
    blue_button_pos: 4:1.00, 8:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 7:0.87, 4:0.11, 1:0.02
    red_button_pos: 6:0.14, 1:0.14, 5:0.14
    blue_button_pos: 6:0.14, 1:0.14, 5:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 22:0.11; 4:0.11; 10:0.11; 21:0.04; 3:0.04
  Agent2 top policies: 16:0.24; 4:0.22; 12:0.06; 14:0.06; 2:0.05
. r .
. b 1
2 . .

Reward: +0.00, Result: neutral

--- Step 5 ---
Agent 1: DOWN, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 5:1.00, 3:0.00, 0:0.00
    red_button_pos: 8:0.20, 7:0.20, 6:0.20
    blue_button_pos: 4:0.99, 8:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 6:1.00, 3:0.00, 0:0.00
    red_button_pos: 4:0.17, 5:0.17, 2:0.17
    blue_button_pos: 4:0.17, 5:0.17, 2:0.17
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 10:0.14; 4:0.14; 8:0.05; 2:0.05; 7:0.05
  Agent2 top policies: 4:0.45; 3:0.10; 0:0.10; 2:0.09; 5:0.07
. r .
2 b .
. . 1

Reward: +0.00, Result: neutral

--- Step 6 ---
Agent 1: LEFT, Agent 2: RIGHT
  Agent1 beliefs:
    agent_pos: 8:1.00, 5:0.00, 3:0.00
    red_button_pos: 7:0.24, 6:0.24, 1:0.24
    blue_button_pos: 4:0.98, 1:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 3:1.00, 6:0.00, 7:0.00
    red_button_pos: 4:0.20, 5:0.20, 2:0.20
    blue_button_pos: 4:0.20, 5:0.20, 2:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 16:0.27; 14:0.09; 13:0.09; 17:0.07; 12:0.05
  Agent2 top policies: 22:0.28; 4:0.28; 3:0.05; 18:0.05; 0:0.05
. r .
. 2 .
. 1 .

Reward: +0.00, Result: neutral

--- Step 7 ---
Agent 1: LEFT, Agent 2: RIGHT
  Agent1 beliefs:
    agent_pos: 7:1.00, 8:0.00, 5:0.00
    red_button_pos: 6:0.32, 1:0.32, 2:0.32
    blue_button_pos: 4:0.98, 2:0.00, 6:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 4:1.00, 8:0.00, 2:0.00
    red_button_pos: 5:0.24, 2:0.24, 1:0.24
    blue_button_pos: 4:1.00, 0:0.00, 5:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 16:0.33; 14:0.09; 13:0.09; 17:0.07; 0:0.04
  Agent2 top policies: 22:0.18; 4:0.18; 18:0.06; 0:0.06; 3:0.06
. r .
. b 2
1 . .

Reward: +0.00, Result: neutral

--- Step 8 ---
Agent 1: UP, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 6:1.00, 7:0.00, 8:0.00
    red_button_pos: 1:0.47, 2:0.47, 0:0.02
    blue_button_pos: 4:0.97, 2:0.00, 3:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 5:1.00, 3:0.00, 6:0.00
    red_button_pos: 2:0.32, 0:0.32, 1:0.32
    blue_button_pos: 4:0.99, 1:0.00, 0:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 3:0.05; 4:0.05; 18:0.05; 0:0.04; 2:0.04
  Agent2 top policies: 4:0.31; 2:0.09; 0:0.09; 3:0.09; 5:0.07
. r 2
1 b .
. . .

Reward: +0.00, Result: neutral

--- Step 9 ---
Agent 1: RIGHT, Agent 2: LEFT
  Agent1 beliefs:
    agent_pos: 3:1.00, 6:0.00, 7:0.00
    red_button_pos: 1:0.47, 2:0.47, 0:0.02
    blue_button_pos: 4:0.97, 2:0.01, 1:0.01
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 2:1.00, 5:0.00, 3:0.00
    red_button_pos: 1:0.47, 0:0.47, 8:0.03
    blue_button_pos: 4:0.98, 1:0.00, 0:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 18:0.12; 3:0.10; 4:0.05; 23:0.04; 21:0.04
  Agent2 top policies: 16:0.40; 12:0.10; 14:0.10; 17:0.08; 13:0.04
. 2 .
. 1 .
. . .

Reward: +0.00, Result: neutral

--- Step 10 ---
Agent 1: UP, Agent 2: PRESS
  Agent1 beliefs:
    agent_pos: 4:1.00, 8:0.00, 2:0.00
    red_button_pos: 1:0.47, 2:0.47, 0:0.03
    blue_button_pos: 4:1.00, 1:0.00, 0:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 1:1.00, 6:0.00, 0:0.00
    red_button_pos: 1:1.00, 0:0.00, 8:0.00
    blue_button_pos: 4:0.98, 0:0.00, 8:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 4:0.42; 0:0.10; 3:0.10; 5:0.08; 1:0.04
  Agent2 top policies: 25:0.07; 24:0.06; 4:0.06; 26:0.05; 27:0.05
. 2 .
. 1 .
. . .

Reward: +0.00, Result: neutral
Button pressed: red by Agent 2

--- Step 11 ---
Agent 1: UP, Agent 2: DOWN
  Agent1 beliefs:
    agent_pos: 4:1.00, 1:0.00, 8:0.00
    red_button_pos: 1:0.47, 2:0.47, 0:0.03
    blue_button_pos: 4:1.00, 8:0.00, 7:0.00
    red_button_state: 0:0.50, 1:0.50
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 0:0.00, 8:0.00
    blue_button_pos: 4:0.97, 0:0.00, 8:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 0:0.12; 3:0.12; 4:0.11; 5:0.10; 24:0.08
  Agent2 top policies: 10:0.40; 25:0.03; 1:0.03; 6:0.03; 11:0.02
. 2 .
. 1 .
. . .

Reward: +0.00, Result: neutral

--- Step 12 ---
Agent 1: PRESS, Agent 2: DOWN
  Agent1 beliefs:
    agent_pos: 4:1.00, 1:0.00, 2:0.00
    red_button_pos: 1:0.47, 2:0.47, 0:0.03
    blue_button_pos: 4:1.00, 8:0.00, 7:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 1:1.00, 4:0.00, 8:0.00
    red_button_pos: 1:1.00, 8:0.00, 7:0.00
    blue_button_pos: 4:0.96, 0:0.01, 8:0.01
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 24:0.36; 27:0.12; 25:0.11; 26:0.11; 28:0.10
  Agent2 top policies: 10:0.41; 25:0.02; 1:0.02; 6:0.02; 11:0.02
. 2 .
. 1 .
. . .

Reward: +1.00, Result: win
Button pressed: blue by Agent 1

Result: ✅ WIN - win (steps: 12, reward: +1.00)

================================================================================
EPISODE 91
================================================================================
Environment: Red at (1, 0), Blue at (1, 1)

Initial state:
1 r .
. b .
. . 2


--- Step 1 ---
Agent 1: DOWN, Agent 2: LEFT
  Agent1 beliefs:
    agent_pos: 0:1.00, 8:0.00, 7:0.00
    red_button_pos: 8:0.12, 7:0.12, 6:0.12
    blue_button_pos: 8:0.12, 7:0.12, 6:0.12
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 8:1.00, 7:0.00, 6:0.00
    red_button_pos: 7:0.12, 3:0.12, 6:0.12
    blue_button_pos: 7:0.12, 3:0.12, 6:0.12
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 10:0.21; 22:0.21; 9:0.06; 19:0.06; 21:0.05
  Agent2 top policies: 16:0.21; 4:0.21; 12:0.06; 2:0.06; 0:0.05
. r .
1 b .
. 2 .

Reward: +0.00, Result: neutral

--- Step 2 ---
Agent 1: RIGHT, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 3:1.00, 0:0.00, 8:0.00
    red_button_pos: 8:0.14, 7:0.14, 6:0.14
    blue_button_pos: 8:0.14, 7:0.14, 6:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 7:1.00, 8:0.00, 6:0.00
    red_button_pos: 6:0.14, 1:0.14, 5:0.14
    blue_button_pos: 6:0.14, 1:0.14, 5:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 22:0.23; 10:0.23; 9:0.06; 21:0.05; 19:0.05
  Agent2 top policies: 4:0.23; 16:0.23; 12:0.06; 0:0.05; 2:0.05
. r .
. 1 .
. 2 .

Reward: +0.00, Result: neutral

--- Step 3 ---
Agent 1: DOWN, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 4:1.00, 8:0.00, 5:0.00
    red_button_pos: 8:0.17, 7:0.17, 6:0.17
    blue_button_pos: 4:1.00, 8:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 7:0.87, 4:0.12, 8:0.00
    red_button_pos: 6:0.14, 1:0.14, 5:0.14
    blue_button_pos: 6:0.14, 1:0.14, 5:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 10:0.11; 22:0.11; 4:0.11; 3:0.04; 21:0.04
  Agent2 top policies: 4:0.24; 16:0.23; 12:0.06; 2:0.05; 14:0.05
. r .
. 1 .
. 2 .

Reward: +0.00, Result: neutral

--- Step 4 ---
Agent 1: RIGHT, Agent 2: LEFT
  Agent1 beliefs:
    agent_pos: 4:1.00, 7:0.00, 8:0.00
    red_button_pos: 8:0.17, 7:0.17, 6:0.17
    blue_button_pos: 4:1.00, 8:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 7:0.87, 4:0.11, 1:0.02
    red_button_pos: 6:0.14, 1:0.14, 5:0.14
    blue_button_pos: 6:0.14, 1:0.14, 5:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 22:0.11; 4:0.11; 10:0.11; 21:0.04; 3:0.04
  Agent2 top policies: 16:0.24; 4:0.22; 12:0.06; 14:0.06; 2:0.05
. r .
. b 1
2 . .

Reward: +0.00, Result: neutral

--- Step 5 ---
Agent 1: DOWN, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 5:1.00, 3:0.00, 0:0.00
    red_button_pos: 8:0.20, 7:0.20, 6:0.20
    blue_button_pos: 4:0.99, 8:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 6:1.00, 3:0.00, 0:0.00
    red_button_pos: 4:0.17, 5:0.17, 2:0.17
    blue_button_pos: 4:0.17, 5:0.17, 2:0.17
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 10:0.14; 4:0.14; 8:0.05; 2:0.05; 7:0.05
  Agent2 top policies: 4:0.45; 3:0.10; 0:0.10; 2:0.09; 5:0.07
. r .
2 b .
. . 1

Reward: +0.00, Result: neutral

--- Step 6 ---
Agent 1: LEFT, Agent 2: RIGHT
  Agent1 beliefs:
    agent_pos: 8:1.00, 5:0.00, 3:0.00
    red_button_pos: 7:0.24, 6:0.24, 1:0.24
    blue_button_pos: 4:0.98, 1:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 3:1.00, 6:0.00, 7:0.00
    red_button_pos: 4:0.20, 5:0.20, 2:0.20
    blue_button_pos: 4:0.20, 5:0.20, 2:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 16:0.27; 14:0.09; 13:0.09; 17:0.07; 12:0.05
  Agent2 top policies: 22:0.28; 4:0.28; 3:0.05; 18:0.05; 0:0.05
. r .
. 2 .
. 1 .

Reward: +0.00, Result: neutral

--- Step 7 ---
Agent 1: LEFT, Agent 2: RIGHT
  Agent1 beliefs:
    agent_pos: 7:1.00, 8:0.00, 5:0.00
    red_button_pos: 6:0.32, 1:0.32, 2:0.32
    blue_button_pos: 4:0.98, 2:0.00, 6:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 4:1.00, 8:0.00, 2:0.00
    red_button_pos: 5:0.24, 2:0.24, 1:0.24
    blue_button_pos: 4:1.00, 0:0.00, 5:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 16:0.33; 14:0.09; 13:0.09; 17:0.07; 0:0.04
  Agent2 top policies: 22:0.18; 4:0.18; 18:0.06; 0:0.06; 3:0.06
. r .
. b 2
1 . .

Reward: +0.00, Result: neutral

--- Step 8 ---
Agent 1: UP, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 6:1.00, 7:0.00, 8:0.00
    red_button_pos: 1:0.47, 2:0.47, 0:0.02
    blue_button_pos: 4:0.97, 2:0.00, 3:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 5:1.00, 3:0.00, 6:0.00
    red_button_pos: 2:0.32, 0:0.32, 1:0.32
    blue_button_pos: 4:0.99, 1:0.00, 0:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 3:0.05; 4:0.05; 18:0.05; 0:0.04; 2:0.04
  Agent2 top policies: 4:0.31; 2:0.09; 0:0.09; 3:0.09; 5:0.07
. r 2
1 b .
. . .

Reward: +0.00, Result: neutral

--- Step 9 ---
Agent 1: RIGHT, Agent 2: LEFT
  Agent1 beliefs:
    agent_pos: 3:1.00, 6:0.00, 7:0.00
    red_button_pos: 1:0.47, 2:0.47, 0:0.02
    blue_button_pos: 4:0.97, 2:0.01, 1:0.01
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 2:1.00, 5:0.00, 3:0.00
    red_button_pos: 1:0.47, 0:0.47, 8:0.03
    blue_button_pos: 4:0.98, 1:0.00, 0:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 18:0.12; 3:0.10; 4:0.05; 23:0.04; 21:0.04
  Agent2 top policies: 16:0.40; 12:0.10; 14:0.10; 17:0.08; 13:0.04
. 2 .
. 1 .
. . .

Reward: +0.00, Result: neutral

--- Step 10 ---
Agent 1: UP, Agent 2: PRESS
  Agent1 beliefs:
    agent_pos: 4:1.00, 8:0.00, 2:0.00
    red_button_pos: 1:0.47, 2:0.47, 0:0.03
    blue_button_pos: 4:1.00, 1:0.00, 0:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 1:1.00, 6:0.00, 0:0.00
    red_button_pos: 1:1.00, 0:0.00, 8:0.00
    blue_button_pos: 4:0.98, 0:0.00, 8:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 4:0.42; 0:0.10; 3:0.10; 5:0.08; 1:0.04
  Agent2 top policies: 25:0.07; 24:0.06; 4:0.06; 26:0.05; 27:0.05
. 2 .
. 1 .
. . .

Reward: +0.00, Result: neutral
Button pressed: red by Agent 2

--- Step 11 ---
Agent 1: UP, Agent 2: DOWN
  Agent1 beliefs:
    agent_pos: 4:1.00, 1:0.00, 8:0.00
    red_button_pos: 1:0.47, 2:0.47, 0:0.03
    blue_button_pos: 4:1.00, 8:0.00, 7:0.00
    red_button_state: 0:0.50, 1:0.50
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 0:0.00, 8:0.00
    blue_button_pos: 4:0.97, 0:0.00, 8:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 0:0.12; 3:0.12; 4:0.11; 5:0.10; 24:0.08
  Agent2 top policies: 10:0.40; 25:0.03; 1:0.03; 6:0.03; 11:0.02
. 2 .
. 1 .
. . .

Reward: +0.00, Result: neutral

--- Step 12 ---
Agent 1: PRESS, Agent 2: DOWN
  Agent1 beliefs:
    agent_pos: 4:1.00, 1:0.00, 2:0.00
    red_button_pos: 1:0.47, 2:0.47, 0:0.03
    blue_button_pos: 4:1.00, 8:0.00, 7:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 1:1.00, 4:0.00, 8:0.00
    red_button_pos: 1:1.00, 8:0.00, 7:0.00
    blue_button_pos: 4:0.96, 0:0.01, 8:0.01
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 24:0.36; 27:0.12; 25:0.11; 26:0.11; 28:0.10
  Agent2 top policies: 10:0.41; 25:0.02; 1:0.02; 6:0.02; 11:0.02
. 2 .
. 1 .
. . .

Reward: +1.00, Result: win
Button pressed: blue by Agent 1

Result: ✅ WIN - win (steps: 12, reward: +1.00)

================================================================================
EPISODE 92
================================================================================
Environment: Red at (1, 0), Blue at (1, 1)

Initial state:
1 r .
. b .
. . 2


--- Step 1 ---
Agent 1: DOWN, Agent 2: LEFT
  Agent1 beliefs:
    agent_pos: 0:1.00, 8:0.00, 7:0.00
    red_button_pos: 8:0.12, 7:0.12, 6:0.12
    blue_button_pos: 8:0.12, 7:0.12, 6:0.12
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 8:1.00, 7:0.00, 6:0.00
    red_button_pos: 7:0.12, 3:0.12, 6:0.12
    blue_button_pos: 7:0.12, 3:0.12, 6:0.12
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 10:0.21; 22:0.21; 9:0.06; 19:0.06; 21:0.05
  Agent2 top policies: 16:0.21; 4:0.21; 12:0.06; 2:0.06; 0:0.05
. r .
1 b .
. 2 .

Reward: +0.00, Result: neutral

--- Step 2 ---
Agent 1: RIGHT, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 3:1.00, 0:0.00, 8:0.00
    red_button_pos: 8:0.14, 7:0.14, 6:0.14
    blue_button_pos: 8:0.14, 7:0.14, 6:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 7:1.00, 8:0.00, 6:0.00
    red_button_pos: 6:0.14, 1:0.14, 5:0.14
    blue_button_pos: 6:0.14, 1:0.14, 5:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 22:0.23; 10:0.23; 9:0.06; 21:0.05; 19:0.05
  Agent2 top policies: 4:0.23; 16:0.23; 12:0.06; 0:0.05; 2:0.05
. r .
. 1 .
. 2 .

Reward: +0.00, Result: neutral

--- Step 3 ---
Agent 1: DOWN, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 4:1.00, 8:0.00, 5:0.00
    red_button_pos: 8:0.17, 7:0.17, 6:0.17
    blue_button_pos: 4:1.00, 8:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 7:0.87, 4:0.12, 8:0.00
    red_button_pos: 6:0.14, 1:0.14, 5:0.14
    blue_button_pos: 6:0.14, 1:0.14, 5:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 10:0.11; 22:0.11; 4:0.11; 3:0.04; 21:0.04
  Agent2 top policies: 4:0.24; 16:0.23; 12:0.06; 2:0.05; 14:0.05
. r .
. 1 .
. 2 .

Reward: +0.00, Result: neutral

--- Step 4 ---
Agent 1: RIGHT, Agent 2: LEFT
  Agent1 beliefs:
    agent_pos: 4:1.00, 7:0.00, 8:0.00
    red_button_pos: 8:0.17, 7:0.17, 6:0.17
    blue_button_pos: 4:1.00, 8:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 7:0.87, 4:0.11, 1:0.02
    red_button_pos: 6:0.14, 1:0.14, 5:0.14
    blue_button_pos: 6:0.14, 1:0.14, 5:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 22:0.11; 4:0.11; 10:0.11; 21:0.04; 3:0.04
  Agent2 top policies: 16:0.24; 4:0.22; 12:0.06; 14:0.06; 2:0.05
. r .
. b 1
2 . .

Reward: +0.00, Result: neutral

--- Step 5 ---
Agent 1: DOWN, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 5:1.00, 3:0.00, 0:0.00
    red_button_pos: 8:0.20, 7:0.20, 6:0.20
    blue_button_pos: 4:0.99, 8:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 6:1.00, 3:0.00, 0:0.00
    red_button_pos: 4:0.17, 5:0.17, 2:0.17
    blue_button_pos: 4:0.17, 5:0.17, 2:0.17
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 10:0.14; 4:0.14; 8:0.05; 2:0.05; 7:0.05
  Agent2 top policies: 4:0.45; 3:0.10; 0:0.10; 2:0.09; 5:0.07
. r .
2 b .
. . 1

Reward: +0.00, Result: neutral

--- Step 6 ---
Agent 1: LEFT, Agent 2: RIGHT
  Agent1 beliefs:
    agent_pos: 8:1.00, 5:0.00, 3:0.00
    red_button_pos: 7:0.24, 6:0.24, 1:0.24
    blue_button_pos: 4:0.98, 1:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 3:1.00, 6:0.00, 7:0.00
    red_button_pos: 4:0.20, 5:0.20, 2:0.20
    blue_button_pos: 4:0.20, 5:0.20, 2:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 16:0.27; 14:0.09; 13:0.09; 17:0.07; 12:0.05
  Agent2 top policies: 22:0.28; 4:0.28; 3:0.05; 18:0.05; 0:0.05
. r .
. 2 .
. 1 .

Reward: +0.00, Result: neutral

--- Step 7 ---
Agent 1: LEFT, Agent 2: RIGHT
  Agent1 beliefs:
    agent_pos: 7:1.00, 8:0.00, 5:0.00
    red_button_pos: 6:0.32, 1:0.32, 2:0.32
    blue_button_pos: 4:0.98, 2:0.00, 6:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 4:1.00, 8:0.00, 2:0.00
    red_button_pos: 5:0.24, 2:0.24, 1:0.24
    blue_button_pos: 4:1.00, 0:0.00, 5:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 16:0.33; 14:0.09; 13:0.09; 17:0.07; 0:0.04
  Agent2 top policies: 22:0.18; 4:0.18; 18:0.06; 0:0.06; 3:0.06
. r .
. b 2
1 . .

Reward: +0.00, Result: neutral

--- Step 8 ---
Agent 1: UP, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 6:1.00, 7:0.00, 8:0.00
    red_button_pos: 1:0.47, 2:0.47, 0:0.02
    blue_button_pos: 4:0.97, 2:0.00, 3:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 5:1.00, 3:0.00, 6:0.00
    red_button_pos: 2:0.32, 0:0.32, 1:0.32
    blue_button_pos: 4:0.99, 1:0.00, 0:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 3:0.05; 4:0.05; 18:0.05; 0:0.04; 2:0.04
  Agent2 top policies: 4:0.31; 2:0.09; 0:0.09; 3:0.09; 5:0.07
. r 2
1 b .
. . .

Reward: +0.00, Result: neutral

--- Step 9 ---
Agent 1: RIGHT, Agent 2: LEFT
  Agent1 beliefs:
    agent_pos: 3:1.00, 6:0.00, 7:0.00
    red_button_pos: 1:0.47, 2:0.47, 0:0.02
    blue_button_pos: 4:0.97, 2:0.01, 1:0.01
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 2:1.00, 5:0.00, 3:0.00
    red_button_pos: 1:0.47, 0:0.47, 8:0.03
    blue_button_pos: 4:0.98, 1:0.00, 0:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 18:0.12; 3:0.10; 4:0.05; 23:0.04; 21:0.04
  Agent2 top policies: 16:0.40; 12:0.10; 14:0.10; 17:0.08; 13:0.04
. 2 .
. 1 .
. . .

Reward: +0.00, Result: neutral

--- Step 10 ---
Agent 1: UP, Agent 2: PRESS
  Agent1 beliefs:
    agent_pos: 4:1.00, 8:0.00, 2:0.00
    red_button_pos: 1:0.47, 2:0.47, 0:0.03
    blue_button_pos: 4:1.00, 1:0.00, 0:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 1:1.00, 6:0.00, 0:0.00
    red_button_pos: 1:1.00, 0:0.00, 8:0.00
    blue_button_pos: 4:0.98, 0:0.00, 8:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 4:0.42; 0:0.10; 3:0.10; 5:0.08; 1:0.04
  Agent2 top policies: 25:0.07; 24:0.06; 4:0.06; 26:0.05; 27:0.05
. 2 .
. 1 .
. . .

Reward: +0.00, Result: neutral
Button pressed: red by Agent 2

--- Step 11 ---
Agent 1: UP, Agent 2: DOWN
  Agent1 beliefs:
    agent_pos: 4:1.00, 1:0.00, 8:0.00
    red_button_pos: 1:0.47, 2:0.47, 0:0.03
    blue_button_pos: 4:1.00, 8:0.00, 7:0.00
    red_button_state: 0:0.50, 1:0.50
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 0:0.00, 8:0.00
    blue_button_pos: 4:0.97, 0:0.00, 8:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 0:0.12; 3:0.12; 4:0.11; 5:0.10; 24:0.08
  Agent2 top policies: 10:0.40; 25:0.03; 1:0.03; 6:0.03; 11:0.02
. 2 .
. 1 .
. . .

Reward: +0.00, Result: neutral

--- Step 12 ---
Agent 1: PRESS, Agent 2: DOWN
  Agent1 beliefs:
    agent_pos: 4:1.00, 1:0.00, 2:0.00
    red_button_pos: 1:0.47, 2:0.47, 0:0.03
    blue_button_pos: 4:1.00, 8:0.00, 7:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 1:1.00, 4:0.00, 8:0.00
    red_button_pos: 1:1.00, 8:0.00, 7:0.00
    blue_button_pos: 4:0.96, 0:0.01, 8:0.01
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 24:0.36; 27:0.12; 25:0.11; 26:0.11; 28:0.10
  Agent2 top policies: 10:0.41; 25:0.02; 1:0.02; 6:0.02; 11:0.02
. 2 .
. 1 .
. . .

Reward: +1.00, Result: win
Button pressed: blue by Agent 1

Result: ✅ WIN - win (steps: 12, reward: +1.00)

================================================================================
EPISODE 93
================================================================================
Environment: Red at (1, 0), Blue at (1, 1)

Initial state:
1 r .
. b .
. . 2


--- Step 1 ---
Agent 1: DOWN, Agent 2: LEFT
  Agent1 beliefs:
    agent_pos: 0:1.00, 8:0.00, 7:0.00
    red_button_pos: 8:0.12, 7:0.12, 6:0.12
    blue_button_pos: 8:0.12, 7:0.12, 6:0.12
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 8:1.00, 7:0.00, 6:0.00
    red_button_pos: 7:0.12, 3:0.12, 6:0.12
    blue_button_pos: 7:0.12, 3:0.12, 6:0.12
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 10:0.21; 22:0.21; 9:0.06; 19:0.06; 21:0.05
  Agent2 top policies: 16:0.21; 4:0.21; 12:0.06; 2:0.06; 0:0.05
. r .
1 b .
. 2 .

Reward: +0.00, Result: neutral

--- Step 2 ---
Agent 1: RIGHT, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 3:1.00, 0:0.00, 8:0.00
    red_button_pos: 8:0.14, 7:0.14, 6:0.14
    blue_button_pos: 8:0.14, 7:0.14, 6:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 7:1.00, 8:0.00, 6:0.00
    red_button_pos: 6:0.14, 1:0.14, 5:0.14
    blue_button_pos: 6:0.14, 1:0.14, 5:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 22:0.23; 10:0.23; 9:0.06; 21:0.05; 19:0.05
  Agent2 top policies: 4:0.23; 16:0.23; 12:0.06; 0:0.05; 2:0.05
. r .
. 1 .
. 2 .

Reward: +0.00, Result: neutral

--- Step 3 ---
Agent 1: DOWN, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 4:1.00, 8:0.00, 5:0.00
    red_button_pos: 8:0.17, 7:0.17, 6:0.17
    blue_button_pos: 4:1.00, 8:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 7:0.87, 4:0.12, 8:0.00
    red_button_pos: 6:0.14, 1:0.14, 5:0.14
    blue_button_pos: 6:0.14, 1:0.14, 5:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 10:0.11; 22:0.11; 4:0.11; 3:0.04; 21:0.04
  Agent2 top policies: 4:0.24; 16:0.23; 12:0.06; 2:0.05; 14:0.05
. r .
. 1 .
. 2 .

Reward: +0.00, Result: neutral

--- Step 4 ---
Agent 1: RIGHT, Agent 2: LEFT
  Agent1 beliefs:
    agent_pos: 4:1.00, 7:0.00, 8:0.00
    red_button_pos: 8:0.17, 7:0.17, 6:0.17
    blue_button_pos: 4:1.00, 8:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 7:0.87, 4:0.11, 1:0.02
    red_button_pos: 6:0.14, 1:0.14, 5:0.14
    blue_button_pos: 6:0.14, 1:0.14, 5:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 22:0.11; 4:0.11; 10:0.11; 21:0.04; 3:0.04
  Agent2 top policies: 16:0.24; 4:0.22; 12:0.06; 14:0.06; 2:0.05
. r .
. b 1
2 . .

Reward: +0.00, Result: neutral

--- Step 5 ---
Agent 1: DOWN, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 5:1.00, 3:0.00, 0:0.00
    red_button_pos: 8:0.20, 7:0.20, 6:0.20
    blue_button_pos: 4:0.99, 8:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 6:1.00, 3:0.00, 0:0.00
    red_button_pos: 4:0.17, 5:0.17, 2:0.17
    blue_button_pos: 4:0.17, 5:0.17, 2:0.17
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 10:0.14; 4:0.14; 8:0.05; 2:0.05; 7:0.05
  Agent2 top policies: 4:0.45; 3:0.10; 0:0.10; 2:0.09; 5:0.07
. r .
2 b .
. . 1

Reward: +0.00, Result: neutral

--- Step 6 ---
Agent 1: LEFT, Agent 2: RIGHT
  Agent1 beliefs:
    agent_pos: 8:1.00, 5:0.00, 3:0.00
    red_button_pos: 7:0.24, 6:0.24, 1:0.24
    blue_button_pos: 4:0.98, 1:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 3:1.00, 6:0.00, 7:0.00
    red_button_pos: 4:0.20, 5:0.20, 2:0.20
    blue_button_pos: 4:0.20, 5:0.20, 2:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 16:0.27; 14:0.09; 13:0.09; 17:0.07; 12:0.05
  Agent2 top policies: 22:0.28; 4:0.28; 3:0.05; 18:0.05; 0:0.05
. r .
. 2 .
. 1 .

Reward: +0.00, Result: neutral

--- Step 7 ---
Agent 1: LEFT, Agent 2: RIGHT
  Agent1 beliefs:
    agent_pos: 7:1.00, 8:0.00, 5:0.00
    red_button_pos: 6:0.32, 1:0.32, 2:0.32
    blue_button_pos: 4:0.98, 2:0.00, 6:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 4:1.00, 8:0.00, 2:0.00
    red_button_pos: 5:0.24, 2:0.24, 1:0.24
    blue_button_pos: 4:1.00, 0:0.00, 5:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 16:0.33; 14:0.09; 13:0.09; 17:0.07; 0:0.04
  Agent2 top policies: 22:0.18; 4:0.18; 18:0.06; 0:0.06; 3:0.06
. r .
. b 2
1 . .

Reward: +0.00, Result: neutral

--- Step 8 ---
Agent 1: UP, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 6:1.00, 7:0.00, 8:0.00
    red_button_pos: 1:0.47, 2:0.47, 0:0.02
    blue_button_pos: 4:0.97, 2:0.00, 3:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 5:1.00, 3:0.00, 6:0.00
    red_button_pos: 2:0.32, 0:0.32, 1:0.32
    blue_button_pos: 4:0.99, 1:0.00, 0:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 3:0.05; 4:0.05; 18:0.05; 0:0.04; 2:0.04
  Agent2 top policies: 4:0.31; 2:0.09; 0:0.09; 3:0.09; 5:0.07
. r 2
1 b .
. . .

Reward: +0.00, Result: neutral

--- Step 9 ---
Agent 1: RIGHT, Agent 2: LEFT
  Agent1 beliefs:
    agent_pos: 3:1.00, 6:0.00, 7:0.00
    red_button_pos: 1:0.47, 2:0.47, 0:0.02
    blue_button_pos: 4:0.97, 2:0.01, 1:0.01
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 2:1.00, 5:0.00, 3:0.00
    red_button_pos: 1:0.47, 0:0.47, 8:0.03
    blue_button_pos: 4:0.98, 1:0.00, 0:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 18:0.12; 3:0.10; 4:0.05; 23:0.04; 21:0.04
  Agent2 top policies: 16:0.40; 12:0.10; 14:0.10; 17:0.08; 13:0.04
. 2 .
. 1 .
. . .

Reward: +0.00, Result: neutral

--- Step 10 ---
Agent 1: UP, Agent 2: PRESS
  Agent1 beliefs:
    agent_pos: 4:1.00, 8:0.00, 2:0.00
    red_button_pos: 1:0.47, 2:0.47, 0:0.03
    blue_button_pos: 4:1.00, 1:0.00, 0:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 1:1.00, 6:0.00, 0:0.00
    red_button_pos: 1:1.00, 0:0.00, 8:0.00
    blue_button_pos: 4:0.98, 0:0.00, 8:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 4:0.42; 0:0.10; 3:0.10; 5:0.08; 1:0.04
  Agent2 top policies: 25:0.07; 24:0.06; 4:0.06; 26:0.05; 27:0.05
. 2 .
. 1 .
. . .

Reward: +0.00, Result: neutral
Button pressed: red by Agent 2

--- Step 11 ---
Agent 1: UP, Agent 2: DOWN
  Agent1 beliefs:
    agent_pos: 4:1.00, 1:0.00, 8:0.00
    red_button_pos: 1:0.47, 2:0.47, 0:0.03
    blue_button_pos: 4:1.00, 8:0.00, 7:0.00
    red_button_state: 0:0.50, 1:0.50
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 0:0.00, 8:0.00
    blue_button_pos: 4:0.97, 0:0.00, 8:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 0:0.12; 3:0.12; 4:0.11; 5:0.10; 24:0.08
  Agent2 top policies: 10:0.40; 25:0.03; 1:0.03; 6:0.03; 11:0.02
. 2 .
. 1 .
. . .

Reward: +0.00, Result: neutral

--- Step 12 ---
Agent 1: PRESS, Agent 2: DOWN
  Agent1 beliefs:
    agent_pos: 4:1.00, 1:0.00, 2:0.00
    red_button_pos: 1:0.47, 2:0.47, 0:0.03
    blue_button_pos: 4:1.00, 8:0.00, 7:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 1:1.00, 4:0.00, 8:0.00
    red_button_pos: 1:1.00, 8:0.00, 7:0.00
    blue_button_pos: 4:0.96, 0:0.01, 8:0.01
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 24:0.36; 27:0.12; 25:0.11; 26:0.11; 28:0.10
  Agent2 top policies: 10:0.41; 25:0.02; 1:0.02; 6:0.02; 11:0.02
. 2 .
. 1 .
. . .

Reward: +1.00, Result: win
Button pressed: blue by Agent 1

Result: ✅ WIN - win (steps: 12, reward: +1.00)

================================================================================
EPISODE 94
================================================================================
Environment: Red at (1, 0), Blue at (1, 1)

Initial state:
1 r .
. b .
. . 2


--- Step 1 ---
Agent 1: DOWN, Agent 2: LEFT
  Agent1 beliefs:
    agent_pos: 0:1.00, 8:0.00, 7:0.00
    red_button_pos: 8:0.12, 7:0.12, 6:0.12
    blue_button_pos: 8:0.12, 7:0.12, 6:0.12
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 8:1.00, 7:0.00, 6:0.00
    red_button_pos: 7:0.12, 3:0.12, 6:0.12
    blue_button_pos: 7:0.12, 3:0.12, 6:0.12
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 10:0.21; 22:0.21; 9:0.06; 19:0.06; 21:0.05
  Agent2 top policies: 16:0.21; 4:0.21; 12:0.06; 2:0.06; 0:0.05
. r .
1 b .
. 2 .

Reward: +0.00, Result: neutral

--- Step 2 ---
Agent 1: RIGHT, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 3:1.00, 0:0.00, 8:0.00
    red_button_pos: 8:0.14, 7:0.14, 6:0.14
    blue_button_pos: 8:0.14, 7:0.14, 6:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 7:1.00, 8:0.00, 6:0.00
    red_button_pos: 6:0.14, 1:0.14, 5:0.14
    blue_button_pos: 6:0.14, 1:0.14, 5:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 22:0.23; 10:0.23; 9:0.06; 21:0.05; 19:0.05
  Agent2 top policies: 4:0.23; 16:0.23; 12:0.06; 0:0.05; 2:0.05
. r .
. 1 .
. 2 .

Reward: +0.00, Result: neutral

--- Step 3 ---
Agent 1: DOWN, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 4:1.00, 8:0.00, 5:0.00
    red_button_pos: 8:0.17, 7:0.17, 6:0.17
    blue_button_pos: 4:1.00, 8:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 7:0.87, 4:0.12, 8:0.00
    red_button_pos: 6:0.14, 1:0.14, 5:0.14
    blue_button_pos: 6:0.14, 1:0.14, 5:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 10:0.11; 22:0.11; 4:0.11; 3:0.04; 21:0.04
  Agent2 top policies: 4:0.24; 16:0.23; 12:0.06; 2:0.05; 14:0.05
. r .
. 1 .
. 2 .

Reward: +0.00, Result: neutral

--- Step 4 ---
Agent 1: RIGHT, Agent 2: LEFT
  Agent1 beliefs:
    agent_pos: 4:1.00, 7:0.00, 8:0.00
    red_button_pos: 8:0.17, 7:0.17, 6:0.17
    blue_button_pos: 4:1.00, 8:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 7:0.87, 4:0.11, 1:0.02
    red_button_pos: 6:0.14, 1:0.14, 5:0.14
    blue_button_pos: 6:0.14, 1:0.14, 5:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 22:0.11; 4:0.11; 10:0.11; 21:0.04; 3:0.04
  Agent2 top policies: 16:0.24; 4:0.22; 12:0.06; 14:0.06; 2:0.05
. r .
. b 1
2 . .

Reward: +0.00, Result: neutral

--- Step 5 ---
Agent 1: DOWN, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 5:1.00, 3:0.00, 0:0.00
    red_button_pos: 8:0.20, 7:0.20, 6:0.20
    blue_button_pos: 4:0.99, 8:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 6:1.00, 3:0.00, 0:0.00
    red_button_pos: 4:0.17, 5:0.17, 2:0.17
    blue_button_pos: 4:0.17, 5:0.17, 2:0.17
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 10:0.14; 4:0.14; 8:0.05; 2:0.05; 7:0.05
  Agent2 top policies: 4:0.45; 3:0.10; 0:0.10; 2:0.09; 5:0.07
. r .
2 b .
. . 1

Reward: +0.00, Result: neutral

--- Step 6 ---
Agent 1: LEFT, Agent 2: RIGHT
  Agent1 beliefs:
    agent_pos: 8:1.00, 5:0.00, 3:0.00
    red_button_pos: 7:0.24, 6:0.24, 1:0.24
    blue_button_pos: 4:0.98, 1:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 3:1.00, 6:0.00, 7:0.00
    red_button_pos: 4:0.20, 5:0.20, 2:0.20
    blue_button_pos: 4:0.20, 5:0.20, 2:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 16:0.27; 14:0.09; 13:0.09; 17:0.07; 12:0.05
  Agent2 top policies: 22:0.28; 4:0.28; 3:0.05; 18:0.05; 0:0.05
. r .
. 2 .
. 1 .

Reward: +0.00, Result: neutral

--- Step 7 ---
Agent 1: LEFT, Agent 2: RIGHT
  Agent1 beliefs:
    agent_pos: 7:1.00, 8:0.00, 5:0.00
    red_button_pos: 6:0.32, 1:0.32, 2:0.32
    blue_button_pos: 4:0.98, 2:0.00, 6:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 4:1.00, 8:0.00, 2:0.00
    red_button_pos: 5:0.24, 2:0.24, 1:0.24
    blue_button_pos: 4:1.00, 0:0.00, 5:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 16:0.33; 14:0.09; 13:0.09; 17:0.07; 0:0.04
  Agent2 top policies: 22:0.18; 4:0.18; 18:0.06; 0:0.06; 3:0.06
. r .
. b 2
1 . .

Reward: +0.00, Result: neutral

--- Step 8 ---
Agent 1: UP, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 6:1.00, 7:0.00, 8:0.00
    red_button_pos: 1:0.47, 2:0.47, 0:0.02
    blue_button_pos: 4:0.97, 2:0.00, 3:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 5:1.00, 3:0.00, 6:0.00
    red_button_pos: 2:0.32, 0:0.32, 1:0.32
    blue_button_pos: 4:0.99, 1:0.00, 0:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 3:0.05; 4:0.05; 18:0.05; 0:0.04; 2:0.04
  Agent2 top policies: 4:0.31; 2:0.09; 0:0.09; 3:0.09; 5:0.07
. r 2
1 b .
. . .

Reward: +0.00, Result: neutral

--- Step 9 ---
Agent 1: RIGHT, Agent 2: LEFT
  Agent1 beliefs:
    agent_pos: 3:1.00, 6:0.00, 7:0.00
    red_button_pos: 1:0.47, 2:0.47, 0:0.02
    blue_button_pos: 4:0.97, 2:0.01, 1:0.01
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 2:1.00, 5:0.00, 3:0.00
    red_button_pos: 1:0.47, 0:0.47, 8:0.03
    blue_button_pos: 4:0.98, 1:0.00, 0:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 18:0.12; 3:0.10; 4:0.05; 23:0.04; 21:0.04
  Agent2 top policies: 16:0.40; 12:0.10; 14:0.10; 17:0.08; 13:0.04
. 2 .
. 1 .
. . .

Reward: +0.00, Result: neutral

--- Step 10 ---
Agent 1: UP, Agent 2: PRESS
  Agent1 beliefs:
    agent_pos: 4:1.00, 8:0.00, 2:0.00
    red_button_pos: 1:0.47, 2:0.47, 0:0.03
    blue_button_pos: 4:1.00, 1:0.00, 0:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 1:1.00, 6:0.00, 0:0.00
    red_button_pos: 1:1.00, 0:0.00, 8:0.00
    blue_button_pos: 4:0.98, 0:0.00, 8:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 4:0.42; 0:0.10; 3:0.10; 5:0.08; 1:0.04
  Agent2 top policies: 25:0.07; 24:0.06; 4:0.06; 26:0.05; 27:0.05
. 2 .
. 1 .
. . .

Reward: +0.00, Result: neutral
Button pressed: red by Agent 2

--- Step 11 ---
Agent 1: UP, Agent 2: DOWN
  Agent1 beliefs:
    agent_pos: 4:1.00, 1:0.00, 8:0.00
    red_button_pos: 1:0.47, 2:0.47, 0:0.03
    blue_button_pos: 4:1.00, 8:0.00, 7:0.00
    red_button_state: 0:0.50, 1:0.50
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 0:0.00, 8:0.00
    blue_button_pos: 4:0.97, 0:0.00, 8:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 0:0.12; 3:0.12; 4:0.11; 5:0.10; 24:0.08
  Agent2 top policies: 10:0.40; 25:0.03; 1:0.03; 6:0.03; 11:0.02
. 2 .
. 1 .
. . .

Reward: +0.00, Result: neutral

--- Step 12 ---
Agent 1: PRESS, Agent 2: DOWN
  Agent1 beliefs:
    agent_pos: 4:1.00, 1:0.00, 2:0.00
    red_button_pos: 1:0.47, 2:0.47, 0:0.03
    blue_button_pos: 4:1.00, 8:0.00, 7:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 1:1.00, 4:0.00, 8:0.00
    red_button_pos: 1:1.00, 8:0.00, 7:0.00
    blue_button_pos: 4:0.96, 0:0.01, 8:0.01
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 24:0.36; 27:0.12; 25:0.11; 26:0.11; 28:0.10
  Agent2 top policies: 10:0.41; 25:0.02; 1:0.02; 6:0.02; 11:0.02
. 2 .
. 1 .
. . .

Reward: +1.00, Result: win
Button pressed: blue by Agent 1

Result: ✅ WIN - win (steps: 12, reward: +1.00)

================================================================================
EPISODE 95
================================================================================
Environment: Red at (1, 0), Blue at (1, 1)

Initial state:
1 r .
. b .
. . 2


--- Step 1 ---
Agent 1: DOWN, Agent 2: LEFT
  Agent1 beliefs:
    agent_pos: 0:1.00, 8:0.00, 7:0.00
    red_button_pos: 8:0.12, 7:0.12, 6:0.12
    blue_button_pos: 8:0.12, 7:0.12, 6:0.12
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 8:1.00, 7:0.00, 6:0.00
    red_button_pos: 7:0.12, 3:0.12, 6:0.12
    blue_button_pos: 7:0.12, 3:0.12, 6:0.12
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 10:0.21; 22:0.21; 9:0.06; 19:0.06; 21:0.05
  Agent2 top policies: 16:0.21; 4:0.21; 12:0.06; 2:0.06; 0:0.05
. r .
1 b .
. 2 .

Reward: +0.00, Result: neutral

--- Step 2 ---
Agent 1: RIGHT, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 3:1.00, 0:0.00, 8:0.00
    red_button_pos: 8:0.14, 7:0.14, 6:0.14
    blue_button_pos: 8:0.14, 7:0.14, 6:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 7:1.00, 8:0.00, 6:0.00
    red_button_pos: 6:0.14, 1:0.14, 5:0.14
    blue_button_pos: 6:0.14, 1:0.14, 5:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 22:0.23; 10:0.23; 9:0.06; 21:0.05; 19:0.05
  Agent2 top policies: 4:0.23; 16:0.23; 12:0.06; 0:0.05; 2:0.05
. r .
. 1 .
. 2 .

Reward: +0.00, Result: neutral

--- Step 3 ---
Agent 1: DOWN, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 4:1.00, 8:0.00, 5:0.00
    red_button_pos: 8:0.17, 7:0.17, 6:0.17
    blue_button_pos: 4:1.00, 8:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 7:0.87, 4:0.12, 8:0.00
    red_button_pos: 6:0.14, 1:0.14, 5:0.14
    blue_button_pos: 6:0.14, 1:0.14, 5:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 10:0.11; 22:0.11; 4:0.11; 3:0.04; 21:0.04
  Agent2 top policies: 4:0.24; 16:0.23; 12:0.06; 2:0.05; 14:0.05
. r .
. 1 .
. 2 .

Reward: +0.00, Result: neutral

--- Step 4 ---
Agent 1: RIGHT, Agent 2: LEFT
  Agent1 beliefs:
    agent_pos: 4:1.00, 7:0.00, 8:0.00
    red_button_pos: 8:0.17, 7:0.17, 6:0.17
    blue_button_pos: 4:1.00, 8:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 7:0.87, 4:0.11, 1:0.02
    red_button_pos: 6:0.14, 1:0.14, 5:0.14
    blue_button_pos: 6:0.14, 1:0.14, 5:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 22:0.11; 4:0.11; 10:0.11; 21:0.04; 3:0.04
  Agent2 top policies: 16:0.24; 4:0.22; 12:0.06; 14:0.06; 2:0.05
. r .
. b 1
2 . .

Reward: +0.00, Result: neutral

--- Step 5 ---
Agent 1: DOWN, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 5:1.00, 3:0.00, 0:0.00
    red_button_pos: 8:0.20, 7:0.20, 6:0.20
    blue_button_pos: 4:0.99, 8:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 6:1.00, 3:0.00, 0:0.00
    red_button_pos: 4:0.17, 5:0.17, 2:0.17
    blue_button_pos: 4:0.17, 5:0.17, 2:0.17
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 10:0.14; 4:0.14; 8:0.05; 2:0.05; 7:0.05
  Agent2 top policies: 4:0.45; 3:0.10; 0:0.10; 2:0.09; 5:0.07
. r .
2 b .
. . 1

Reward: +0.00, Result: neutral

--- Step 6 ---
Agent 1: LEFT, Agent 2: RIGHT
  Agent1 beliefs:
    agent_pos: 8:1.00, 5:0.00, 3:0.00
    red_button_pos: 7:0.24, 6:0.24, 1:0.24
    blue_button_pos: 4:0.98, 1:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 3:1.00, 6:0.00, 7:0.00
    red_button_pos: 4:0.20, 5:0.20, 2:0.20
    blue_button_pos: 4:0.20, 5:0.20, 2:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 16:0.27; 14:0.09; 13:0.09; 17:0.07; 12:0.05
  Agent2 top policies: 22:0.28; 4:0.28; 3:0.05; 18:0.05; 0:0.05
. r .
. 2 .
. 1 .

Reward: +0.00, Result: neutral

--- Step 7 ---
Agent 1: LEFT, Agent 2: RIGHT
  Agent1 beliefs:
    agent_pos: 7:1.00, 8:0.00, 5:0.00
    red_button_pos: 6:0.32, 1:0.32, 2:0.32
    blue_button_pos: 4:0.98, 2:0.00, 6:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 4:1.00, 8:0.00, 2:0.00
    red_button_pos: 5:0.24, 2:0.24, 1:0.24
    blue_button_pos: 4:1.00, 0:0.00, 5:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 16:0.33; 14:0.09; 13:0.09; 17:0.07; 0:0.04
  Agent2 top policies: 22:0.18; 4:0.18; 18:0.06; 0:0.06; 3:0.06
. r .
. b 2
1 . .

Reward: +0.00, Result: neutral

--- Step 8 ---
Agent 1: UP, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 6:1.00, 7:0.00, 8:0.00
    red_button_pos: 1:0.47, 2:0.47, 0:0.02
    blue_button_pos: 4:0.97, 2:0.00, 3:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 5:1.00, 3:0.00, 6:0.00
    red_button_pos: 2:0.32, 0:0.32, 1:0.32
    blue_button_pos: 4:0.99, 1:0.00, 0:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 3:0.05; 4:0.05; 18:0.05; 0:0.04; 2:0.04
  Agent2 top policies: 4:0.31; 2:0.09; 0:0.09; 3:0.09; 5:0.07
. r 2
1 b .
. . .

Reward: +0.00, Result: neutral

--- Step 9 ---
Agent 1: RIGHT, Agent 2: LEFT
  Agent1 beliefs:
    agent_pos: 3:1.00, 6:0.00, 7:0.00
    red_button_pos: 1:0.47, 2:0.47, 0:0.02
    blue_button_pos: 4:0.97, 2:0.01, 1:0.01
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 2:1.00, 5:0.00, 3:0.00
    red_button_pos: 1:0.47, 0:0.47, 8:0.03
    blue_button_pos: 4:0.98, 1:0.00, 0:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 18:0.12; 3:0.10; 4:0.05; 23:0.04; 21:0.04
  Agent2 top policies: 16:0.40; 12:0.10; 14:0.10; 17:0.08; 13:0.04
. 2 .
. 1 .
. . .

Reward: +0.00, Result: neutral

--- Step 10 ---
Agent 1: UP, Agent 2: PRESS
  Agent1 beliefs:
    agent_pos: 4:1.00, 8:0.00, 2:0.00
    red_button_pos: 1:0.47, 2:0.47, 0:0.03
    blue_button_pos: 4:1.00, 1:0.00, 0:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 1:1.00, 6:0.00, 0:0.00
    red_button_pos: 1:1.00, 0:0.00, 8:0.00
    blue_button_pos: 4:0.98, 0:0.00, 8:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 4:0.42; 0:0.10; 3:0.10; 5:0.08; 1:0.04
  Agent2 top policies: 25:0.07; 24:0.06; 4:0.06; 26:0.05; 27:0.05
. 2 .
. 1 .
. . .

Reward: +0.00, Result: neutral
Button pressed: red by Agent 2

--- Step 11 ---
Agent 1: UP, Agent 2: DOWN
  Agent1 beliefs:
    agent_pos: 4:1.00, 1:0.00, 8:0.00
    red_button_pos: 1:0.47, 2:0.47, 0:0.03
    blue_button_pos: 4:1.00, 8:0.00, 7:0.00
    red_button_state: 0:0.50, 1:0.50
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 0:0.00, 8:0.00
    blue_button_pos: 4:0.97, 0:0.00, 8:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 0:0.12; 3:0.12; 4:0.11; 5:0.10; 24:0.08
  Agent2 top policies: 10:0.40; 25:0.03; 1:0.03; 6:0.03; 11:0.02
. 2 .
. 1 .
. . .

Reward: +0.00, Result: neutral

--- Step 12 ---
Agent 1: PRESS, Agent 2: DOWN
  Agent1 beliefs:
    agent_pos: 4:1.00, 1:0.00, 2:0.00
    red_button_pos: 1:0.47, 2:0.47, 0:0.03
    blue_button_pos: 4:1.00, 8:0.00, 7:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 1:1.00, 4:0.00, 8:0.00
    red_button_pos: 1:1.00, 8:0.00, 7:0.00
    blue_button_pos: 4:0.96, 0:0.01, 8:0.01
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 24:0.36; 27:0.12; 25:0.11; 26:0.11; 28:0.10
  Agent2 top policies: 10:0.41; 25:0.02; 1:0.02; 6:0.02; 11:0.02
. 2 .
. 1 .
. . .

Reward: +1.00, Result: win
Button pressed: blue by Agent 1

Result: ✅ WIN - win (steps: 12, reward: +1.00)

================================================================================
EPISODE 96
================================================================================
Environment: Red at (1, 0), Blue at (1, 1)

Initial state:
1 r .
. b .
. . 2


--- Step 1 ---
Agent 1: DOWN, Agent 2: LEFT
  Agent1 beliefs:
    agent_pos: 0:1.00, 8:0.00, 7:0.00
    red_button_pos: 8:0.12, 7:0.12, 6:0.12
    blue_button_pos: 8:0.12, 7:0.12, 6:0.12
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 8:1.00, 7:0.00, 6:0.00
    red_button_pos: 7:0.12, 3:0.12, 6:0.12
    blue_button_pos: 7:0.12, 3:0.12, 6:0.12
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 10:0.21; 22:0.21; 9:0.06; 19:0.06; 21:0.05
  Agent2 top policies: 16:0.21; 4:0.21; 12:0.06; 2:0.06; 0:0.05
. r .
1 b .
. 2 .

Reward: +0.00, Result: neutral

--- Step 2 ---
Agent 1: RIGHT, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 3:1.00, 0:0.00, 8:0.00
    red_button_pos: 8:0.14, 7:0.14, 6:0.14
    blue_button_pos: 8:0.14, 7:0.14, 6:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 7:1.00, 8:0.00, 6:0.00
    red_button_pos: 6:0.14, 1:0.14, 5:0.14
    blue_button_pos: 6:0.14, 1:0.14, 5:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 22:0.23; 10:0.23; 9:0.06; 21:0.05; 19:0.05
  Agent2 top policies: 4:0.23; 16:0.23; 12:0.06; 0:0.05; 2:0.05
. r .
. 1 .
. 2 .

Reward: +0.00, Result: neutral

--- Step 3 ---
Agent 1: DOWN, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 4:1.00, 8:0.00, 5:0.00
    red_button_pos: 8:0.17, 7:0.17, 6:0.17
    blue_button_pos: 4:1.00, 8:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 7:0.87, 4:0.12, 8:0.00
    red_button_pos: 6:0.14, 1:0.14, 5:0.14
    blue_button_pos: 6:0.14, 1:0.14, 5:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 10:0.11; 22:0.11; 4:0.11; 3:0.04; 21:0.04
  Agent2 top policies: 4:0.24; 16:0.23; 12:0.06; 2:0.05; 14:0.05
. r .
. 1 .
. 2 .

Reward: +0.00, Result: neutral

--- Step 4 ---
Agent 1: RIGHT, Agent 2: LEFT
  Agent1 beliefs:
    agent_pos: 4:1.00, 7:0.00, 8:0.00
    red_button_pos: 8:0.17, 7:0.17, 6:0.17
    blue_button_pos: 4:1.00, 8:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 7:0.87, 4:0.11, 1:0.02
    red_button_pos: 6:0.14, 1:0.14, 5:0.14
    blue_button_pos: 6:0.14, 1:0.14, 5:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 22:0.11; 4:0.11; 10:0.11; 21:0.04; 3:0.04
  Agent2 top policies: 16:0.24; 4:0.22; 12:0.06; 14:0.06; 2:0.05
. r .
. b 1
2 . .

Reward: +0.00, Result: neutral

--- Step 5 ---
Agent 1: DOWN, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 5:1.00, 3:0.00, 0:0.00
    red_button_pos: 8:0.20, 7:0.20, 6:0.20
    blue_button_pos: 4:0.99, 8:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 6:1.00, 3:0.00, 0:0.00
    red_button_pos: 4:0.17, 5:0.17, 2:0.17
    blue_button_pos: 4:0.17, 5:0.17, 2:0.17
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 10:0.14; 4:0.14; 8:0.05; 2:0.05; 7:0.05
  Agent2 top policies: 4:0.45; 3:0.10; 0:0.10; 2:0.09; 5:0.07
. r .
2 b .
. . 1

Reward: +0.00, Result: neutral

--- Step 6 ---
Agent 1: LEFT, Agent 2: RIGHT
  Agent1 beliefs:
    agent_pos: 8:1.00, 5:0.00, 3:0.00
    red_button_pos: 7:0.24, 6:0.24, 1:0.24
    blue_button_pos: 4:0.98, 1:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 3:1.00, 6:0.00, 7:0.00
    red_button_pos: 4:0.20, 5:0.20, 2:0.20
    blue_button_pos: 4:0.20, 5:0.20, 2:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 16:0.27; 14:0.09; 13:0.09; 17:0.07; 12:0.05
  Agent2 top policies: 22:0.28; 4:0.28; 3:0.05; 18:0.05; 0:0.05
. r .
. 2 .
. 1 .

Reward: +0.00, Result: neutral

--- Step 7 ---
Agent 1: LEFT, Agent 2: RIGHT
  Agent1 beliefs:
    agent_pos: 7:1.00, 8:0.00, 5:0.00
    red_button_pos: 6:0.32, 1:0.32, 2:0.32
    blue_button_pos: 4:0.98, 2:0.00, 6:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 4:1.00, 8:0.00, 2:0.00
    red_button_pos: 5:0.24, 2:0.24, 1:0.24
    blue_button_pos: 4:1.00, 0:0.00, 5:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 16:0.33; 14:0.09; 13:0.09; 17:0.07; 0:0.04
  Agent2 top policies: 22:0.18; 4:0.18; 18:0.06; 0:0.06; 3:0.06
. r .
. b 2
1 . .

Reward: +0.00, Result: neutral

--- Step 8 ---
Agent 1: UP, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 6:1.00, 7:0.00, 8:0.00
    red_button_pos: 1:0.47, 2:0.47, 0:0.02
    blue_button_pos: 4:0.97, 2:0.00, 3:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 5:1.00, 3:0.00, 6:0.00
    red_button_pos: 2:0.32, 0:0.32, 1:0.32
    blue_button_pos: 4:0.99, 1:0.00, 0:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 3:0.05; 4:0.05; 18:0.05; 0:0.04; 2:0.04
  Agent2 top policies: 4:0.31; 2:0.09; 0:0.09; 3:0.09; 5:0.07
. r 2
1 b .
. . .

Reward: +0.00, Result: neutral

--- Step 9 ---
Agent 1: RIGHT, Agent 2: LEFT
  Agent1 beliefs:
    agent_pos: 3:1.00, 6:0.00, 7:0.00
    red_button_pos: 1:0.47, 2:0.47, 0:0.02
    blue_button_pos: 4:0.97, 2:0.01, 1:0.01
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 2:1.00, 5:0.00, 3:0.00
    red_button_pos: 1:0.47, 0:0.47, 8:0.03
    blue_button_pos: 4:0.98, 1:0.00, 0:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 18:0.12; 3:0.10; 4:0.05; 23:0.04; 21:0.04
  Agent2 top policies: 16:0.40; 12:0.10; 14:0.10; 17:0.08; 13:0.04
. 2 .
. 1 .
. . .

Reward: +0.00, Result: neutral

--- Step 10 ---
Agent 1: UP, Agent 2: PRESS
  Agent1 beliefs:
    agent_pos: 4:1.00, 8:0.00, 2:0.00
    red_button_pos: 1:0.47, 2:0.47, 0:0.03
    blue_button_pos: 4:1.00, 1:0.00, 0:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 1:1.00, 6:0.00, 0:0.00
    red_button_pos: 1:1.00, 0:0.00, 8:0.00
    blue_button_pos: 4:0.98, 0:0.00, 8:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 4:0.42; 0:0.10; 3:0.10; 5:0.08; 1:0.04
  Agent2 top policies: 25:0.07; 24:0.06; 4:0.06; 26:0.05; 27:0.05
. 2 .
. 1 .
. . .

Reward: +0.00, Result: neutral
Button pressed: red by Agent 2

--- Step 11 ---
Agent 1: UP, Agent 2: DOWN
  Agent1 beliefs:
    agent_pos: 4:1.00, 1:0.00, 8:0.00
    red_button_pos: 1:0.47, 2:0.47, 0:0.03
    blue_button_pos: 4:1.00, 8:0.00, 7:0.00
    red_button_state: 0:0.50, 1:0.50
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 0:0.00, 8:0.00
    blue_button_pos: 4:0.97, 0:0.00, 8:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 0:0.12; 3:0.12; 4:0.11; 5:0.10; 24:0.08
  Agent2 top policies: 10:0.40; 25:0.03; 1:0.03; 6:0.03; 11:0.02
. 2 .
. 1 .
. . .

Reward: +0.00, Result: neutral

--- Step 12 ---
Agent 1: PRESS, Agent 2: DOWN
  Agent1 beliefs:
    agent_pos: 4:1.00, 1:0.00, 2:0.00
    red_button_pos: 1:0.47, 2:0.47, 0:0.03
    blue_button_pos: 4:1.00, 8:0.00, 7:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 1:1.00, 4:0.00, 8:0.00
    red_button_pos: 1:1.00, 8:0.00, 7:0.00
    blue_button_pos: 4:0.96, 0:0.01, 8:0.01
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 24:0.36; 27:0.12; 25:0.11; 26:0.11; 28:0.10
  Agent2 top policies: 10:0.41; 25:0.02; 1:0.02; 6:0.02; 11:0.02
. 2 .
. 1 .
. . .

Reward: +1.00, Result: win
Button pressed: blue by Agent 1

Result: ✅ WIN - win (steps: 12, reward: +1.00)

================================================================================
EPISODE 97
================================================================================
Environment: Red at (1, 0), Blue at (1, 1)

Initial state:
1 r .
. b .
. . 2


--- Step 1 ---
Agent 1: DOWN, Agent 2: LEFT
  Agent1 beliefs:
    agent_pos: 0:1.00, 8:0.00, 7:0.00
    red_button_pos: 8:0.12, 7:0.12, 6:0.12
    blue_button_pos: 8:0.12, 7:0.12, 6:0.12
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 8:1.00, 7:0.00, 6:0.00
    red_button_pos: 7:0.12, 3:0.12, 6:0.12
    blue_button_pos: 7:0.12, 3:0.12, 6:0.12
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 10:0.21; 22:0.21; 9:0.06; 19:0.06; 21:0.05
  Agent2 top policies: 16:0.21; 4:0.21; 12:0.06; 2:0.06; 0:0.05
. r .
1 b .
. 2 .

Reward: +0.00, Result: neutral

--- Step 2 ---
Agent 1: RIGHT, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 3:1.00, 0:0.00, 8:0.00
    red_button_pos: 8:0.14, 7:0.14, 6:0.14
    blue_button_pos: 8:0.14, 7:0.14, 6:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 7:1.00, 8:0.00, 6:0.00
    red_button_pos: 6:0.14, 1:0.14, 5:0.14
    blue_button_pos: 6:0.14, 1:0.14, 5:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 22:0.23; 10:0.23; 9:0.06; 21:0.05; 19:0.05
  Agent2 top policies: 4:0.23; 16:0.23; 12:0.06; 0:0.05; 2:0.05
. r .
. 1 .
. 2 .

Reward: +0.00, Result: neutral

--- Step 3 ---
Agent 1: DOWN, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 4:1.00, 8:0.00, 5:0.00
    red_button_pos: 8:0.17, 7:0.17, 6:0.17
    blue_button_pos: 4:1.00, 8:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 7:0.87, 4:0.12, 8:0.00
    red_button_pos: 6:0.14, 1:0.14, 5:0.14
    blue_button_pos: 6:0.14, 1:0.14, 5:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 10:0.11; 22:0.11; 4:0.11; 3:0.04; 21:0.04
  Agent2 top policies: 4:0.24; 16:0.23; 12:0.06; 2:0.05; 14:0.05
. r .
. 1 .
. 2 .

Reward: +0.00, Result: neutral

--- Step 4 ---
Agent 1: RIGHT, Agent 2: LEFT
  Agent1 beliefs:
    agent_pos: 4:1.00, 7:0.00, 8:0.00
    red_button_pos: 8:0.17, 7:0.17, 6:0.17
    blue_button_pos: 4:1.00, 8:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 7:0.87, 4:0.11, 1:0.02
    red_button_pos: 6:0.14, 1:0.14, 5:0.14
    blue_button_pos: 6:0.14, 1:0.14, 5:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 22:0.11; 4:0.11; 10:0.11; 21:0.04; 3:0.04
  Agent2 top policies: 16:0.24; 4:0.22; 12:0.06; 14:0.06; 2:0.05
. r .
. b 1
2 . .

Reward: +0.00, Result: neutral

--- Step 5 ---
Agent 1: DOWN, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 5:1.00, 3:0.00, 0:0.00
    red_button_pos: 8:0.20, 7:0.20, 6:0.20
    blue_button_pos: 4:0.99, 8:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 6:1.00, 3:0.00, 0:0.00
    red_button_pos: 4:0.17, 5:0.17, 2:0.17
    blue_button_pos: 4:0.17, 5:0.17, 2:0.17
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 10:0.14; 4:0.14; 8:0.05; 2:0.05; 7:0.05
  Agent2 top policies: 4:0.45; 3:0.10; 0:0.10; 2:0.09; 5:0.07
. r .
2 b .
. . 1

Reward: +0.00, Result: neutral

--- Step 6 ---
Agent 1: LEFT, Agent 2: RIGHT
  Agent1 beliefs:
    agent_pos: 8:1.00, 5:0.00, 3:0.00
    red_button_pos: 7:0.24, 6:0.24, 1:0.24
    blue_button_pos: 4:0.98, 1:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 3:1.00, 6:0.00, 7:0.00
    red_button_pos: 4:0.20, 5:0.20, 2:0.20
    blue_button_pos: 4:0.20, 5:0.20, 2:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 16:0.27; 14:0.09; 13:0.09; 17:0.07; 12:0.05
  Agent2 top policies: 22:0.28; 4:0.28; 3:0.05; 18:0.05; 0:0.05
. r .
. 2 .
. 1 .

Reward: +0.00, Result: neutral

--- Step 7 ---
Agent 1: LEFT, Agent 2: RIGHT
  Agent1 beliefs:
    agent_pos: 7:1.00, 8:0.00, 5:0.00
    red_button_pos: 6:0.32, 1:0.32, 2:0.32
    blue_button_pos: 4:0.98, 2:0.00, 6:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 4:1.00, 8:0.00, 2:0.00
    red_button_pos: 5:0.24, 2:0.24, 1:0.24
    blue_button_pos: 4:1.00, 0:0.00, 5:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 16:0.33; 14:0.09; 13:0.09; 17:0.07; 0:0.04
  Agent2 top policies: 22:0.18; 4:0.18; 18:0.06; 0:0.06; 3:0.06
. r .
. b 2
1 . .

Reward: +0.00, Result: neutral

--- Step 8 ---
Agent 1: UP, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 6:1.00, 7:0.00, 8:0.00
    red_button_pos: 1:0.47, 2:0.47, 0:0.02
    blue_button_pos: 4:0.97, 2:0.00, 3:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 5:1.00, 3:0.00, 6:0.00
    red_button_pos: 2:0.32, 0:0.32, 1:0.32
    blue_button_pos: 4:0.99, 1:0.00, 0:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 3:0.05; 4:0.05; 18:0.05; 0:0.04; 2:0.04
  Agent2 top policies: 4:0.31; 2:0.09; 0:0.09; 3:0.09; 5:0.07
. r 2
1 b .
. . .

Reward: +0.00, Result: neutral

--- Step 9 ---
Agent 1: RIGHT, Agent 2: LEFT
  Agent1 beliefs:
    agent_pos: 3:1.00, 6:0.00, 7:0.00
    red_button_pos: 1:0.47, 2:0.47, 0:0.02
    blue_button_pos: 4:0.97, 2:0.01, 1:0.01
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 2:1.00, 5:0.00, 3:0.00
    red_button_pos: 1:0.47, 0:0.47, 8:0.03
    blue_button_pos: 4:0.98, 1:0.00, 0:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 18:0.12; 3:0.10; 4:0.05; 23:0.04; 21:0.04
  Agent2 top policies: 16:0.40; 12:0.10; 14:0.10; 17:0.08; 13:0.04
. 2 .
. 1 .
. . .

Reward: +0.00, Result: neutral

--- Step 10 ---
Agent 1: UP, Agent 2: PRESS
  Agent1 beliefs:
    agent_pos: 4:1.00, 8:0.00, 2:0.00
    red_button_pos: 1:0.47, 2:0.47, 0:0.03
    blue_button_pos: 4:1.00, 1:0.00, 0:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 1:1.00, 6:0.00, 0:0.00
    red_button_pos: 1:1.00, 0:0.00, 8:0.00
    blue_button_pos: 4:0.98, 0:0.00, 8:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 4:0.42; 0:0.10; 3:0.10; 5:0.08; 1:0.04
  Agent2 top policies: 25:0.07; 24:0.06; 4:0.06; 26:0.05; 27:0.05
. 2 .
. 1 .
. . .

Reward: +0.00, Result: neutral
Button pressed: red by Agent 2

--- Step 11 ---
Agent 1: UP, Agent 2: DOWN
  Agent1 beliefs:
    agent_pos: 4:1.00, 1:0.00, 8:0.00
    red_button_pos: 1:0.47, 2:0.47, 0:0.03
    blue_button_pos: 4:1.00, 8:0.00, 7:0.00
    red_button_state: 0:0.50, 1:0.50
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 0:0.00, 8:0.00
    blue_button_pos: 4:0.97, 0:0.00, 8:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 0:0.12; 3:0.12; 4:0.11; 5:0.10; 24:0.08
  Agent2 top policies: 10:0.40; 25:0.03; 1:0.03; 6:0.03; 11:0.02
. 2 .
. 1 .
. . .

Reward: +0.00, Result: neutral

--- Step 12 ---
Agent 1: PRESS, Agent 2: DOWN
  Agent1 beliefs:
    agent_pos: 4:1.00, 1:0.00, 2:0.00
    red_button_pos: 1:0.47, 2:0.47, 0:0.03
    blue_button_pos: 4:1.00, 8:0.00, 7:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 1:1.00, 4:0.00, 8:0.00
    red_button_pos: 1:1.00, 8:0.00, 7:0.00
    blue_button_pos: 4:0.96, 0:0.01, 8:0.01
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 24:0.36; 27:0.12; 25:0.11; 26:0.11; 28:0.10
  Agent2 top policies: 10:0.41; 25:0.02; 1:0.02; 6:0.02; 11:0.02
. 2 .
. 1 .
. . .

Reward: +1.00, Result: win
Button pressed: blue by Agent 1

Result: ✅ WIN - win (steps: 12, reward: +1.00)

================================================================================
EPISODE 98
================================================================================
Environment: Red at (1, 0), Blue at (1, 1)

Initial state:
1 r .
. b .
. . 2


--- Step 1 ---
Agent 1: DOWN, Agent 2: LEFT
  Agent1 beliefs:
    agent_pos: 0:1.00, 8:0.00, 7:0.00
    red_button_pos: 8:0.12, 7:0.12, 6:0.12
    blue_button_pos: 8:0.12, 7:0.12, 6:0.12
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 8:1.00, 7:0.00, 6:0.00
    red_button_pos: 7:0.12, 3:0.12, 6:0.12
    blue_button_pos: 7:0.12, 3:0.12, 6:0.12
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 10:0.21; 22:0.21; 9:0.06; 19:0.06; 21:0.05
  Agent2 top policies: 16:0.21; 4:0.21; 12:0.06; 2:0.06; 0:0.05
. r .
1 b .
. 2 .

Reward: +0.00, Result: neutral

--- Step 2 ---
Agent 1: RIGHT, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 3:1.00, 0:0.00, 8:0.00
    red_button_pos: 8:0.14, 7:0.14, 6:0.14
    blue_button_pos: 8:0.14, 7:0.14, 6:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 7:1.00, 8:0.00, 6:0.00
    red_button_pos: 6:0.14, 1:0.14, 5:0.14
    blue_button_pos: 6:0.14, 1:0.14, 5:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 22:0.23; 10:0.23; 9:0.06; 21:0.05; 19:0.05
  Agent2 top policies: 4:0.23; 16:0.23; 12:0.06; 0:0.05; 2:0.05
. r .
. 1 .
. 2 .

Reward: +0.00, Result: neutral

--- Step 3 ---
Agent 1: DOWN, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 4:1.00, 8:0.00, 5:0.00
    red_button_pos: 8:0.17, 7:0.17, 6:0.17
    blue_button_pos: 4:1.00, 8:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 7:0.87, 4:0.12, 8:0.00
    red_button_pos: 6:0.14, 1:0.14, 5:0.14
    blue_button_pos: 6:0.14, 1:0.14, 5:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 10:0.11; 22:0.11; 4:0.11; 3:0.04; 21:0.04
  Agent2 top policies: 4:0.24; 16:0.23; 12:0.06; 2:0.05; 14:0.05
. r .
. 1 .
. 2 .

Reward: +0.00, Result: neutral

--- Step 4 ---
Agent 1: RIGHT, Agent 2: LEFT
  Agent1 beliefs:
    agent_pos: 4:1.00, 7:0.00, 8:0.00
    red_button_pos: 8:0.17, 7:0.17, 6:0.17
    blue_button_pos: 4:1.00, 8:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 7:0.87, 4:0.11, 1:0.02
    red_button_pos: 6:0.14, 1:0.14, 5:0.14
    blue_button_pos: 6:0.14, 1:0.14, 5:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 22:0.11; 4:0.11; 10:0.11; 21:0.04; 3:0.04
  Agent2 top policies: 16:0.24; 4:0.22; 12:0.06; 14:0.06; 2:0.05
. r .
. b 1
2 . .

Reward: +0.00, Result: neutral

--- Step 5 ---
Agent 1: DOWN, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 5:1.00, 3:0.00, 0:0.00
    red_button_pos: 8:0.20, 7:0.20, 6:0.20
    blue_button_pos: 4:0.99, 8:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 6:1.00, 3:0.00, 0:0.00
    red_button_pos: 4:0.17, 5:0.17, 2:0.17
    blue_button_pos: 4:0.17, 5:0.17, 2:0.17
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 10:0.14; 4:0.14; 8:0.05; 2:0.05; 7:0.05
  Agent2 top policies: 4:0.45; 3:0.10; 0:0.10; 2:0.09; 5:0.07
. r .
2 b .
. . 1

Reward: +0.00, Result: neutral

--- Step 6 ---
Agent 1: LEFT, Agent 2: RIGHT
  Agent1 beliefs:
    agent_pos: 8:1.00, 5:0.00, 3:0.00
    red_button_pos: 7:0.24, 6:0.24, 1:0.24
    blue_button_pos: 4:0.98, 1:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 3:1.00, 6:0.00, 7:0.00
    red_button_pos: 4:0.20, 5:0.20, 2:0.20
    blue_button_pos: 4:0.20, 5:0.20, 2:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 16:0.27; 14:0.09; 13:0.09; 17:0.07; 12:0.05
  Agent2 top policies: 22:0.28; 4:0.28; 3:0.05; 18:0.05; 0:0.05
. r .
. 2 .
. 1 .

Reward: +0.00, Result: neutral

--- Step 7 ---
Agent 1: LEFT, Agent 2: RIGHT
  Agent1 beliefs:
    agent_pos: 7:1.00, 8:0.00, 5:0.00
    red_button_pos: 6:0.32, 1:0.32, 2:0.32
    blue_button_pos: 4:0.98, 2:0.00, 6:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 4:1.00, 8:0.00, 2:0.00
    red_button_pos: 5:0.24, 2:0.24, 1:0.24
    blue_button_pos: 4:1.00, 0:0.00, 5:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 16:0.33; 14:0.09; 13:0.09; 17:0.07; 0:0.04
  Agent2 top policies: 22:0.18; 4:0.18; 18:0.06; 0:0.06; 3:0.06
. r .
. b 2
1 . .

Reward: +0.00, Result: neutral

--- Step 8 ---
Agent 1: UP, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 6:1.00, 7:0.00, 8:0.00
    red_button_pos: 1:0.47, 2:0.47, 0:0.02
    blue_button_pos: 4:0.97, 2:0.00, 3:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 5:1.00, 3:0.00, 6:0.00
    red_button_pos: 2:0.32, 0:0.32, 1:0.32
    blue_button_pos: 4:0.99, 1:0.00, 0:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 3:0.05; 4:0.05; 18:0.05; 0:0.04; 2:0.04
  Agent2 top policies: 4:0.31; 2:0.09; 0:0.09; 3:0.09; 5:0.07
. r 2
1 b .
. . .

Reward: +0.00, Result: neutral

--- Step 9 ---
Agent 1: RIGHT, Agent 2: LEFT
  Agent1 beliefs:
    agent_pos: 3:1.00, 6:0.00, 7:0.00
    red_button_pos: 1:0.47, 2:0.47, 0:0.02
    blue_button_pos: 4:0.97, 2:0.01, 1:0.01
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 2:1.00, 5:0.00, 3:0.00
    red_button_pos: 1:0.47, 0:0.47, 8:0.03
    blue_button_pos: 4:0.98, 1:0.00, 0:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 18:0.12; 3:0.10; 4:0.05; 23:0.04; 21:0.04
  Agent2 top policies: 16:0.40; 12:0.10; 14:0.10; 17:0.08; 13:0.04
. 2 .
. 1 .
. . .

Reward: +0.00, Result: neutral

--- Step 10 ---
Agent 1: UP, Agent 2: PRESS
  Agent1 beliefs:
    agent_pos: 4:1.00, 8:0.00, 2:0.00
    red_button_pos: 1:0.47, 2:0.47, 0:0.03
    blue_button_pos: 4:1.00, 1:0.00, 0:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 1:1.00, 6:0.00, 0:0.00
    red_button_pos: 1:1.00, 0:0.00, 8:0.00
    blue_button_pos: 4:0.98, 0:0.00, 8:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 4:0.42; 0:0.10; 3:0.10; 5:0.08; 1:0.04
  Agent2 top policies: 25:0.07; 24:0.06; 4:0.06; 26:0.05; 27:0.05
. 2 .
. 1 .
. . .

Reward: +0.00, Result: neutral
Button pressed: red by Agent 2

--- Step 11 ---
Agent 1: UP, Agent 2: DOWN
  Agent1 beliefs:
    agent_pos: 4:1.00, 1:0.00, 8:0.00
    red_button_pos: 1:0.47, 2:0.47, 0:0.03
    blue_button_pos: 4:1.00, 8:0.00, 7:0.00
    red_button_state: 0:0.50, 1:0.50
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 0:0.00, 8:0.00
    blue_button_pos: 4:0.97, 0:0.00, 8:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 0:0.12; 3:0.12; 4:0.11; 5:0.10; 24:0.08
  Agent2 top policies: 10:0.40; 25:0.03; 1:0.03; 6:0.03; 11:0.02
. 2 .
. 1 .
. . .

Reward: +0.00, Result: neutral

--- Step 12 ---
Agent 1: PRESS, Agent 2: DOWN
  Agent1 beliefs:
    agent_pos: 4:1.00, 1:0.00, 2:0.00
    red_button_pos: 1:0.47, 2:0.47, 0:0.03
    blue_button_pos: 4:1.00, 8:0.00, 7:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 1:1.00, 4:0.00, 8:0.00
    red_button_pos: 1:1.00, 8:0.00, 7:0.00
    blue_button_pos: 4:0.96, 0:0.01, 8:0.01
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 24:0.36; 27:0.12; 25:0.11; 26:0.11; 28:0.10
  Agent2 top policies: 10:0.41; 25:0.02; 1:0.02; 6:0.02; 11:0.02
. 2 .
. 1 .
. . .

Reward: +1.00, Result: win
Button pressed: blue by Agent 1

Result: ✅ WIN - win (steps: 12, reward: +1.00)

================================================================================
EPISODE 99
================================================================================
Environment: Red at (1, 0), Blue at (1, 1)

Initial state:
1 r .
. b .
. . 2


--- Step 1 ---
Agent 1: DOWN, Agent 2: LEFT
  Agent1 beliefs:
    agent_pos: 0:1.00, 8:0.00, 7:0.00
    red_button_pos: 8:0.12, 7:0.12, 6:0.12
    blue_button_pos: 8:0.12, 7:0.12, 6:0.12
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 8:1.00, 7:0.00, 6:0.00
    red_button_pos: 7:0.12, 3:0.12, 6:0.12
    blue_button_pos: 7:0.12, 3:0.12, 6:0.12
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 10:0.21; 22:0.21; 9:0.06; 19:0.06; 21:0.05
  Agent2 top policies: 16:0.21; 4:0.21; 12:0.06; 2:0.06; 0:0.05
. r .
1 b .
. 2 .

Reward: +0.00, Result: neutral

--- Step 2 ---
Agent 1: RIGHT, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 3:1.00, 0:0.00, 8:0.00
    red_button_pos: 8:0.14, 7:0.14, 6:0.14
    blue_button_pos: 8:0.14, 7:0.14, 6:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 7:1.00, 8:0.00, 6:0.00
    red_button_pos: 6:0.14, 1:0.14, 5:0.14
    blue_button_pos: 6:0.14, 1:0.14, 5:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 22:0.23; 10:0.23; 9:0.06; 21:0.05; 19:0.05
  Agent2 top policies: 4:0.23; 16:0.23; 12:0.06; 0:0.05; 2:0.05
. r .
. 1 .
. 2 .

Reward: +0.00, Result: neutral

--- Step 3 ---
Agent 1: DOWN, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 4:1.00, 8:0.00, 5:0.00
    red_button_pos: 8:0.17, 7:0.17, 6:0.17
    blue_button_pos: 4:1.00, 8:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 7:0.87, 4:0.12, 8:0.00
    red_button_pos: 6:0.14, 1:0.14, 5:0.14
    blue_button_pos: 6:0.14, 1:0.14, 5:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 10:0.11; 22:0.11; 4:0.11; 3:0.04; 21:0.04
  Agent2 top policies: 4:0.24; 16:0.23; 12:0.06; 2:0.05; 14:0.05
. r .
. 1 .
. 2 .

Reward: +0.00, Result: neutral

--- Step 4 ---
Agent 1: RIGHT, Agent 2: LEFT
  Agent1 beliefs:
    agent_pos: 4:1.00, 7:0.00, 8:0.00
    red_button_pos: 8:0.17, 7:0.17, 6:0.17
    blue_button_pos: 4:1.00, 8:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 7:0.87, 4:0.11, 1:0.02
    red_button_pos: 6:0.14, 1:0.14, 5:0.14
    blue_button_pos: 6:0.14, 1:0.14, 5:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 22:0.11; 4:0.11; 10:0.11; 21:0.04; 3:0.04
  Agent2 top policies: 16:0.24; 4:0.22; 12:0.06; 14:0.06; 2:0.05
. r .
. b 1
2 . .

Reward: +0.00, Result: neutral

--- Step 5 ---
Agent 1: DOWN, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 5:1.00, 3:0.00, 0:0.00
    red_button_pos: 8:0.20, 7:0.20, 6:0.20
    blue_button_pos: 4:0.99, 8:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 6:1.00, 3:0.00, 0:0.00
    red_button_pos: 4:0.17, 5:0.17, 2:0.17
    blue_button_pos: 4:0.17, 5:0.17, 2:0.17
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 10:0.14; 4:0.14; 8:0.05; 2:0.05; 7:0.05
  Agent2 top policies: 4:0.45; 3:0.10; 0:0.10; 2:0.09; 5:0.07
. r .
2 b .
. . 1

Reward: +0.00, Result: neutral

--- Step 6 ---
Agent 1: LEFT, Agent 2: RIGHT
  Agent1 beliefs:
    agent_pos: 8:1.00, 5:0.00, 3:0.00
    red_button_pos: 7:0.24, 6:0.24, 1:0.24
    blue_button_pos: 4:0.98, 1:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 3:1.00, 6:0.00, 7:0.00
    red_button_pos: 4:0.20, 5:0.20, 2:0.20
    blue_button_pos: 4:0.20, 5:0.20, 2:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 16:0.27; 14:0.09; 13:0.09; 17:0.07; 12:0.05
  Agent2 top policies: 22:0.28; 4:0.28; 3:0.05; 18:0.05; 0:0.05
. r .
. 2 .
. 1 .

Reward: +0.00, Result: neutral

--- Step 7 ---
Agent 1: LEFT, Agent 2: RIGHT
  Agent1 beliefs:
    agent_pos: 7:1.00, 8:0.00, 5:0.00
    red_button_pos: 6:0.32, 1:0.32, 2:0.32
    blue_button_pos: 4:0.98, 2:0.00, 6:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 4:1.00, 8:0.00, 2:0.00
    red_button_pos: 5:0.24, 2:0.24, 1:0.24
    blue_button_pos: 4:1.00, 0:0.00, 5:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 16:0.33; 14:0.09; 13:0.09; 17:0.07; 0:0.04
  Agent2 top policies: 22:0.18; 4:0.18; 18:0.06; 0:0.06; 3:0.06
. r .
. b 2
1 . .

Reward: +0.00, Result: neutral

--- Step 8 ---
Agent 1: UP, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 6:1.00, 7:0.00, 8:0.00
    red_button_pos: 1:0.47, 2:0.47, 0:0.02
    blue_button_pos: 4:0.97, 2:0.00, 3:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 5:1.00, 3:0.00, 6:0.00
    red_button_pos: 2:0.32, 0:0.32, 1:0.32
    blue_button_pos: 4:0.99, 1:0.00, 0:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 3:0.05; 4:0.05; 18:0.05; 0:0.04; 2:0.04
  Agent2 top policies: 4:0.31; 2:0.09; 0:0.09; 3:0.09; 5:0.07
. r 2
1 b .
. . .

Reward: +0.00, Result: neutral

--- Step 9 ---
Agent 1: RIGHT, Agent 2: LEFT
  Agent1 beliefs:
    agent_pos: 3:1.00, 6:0.00, 7:0.00
    red_button_pos: 1:0.47, 2:0.47, 0:0.02
    blue_button_pos: 4:0.97, 2:0.01, 1:0.01
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 2:1.00, 5:0.00, 3:0.00
    red_button_pos: 1:0.47, 0:0.47, 8:0.03
    blue_button_pos: 4:0.98, 1:0.00, 0:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 18:0.12; 3:0.10; 4:0.05; 23:0.04; 21:0.04
  Agent2 top policies: 16:0.40; 12:0.10; 14:0.10; 17:0.08; 13:0.04
. 2 .
. 1 .
. . .

Reward: +0.00, Result: neutral

--- Step 10 ---
Agent 1: UP, Agent 2: PRESS
  Agent1 beliefs:
    agent_pos: 4:1.00, 8:0.00, 2:0.00
    red_button_pos: 1:0.47, 2:0.47, 0:0.03
    blue_button_pos: 4:1.00, 1:0.00, 0:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 1:1.00, 6:0.00, 0:0.00
    red_button_pos: 1:1.00, 0:0.00, 8:0.00
    blue_button_pos: 4:0.98, 0:0.00, 8:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 4:0.42; 0:0.10; 3:0.10; 5:0.08; 1:0.04
  Agent2 top policies: 25:0.07; 24:0.06; 4:0.06; 26:0.05; 27:0.05
. 2 .
. 1 .
. . .

Reward: +0.00, Result: neutral
Button pressed: red by Agent 2

--- Step 11 ---
Agent 1: UP, Agent 2: DOWN
  Agent1 beliefs:
    agent_pos: 4:1.00, 1:0.00, 8:0.00
    red_button_pos: 1:0.47, 2:0.47, 0:0.03
    blue_button_pos: 4:1.00, 8:0.00, 7:0.00
    red_button_state: 0:0.50, 1:0.50
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 0:0.00, 8:0.00
    blue_button_pos: 4:0.97, 0:0.00, 8:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 0:0.12; 3:0.12; 4:0.11; 5:0.10; 24:0.08
  Agent2 top policies: 10:0.40; 25:0.03; 1:0.03; 6:0.03; 11:0.02
. 2 .
. 1 .
. . .

Reward: +0.00, Result: neutral

--- Step 12 ---
Agent 1: PRESS, Agent 2: DOWN
  Agent1 beliefs:
    agent_pos: 4:1.00, 1:0.00, 2:0.00
    red_button_pos: 1:0.47, 2:0.47, 0:0.03
    blue_button_pos: 4:1.00, 8:0.00, 7:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 1:1.00, 4:0.00, 8:0.00
    red_button_pos: 1:1.00, 8:0.00, 7:0.00
    blue_button_pos: 4:0.96, 0:0.01, 8:0.01
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 24:0.36; 27:0.12; 25:0.11; 26:0.11; 28:0.10
  Agent2 top policies: 10:0.41; 25:0.02; 1:0.02; 6:0.02; 11:0.02
. 2 .
. 1 .
. . .

Reward: +1.00, Result: win
Button pressed: blue by Agent 1

Result: ✅ WIN - win (steps: 12, reward: +1.00)

================================================================================
EPISODE 100
================================================================================
Environment: Red at (1, 0), Blue at (1, 1)

Initial state:
1 r .
. b .
. . 2


--- Step 1 ---
Agent 1: DOWN, Agent 2: LEFT
  Agent1 beliefs:
    agent_pos: 0:1.00, 8:0.00, 7:0.00
    red_button_pos: 8:0.12, 7:0.12, 6:0.12
    blue_button_pos: 8:0.12, 7:0.12, 6:0.12
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 8:1.00, 7:0.00, 6:0.00
    red_button_pos: 7:0.12, 3:0.12, 6:0.12
    blue_button_pos: 7:0.12, 3:0.12, 6:0.12
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 10:0.21; 22:0.21; 9:0.06; 19:0.06; 21:0.05
  Agent2 top policies: 16:0.21; 4:0.21; 12:0.06; 2:0.06; 0:0.05
. r .
1 b .
. 2 .

Reward: +0.00, Result: neutral

--- Step 2 ---
Agent 1: RIGHT, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 3:1.00, 0:0.00, 8:0.00
    red_button_pos: 8:0.14, 7:0.14, 6:0.14
    blue_button_pos: 8:0.14, 7:0.14, 6:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 7:1.00, 8:0.00, 6:0.00
    red_button_pos: 6:0.14, 1:0.14, 5:0.14
    blue_button_pos: 6:0.14, 1:0.14, 5:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 22:0.23; 10:0.23; 9:0.06; 21:0.05; 19:0.05
  Agent2 top policies: 4:0.23; 16:0.23; 12:0.06; 0:0.05; 2:0.05
. r .
. 1 .
. 2 .

Reward: +0.00, Result: neutral

--- Step 3 ---
Agent 1: DOWN, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 4:1.00, 8:0.00, 5:0.00
    red_button_pos: 8:0.17, 7:0.17, 6:0.17
    blue_button_pos: 4:1.00, 8:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 7:0.87, 4:0.12, 8:0.00
    red_button_pos: 6:0.14, 1:0.14, 5:0.14
    blue_button_pos: 6:0.14, 1:0.14, 5:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 10:0.11; 22:0.11; 4:0.11; 3:0.04; 21:0.04
  Agent2 top policies: 4:0.24; 16:0.23; 12:0.06; 2:0.05; 14:0.05
. r .
. 1 .
. 2 .

Reward: +0.00, Result: neutral

--- Step 4 ---
Agent 1: RIGHT, Agent 2: LEFT
  Agent1 beliefs:
    agent_pos: 4:1.00, 7:0.00, 8:0.00
    red_button_pos: 8:0.17, 7:0.17, 6:0.17
    blue_button_pos: 4:1.00, 8:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 7:0.87, 4:0.11, 1:0.02
    red_button_pos: 6:0.14, 1:0.14, 5:0.14
    blue_button_pos: 6:0.14, 1:0.14, 5:0.14
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 22:0.11; 4:0.11; 10:0.11; 21:0.04; 3:0.04
  Agent2 top policies: 16:0.24; 4:0.22; 12:0.06; 14:0.06; 2:0.05
. r .
. b 1
2 . .

Reward: +0.00, Result: neutral

--- Step 5 ---
Agent 1: DOWN, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 5:1.00, 3:0.00, 0:0.00
    red_button_pos: 8:0.20, 7:0.20, 6:0.20
    blue_button_pos: 4:0.99, 8:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 6:1.00, 3:0.00, 0:0.00
    red_button_pos: 4:0.17, 5:0.17, 2:0.17
    blue_button_pos: 4:0.17, 5:0.17, 2:0.17
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 10:0.14; 4:0.14; 8:0.05; 2:0.05; 7:0.05
  Agent2 top policies: 4:0.45; 3:0.10; 0:0.10; 2:0.09; 5:0.07
. r .
2 b .
. . 1

Reward: +0.00, Result: neutral

--- Step 6 ---
Agent 1: LEFT, Agent 2: RIGHT
  Agent1 beliefs:
    agent_pos: 8:1.00, 5:0.00, 3:0.00
    red_button_pos: 7:0.24, 6:0.24, 1:0.24
    blue_button_pos: 4:0.98, 1:0.00, 7:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 3:1.00, 6:0.00, 7:0.00
    red_button_pos: 4:0.20, 5:0.20, 2:0.20
    blue_button_pos: 4:0.20, 5:0.20, 2:0.20
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 16:0.27; 14:0.09; 13:0.09; 17:0.07; 12:0.05
  Agent2 top policies: 22:0.28; 4:0.28; 3:0.05; 18:0.05; 0:0.05
. r .
. 2 .
. 1 .

Reward: +0.00, Result: neutral

--- Step 7 ---
Agent 1: LEFT, Agent 2: RIGHT
  Agent1 beliefs:
    agent_pos: 7:1.00, 8:0.00, 5:0.00
    red_button_pos: 6:0.32, 1:0.32, 2:0.32
    blue_button_pos: 4:0.98, 2:0.00, 6:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 4:1.00, 8:0.00, 2:0.00
    red_button_pos: 5:0.24, 2:0.24, 1:0.24
    blue_button_pos: 4:1.00, 0:0.00, 5:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 16:0.33; 14:0.09; 13:0.09; 17:0.07; 0:0.04
  Agent2 top policies: 22:0.18; 4:0.18; 18:0.06; 0:0.06; 3:0.06
. r .
. b 2
1 . .

Reward: +0.00, Result: neutral

--- Step 8 ---
Agent 1: UP, Agent 2: UP
  Agent1 beliefs:
    agent_pos: 6:1.00, 7:0.00, 8:0.00
    red_button_pos: 1:0.47, 2:0.47, 0:0.02
    blue_button_pos: 4:0.97, 2:0.00, 3:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 5:1.00, 3:0.00, 6:0.00
    red_button_pos: 2:0.32, 0:0.32, 1:0.32
    blue_button_pos: 4:0.99, 1:0.00, 0:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 3:0.05; 4:0.05; 18:0.05; 0:0.04; 2:0.04
  Agent2 top policies: 4:0.31; 2:0.09; 0:0.09; 3:0.09; 5:0.07
. r 2
1 b .
. . .

Reward: +0.00, Result: neutral

--- Step 9 ---
Agent 1: RIGHT, Agent 2: LEFT
  Agent1 beliefs:
    agent_pos: 3:1.00, 6:0.00, 7:0.00
    red_button_pos: 1:0.47, 2:0.47, 0:0.02
    blue_button_pos: 4:0.97, 2:0.01, 1:0.01
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 2:1.00, 5:0.00, 3:0.00
    red_button_pos: 1:0.47, 0:0.47, 8:0.03
    blue_button_pos: 4:0.98, 1:0.00, 0:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 18:0.12; 3:0.10; 4:0.05; 23:0.04; 21:0.04
  Agent2 top policies: 16:0.40; 12:0.10; 14:0.10; 17:0.08; 13:0.04
. 2 .
. 1 .
. . .

Reward: +0.00, Result: neutral

--- Step 10 ---
Agent 1: UP, Agent 2: PRESS
  Agent1 beliefs:
    agent_pos: 4:1.00, 8:0.00, 2:0.00
    red_button_pos: 1:0.47, 2:0.47, 0:0.03
    blue_button_pos: 4:1.00, 1:0.00, 0:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 1:1.00, 6:0.00, 0:0.00
    red_button_pos: 1:1.00, 0:0.00, 8:0.00
    blue_button_pos: 4:0.98, 0:0.00, 8:0.00
    red_button_state: 0:1.00, 1:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 4:0.42; 0:0.10; 3:0.10; 5:0.08; 1:0.04
  Agent2 top policies: 25:0.07; 24:0.06; 4:0.06; 26:0.05; 27:0.05
. 2 .
. 1 .
. . .

Reward: +0.00, Result: neutral
Button pressed: red by Agent 2

--- Step 11 ---
Agent 1: UP, Agent 2: DOWN
  Agent1 beliefs:
    agent_pos: 4:1.00, 1:0.00, 8:0.00
    red_button_pos: 1:0.47, 2:0.47, 0:0.03
    blue_button_pos: 4:1.00, 8:0.00, 7:0.00
    red_button_state: 0:0.50, 1:0.50
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 1:1.00, 8:0.00, 7:0.00
    red_button_pos: 1:1.00, 0:0.00, 8:0.00
    blue_button_pos: 4:0.97, 0:0.00, 8:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 0:0.12; 3:0.12; 4:0.11; 5:0.10; 24:0.08
  Agent2 top policies: 10:0.40; 25:0.03; 1:0.03; 6:0.03; 11:0.02
. 2 .
. 1 .
. . .

Reward: +0.00, Result: neutral

--- Step 12 ---
Agent 1: PRESS, Agent 2: DOWN
  Agent1 beliefs:
    agent_pos: 4:1.00, 1:0.00, 2:0.00
    red_button_pos: 1:0.47, 2:0.47, 0:0.03
    blue_button_pos: 4:1.00, 8:0.00, 7:0.00
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent2 beliefs:
    agent_pos: 1:1.00, 4:0.00, 8:0.00
    red_button_pos: 1:1.00, 8:0.00, 7:0.00
    blue_button_pos: 4:0.96, 0:0.01, 8:0.01
    red_button_state: 1:1.00, 0:0.00
    blue_button_state: 0:1.00, 1:0.00
  Agent1 top policies: 24:0.36; 27:0.12; 25:0.11; 26:0.11; 28:0.10
  Agent2 top policies: 10:0.41; 25:0.02; 1:0.02; 6:0.02; 11:0.02
. 2 .
. 1 .
. . .

Reward: +1.00, Result: win
Button pressed: blue by Agent 1

Result: ✅ WIN - win (steps: 12, reward: +1.00)
  Seed 0, Episode 100/100: Last 100 win rate: 100.0% (100/100)

Seed 0 Summary:
  Success rate: 100/100 (100.0%)
  Average reward: +1.00
  Average steps: 9.8
  Learning: First half 50/50, Second half 50/50

✓ Log saved to: /localscratch/toulabin.15760715.0/project/Fn_ActiveInference/logs/two_aif_agents_seeds1_ep100_20251216_034907.csv

================================================================================
OVERALL RESULTS SUMMARY
================================================================================

Total episodes: 100
Total successes: 100 (100.0%)
Overall average reward: +1.00
Overall average steps: 9.8

Seed   Success Rate       Avg Reward   1st Half   2nd Half  
-----------------------------------------------------------------
0       100/100  (100.0%)    +1.00      50/50       50/50   

Learning Progress:
  First half: 50/50 (100.0%)
  Second half: 50/50 (100.0%)

(plots disabled; pass --plots to generate figures)

================================================================================
EXPERIMENT COMPLETE
================================================================================
Copying logs...
Copy done
---- Independent paradigm seed index 1 complete ----
